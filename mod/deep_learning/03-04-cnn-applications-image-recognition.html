<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CNN Applications in Image Recognition</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/03-04-cnn-applications-image-recognition" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/deep_learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/deep_learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='03-03-popular-cnn-architectures' title="Popular CNN Architectures">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">CNN Applications in Image Recognition</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='04-01-introduction-rnn' title="Introduction to RNN">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Convolutional Neural Networks (CNNs) have revolutionized the field of image recognition. Their ability to automatically and adaptively learn spatial hierarchies of features from input images has made them the go-to architecture for various image-related tasks. In this section, we will delve into the applications of CNNs in image recognition, exploring their practical uses, providing examples, and offering exercises to solidify your understanding.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ol>
<li><strong>Image Classification</strong>: Assigning a label to an entire image.</li>
<li><strong>Object Detection</strong>: Identifying and locating objects within an image.</li>
<li><strong>Image Segmentation</strong>: Partitioning an image into segments to simplify or change its representation.</li>
<li><strong>Face Recognition</strong>: Identifying or verifying a person from a digital image or video frame.</li>
<li><strong>Style Transfer</strong>: Applying the style of one image to the content of another.</li>
</ol>
</div><h1>Image Classification</h1>
<div class='content'></div><h2>Explanation</h2>
<div class='content'><p>Image classification involves categorizing an image into one of several predefined classes. CNNs are particularly effective for this task due to their ability to capture spatial hierarchies in images.</p>
</div><h2>Example</h2>
<div class='content'><p>Consider a dataset of images containing different types of animals (cats, dogs, birds, etc.). A CNN can be trained to classify each image into the correct animal category.</p>
</div><h2>Code Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBkYXRhc2V0cywgbGF5ZXJzLCBtb2RlbHMKCiMgTG9hZCBhbmQgcHJlcHJvY2VzcyB0aGUgZGF0YXNldAoodHJhaW5faW1hZ2VzLCB0cmFpbl9sYWJlbHMpLCAodGVzdF9pbWFnZXMsIHRlc3RfbGFiZWxzKSA9IGRhdGFzZXRzLmNpZmFyMTAubG9hZF9kYXRhKCkKdHJhaW5faW1hZ2VzLCB0ZXN0X2ltYWdlcyA9IHRyYWluX2ltYWdlcyAvIDI1NS4wLCB0ZXN0X2ltYWdlcyAvIDI1NS4wCgojIERlZmluZSB0aGUgQ05OIG1vZGVsCm1vZGVsID0gbW9kZWxzLlNlcXVlbnRpYWwoWwogICAgbGF5ZXJzLkNvbnYyRCgzMiwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KDMyLCAzMiwgMykpLAogICAgbGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpLAogICAgbGF5ZXJzLkNvbnYyRCg2NCwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBsYXllcnMuTWF4UG9vbGluZzJEKCgyLCAyKSksCiAgICBsYXllcnMuQ29udjJEKDY0LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIGxheWVycy5GbGF0dGVuKCksCiAgICBsYXllcnMuRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIGxheWVycy5EZW5zZSgxMCkKXSkKCiMgQ29tcGlsZSBhbmQgdHJhaW4gdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz10Zi5rZXJhcy5sb3NzZXMuU3BhcnNlQ2F0ZWdvcmljYWxDcm9zc2VudHJvcHkoZnJvbV9sb2dpdHM9VHJ1ZSksIG1ldHJpY3M9WydhY2N1cmFjeSddKQptb2RlbC5maXQodHJhaW5faW1hZ2VzLCB0cmFpbl9sYWJlbHMsIGVwb2Nocz0xMCwgdmFsaWRhdGlvbl9kYXRhPSh0ZXN0X2ltYWdlcywgdGVzdF9sYWJlbHMpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# Load and preprocess the dataset
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Define the CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10)
])

# Compile and train the model
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))</pre></div><div class='content'></div><h2>Exercise</h2>
<div class='content'><p><strong>Task</strong>: Modify the above code to classify images from the MNIST dataset (handwritten digits).</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBkYXRhc2V0cywgbGF5ZXJzLCBtb2RlbHMKCiMgTG9hZCBhbmQgcHJlcHJvY2VzcyB0aGUgZGF0YXNldAoodHJhaW5faW1hZ2VzLCB0cmFpbl9sYWJlbHMpLCAodGVzdF9pbWFnZXMsIHRlc3RfbGFiZWxzKSA9IGRhdGFzZXRzLm1uaXN0LmxvYWRfZGF0YSgpCnRyYWluX2ltYWdlcyA9IHRyYWluX2ltYWdlcy5yZXNoYXBlKCg2MDAwMCwgMjgsIDI4LCAxKSkuYXN0eXBlKCdmbG9hdDMyJykgLyAyNTUKdGVzdF9pbWFnZXMgPSB0ZXN0X2ltYWdlcy5yZXNoYXBlKCgxMDAwMCwgMjgsIDI4LCAxKSkuYXN0eXBlKCdmbG9hdDMyJykgLyAyNTUKCiMgRGVmaW5lIHRoZSBDTk4gbW9kZWwKbW9kZWwgPSBtb2RlbHMuU2VxdWVudGlhbChbCiAgICBsYXllcnMuQ29udjJEKDMyLCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBpbnB1dF9zaGFwZT0oMjgsIDI4LCAxKSksCiAgICBsYXllcnMuTWF4UG9vbGluZzJEKCgyLCAyKSksCiAgICBsYXllcnMuQ29udjJEKDY0LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIGxheWVycy5NYXhQb29saW5nMkQoKDIsIDIpKSwKICAgIGxheWVycy5Db252MkQoNjQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgbGF5ZXJzLkZsYXR0ZW4oKSwKICAgIGxheWVycy5EZW5zZSg2NCwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgbGF5ZXJzLkRlbnNlKDEwKQpdKQoKIyBDb21waWxlIGFuZCB0cmFpbiB0aGUgbW9kZWwKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPXRmLmtlcmFzLmxvc3Nlcy5TcGFyc2VDYXRlZ29yaWNhbENyb3NzZW50cm9weShmcm9tX2xvZ2l0cz1UcnVlKSwgbWV0cmljcz1bJ2FjY3VyYWN5J10pCm1vZGVsLmZpdCh0cmFpbl9pbWFnZXMsIHRyYWluX2xhYmVscywgZXBvY2hzPTUsIHZhbGlkYXRpb25fZGF0YT0odGVzdF9pbWFnZXMsIHRlc3RfbGFiZWxzKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# Load and preprocess the dataset
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# Define the CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10)
])

# Compile and train the model
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))</pre></div><div class='content'></div><h1>Object Detection</h1>
<div class='content'></div><h2>Explanation</h2>
<div class='content'><p>Object detection involves not only classifying objects within an image but also locating them with bounding boxes. This is more complex than image classification as it requires the network to predict multiple objects and their locations.</p>
</div><h2>Example</h2>
<div class='content'><p>Detecting cars, pedestrians, and traffic signs in a street scene.</p>
</div><h2>Code Example</h2>
<div class='content'><p>For object detection, frameworks like YOLO (You Only Look Once) or SSD (Single Shot MultiBox Detector) are commonly used. Here is a simplified example using a pre-trained model from TensorFlow's Object Detection API.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKaW1wb3J0IGN2MgppbXBvcnQgbnVtcHkgYXMgbnAKCiMgTG9hZCBhIHByZS10cmFpbmVkIG1vZGVsCm1vZGVsID0gdGYuc2F2ZWRfbW9kZWwubG9hZCgic3NkX21vYmlsZW5ldF92Ml9mcG5saXRlXzMyMHgzMjAvc2F2ZWRfbW9kZWwiKQoKIyBMb2FkIGFuZCBwcmVwcm9jZXNzIGFuIGltYWdlCmltYWdlID0gY3YyLmltcmVhZCgnc3RyZWV0X3NjZW5lLmpwZycpCmlucHV0X3RlbnNvciA9IHRmLmNvbnZlcnRfdG9fdGVuc29yKGltYWdlKQppbnB1dF90ZW5zb3IgPSBpbnB1dF90ZW5zb3JbdGYubmV3YXhpcywgLi4uXQoKIyBQZXJmb3JtIG9iamVjdCBkZXRlY3Rpb24KZGV0ZWN0aW9ucyA9IG1vZGVsKGlucHV0X3RlbnNvcikKCiMgVmlzdWFsaXplIHRoZSByZXN1bHRzCmZvciBpIGluIHJhbmdlKGludChkZXRlY3Rpb25zLnBvcCgnbnVtX2RldGVjdGlvbnMnKSkpOgogICAgc2NvcmUgPSBkZXRlY3Rpb25zWydkZXRlY3Rpb25fc2NvcmVzJ11bMF1baV0ubnVtcHkoKQogICAgaWYgc2NvcmUgPiAwLjU6CiAgICAgICAgYmJveCA9IGRldGVjdGlvbnNbJ2RldGVjdGlvbl9ib3hlcyddWzBdW2ldLm51bXB5KCkKICAgICAgICBjbGFzc19pZCA9IGludChkZXRlY3Rpb25zWydkZXRlY3Rpb25fY2xhc3NlcyddWzBdW2ldLm51bXB5KCkpCiAgICAgICAgIyBEcmF3IGJvdW5kaW5nIGJveCBhbmQgbGFiZWwgb24gdGhlIGltYWdlCiAgICAgICAgIyAoSW1wbGVtZW50YXRpb24gb2YgZHJhd2luZyBmdW5jdGlvbiBpcyBvbWl0dGVkIGZvciBicmV2aXR5KQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
import cv2
import numpy as np

# Load a pre-trained model
model = tf.saved_model.load(&quot;ssd_mobilenet_v2_fpnlite_320x320/saved_model&quot;)

# Load and preprocess an image
image = cv2.imread('street_scene.jpg')
input_tensor = tf.convert_to_tensor(image)
input_tensor = input_tensor[tf.newaxis, ...]

# Perform object detection
detections = model(input_tensor)

# Visualize the results
for i in range(int(detections.pop('num_detections'))):
    score = detections['detection_scores'][0][i].numpy()
    if score &gt; 0.5:
        bbox = detections['detection_boxes'][0][i].numpy()
        class_id = int(detections['detection_classes'][0][i].numpy())
        # Draw bounding box and label on the image
        # (Implementation of drawing function is omitted for brevity)</pre></div><div class='content'></div><h2>Exercise</h2>
<div class='content'><p><strong>Task</strong>: Use a different pre-trained model from TensorFlow's Object Detection API and apply it to a new image.</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Download a different model from the TensorFlow Model Zoo.</li>
<li>Load the new model using <code>tf.saved_model.load()</code>.</li>
<li>Apply the model to a new image and visualize the results.</li>
</ol>
</div><h1>Image Segmentation</h1>
<div class='content'></div><h2>Explanation</h2>
<div class='content'><p>Image segmentation involves partitioning an image into multiple segments (sets of pixels) to simplify its representation. This is useful for tasks where precise localization of objects is required.</p>
</div><h2>Example</h2>
<div class='content'><p>Segmenting different organs in a medical image.</p>
</div><h2>Code Example</h2>
<div class='content'><p>Using a pre-trained model for semantic segmentation (e.g., DeepLab).</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKaW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBjdjIKCiMgTG9hZCBhIHByZS10cmFpbmVkIG1vZGVsCm1vZGVsID0gdGYuc2F2ZWRfbW9kZWwubG9hZCgiZGVlcGxhYnYzX21udjJfcGFzY2FsX3RyYWluX2F1Zy9zYXZlZF9tb2RlbCIpCgojIExvYWQgYW5kIHByZXByb2Nlc3MgYW4gaW1hZ2UKaW1hZ2UgPSBjdjIuaW1yZWFkKCdtZWRpY2FsX2ltYWdlLmpwZycpCmlucHV0X3RlbnNvciA9IHRmLmNvbnZlcnRfdG9fdGVuc29yKGltYWdlKQppbnB1dF90ZW5zb3IgPSBpbnB1dF90ZW5zb3JbdGYubmV3YXhpcywgLi4uXQoKIyBQZXJmb3JtIHNlZ21lbnRhdGlvbgpvdXRwdXQgPSBtb2RlbChpbnB1dF90ZW5zb3IpWydzZW1hbnRpYyddCgojIFZpc3VhbGl6ZSB0aGUgcmVzdWx0cwpzZWdtZW50YXRpb25fbWFwID0gdGYuYXJnbWF4KG91dHB1dCwgYXhpcz0tMSkKc2VnbWVudGF0aW9uX21hcCA9IHNlZ21lbnRhdGlvbl9tYXBbMF0ubnVtcHkoKQojIChJbXBsZW1lbnRhdGlvbiBvZiB2aXN1YWxpemF0aW9uIGZ1bmN0aW9uIGlzIG9taXR0ZWQgZm9yIGJyZXZpdHkp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
import numpy as np
import cv2

# Load a pre-trained model
model = tf.saved_model.load(&quot;deeplabv3_mnv2_pascal_train_aug/saved_model&quot;)

# Load and preprocess an image
image = cv2.imread('medical_image.jpg')
input_tensor = tf.convert_to_tensor(image)
input_tensor = input_tensor[tf.newaxis, ...]

# Perform segmentation
output = model(input_tensor)['semantic']

# Visualize the results
segmentation_map = tf.argmax(output, axis=-1)
segmentation_map = segmentation_map[0].numpy()
# (Implementation of visualization function is omitted for brevity)</pre></div><div class='content'></div><h2>Exercise</h2>
<div class='content'><p><strong>Task</strong>: Apply the segmentation model to a different dataset (e.g., Cityscapes for urban scene segmentation).</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Download the Cityscapes dataset.</li>
<li>Preprocess the images to match the input requirements of the model.</li>
<li>Apply the model and visualize the segmentation maps.</li>
</ol>
</div><h1>Face Recognition</h1>
<div class='content'></div><h2>Explanation</h2>
<div class='content'><p>Face recognition involves identifying or verifying a person from a digital image or video frame. This is widely used in security systems and personal device authentication.</p>
</div><h2>Example</h2>
<div class='content'><p>Unlocking a smartphone using facial recognition.</p>
</div><h2>Code Example</h2>
<div class='content'><p>Using a pre-trained face recognition model (e.g., FaceNet).</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKaW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBjdjIKCiMgTG9hZCBhIHByZS10cmFpbmVkIG1vZGVsCm1vZGVsID0gdGYuc2F2ZWRfbW9kZWwubG9hZCgiZmFjZW5ldC9zYXZlZF9tb2RlbCIpCgojIExvYWQgYW5kIHByZXByb2Nlc3MgYW4gaW1hZ2UKaW1hZ2UgPSBjdjIuaW1yZWFkKCdmYWNlX2ltYWdlLmpwZycpCmlucHV0X3RlbnNvciA9IHRmLmNvbnZlcnRfdG9fdGVuc29yKGltYWdlKQppbnB1dF90ZW5zb3IgPSBpbnB1dF90ZW5zb3JbdGYubmV3YXhpcywgLi4uXQoKIyBQZXJmb3JtIGZhY2UgcmVjb2duaXRpb24KZW1iZWRkaW5ncyA9IG1vZGVsKGlucHV0X3RlbnNvcikKCiMgQ29tcGFyZSBlbWJlZGRpbmdzIHdpdGgga25vd24gZmFjZXMKIyAoSW1wbGVtZW50YXRpb24gb2YgY29tcGFyaXNvbiBmdW5jdGlvbiBpcyBvbWl0dGVkIGZvciBicmV2aXR5KQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
import numpy as np
import cv2

# Load a pre-trained model
model = tf.saved_model.load(&quot;facenet/saved_model&quot;)

# Load and preprocess an image
image = cv2.imread('face_image.jpg')
input_tensor = tf.convert_to_tensor(image)
input_tensor = input_tensor[tf.newaxis, ...]

# Perform face recognition
embeddings = model(input_tensor)

# Compare embeddings with known faces
# (Implementation of comparison function is omitted for brevity)</pre></div><div class='content'></div><h2>Exercise</h2>
<div class='content'><p><strong>Task</strong>: Implement a simple face verification system using the FaceNet model.</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Load images of known faces and compute their embeddings.</li>
<li>For a new image, compute its embedding and compare it with the known embeddings using a distance metric (e.g., Euclidean distance).</li>
<li>If the distance is below a certain threshold, consider it a match.</li>
</ol>
</div><h1>Style Transfer</h1>
<div class='content'></div><h2>Explanation</h2>
<div class='content'><p>Style transfer involves applying the style of one image to the content of another. This is achieved by separating and recombining the content and style of images.</p>
</div><h2>Example</h2>
<div class='content'><p>Applying the style of a famous painting to a photograph.</p>
</div><h2>Code Example</h2>
<div class='content'><p>Using a pre-trained style transfer model.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKaW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBjdjIKCiMgTG9hZCBhIHByZS10cmFpbmVkIG1vZGVsCm1vZGVsID0gdGYuc2F2ZWRfbW9kZWwubG9hZCgibWFnZW50YV9hcmJpdHJhcnktaW1hZ2Utc3R5bGl6YXRpb24tdjEtMjU2L3NhdmVkX21vZGVsIikKCiMgTG9hZCBhbmQgcHJlcHJvY2VzcyBjb250ZW50IGFuZCBzdHlsZSBpbWFnZXMKY29udGVudF9pbWFnZSA9IGN2Mi5pbXJlYWQoJ2NvbnRlbnQuanBnJykKc3R5bGVfaW1hZ2UgPSBjdjIuaW1yZWFkKCdzdHlsZS5qcGcnKQpjb250ZW50X3RlbnNvciA9IHRmLmNvbnZlcnRfdG9fdGVuc29yKGNvbnRlbnRfaW1hZ2UpCnN0eWxlX3RlbnNvciA9IHRmLmNvbnZlcnRfdG9fdGVuc29yKHN0eWxlX2ltYWdlKQpjb250ZW50X3RlbnNvciA9IGNvbnRlbnRfdGVuc29yW3RmLm5ld2F4aXMsIC4uLl0Kc3R5bGVfdGVuc29yID0gc3R5bGVfdGVuc29yW3RmLm5ld2F4aXMsIC4uLl0KCiMgUGVyZm9ybSBzdHlsZSB0cmFuc2ZlcgpvdXRwdXRzID0gbW9kZWwodGYuY29uc3RhbnQoY29udGVudF90ZW5zb3IpLCB0Zi5jb25zdGFudChzdHlsZV90ZW5zb3IpKQpzdHlsaXplZF9pbWFnZSA9IG91dHB1dHNbMF0ubnVtcHkoKQoKIyBWaXN1YWxpemUgdGhlIHJlc3VsdApjdjIuaW1zaG93KCdTdHlsaXplZCBJbWFnZScsIHN0eWxpemVkX2ltYWdlKQpjdjIud2FpdEtleSgwKQpjdjIuZGVzdHJveUFsbFdpbmRvd3MoKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
import numpy as np
import cv2

# Load a pre-trained model
model = tf.saved_model.load(&quot;magenta_arbitrary-image-stylization-v1-256/saved_model&quot;)

# Load and preprocess content and style images
content_image = cv2.imread('content.jpg')
style_image = cv2.imread('style.jpg')
content_tensor = tf.convert_to_tensor(content_image)
style_tensor = tf.convert_to_tensor(style_image)
content_tensor = content_tensor[tf.newaxis, ...]
style_tensor = style_tensor[tf.newaxis, ...]

# Perform style transfer
outputs = model(tf.constant(content_tensor), tf.constant(style_tensor))
stylized_image = outputs[0].numpy()

# Visualize the result
cv2.imshow('Stylized Image', stylized_image)
cv2.waitKey(0)
cv2.destroyAllWindows()</pre></div><div class='content'></div><h2>Exercise</h2>
<div class='content'><p><strong>Task</strong>: Apply style transfer to a different pair of content and style images.</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Choose a new content image and a new style image.</li>
<li>Preprocess the images and apply the style transfer model.</li>
<li>Visualize the resulting stylized image.</li>
</ol>
</div><h1>Conclusion</h1>
<div class='content'><p>CNNs have a wide range of applications in image recognition, from simple classification tasks to complex object detection and segmentation. By understanding and implementing these applications, you can leverage the power of CNNs to solve various real-world problems. In the next module, we will explore Recurrent Neural Networks (RNNs) and their applications in sequence and time series data.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='03-03-popular-cnn-architectures' title="Popular CNN Architectures">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='04-01-introduction-rnn' title="Introduction to RNN">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
