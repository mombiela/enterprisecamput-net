<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Autoencoders</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/05-02-autoencoders" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/05-02-autoencoders" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/05-02-autoencoders" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=3" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/05-02-autoencoders" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/deep_learning/05-02-autoencoders" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>Building today's and tomorrow's society</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Languages</a>
				 					<a href="/categ/frameworks">Frameworks</a>
				 					<a href="/categ/tech-tools">Tools</a>
				 					<a href="/categ/foundations">Foundations</a>
				 					<a href="/categ/soft-skills">Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-generative-adversarial-networks' title="Generative Adversarial Networks (GAN)">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Autoencoders</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Autoencoders are a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). They are primarily used for dimensionality reduction, feature learning, and anomaly detection. In this section, we will cover the following topics:</p>
<ol>
<li><strong>What are Autoencoders?</strong></li>
<li><strong>Architecture of Autoencoders</strong></li>
<li><strong>Types of Autoencoders</strong></li>
<li><strong>Applications of Autoencoders</strong></li>
<li><strong>Practical Example: Implementing an Autoencoder in Python</strong></li>
<li><strong>Exercises</strong></li>
</ol>
</div><h1><p>What are Autoencoders?</p>
</h1>
<div class='content'><p>Autoencoders are neural networks designed to learn a compressed representation (encoding) of input data. They consist of two main parts:</p>
<ul>
<li><strong>Encoder:</strong> Compresses the input into a latent-space representation.</li>
<li><strong>Decoder:</strong> Reconstructs the input from the latent space representation.</li>
</ul>
<p>The goal of an autoencoder is to minimize the difference between the input and the reconstructed output.</p>
</div><h1><p>Architecture of Autoencoders</p>
</h1>
<div class='content'><p>The basic architecture of an autoencoder consists of three main components:</p>
<ol>
<li><strong>Input Layer:</strong> The original data to be compressed.</li>
<li><strong>Hidden Layers (Encoder and Decoder):</strong> The encoder compresses the input data into a lower-dimensional representation, and the decoder reconstructs the data from this representation.</li>
<li><strong>Output Layer:</strong> The reconstructed data, which should be as close as possible to the input data.</li>
</ol>
</div><h2><p>Diagram of a Basic Autoencoder</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("SW5wdXQgLT4gW0VuY29kZXJdIC0+IExhdGVudCBTcGFjZSAtPiBbRGVjb2Rlcl0gLT4gT3V0cHV0"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Input -&gt; [Encoder] -&gt; Latent Space -&gt; [Decoder] -&gt; Output</pre></div><div class='content'></div><h2><p>Example Code: Basic Autoencoder in Keras</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmZyb20ga2VyYXMubGF5ZXJzIGltcG9ydCBJbnB1dCwgRGVuc2UKZnJvbSBrZXJhcy5tb2RlbHMgaW1wb3J0IE1vZGVsCgojIERlZmluZSB0aGUgc2l6ZSBvZiB0aGUgaW5wdXQgYW5kIHRoZSBlbmNvZGluZyBkaW1lbnNpb24KaW5wdXRfZGltID0gNzg0ICAjIEV4YW1wbGUgZm9yIE1OSVNUIGRhdGFzZXQgKDI4eDI4IGltYWdlcykKZW5jb2RpbmdfZGltID0gMzIgICMgQ29tcHJlc3Npb24gdG8gMzIgZmVhdHVyZXMKCiMgSW5wdXQgcGxhY2Vob2xkZXIKaW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KGlucHV0X2RpbSwpKQoKIyBFbmNvZGVyIGxheWVycwplbmNvZGVkID0gRGVuc2UoZW5jb2RpbmdfZGltLCBhY3RpdmF0aW9uPSdyZWx1JykoaW5wdXRfaW1nKQoKIyBEZWNvZGVyIGxheWVycwpkZWNvZGVkID0gRGVuc2UoaW5wdXRfZGltLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykoZW5jb2RlZCkKCiMgQXV0b2VuY29kZXIgbW9kZWwKYXV0b2VuY29kZXIgPSBNb2RlbChpbnB1dF9pbWcsIGRlY29kZWQpCgojIENvbXBpbGUgdGhlIG1vZGVsCmF1dG9lbmNvZGVyLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScpCgojIFN1bW1hcnkgb2YgdGhlIG1vZGVsCmF1dG9lbmNvZGVyLnN1bW1hcnkoKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
from keras.layers import Input, Dense
from keras.models import Model

# Define the size of the input and the encoding dimension
input_dim = 784  # Example for MNIST dataset (28x28 images)
encoding_dim = 32  # Compression to 32 features

# Input placeholder
input_img = Input(shape=(input_dim,))

# Encoder layers
encoded = Dense(encoding_dim, activation='relu')(input_img)

# Decoder layers
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Autoencoder model
autoencoder = Model(input_img, decoded)

# Compile the model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Summary of the model
autoencoder.summary()</pre></div><div class='content'></div><h1><p>Types of Autoencoders</p>
</h1>
<div class='content'><p>There are several types of autoencoders, each designed for specific tasks:</p>
<ol>
<li><strong>Vanilla Autoencoder:</strong> The basic form of autoencoder.</li>
<li><strong>Sparse Autoencoder:</strong> Adds a sparsity constraint on the hidden layer to enforce the model to learn useful features.</li>
<li><strong>Denoising Autoencoder:</strong> Trained to remove noise from the input data.</li>
<li><strong>Variational Autoencoder (VAE):</strong> Uses probabilistic methods to learn the latent space representation.</li>
</ol>
</div><h2><p>Table: Comparison of Autoencoder Types</p>
</h2>
<div class='content'><table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla Autoencoder</td>
<td>Basic autoencoder with no constraints</td>
<td>Dimensionality reduction</td>
</tr>
<tr>
<td>Sparse Autoencoder</td>
<td>Adds sparsity constraint to hidden layer</td>
<td>Feature learning</td>
</tr>
<tr>
<td>Denoising Autoencoder</td>
<td>Trained to remove noise from input data</td>
<td>Image denoising</td>
</tr>
<tr>
<td>Variational Autoencoder (VAE)</td>
<td>Uses probabilistic approach for latent space</td>
<td>Generative models</td>
</tr>
</tbody>
</table>
</div><h1><p>Applications of Autoencoders</p>
</h1>
<div class='content'><p>Autoencoders have a wide range of applications, including but not limited to:</p>
<ul>
<li><strong>Dimensionality Reduction:</strong> Reducing the number of features in a dataset while preserving important information.</li>
<li><strong>Anomaly Detection:</strong> Identifying unusual patterns that do not conform to expected behavior.</li>
<li><strong>Image Denoising:</strong> Removing noise from images to improve their quality.</li>
<li><strong>Data Compression:</strong> Compressing data for efficient storage and transmission.</li>
</ul>
</div><h1><p>Practical Example: Implementing an Autoencoder in Python</p>
</h1>
<div class='content'><p>Let's implement a simple autoencoder using the MNIST dataset.</p>
</div><h2><p>Step-by-Step Implementation</p>
</h2>
<div class='content'><ol>
<li><strong>Load the MNIST dataset:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrZXJhcy5kYXRhc2V0cyBpbXBvcnQgbW5pc3QKCiMgTG9hZCB0aGUgZGF0YXNldAooeF90cmFpbiwgXyksICh4X3Rlc3QsIF8pID0gbW5pc3QubG9hZF9kYXRhKCkKCiMgTm9ybWFsaXplIHRoZSBkYXRhCnhfdHJhaW4gPSB4X3RyYWluLmFzdHlwZSgnZmxvYXQzMicpIC8gMjU1Lgp4X3Rlc3QgPSB4X3Rlc3QuYXN0eXBlKCdmbG9hdDMyJykgLyAyNTUuCgojIEZsYXR0ZW4gdGhlIGltYWdlcwp4X3RyYWluID0geF90cmFpbi5yZXNoYXBlKChsZW4oeF90cmFpbiksIG5wLnByb2QoeF90cmFpbi5zaGFwZVsxOl0pKSkKeF90ZXN0ID0geF90ZXN0LnJlc2hhcGUoKGxlbih4X3Rlc3QpLCBucC5wcm9kKHhfdGVzdC5zaGFwZVsxOl0pKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from keras.datasets import mnist

# Load the dataset
(x_train, _), (x_test, _) = mnist.load_data()

# Normalize the data
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# Flatten the images
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))</pre></div><div class='content'><ol start="2">
<li><strong>Define the autoencoder model:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KDc4NCwpKQplbmNvZGVkID0gRGVuc2UoMzIsIGFjdGl2YXRpb249J3JlbHUnKShpbnB1dF9pbWcpCmRlY29kZWQgPSBEZW5zZSg3ODQsIGFjdGl2YXRpb249J3NpZ21vaWQnKShlbmNvZGVkKQoKYXV0b2VuY29kZXIgPSBNb2RlbChpbnB1dF9pbWcsIGRlY29kZWQpCmF1dG9lbmNvZGVyLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>input_img = Input(shape=(784,))
encoded = Dense(32, activation='relu')(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')</pre></div><div class='content'><ol start="3">
<li><strong>Train the autoencoder:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("YXV0b2VuY29kZXIuZml0KHhfdHJhaW4sIHhfdHJhaW4sCiAgICAgICAgICAgICAgICBlcG9jaHM9NTAsCiAgICAgICAgICAgICAgICBiYXRjaF9zaXplPTI1NiwKICAgICAgICAgICAgICAgIHNodWZmbGU9VHJ1ZSwKICAgICAgICAgICAgICAgIHZhbGlkYXRpb25fZGF0YT0oeF90ZXN0LCB4X3Rlc3QpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))</pre></div><div class='content'><ol start="4">
<li><strong>Evaluate the autoencoder:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFbmNvZGUgYW5kIGRlY29kZSBzb21lIGRpZ2l0cwplbmNvZGVkX2ltZ3MgPSBhdXRvZW5jb2Rlci5wcmVkaWN0KHhfdGVzdCkKZGVjb2RlZF9pbWdzID0gYXV0b2VuY29kZXIucHJlZGljdChlbmNvZGVkX2ltZ3MpCgojIERpc3BsYXkgb3JpZ2luYWwgYW5kIHJlY29uc3RydWN0ZWQgaW1hZ2VzCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKCm4gPSAxMCAgIyBOdW1iZXIgb2YgZGlnaXRzIHRvIGRpc3BsYXkKcGx0LmZpZ3VyZShmaWdzaXplPSgyMCwgNCkpCmZvciBpIGluIHJhbmdlKG4pOgogICAgIyBEaXNwbGF5IG9yaWdpbmFsCiAgICBheCA9IHBsdC5zdWJwbG90KDIsIG4sIGkgKyAxKQogICAgcGx0Lmltc2hvdyh4X3Rlc3RbaV0ucmVzaGFwZSgyOCwgMjgpKQogICAgcGx0LmdyYXkoKQogICAgYXguZ2V0X3hheGlzKCkuc2V0X3Zpc2libGUoRmFsc2UpCiAgICBheC5nZXRfeWF4aXMoKS5zZXRfdmlzaWJsZShGYWxzZSkKCiAgICAjIERpc3BsYXkgcmVjb25zdHJ1Y3Rpb24KICAgIGF4ID0gcGx0LnN1YnBsb3QoMiwgbiwgaSArIDEgKyBuKQogICAgcGx0Lmltc2hvdyhkZWNvZGVkX2ltZ3NbaV0ucmVzaGFwZSgyOCwgMjgpKQogICAgcGx0LmdyYXkoKQogICAgYXguZ2V0X3hheGlzKCkuc2V0X3Zpc2libGUoRmFsc2UpCiAgICBheC5nZXRfeWF4aXMoKS5zZXRfdmlzaWJsZShGYWxzZSkKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Encode and decode some digits
encoded_imgs = autoencoder.predict(x_test)
decoded_imgs = autoencoder.predict(encoded_imgs)

# Display original and reconstructed images
import matplotlib.pyplot as plt

n = 10  # Number of digits to display
plt.figure(figsize=(20, 4))
for i in range(n):
    # Display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()</pre></div><div class='content'></div><h1><p>Exercises</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: Implement a Sparse Autoencoder</p>
</h2>
<div class='content'><p>Modify the basic autoencoder to include a sparsity constraint on the hidden layer.</p>
<p><strong>Hint:</strong> Use the <code>activity_regularizer</code> parameter in the <code>Dense</code> layer.</p>
</div><h2><p>Solution:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrZXJhcyBpbXBvcnQgcmVndWxhcml6ZXJzCgojIERlZmluZSB0aGUgc3BhcnNlIGF1dG9lbmNvZGVyCmlucHV0X2ltZyA9IElucHV0KHNoYXBlPSg3ODQsKSkKZW5jb2RlZCA9IERlbnNlKDMyLCBhY3RpdmF0aW9uPSdyZWx1JywgYWN0aXZpdHlfcmVndWxhcml6ZXI9cmVndWxhcml6ZXJzLmwxKDEwZS01KSkoaW5wdXRfaW1nKQpkZWNvZGVkID0gRGVuc2UoNzg0LCBhY3RpdmF0aW9uPSdzaWdtb2lkJykoZW5jb2RlZCkKCnNwYXJzZV9hdXRvZW5jb2RlciA9IE1vZGVsKGlucHV0X2ltZywgZGVjb2RlZCkKc3BhcnNlX2F1dG9lbmNvZGVyLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScpCgojIFRyYWluIHRoZSBzcGFyc2UgYXV0b2VuY29kZXIKc3BhcnNlX2F1dG9lbmNvZGVyLmZpdCh4X3RyYWluLCB4X3RyYWluLAogICAgICAgICAgICAgICAgICAgICAgIGVwb2Nocz01MCwKICAgICAgICAgICAgICAgICAgICAgICBiYXRjaF9zaXplPTI1NiwKICAgICAgICAgICAgICAgICAgICAgICBzaHVmZmxlPVRydWUsCiAgICAgICAgICAgICAgICAgICAgICAgdmFsaWRhdGlvbl9kYXRhPSh4X3Rlc3QsIHhfdGVzdCkp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from keras import regularizers

# Define the sparse autoencoder
input_img = Input(shape=(784,))
encoded = Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

sparse_autoencoder = Model(input_img, decoded)
sparse_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the sparse autoencoder
sparse_autoencoder.fit(x_train, x_train,
                       epochs=50,
                       batch_size=256,
                       shuffle=True,
                       validation_data=(x_test, x_test))</pre></div><div class='content'></div><h2><p>Exercise 2: Implement a Denoising Autoencoder</p>
</h2>
<div class='content'><p>Train an autoencoder to remove noise from the MNIST dataset.</p>
<p><strong>Hint:</strong> Add noise to the input data before training.</p>
</div><h2><p>Solution:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBBZGQgbm9pc2UgdG8gdGhlIGRhdGEKbm9pc2VfZmFjdG9yID0gMC41CnhfdHJhaW5fbm9pc3kgPSB4X3RyYWluICsgbm9pc2VfZmFjdG9yICogbnAucmFuZG9tLm5vcm1hbChsb2M9MC4wLCBzY2FsZT0xLjAsIHNpemU9eF90cmFpbi5zaGFwZSkKeF90ZXN0X25vaXN5ID0geF90ZXN0ICsgbm9pc2VfZmFjdG9yICogbnAucmFuZG9tLm5vcm1hbChsb2M9MC4wLCBzY2FsZT0xLjAsIHNpemU9eF90ZXN0LnNoYXBlKQoKeF90cmFpbl9ub2lzeSA9IG5wLmNsaXAoeF90cmFpbl9ub2lzeSwgMC4sIDEuKQp4X3Rlc3Rfbm9pc3kgPSBucC5jbGlwKHhfdGVzdF9ub2lzeSwgMC4sIDEuKQoKIyBEZWZpbmUgdGhlIGRlbm9pc2luZyBhdXRvZW5jb2RlcgppbnB1dF9pbWcgPSBJbnB1dChzaGFwZT0oNzg0LCkpCmVuY29kZWQgPSBEZW5zZSgzMiwgYWN0aXZhdGlvbj0ncmVsdScpKGlucHV0X2ltZykKZGVjb2RlZCA9IERlbnNlKDc4NCwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpKGVuY29kZWQpCgpkZW5vaXNpbmdfYXV0b2VuY29kZXIgPSBNb2RlbChpbnB1dF9pbWcsIGRlY29kZWQpCmRlbm9pc2luZ19hdXRvZW5jb2Rlci5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknKQoKIyBUcmFpbiB0aGUgZGVub2lzaW5nIGF1dG9lbmNvZGVyCmRlbm9pc2luZ19hdXRvZW5jb2Rlci5maXQoeF90cmFpbl9ub2lzeSwgeF90cmFpbiwKICAgICAgICAgICAgICAgICAgICAgICAgICBlcG9jaHM9NTAsCiAgICAgICAgICAgICAgICAgICAgICAgICAgYmF0Y2hfc2l6ZT0yNTYsCiAgICAgICAgICAgICAgICAgICAgICAgICAgc2h1ZmZsZT1UcnVlLAogICAgICAgICAgICAgICAgICAgICAgICAgIHZhbGlkYXRpb25fZGF0YT0oeF90ZXN0X25vaXN5LCB4X3Rlc3QpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Add noise to the data
noise_factor = 0.5
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)

x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

# Define the denoising autoencoder
input_img = Input(shape=(784,))
encoded = Dense(32, activation='relu')(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

denoising_autoencoder = Model(input_img, decoded)
denoising_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the denoising autoencoder
denoising_autoencoder.fit(x_train_noisy, x_train,
                          epochs=50,
                          batch_size=256,
                          shuffle=True,
                          validation_data=(x_test_noisy, x_test))</pre></div><div class='content'></div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we explored the concept of autoencoders, their architecture, types, and applications. We also implemented a basic autoencoder and explored practical examples to reinforce the concepts. Autoencoders are powerful tools in the deep learning toolkit, especially for tasks like dimensionality reduction, anomaly detection, and data denoising. Understanding and implementing autoencoders can significantly enhance your ability to work with complex datasets and extract meaningful features.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-generative-adversarial-networks' title="Generative Adversarial Networks (GAN)">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
