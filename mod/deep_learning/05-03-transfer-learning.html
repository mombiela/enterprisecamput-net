<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Transfer Learning</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/05-03-transfer-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/05-03-transfer-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/05-03-transfer-learning" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=3" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/05-03-transfer-learning" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/deep_learning/05-03-transfer-learning" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>Building today's and tomorrow's society</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Languages</a>
				 					<a href="/categ/frameworks">Frameworks</a>
				 					<a href="/categ/tech-tools">Tools</a>
				 					<a href="/categ/foundations">Foundations</a>
				 					<a href="/categ/soft-skills">Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-autoencoders' title="Autoencoders">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Transfer Learning</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-04-regularization-improvement-techniques' title="Regularization and Improvement Techniques">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1><p>Introduction to Transfer Learning</p>
</h1>
<div class='content'><p>Transfer Learning is a powerful technique in deep learning where a pre-trained model is used as the starting point for a new, related task. This approach leverages the knowledge gained from a previous task to improve the performance and efficiency of the model on a new task. It is particularly useful when the new task has limited data.</p>
</div><h2><p>Key Concepts</p>
</h2>
<div class='content'><ol>
<li><strong>Pre-trained Models</strong>: Models that have been previously trained on large datasets, such as ImageNet for image classification tasks.</li>
<li><strong>Feature Extraction</strong>: Using the pre-trained model to extract features from the new dataset.</li>
<li><strong>Fine-Tuning</strong>: Adjusting the weights of the pre-trained model to better fit the new task.</li>
</ol>
</div><h2><p>Benefits of Transfer Learning</p>
</h2>
<div class='content'><ul>
<li><strong>Reduced Training Time</strong>: Since the model has already learned useful features, training time is significantly reduced.</li>
<li><strong>Improved Performance</strong>: Pre-trained models often provide better performance, especially when the new dataset is small.</li>
<li><strong>Less Data Requirement</strong>: Transfer learning can achieve good results even with limited data.</li>
</ul>
</div><h1><p>How Transfer Learning Works</p>
</h1>
<div class='content'></div><h2><p>Steps Involved</p>
</h2>
<div class='content'><ol>
<li><strong>Select a Pre-trained Model</strong>: Choose a model that has been trained on a large dataset similar to your task.</li>
<li><strong>Replace the Final Layer</strong>: Modify the final layer(s) of the pre-trained model to match the number of classes in your new task.</li>
<li><strong>Feature Extraction</strong>: Use the pre-trained model to extract features from your new dataset.</li>
<li><strong>Fine-Tuning</strong>: Optionally, fine-tune the entire model or just the top layers to better fit your new task.</li>
</ol>
</div><h2><p>Example: Transfer Learning with a Pre-trained CNN</p>
</h2>
<div class='content'><p>Let's walk through an example using a pre-trained Convolutional Neural Network (CNN) for image classification.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmFwcGxpY2F0aW9ucyBpbXBvcnQgVkdHMTYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgTW9kZWwKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRGVuc2UsIEZsYXR0ZW4KZnJvbSB0ZW5zb3JmbG93LmtlcmFzLnByZXByb2Nlc3NpbmcuaW1hZ2UgaW1wb3J0IEltYWdlRGF0YUdlbmVyYXRvcgoKIyBMb2FkIHRoZSBwcmUtdHJhaW5lZCBWR0cxNiBtb2RlbCB3aXRob3V0IHRoZSB0b3AgbGF5ZXIKYmFzZV9tb2RlbCA9IFZHRzE2KHdlaWdodHM9J2ltYWdlbmV0JywgaW5jbHVkZV90b3A9RmFsc2UsIGlucHV0X3NoYXBlPSgyMjQsIDIyNCwgMykpCgojIEZyZWV6ZSB0aGUgYmFzZSBtb2RlbApmb3IgbGF5ZXIgaW4gYmFzZV9tb2RlbC5sYXllcnM6CiAgICBsYXllci50cmFpbmFibGUgPSBGYWxzZQoKIyBBZGQgbmV3IHRvcCBsYXllcnMKeCA9IGJhc2VfbW9kZWwub3V0cHV0CnggPSBGbGF0dGVuKCkoeCkKeCA9IERlbnNlKDEwMjQsIGFjdGl2YXRpb249J3JlbHUnKSh4KQpwcmVkaWN0aW9ucyA9IERlbnNlKDEwLCBhY3RpdmF0aW9uPSdzb2Z0bWF4JykoeCkgICMgQXNzdW1pbmcgMTAgY2xhc3NlcyBpbiB0aGUgbmV3IHRhc2sKCiMgQ3JlYXRlIHRoZSBuZXcgbW9kZWwKbW9kZWwgPSBNb2RlbChpbnB1dHM9YmFzZV9tb2RlbC5pbnB1dCwgb3V0cHV0cz1wcmVkaWN0aW9ucykKCiMgQ29tcGlsZSB0aGUgbW9kZWwKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSkKCiMgUHJlcGFyZSBkYXRhIHVzaW5nIEltYWdlRGF0YUdlbmVyYXRvcgp0cmFpbl9kYXRhZ2VuID0gSW1hZ2VEYXRhR2VuZXJhdG9yKHJlc2NhbGU9MS4vMjU1KQp0cmFpbl9nZW5lcmF0b3IgPSB0cmFpbl9kYXRhZ2VuLmZsb3dfZnJvbV9kaXJlY3RvcnkoCiAgICAncGF0aF90b190cmFpbl9kYXRhJywKICAgIHRhcmdldF9zaXplPSgyMjQsIDIyNCksCiAgICBiYXRjaF9zaXplPTMyLAogICAgY2xhc3NfbW9kZT0nY2F0ZWdvcmljYWwnCikKCiMgVHJhaW4gdGhlIG1vZGVsCm1vZGVsLmZpdCh0cmFpbl9nZW5lcmF0b3IsIGVwb2Nocz0xMCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load the pre-trained VGG16 model without the top layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model
for layer in base_model.layers:
    layer.trainable = False

# Add new top layers
x = base_model.output
x = Flatten()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(10, activation='softmax')(x)  # Assuming 10 classes in the new task

# Create the new model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Prepare data using ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    'path_to_train_data',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Train the model
model.fit(train_generator, epochs=10)</pre></div><div class='content'></div><h2><p>Explanation</p>
</h2>
<div class='content'><ul>
<li><strong>Loading the Pre-trained Model</strong>: We load the VGG16 model pre-trained on ImageNet without the top layer (<code>include_top=False</code>).</li>
<li><strong>Freezing Layers</strong>: We freeze the layers of the base model to prevent them from being updated during training.</li>
<li><strong>Adding New Layers</strong>: We add new layers to the model to adapt it to our new task.</li>
<li><strong>Compiling the Model</strong>: We compile the model with an appropriate optimizer and loss function.</li>
<li><strong>Preparing Data</strong>: We use <code>ImageDataGenerator</code> to preprocess and load the training data.</li>
<li><strong>Training</strong>: We train the model on the new dataset.</li>
</ul>
</div><h1><p>Practical Exercise</p>
</h1>
<div class='content'></div><h2><p>Exercise: Transfer Learning with a Different Pre-trained Model</p>
</h2>
<div class='content'><ol>
<li><strong>Select a different pre-trained model</strong> (e.g., ResNet50).</li>
<li><strong>Replace the final layer</strong> to match the number of classes in your new task.</li>
<li><strong>Compile and train</strong> the model on a new dataset.</li>
</ol>
</div><h2><p>Solution</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmFwcGxpY2F0aW9ucyBpbXBvcnQgUmVzTmV0NTAKCiMgTG9hZCB0aGUgcHJlLXRyYWluZWQgUmVzTmV0NTAgbW9kZWwgd2l0aG91dCB0aGUgdG9wIGxheWVyCmJhc2VfbW9kZWwgPSBSZXNOZXQ1MCh3ZWlnaHRzPSdpbWFnZW5ldCcsIGluY2x1ZGVfdG9wPUZhbHNlLCBpbnB1dF9zaGFwZT0oMjI0LCAyMjQsIDMpKQoKIyBGcmVlemUgdGhlIGJhc2UgbW9kZWwKZm9yIGxheWVyIGluIGJhc2VfbW9kZWwubGF5ZXJzOgogICAgbGF5ZXIudHJhaW5hYmxlID0gRmFsc2UKCiMgQWRkIG5ldyB0b3AgbGF5ZXJzCnggPSBiYXNlX21vZGVsLm91dHB1dAp4ID0gRmxhdHRlbigpKHgpCnggPSBEZW5zZSgxMDI0LCBhY3RpdmF0aW9uPSdyZWx1JykoeCkKcHJlZGljdGlvbnMgPSBEZW5zZSgxMCwgYWN0aXZhdGlvbj0nc29mdG1heCcpKHgpICAjIEFzc3VtaW5nIDEwIGNsYXNzZXMgaW4gdGhlIG5ldyB0YXNrCgojIENyZWF0ZSB0aGUgbmV3IG1vZGVsCm1vZGVsID0gTW9kZWwoaW5wdXRzPWJhc2VfbW9kZWwuaW5wdXQsIG91dHB1dHM9cHJlZGljdGlvbnMpCgojIENvbXBpbGUgdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5JywgbWV0cmljcz1bJ2FjY3VyYWN5J10pCgojIFByZXBhcmUgZGF0YSB1c2luZyBJbWFnZURhdGFHZW5lcmF0b3IKdHJhaW5fZGF0YWdlbiA9IEltYWdlRGF0YUdlbmVyYXRvcihyZXNjYWxlPTEuLzI1NSkKdHJhaW5fZ2VuZXJhdG9yID0gdHJhaW5fZGF0YWdlbi5mbG93X2Zyb21fZGlyZWN0b3J5KAogICAgJ3BhdGhfdG9fdHJhaW5fZGF0YScsCiAgICB0YXJnZXRfc2l6ZT0oMjI0LCAyMjQpLAogICAgYmF0Y2hfc2l6ZT0zMiwKICAgIGNsYXNzX21vZGU9J2NhdGVnb3JpY2FsJwopCgojIFRyYWluIHRoZSBtb2RlbAptb2RlbC5maXQodHJhaW5fZ2VuZXJhdG9yLCBlcG9jaHM9MTAp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.applications import ResNet50

# Load the pre-trained ResNet50 model without the top layer
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model
for layer in base_model.layers:
    layer.trainable = False

# Add new top layers
x = base_model.output
x = Flatten()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(10, activation='softmax')(x)  # Assuming 10 classes in the new task

# Create the new model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Prepare data using ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    'path_to_train_data',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Train the model
model.fit(train_generator, epochs=10)</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Overfitting</strong>: Fine-tuning too many layers can lead to overfitting. Start with freezing most layers and gradually unfreeze if needed.</li>
<li><strong>Learning Rate</strong>: Use a smaller learning rate for fine-tuning to avoid large updates that can disrupt the pre-trained weights.</li>
<li><strong>Data Augmentation</strong>: Use data augmentation techniques to artificially increase the size of your training dataset and improve generalization.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>Transfer Learning is a highly effective technique in deep learning, allowing you to leverage pre-trained models to solve new tasks efficiently. By understanding the key concepts and steps involved, you can apply transfer learning to various domains and achieve impressive results even with limited data.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-autoencoders' title="Autoencoders">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-04-regularization-improvement-techniques' title="Regularization and Improvement Techniques">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
