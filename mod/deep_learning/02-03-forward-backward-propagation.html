<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Forward and Backward Propagation</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/02-03-forward-backward-propagation" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "2-3";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/02-03-forward-backward-propagation";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.49d891d32f.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my_modules" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/end_modules" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" style="display:none;" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="2-3" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="2-3" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-02-activation-function' title="Activation Function" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-02-activation-function' title="Activation Function" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Forward and Backward Propagation</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-04-optimization-loss-function' title="Optimization and Loss Function" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="2-3">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-04-optimization-loss-function' title="Optimization and Loss Function" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="2-3">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>Forward and backward propagation are fundamental processes in training neural networks. They are the mechanisms through which a neural network learns from data by adjusting its weights and biases. This section will cover the concepts, mathematical foundations, and practical implementation of forward and backward propagation.</p>
</div><h1>Forward Propagation</h1>
<div class='content'><p>Forward propagation is the process of passing input data through the neural network to obtain an output. This involves computing the activations of each neuron in the network layer by layer, starting from the input layer and moving towards the output layer.</p>
</div><h2>Steps in Forward Propagation</h2>
<div class='content'><ol>
<li><strong>Input Layer</strong>: The input data is fed into the input layer of the neural network.</li>
<li><strong>Weighted Sum</strong>: For each neuron in the subsequent layers, compute the weighted sum of inputs:
\[
z = \sum_{i=1}^{n} w_i x_i + b
\]
where \( w_i \) are the weights, \( x_i \) are the inputs, and \( b \) is the bias.</li>
<li><strong>Activation Function</strong>: Apply an activation function \( f \) to the weighted sum to get the neuron's output:
\[
a = f(z)
\]</li>
<li><strong>Output Layer</strong>: The final layer's activations are the network's output.</li>
</ol>
</div><h2>Example Code for Forward Propagation</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgpkZWYgc2lnbW9pZCh6KToKICAgIHJldHVybiAxIC8gKDEgKyBucC5leHAoLXopKQoKZGVmIGZvcndhcmRfcHJvcGFnYXRpb24oWCwgd2VpZ2h0cywgYmlhc2VzKToKICAgIGFjdGl2YXRpb25zID0gWAogICAgZm9yIHcsIGIgaW4gemlwKHdlaWdodHMsIGJpYXNlcyk6CiAgICAgICAgeiA9IG5wLmRvdChhY3RpdmF0aW9ucywgdykgKyBiCiAgICAgICAgYWN0aXZhdGlvbnMgPSBzaWdtb2lkKHopCiAgICByZXR1cm4gYWN0aXZhdGlvbnMKCiMgRXhhbXBsZSB1c2FnZQpYID0gbnAuYXJyYXkoW1swLjUsIDAuMV1dKSAgIyBJbnB1dCBkYXRhCndlaWdodHMgPSBbbnAuYXJyYXkoW1swLjIsIDAuOF0sIFswLjUsIDAuM11dKSwgbnAuYXJyYXkoW1swLjddLCBbMC45XV0pXSAgIyBXZWlnaHRzCmJpYXNlcyA9IFtucC5hcnJheShbMC4xLCAwLjJdKSwgbnAuYXJyYXkoWzAuM10pXSAgIyBCaWFzZXMKCm91dHB1dCA9IGZvcndhcmRfcHJvcGFnYXRpb24oWCwgd2VpZ2h0cywgYmlhc2VzKQpwcmludCgiT3V0cHV0OiIsIG91dHB1dCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def forward_propagation(X, weights, biases):
    activations = X
    for w, b in zip(weights, biases):
        z = np.dot(activations, w) + b
        activations = sigmoid(z)
    return activations

# Example usage
X = np.array([[0.5, 0.1]])  # Input data
weights = [np.array([[0.2, 0.8], [0.5, 0.3]]), np.array([[0.7], [0.9]])]  # Weights
biases = [np.array([0.1, 0.2]), np.array([0.3])]  # Biases

output = forward_propagation(X, weights, biases)
print(&quot;Output:&quot;, output)</pre></div><div class='content'></div><h1>Backward Propagation</h1>
<div class='content'><p>Backward propagation (backpropagation) is the process of updating the weights and biases of the network to minimize the error between the predicted output and the actual output. This is done by computing the gradient of the loss function with respect to each weight and bias and then adjusting them in the direction that reduces the loss.</p>
</div><h2>Steps in Backward Propagation</h2>
<div class='content'><ol>
<li><strong>Compute Loss</strong>: Calculate the loss (error) between the predicted output and the actual output using a loss function \( L \).</li>
<li><strong>Output Layer Gradient</strong>: Compute the gradient of the loss with respect to the output layer's activation.</li>
<li><strong>Backpropagate the Error</strong>: For each layer, starting from the output layer and moving backward:
<ul>
<li>Compute the gradient of the loss with respect to the weighted sum \( z \).</li>
<li>Compute the gradient of the loss with respect to the weights and biases.</li>
<li>Update the weights and biases using the gradients and a learning rate \( \eta \).</li>
</ul>
</li>
</ol>
</div><h2>Mathematical Formulation</h2>
<div class='content'><p>For a single training example, the gradients are computed as follows:</p>
<ol>
<li><strong>Loss Function</strong>: Assume a simple mean squared error loss:
\[
L = \frac{1}{2} (y_{\text{pred}} - y_{\text{true}})^2
\]</li>
<li><strong>Gradient of Loss w.r.t. Output Activation</strong>:
\[
\delta = \frac{\partial L}{\partial a} = (a - y_{\text{true}})
\]</li>
<li><strong>Gradient of Loss w.r.t. Weighted Sum</strong>:
\[
\delta_z = \delta \cdot f'(z)
\]
where \( f'(z) \) is the derivative of the activation function.</li>
<li><strong>Gradient of Loss w.r.t. Weights and Biases</strong>:
\[
\frac{\partial L}{\partial w} = \delta_z \cdot a_{\text{prev}}
\]
\[
\frac{\partial L}{\partial b} = \delta_z
\]</li>
</ol>
</div><h2>Example Code for Backward Propagation</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIHNpZ21vaWRfZGVyaXZhdGl2ZSh6KToKICAgIHJldHVybiBzaWdtb2lkKHopICogKDEgLSBzaWdtb2lkKHopKQoKZGVmIGJhY2t3YXJkX3Byb3BhZ2F0aW9uKFgsIFksIHdlaWdodHMsIGJpYXNlcywgbGVhcm5pbmdfcmF0ZSk6CiAgICBhY3RpdmF0aW9ucyA9IFtYXQogICAgenMgPSBbXQogICAgCiAgICAjIEZvcndhcmQgcGFzcwogICAgZm9yIHcsIGIgaW4gemlwKHdlaWdodHMsIGJpYXNlcyk6CiAgICAgICAgeiA9IG5wLmRvdChhY3RpdmF0aW9uc1stMV0sIHcpICsgYgogICAgICAgIHpzLmFwcGVuZCh6KQogICAgICAgIGFjdGl2YXRpb25zLmFwcGVuZChzaWdtb2lkKHopKQogICAgCiAgICAjIEJhY2t3YXJkIHBhc3MKICAgIGRlbHRhID0gYWN0aXZhdGlvbnNbLTFdIC0gWQogICAgZGVsdGFzID0gW2RlbHRhXQogICAgCiAgICBmb3IgbCBpbiByYW5nZSgyLCBsZW4od2VpZ2h0cykgKyAxKToKICAgICAgICB6ID0genNbLWxdCiAgICAgICAgc3AgPSBzaWdtb2lkX2Rlcml2YXRpdmUoeikKICAgICAgICBkZWx0YSA9IG5wLmRvdChkZWx0YXNbLTFdLCB3ZWlnaHRzWy1sICsgMV0uVCkgKiBzcAogICAgICAgIGRlbHRhcy5hcHBlbmQoZGVsdGEpCiAgICAKICAgIGRlbHRhcy5yZXZlcnNlKCkKICAgIAogICAgIyBHcmFkaWVudCBkZXNjZW50IHVwZGF0ZQogICAgZm9yIGkgaW4gcmFuZ2UobGVuKHdlaWdodHMpKToKICAgICAgICB3ZWlnaHRzW2ldIC09IGxlYXJuaW5nX3JhdGUgKiBucC5kb3QoYWN0aXZhdGlvbnNbaV0uVCwgZGVsdGFzW2ldKQogICAgICAgIGJpYXNlc1tpXSAtPSBsZWFybmluZ19yYXRlICogbnAuc3VtKGRlbHRhc1tpXSwgYXhpcz0wLCBrZWVwZGltcz1UcnVlKQogICAgCiAgICByZXR1cm4gd2VpZ2h0cywgYmlhc2VzCgojIEV4YW1wbGUgdXNhZ2UKWSA9IG5wLmFycmF5KFtbMV1dKSAgIyBUcnVlIG91dHB1dApsZWFybmluZ19yYXRlID0gMC4xCgp3ZWlnaHRzLCBiaWFzZXMgPSBiYWNrd2FyZF9wcm9wYWdhdGlvbihYLCBZLCB3ZWlnaHRzLCBiaWFzZXMsIGxlYXJuaW5nX3JhdGUpCnByaW50KCJVcGRhdGVkIFdlaWdodHM6Iiwgd2VpZ2h0cykKcHJpbnQoIlVwZGF0ZWQgQmlhc2VzOiIsIGJpYXNlcyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def sigmoid_derivative(z):
    return sigmoid(z) * (1 - sigmoid(z))

def backward_propagation(X, Y, weights, biases, learning_rate):
    activations = [X]
    zs = []
    
    # Forward pass
    for w, b in zip(weights, biases):
        z = np.dot(activations[-1], w) + b
        zs.append(z)
        activations.append(sigmoid(z))
    
    # Backward pass
    delta = activations[-1] - Y
    deltas = [delta]
    
    for l in range(2, len(weights) + 1):
        z = zs[-l]
        sp = sigmoid_derivative(z)
        delta = np.dot(deltas[-1], weights[-l + 1].T) * sp
        deltas.append(delta)
    
    deltas.reverse()
    
    # Gradient descent update
    for i in range(len(weights)):
        weights[i] -= learning_rate * np.dot(activations[i].T, deltas[i])
        biases[i] -= learning_rate * np.sum(deltas[i], axis=0, keepdims=True)
    
    return weights, biases

# Example usage
Y = np.array([[1]])  # True output
learning_rate = 0.1

weights, biases = backward_propagation(X, Y, weights, biases, learning_rate)
print(&quot;Updated Weights:&quot;, weights)
print(&quot;Updated Biases:&quot;, biases)</pre></div><div class='content'></div><h1>Practical Exercise</h1>
<div class='content'></div><h2>Exercise: Implement Forward and Backward Propagation</h2>
<div class='content'><p><strong>Task</strong>: Implement a simple neural network with one hidden layer and train it using forward and backward propagation.</p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Initialize the weights and biases.</li>
<li>Implement forward propagation.</li>
<li>Implement backward propagation.</li>
<li>Train the network on a simple dataset.</li>
</ol>
<p><strong>Dataset</strong>: XOR problem</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# XOR dataset
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
Y = np.array([[0], [1], [1], [0]])

# Initialize weights and biases
np.random.seed(42)
weights = [np.random.randn(2, 2), np.random.randn(2, 1)]
biases = [np.random.randn(1, 2), np.random.randn(1, 1)]

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def sigmoid_derivative(z):
    return sigmoid(z) * (1 - sigmoid(z))

def forward_propagation(X, weights, biases):
    activations = X
    for w, b in zip(weights, biases):
        z = np.dot(activations, w) + b
        activations = sigmoid(z)
    return activations

def backward_propagation(X, Y, weights, biases, learning_rate):
    activations = [X]
    zs = []
    
    # Forward pass
    for w, b in zip(weights, biases):
        z = np.dot(activations[-1], w) + b
        zs.append(z)
        activations.append(sigmoid(z))
    
    # Backward pass
    delta = activations[-1] - Y
    deltas = [delta]
    
    for l in range(2, len(weights) + 1):
        z = zs[-l]
        sp = sigmoid_derivative(z)
        delta = np.dot(deltas[-1], weights[-l + 1].T) * sp
        deltas.append(delta)
    
    deltas.reverse()
    
    # Gradient descent update
    for i in range(len(weights)):
        weights[i] -= learning_rate * np.dot(activations[i].T, deltas[i])
        biases[i] -= learning_rate * np.sum(deltas[i], axis=0, keepdims=True)
    
    return weights, biases

# Training the network
learning_rate = 0.1
epochs = 10000

for epoch in range(epochs):
    weights, biases = backward_propagation(X, Y, weights, biases, learning_rate)

# Testing the network
output = forward_propagation(X, weights, biases)
print(&quot;Predicted Output:\n&quot;, output)</pre></div><div class='content'></div><h2>Solution Explanation</h2>
<div class='content'><ol>
<li><strong>Initialization</strong>: Randomly initialize the weights and biases.</li>
<li><strong>Forward Propagation</strong>: Compute the activations for each layer.</li>
<li><strong>Backward Propagation</strong>: Compute the gradients and update the weights and biases.</li>
<li><strong>Training</strong>: Iterate the forward and backward propagation steps for a specified number of epochs.</li>
</ol>
</div><h1>Summary</h1>
<div class='content'><p>In this section, we covered the essential concepts of forward and backward propagation in neural networks. We explored the mathematical foundations, implemented the processes in code, and applied them to a practical exercise. Understanding these concepts is crucial for training neural networks effectively and forms the basis for more advanced deep learning techniques.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-02-activation-function' title="Activation Function" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-02-activation-function' title="Activation Function" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-04-optimization-loss-function' title="Optimization and Loss Function" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="2-3">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-04-optimization-loss-function' title="Optimization and Loss Function" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="2-3">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Deep Learning Course</h1>
<h2>Module 1: Introduction to Deep Learning</h2>
<ul>
<li><a href="01-01-what-is-deep-learning">What is Deep Learning?</a></li>
<li><a href="01-02-history-evolution-deep-learning">History and Evolution of Deep Learning</a></li>
<li><a href="01-03-applications-deep-learning">Applications of Deep Learning</a></li>
<li><a href="01-04-basic-concepts-neural-networks">Basic Concepts of Neural Networks</a></li>
</ul>
<h2>Module 2: Fundamentals of Neural Networks</h2>
<ul>
<li><a href="02-01-perceptron-multilayer-perceptron">Perceptron and Multilayer Perceptron</a></li>
<li><a href="02-02-activation-function">Activation Function</a></li>
<li><a href="02-03-forward-backward-propagation">Forward and Backward Propagation</a></li>
<li><a href="02-04-optimization-loss-function">Optimization and Loss Function</a></li>
</ul>
<h2>Module 3: Convolutional Neural Networks (CNN)</h2>
<ul>
<li><a href="03-01-introduction-cnn">Introduction to CNN</a></li>
<li><a href="03-02-convolutional-pooling-layers">Convolutional and Pooling Layers</a></li>
<li><a href="03-03-popular-cnn-architectures">Popular CNN Architectures</a></li>
<li><a href="03-04-cnn-applications-image-recognition">CNN Applications in Image Recognition</a></li>
</ul>
<h2>Module 4: Recurrent Neural Networks (RNN)</h2>
<ul>
<li><a href="04-01-introduction-rnn">Introduction to RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM and GRU</a></li>
<li><a href="04-03-rnn-applications-nlp">RNN Applications in Natural Language Processing</a></li>
<li><a href="04-04-sequences-time-series">Sequences and Time Series</a></li>
</ul>
<h2>Module 5: Advanced Techniques in Deep Learning</h2>
<ul>
<li><a href="05-01-generative-adversarial-networks">Generative Adversarial Networks (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularization-improvement-techniques">Regularization and Improvement Techniques</a></li>
</ul>
<h2>Module 6: Tools and Frameworks</h2>
<ul>
<li><a href="06-01-introduction-tensorflow">Introduction to TensorFlow</a></li>
<li><a href="06-02-introduction-pytorch">Introduction to PyTorch</a></li>
<li><a href="06-03-framework-comparison">Framework Comparison</a></li>
<li><a href="06-04-development-environments-resources">Development Environments and Additional Resources</a></li>
</ul>
<h2>Module 7: Practical Projects</h2>
<ul>
<li><a href="07-01-image-classification-cnn">Image Classification with CNN</a></li>
<li><a href="07-02-text-generation-rnn">Text Generation with RNN</a></li>
<li><a href="07-03-anomaly-detection-autoencoders">Anomaly Detection with Autoencoders</a></li>
<li><a href="07-04-creating-gan-image-generation">Creating a GAN for Image Generation</a></li>
</ul>
<h2>Module 8: Ethical Considerations and the Future of Deep Learning</h2>
<ul>
<li><a href="08-01-ethics-deep-learning">Ethics in Deep Learning</a></li>
<li><a href="08-02-social-economic-impact">Social and Economic Impact</a></li>
<li><a href="08-03-future-trends-deep-learning">Future Trends in Deep Learning</a></li>
<li><a href="08-04-challenges-opportunities">Challenges and Opportunities</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<p id="loginModalEmail"></p>
            	<div id="mensaje" class="d-none alert alert-danger"></div>
            	<div id="mensaje_info" class="d-none alert alert-success"></div>
            	
            	<div id="modal-body-main">
					<div class="mt-4 d-none" id="forgotPasswordSection">
						<div class="mb-3">
    <label for="recovery-email" class="form-label">Email</label>
    <input type="email" required class="form-control" id="recovery-email" placeholder="Enter your email">
</div>
<button class="btn btn-primary" id="btnRecover">Send recovery link</button>

					</div>
									
					<div class="mt-4 d-none" id="deleteUserSection">	
						<div class="mb-3 alert alert-danger">
	Warning! You are about to delete all registration and progress data.<br><b>This action cannot be undone.</b>
</div>
<div class="mb-3">
    <input type="password" required class="form-control" id="delete-user-pwd" placeholder="Enter your password">
</div>
<button class="btn btn-primary" id="btnDeleteUser">Delete user</button>

					</div>
					
					<div class="mt-4 d-none" id="changePassordSection">
						<div class="mb-3 row">
	<div class="col col-12 my-2">
	    <input type="password" required class="form-control" id="change-pwd-actual" placeholder="Enter current password">
	</div>
	<div class="col col-12 my-2">
    	<input type="password" required class="form-control" id="change-pwd-new-1" placeholder="Enter new password">
	</div>
	<div class="col col-12 my-2">
    	<input type="password" required class="form-control" id="change-pwd-new-2" placeholder="Repeat new password">
	</div>
</div>
<button class="btn btn-primary" id="btnChangePassword">Change password</button>

					</div>
					
					<div class="mt-4 d-none alert alert-warning" id="verifyPasswordSection">
						<p><b>Falta verificar correu</b></p>
						<a id="btnVerifyEmail" href="#">Send verification link</a>

					</div>
					
					<div class="mt-4 d-none" id="disconnectUserSection">
						<div class="mb-3">
    <button id="btnDisconnect" class="btn btn-primary">Disconnect</button>
</div>

<hr>

<div class="mt-3">
    <button class="btn btn-outline-secondary" id="change-password-link">Change password</button>
</div>

<div class="mt-3">
    <a href="#" id="delete-user-link">Delete user</a>
</div>

					</div>
	            
	            	<div class="mt-4 d-none" id="modalTabsSection">
	            		<ul class="nav nav-tabs" id="authTabs" role="tablist">
    <li class="nav-item" role="presentation">
        <button class="nav-link active" id="login-tab" data-bs-toggle="tab" data-bs-target="#login" type="button" role="tab" aria-controls="login" aria-selected="true">
        	Log in
        </button>
    </li>
    <li class="nav-item" role="presentation">
        <button class="nav-link" id="register-tab" data-bs-toggle="tab" data-bs-target="#register" type="button" role="tab" aria-controls="register" aria-selected="false">
        	Sign up
        </button>
    </li>
</ul>

<div class="tab-content mt-3" id="authTabsContent">
    <div class="tab-pane fade show active" id="login" role="tabpanel" aria-labelledby="login-tab">
    	<div class="mb-3">
    <label for="login-username" class="form-label">Email</label>
    <input type="email" required class="form-control" id="login-username" placeholder="Enter your email">
</div>
<div class="mb-3">
    <label for="login-password" class="form-label">Password</label>
    <input type="password"  required class="form-control" id="login-password" placeholder="Enter your password">
</div>
<button class="btn btn-primary" id="btnLogin">Log in</button>
<div class="mt-3">
    <a href="#" id="forgot-password-link">Have you forgotten your password?</a>
</div>
    </div>

    <div class="tab-pane fade" id="register" role="tabpanel" aria-labelledby="register-tab">
    	<div class="mb-3">
    <label for="register-email" class="form-label">Email</label>
    <input type="email" class="form-control" id="register-email" required placeholder="Enter your email">
</div>

<div class="mb-3">
    <label for="register-password" class="form-label">Password</label>
    <input type="password" class="form-control"  required id="register-password" placeholder="Enter your password">
</div>

<div class="mb-3">
    <label for="register-name" class="form-label">Name</label>
    <input type="text" class="form-control"  required id="register-name" placeholder="Enter your name">
</div>

<div class="form-check mb-3">
    <input type="checkbox" class="form-check-input" id="accept-conditions-reg">
    <label for="accept-conditions-reg" class="form-check-label">
        I have read and accept the <a href="/privacity" target="blank">Privacy Policy</a> and the <a href="/licence" target="blank">Terms and Conditions of Use</a>.
    </label>
</div>

<div class="form-check mb-3">
    <input type="checkbox" class="form-check-input" id="accept-allow_comunications">
    <label for="accept-allow_comunications" class="form-check-label">
        I wish to receive news and updates about courses (optional).
    </label>
</div>

<button id="btnRegister" class="btn btn-primary">Sign up</button>
    </div>
</div>
	            	</div>
            	</div>
            </div>
        </div>
    </div>
</div>

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
