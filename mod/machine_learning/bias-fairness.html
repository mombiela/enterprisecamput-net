<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bias and Fairness in Machine Learning</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/bias-fairness" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/bias-fairness" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/bias-fairness" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/machine_learning/bias-fairness" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/bias-fairness" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Attention!</b> There has been an error in the course generation, and it may contain translation errors.We are working to resolve this issue, so please use the content with caution.You can check the correct content in another language at the following link:<br>
						<a href="https://campusempresa.com/mod/machine_learning/bias-fairness">https://campusempresa.com/mod/machine_learning/bias-fairness</a></p>
					</div>
								<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>In the context of Machine Learning, the concepts of bias and fairness are fundamental to developing models that are not only accurate but also ethical and equitable. This topic will address definitions, types of biases, methods to detect and mitigate biases, and how to evaluate fairness in Machine Learning models.</p>
</div><h1>What is Bias?</h1>
<div class='content'><p>Bias in Machine Learning refers to any systematic error in the model that leads to inaccurate or unfair results. It can arise at various stages of the model development process, from data collection to model implementation.</p>
</div><h2>Types of Bias</h2>
<div class='content'><ul>
<li><strong>Selection Bias</strong>: Occurs when the training data does not adequately represent the target population.</li>
<li><strong>Confirmation Bias</strong>: Arises when data is sought or interpreted in a way that confirms pre-existing beliefs.</li>
<li><strong>Exclusion Bias</strong>: Occurs when certain groups or characteristics are excluded from the dataset.</li>
<li><strong>Measurement Bias</strong>: Appears when input variables are not measured accurately.</li>
</ul>
</div><h1>What is Fairness?</h1>
<div class='content'><p>Fairness in Machine Learning refers to creating models that treat all individuals or groups equitably. Fairness can be evaluated from different perspectives, such as demographic fairness, opportunity fairness, and outcome fairness.</p>
</div><h2>Methods to Evaluate Fairness</h2>
<div class='content'><ul>
<li><strong>Demographic Fairness</strong>: Ensures that all classes or demographic groups have equitable representation in the model's outcomes.</li>
<li><strong>Opportunity Fairness</strong>: Guarantees that all individuals have the same opportunities to receive a positive outcome.</li>
<li><strong>Outcome Fairness</strong>: Focuses on ensuring that the final outcomes are equitable for all groups.</li>
</ul>
</div><h1>Examples of Bias and Fairness</h1>
<div class='content'></div><h2>Example of Selection Bias</h2>
<div class='content'><p>Suppose we are developing a classification model to predict whether a candidate will be hired. If the training dataset mainly contains data from candidates from a single university, the model could have selection bias.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHBhbmRhcyBhcyBwZApmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5saW5lYXJfbW9kZWwgaW1wb3J0IExvZ2lzdGljUmVncmVzc2lvbgoKIyBMb2FkIGRhdGEKZGF0YSA9IHBkLnJlYWRfY3N2KCdjYW5kaWRhdGVzLmNzdicpCgojIENoZWNrIHRoZSBkaXN0cmlidXRpb24gb2YgdGhlIHVuaXZlcnNpdHkKcHJpbnQoZGF0YVsndW5pdmVyc2l0eSddLnZhbHVlX2NvdW50cygpKQoKIyBTcGxpdCB0aGUgZGF0YSBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0aW5nIHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KGRhdGEuZHJvcCgnaGlyZWQnLCBheGlzPTEpLCBkYXRhWydoaXJlZCddLCB0ZXN0X3NpemU9MC4yLCByYW5kb21fc3RhdGU9NDIpCgojIFRyYWluIHRoZSBtb2RlbAptb2RlbCA9IExvZ2lzdGljUmVncmVzc2lvbigpCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBFdmFsdWF0ZSB0aGUgbW9kZWwKYWNjdXJhY3kgPSBtb2RlbC5zY29yZShYX3Rlc3QsIHlfdGVzdCkKcHJpbnQoZidBY2N1cmFjeToge2FjY3VyYWN5fScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Load data
data = pd.read_csv('candidates.csv')

# Check the distribution of the university
print(data['university'].value_counts())

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data.drop('hired', axis=1), data['hired'], test_size=0.2, random_state=42)

# Train the model
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate the model
accuracy = model.score(X_test, y_test)
print(f'Accuracy: {accuracy}')</pre></div><div class='content'></div><h2>Example of Fairness Evaluation</h2>
<div class='content'><p>To evaluate demographic fairness, we can use metrics such as the False Positive Rate (FPR) and the False Negative Rate (FNR) for different demographic groups.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IGNvbmZ1c2lvbl9tYXRyaXgKCiMgTW9kZWwgcHJlZGljdGlvbnMKeV9wcmVkID0gbW9kZWwucHJlZGljdChYX3Rlc3QpCgojIENvbmZ1c2lvbiBtYXRyaXggZm9yIGRpZmZlcmVudCBncm91cHMKY29uZl9tYXRyaXhfZ3JvdXAxID0gY29uZnVzaW9uX21hdHJpeCh5X3Rlc3RbWF90ZXN0Wydncm91cCddID09IDFdLCB5X3ByZWRbWF90ZXN0Wydncm91cCddID09IDFdKQpjb25mX21hdHJpeF9ncm91cDIgPSBjb25mdXNpb25fbWF0cml4KHlfdGVzdFtYX3Rlc3RbJ2dyb3VwJ10gPT0gMl0sIHlfcHJlZFtYX3Rlc3RbJ2dyb3VwJ10gPT0gMl0pCgojIENhbGN1bGF0ZSBGUFIgYW5kIEZOUgpkZWYgY2FsY3VsYXRlX2Zwcl9mbnIoY29uZl9tYXRyaXgpOgogICAgdG4sIGZwLCBmbiwgdHAgPSBjb25mX21hdHJpeC5yYXZlbCgpCiAgICBmcHIgPSBmcCAvIChmcCArIHRuKQogICAgZm5yID0gZm4gLyAoZm4gKyB0cCkKICAgIHJldHVybiBmcHIsIGZucgoKZnByX2dyb3VwMSwgZm5yX2dyb3VwMSA9IGNhbGN1bGF0ZV9mcHJfZm5yKGNvbmZfbWF0cml4X2dyb3VwMSkKZnByX2dyb3VwMiwgZm5yX2dyb3VwMiA9IGNhbGN1bGF0ZV9mcHJfZm5yKGNvbmZfbWF0cml4X2dyb3VwMikKCnByaW50KGYnR3JvdXAgMSAtIEZQUjoge2Zwcl9ncm91cDF9LCBGTlI6IHtmbnJfZ3JvdXAxfScpCnByaW50KGYnR3JvdXAgMiAtIEZQUjoge2Zwcl9ncm91cDJ9LCBGTlI6IHtmbnJfZ3JvdXAyfScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.metrics import confusion_matrix

# Model predictions
y_pred = model.predict(X_test)

# Confusion matrix for different groups
conf_matrix_group1 = confusion_matrix(y_test[X_test['group'] == 1], y_pred[X_test['group'] == 1])
conf_matrix_group2 = confusion_matrix(y_test[X_test['group'] == 2], y_pred[X_test['group'] == 2])

# Calculate FPR and FNR
def calculate_fpr_fnr(conf_matrix):
    tn, fp, fn, tp = conf_matrix.ravel()
    fpr = fp / (fp + tn)
    fnr = fn / (fn + tp)
    return fpr, fnr

fpr_group1, fnr_group1 = calculate_fpr_fnr(conf_matrix_group1)
fpr_group2, fnr_group2 = calculate_fpr_fnr(conf_matrix_group2)

print(f'Group 1 - FPR: {fpr_group1}, FNR: {fnr_group1}')
print(f'Group 2 - FPR: {fpr_group2}, FNR: {fnr_group2}')</pre></div><div class='content'></div><h1>Methods to Mitigate Bias</h1>
<div class='content'><ul>
<li><strong>Diverse Data Collection</strong>: Ensure that the training dataset is representative of the target population.</li>
<li><strong>Data Preprocessing</strong>: Apply data balancing techniques, such as oversampling or undersampling.</li>
<li><strong>Model Regularization</strong>: Use regularization techniques to reduce overfitting and bias.</li>
<li><strong>Fairness Audits</strong>: Conduct periodic audits to evaluate and mitigate bias in the model.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>Bias and fairness are critical aspects of developing Machine Learning models. Understanding and addressing these concepts not only improves model accuracy but also ensures that models are fair and ethical. By implementing techniques to detect and mitigate bias and evaluate fairness, professionals can develop more robust and equitable models.</p>
</div>
			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
