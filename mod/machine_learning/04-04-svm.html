<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Support Vector Machines (SVM)</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/04-04-svm" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/04-04-svm" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/04-04-svm" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/machine_learning/04-04-svm" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/machine_learning/04-04-svm" class="px-2">CA</a>
<br>
			<cite>Building today's and tomorrow's society</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
									<a href="./">Course Content</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Technical Skills</a>
				<a href="/all/conocimientos">Knowledge</a>
				<a href="/all/soft_skills">Social Skills</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-decision-trees' title="Decision Trees">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Support Vector Machines (SVM)</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='04-05-knn' title="K-Nearest Neighbors (K-NN)">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Support Vector Machines (SVM) are a powerful set of supervised learning algorithms used for classification, regression, and outlier detection. They are particularly well-suited for binary classification tasks and are known for their effectiveness in high-dimensional spaces.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'></div><h2><ol>
<li>Hyperplane</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: A hyperplane is a decision boundary that separates different classes in the feature space.</li>
<li><strong>Equation</strong>: In an n-dimensional space, a hyperplane can be defined by the equation \( w \cdot x + b = 0 \), where \( w \) is the weight vector, \( x \) is the feature vector, and \( b \) is the bias term.</li>
</ul>
</div><h2><ol start="2">
<li>Support Vectors</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Support vectors are the data points that are closest to the hyperplane. These points are critical in defining the position and orientation of the hyperplane.</li>
<li><strong>Role</strong>: They help maximize the margin between the classes.</li>
</ul>
</div><h2><ol start="3">
<li>Margin</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: The margin is the distance between the hyperplane and the nearest data points from either class.</li>
<li><strong>Objective</strong>: SVM aims to find the hyperplane that maximizes this margin, ensuring better generalization to unseen data.</li>
</ul>
</div><h2><ol start="4">
<li>Kernel Trick</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: The kernel trick allows SVM to operate in a high-dimensional space without explicitly computing the coordinates of the data in that space.</li>
<li><strong>Common Kernels</strong>:
<ul>
<li><strong>Linear Kernel</strong>: \( K(x_i, x_j) = x_i \cdot x_j \)</li>
<li><strong>Polynomial Kernel</strong>: \( K(x_i, x_j) = (x_i \cdot x_j + c)^d \)</li>
<li><strong>Radial Basis Function (RBF) Kernel</strong>: \( K(x_i, x_j) = \exp(-\gamma | x_i - x_j |^2) \)</li>
</ul>
</li>
</ul>
</div><h1><p>Practical Example</p>
</h1>
<div class='content'><p>Let's implement a simple SVM classifier using Python's <code>scikit-learn</code> library.</p>
</div><h2><p>Step-by-Step Implementation</p>
</h2>
<div class='content'><ol>
<li><strong>Import Libraries</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gc2tsZWFybiBpbXBvcnQgZGF0YXNldHMKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4uc3ZtIGltcG9ydCBTVkMKZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IGNsYXNzaWZpY2F0aW9uX3JlcG9ydCwgY29uZnVzaW9uX21hdHJpeAppbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt</pre></div><div class='content'><ol start="2">
<li><strong>Load Dataset</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIHRoZSBJcmlzIGRhdGFzZXQKaXJpcyA9IGRhdGFzZXRzLmxvYWRfaXJpcygpClggPSBpcmlzLmRhdGFbOiwgOjJdICAjIFdlIHdpbGwgdXNlIG9ubHkgdGhlIGZpcnN0IHR3byBmZWF0dXJlcyBmb3Igc2ltcGxpY2l0eQp5ID0gaXJpcy50YXJnZXQKCiMgT25seSBjb25zaWRlciB0d28gY2xhc3NlcyBmb3IgYmluYXJ5IGNsYXNzaWZpY2F0aW9uClggPSBYW3kgIT0gMl0KeSA9IHlbeSAhPSAyXQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load the Iris dataset
iris = datasets.load_iris()
X = iris.data[:, :2]  # We will use only the first two features for simplicity
y = iris.target

# Only consider two classes for binary classification
X = X[y != 2]
y = y[y != 2]</pre></div><div class='content'><ol start="3">
<li><strong>Split Data</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTcGxpdCB0aGUgZGF0YSBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0aW5nIHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjMsIHJhbmRvbV9zdGF0ZT00Mik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)</pre></div><div class='content'><ol start="4">
<li><strong>Train the SVM Model</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYW4gU1ZNIGNsYXNzaWZpZXIgd2l0aCBhIGxpbmVhciBrZXJuZWwKc3ZtX2NsYXNzaWZpZXIgPSBTVkMoa2VybmVsPSdsaW5lYXInKQoKIyBUcmFpbiB0aGUgbW9kZWwKc3ZtX2NsYXNzaWZpZXIuZml0KFhfdHJhaW4sIHlfdHJhaW4p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create an SVM classifier with a linear kernel
svm_classifier = SVC(kernel='linear')

# Train the model
svm_classifier.fit(X_train, y_train)</pre></div><div class='content'><ol start="5">
<li><strong>Make Predictions</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQcmVkaWN0IHRoZSBsYWJlbHMgZm9yIHRoZSB0ZXN0IHNldAp5X3ByZWQgPSBzdm1fY2xhc3NpZmllci5wcmVkaWN0KFhfdGVzdCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Predict the labels for the test set
y_pred = svm_classifier.predict(X_test)</pre></div><div class='content'><ol start="6">
<li><strong>Evaluate the Model</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQcmludCB0aGUgY2xhc3NpZmljYXRpb24gcmVwb3J0IGFuZCBjb25mdXNpb24gbWF0cml4CnByaW50KCJDbGFzc2lmaWNhdGlvbiBSZXBvcnQ6XG4iLCBjbGFzc2lmaWNhdGlvbl9yZXBvcnQoeV90ZXN0LCB5X3ByZWQpKQpwcmludCgiQ29uZnVzaW9uIE1hdHJpeDpcbiIsIGNvbmZ1c2lvbl9tYXRyaXgoeV90ZXN0LCB5X3ByZWQpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Print the classification report and confusion matrix
print(&quot;Classification Report:\n&quot;, classification_report(y_test, y_pred))
print(&quot;Confusion Matrix:\n&quot;, confusion_matrix(y_test, y_pred))</pre></div><div class='content'><ol start="7">
<li><strong>Visualize the Decision Boundary</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGdW5jdGlvbiB0byBwbG90IHRoZSBkZWNpc2lvbiBib3VuZGFyeQpkZWYgcGxvdF9kZWNpc2lvbl9ib3VuZGFyeShYLCB5LCBtb2RlbCk6CiAgICBoID0gLjAyICAjIHN0ZXAgc2l6ZSBpbiB0aGUgbWVzaAogICAgeF9taW4sIHhfbWF4ID0gWFs6LCAwXS5taW4oKSAtIDEsIFhbOiwgMF0ubWF4KCkgKyAxCiAgICB5X21pbiwgeV9tYXggPSBYWzosIDFdLm1pbigpIC0gMSwgWFs6LCAxXS5tYXgoKSArIDEKICAgIHh4LCB5eSA9IG5wLm1lc2hncmlkKG5wLmFyYW5nZSh4X21pbiwgeF9tYXgsIGgpLCBucC5hcmFuZ2UoeV9taW4sIHlfbWF4LCBoKSkKICAgIFogPSBtb2RlbC5wcmVkaWN0KG5wLmNfW3h4LnJhdmVsKCksIHl5LnJhdmVsKCldKQogICAgWiA9IFoucmVzaGFwZSh4eC5zaGFwZSkKICAgIHBsdC5jb250b3VyZih4eCwgeXksIFosIGFscGhhPTAuOCkKICAgIHBsdC5zY2F0dGVyKFhbOiwgMF0sIFhbOiwgMV0sIGM9eSwgZWRnZWNvbG9ycz0naycsIG1hcmtlcj0nbycpCiAgICBwbHQueGxhYmVsKCdGZWF0dXJlIDEnKQogICAgcGx0LnlsYWJlbCgnRmVhdHVyZSAyJykKICAgIHBsdC50aXRsZSgnU1ZNIERlY2lzaW9uIEJvdW5kYXJ5JykKICAgIHBsdC5zaG93KCkKCiMgUGxvdCB0aGUgZGVjaXNpb24gYm91bmRhcnkKcGxvdF9kZWNpc2lvbl9ib3VuZGFyeShYX3Rlc3QsIHlfdGVzdCwgc3ZtX2NsYXNzaWZpZXIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Function to plot the decision boundary
def plot_decision_boundary(X, y, model):
    h = .02  # step size in the mesh
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, alpha=0.8)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title('SVM Decision Boundary')
    plt.show()

# Plot the decision boundary
plot_decision_boundary(X_test, y_test, svm_classifier)</pre></div><div class='content'></div><h1><p>Practical Exercises</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: Implement SVM with Different Kernels</p>
</h2>
<div class='content'><ul>
<li><strong>Task</strong>: Implement SVM classifiers using polynomial and RBF kernels. Compare their performance with the linear kernel.</li>
<li><strong>Solution</strong>:</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQb2x5bm9taWFsIEtlcm5lbApzdm1fcG9seSA9IFNWQyhrZXJuZWw9J3BvbHknLCBkZWdyZWU9MykKc3ZtX3BvbHkuZml0KFhfdHJhaW4sIHlfdHJhaW4pCnlfcHJlZF9wb2x5ID0gc3ZtX3BvbHkucHJlZGljdChYX3Rlc3QpCnByaW50KCJQb2x5bm9taWFsIEtlcm5lbCAtIENsYXNzaWZpY2F0aW9uIFJlcG9ydDpcbiIsIGNsYXNzaWZpY2F0aW9uX3JlcG9ydCh5X3Rlc3QsIHlfcHJlZF9wb2x5KSkKCiMgUkJGIEtlcm5lbApzdm1fcmJmID0gU1ZDKGtlcm5lbD0ncmJmJywgZ2FtbWE9MC43KQpzdm1fcmJmLmZpdChYX3RyYWluLCB5X3RyYWluKQp5X3ByZWRfcmJmID0gc3ZtX3JiZi5wcmVkaWN0KFhfdGVzdCkKcHJpbnQoIlJCRiBLZXJuZWwgLSBDbGFzc2lmaWNhdGlvbiBSZXBvcnQ6XG4iLCBjbGFzc2lmaWNhdGlvbl9yZXBvcnQoeV90ZXN0LCB5X3ByZWRfcmJmKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Polynomial Kernel
svm_poly = SVC(kernel='poly', degree=3)
svm_poly.fit(X_train, y_train)
y_pred_poly = svm_poly.predict(X_test)
print(&quot;Polynomial Kernel - Classification Report:\n&quot;, classification_report(y_test, y_pred_poly))

# RBF Kernel
svm_rbf = SVC(kernel='rbf', gamma=0.7)
svm_rbf.fit(X_train, y_train)
y_pred_rbf = svm_rbf.predict(X_test)
print(&quot;RBF Kernel - Classification Report:\n&quot;, classification_report(y_test, y_pred_rbf))</pre></div><div class='content'></div><h2><p>Exercise 2: Hyperparameter Tuning</p>
</h2>
<div class='content'><ul>
<li><strong>Task</strong>: Use grid search to find the best hyperparameters for the SVM model.</li>
<li><strong>Solution</strong>:</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgR3JpZFNlYXJjaENWCgojIERlZmluZSB0aGUgcGFyYW1ldGVyIGdyaWQKcGFyYW1fZ3JpZCA9IHsKICAgICdDJzogWzAuMSwgMSwgMTAsIDEwMF0sCiAgICAnZ2FtbWEnOiBbMSwgMC4xLCAwLjAxLCAwLjAwMV0sCiAgICAna2VybmVsJzogWydyYmYnXQp9CgojIENyZWF0ZSBhIEdyaWRTZWFyY2hDViBvYmplY3QKZ3JpZCA9IEdyaWRTZWFyY2hDVihTVkMoKSwgcGFyYW1fZ3JpZCwgcmVmaXQ9VHJ1ZSwgdmVyYm9zZT0yKQpncmlkLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBQcmludCB0aGUgYmVzdCBwYXJhbWV0ZXJzIGFuZCBlc3RpbWF0b3IKcHJpbnQoIkJlc3QgUGFyYW1ldGVyczpcbiIsIGdyaWQuYmVzdF9wYXJhbXNfKQpwcmludCgiQmVzdCBFc3RpbWF0b3I6XG4iLCBncmlkLmJlc3RfZXN0aW1hdG9yXykKCiMgUHJlZGljdCB1c2luZyB0aGUgYmVzdCBlc3RpbWF0b3IKeV9wcmVkX2dyaWQgPSBncmlkLnByZWRpY3QoWF90ZXN0KQpwcmludCgiR3JpZCBTZWFyY2ggLSBDbGFzc2lmaWNhdGlvbiBSZXBvcnQ6XG4iLCBjbGFzc2lmaWNhdGlvbl9yZXBvcnQoeV90ZXN0LCB5X3ByZWRfZ3JpZCkp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf']
}

# Create a GridSearchCV object
grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)
grid.fit(X_train, y_train)

# Print the best parameters and estimator
print(&quot;Best Parameters:\n&quot;, grid.best_params_)
print(&quot;Best Estimator:\n&quot;, grid.best_estimator_)

# Predict using the best estimator
y_pred_grid = grid.predict(X_test)
print(&quot;Grid Search - Classification Report:\n&quot;, classification_report(y_test, y_pred_grid))</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Feature Scaling</strong>: Always scale your features before training an SVM model, especially when using kernels other than the linear kernel.</li>
<li><strong>Choosing the Right Kernel</strong>: Start with a linear kernel for linearly separable data. Use RBF or polynomial kernels for more complex data.</li>
<li><strong>Hyperparameter Tuning</strong>: Use techniques like grid search or random search to find the optimal hyperparameters for your SVM model.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>Support Vector Machines are a versatile and powerful tool for classification tasks. By understanding the key concepts and practicing with different kernels and hyperparameters, you can effectively apply SVMs to a wide range of problems. In the next section, we will explore another supervised learning algorithm: K-Nearest Neighbors (K-NN).</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-decision-trees' title="Decision Trees">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='04-05-knn' title="K-Nearest Neighbors (K-NN)">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
