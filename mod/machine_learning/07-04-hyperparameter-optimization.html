<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Hyperparameter Optimization</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/07-04-optimizacion-hiperparametros" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/07-04-optimizacion-hiperparametros" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/07-04-hyperparameter-optimization" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=3" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/machine_learning/07-04-optimizacion-hiperparametros" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/machine_learning/07-04-optimizacion-hiperparametros" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>Building today's and tomorrow's society</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Languages</a>
				 					<a href="/categ/frameworks">Frameworks</a>
				 					<a href="/categ/tech-tools">Tools</a>
				 					<a href="/categ/foundations">Foundations</a>
				 					<a href="/categ/soft-skills">Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-03-deep-learning' title="Deep Learning">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Hyperparameter Optimization</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-01-frameworks-libraries' title="Popular Frameworks and Libraries">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Hyperparameter optimization is a crucial step in the machine learning pipeline. It involves selecting the best set of hyperparameters for a learning algorithm to improve its performance. Unlike model parameters, which are learned during training, hyperparameters are set before the learning process begins and control the behavior of the training algorithm.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'></div><h2><ol>
<li>Hyperparameters vs. Parameters</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Hyperparameters</strong>: These are external configurations to the model, such as learning rate, number of trees in a random forest, or the number of hidden layers in a neural network.</li>
<li><strong>Parameters</strong>: These are internal to the model and are learned from the training data, such as weights in a neural network or coefficients in a linear regression model.</li>
</ul>
</div><h2><ol start="2">
<li>Importance of Hyperparameter Optimization</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Performance Improvement</strong>: Proper tuning of hyperparameters can significantly improve the model's performance.</li>
<li><strong>Model Generalization</strong>: Helps in achieving a balance between overfitting and underfitting.</li>
<li><strong>Efficiency</strong>: Optimized hyperparameters can reduce training time and computational resources.</li>
</ul>
</div><h2><ol start="3">
<li>Common Hyperparameters</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Learning Rate</strong>: Controls how much to change the model in response to the estimated error each time the model weights are updated.</li>
<li><strong>Number of Epochs</strong>: Number of times the learning algorithm will work through the entire training dataset.</li>
<li><strong>Batch Size</strong>: Number of training examples utilized in one iteration.</li>
<li><strong>Number of Layers/Neurons</strong>: In neural networks, the architecture can be tuned by changing the number of layers and neurons.</li>
</ul>
</div><h1><p>Hyperparameter Optimization Techniques</p>
</h1>
<div class='content'></div><h2><ol>
<li>Grid Search</li>
</ol>
</h2>
<div class='content'><p>Grid search is a brute-force technique that involves specifying a grid of hyperparameter values and training the model for every combination of these values.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgR3JpZFNlYXJjaENWCmZyb20gc2tsZWFybi5lbnNlbWJsZSBpbXBvcnQgUmFuZG9tRm9yZXN0Q2xhc3NpZmllcgoKIyBEZWZpbmUgdGhlIG1vZGVsCm1vZGVsID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpCgojIERlZmluZSB0aGUgZ3JpZCBvZiBoeXBlcnBhcmFtZXRlcnMKcGFyYW1fZ3JpZCA9IHsKICAgICduX2VzdGltYXRvcnMnOiBbMTAwLCAyMDAsIDMwMF0sCiAgICAnbWF4X2RlcHRoJzogWzEwLCAyMCwgMzBdLAogICAgJ21pbl9zYW1wbGVzX3NwbGl0JzogWzIsIDUsIDEwXQp9CgojIFNldCB1cCB0aGUgZ3JpZCBzZWFyY2gKZ3JpZF9zZWFyY2ggPSBHcmlkU2VhcmNoQ1YoZXN0aW1hdG9yPW1vZGVsLCBwYXJhbV9ncmlkPXBhcmFtX2dyaWQsIGN2PTUsIHNjb3Jpbmc9J2FjY3VyYWN5JykKCiMgRml0IHRoZSBncmlkIHNlYXJjaApncmlkX3NlYXJjaC5maXQoWF90cmFpbiwgeV90cmFpbikKCiMgQmVzdCBoeXBlcnBhcmFtZXRlcnMKcHJpbnQoIkJlc3QgSHlwZXJwYXJhbWV0ZXJzOiIsIGdyaWRfc2VhcmNoLmJlc3RfcGFyYW1zXyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Define the model
model = RandomForestClassifier()

# Define the grid of hyperparameters
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Set up the grid search
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the grid search
grid_search.fit(X_train, y_train)

# Best hyperparameters
print(&quot;Best Hyperparameters:&quot;, grid_search.best_params_)</pre></div><div class='content'></div><h2><ol start="2">
<li>Random Search</li>
</ol>
</h2>
<div class='content'><p>Random search involves randomly sampling the hyperparameter space and evaluating the model performance for a fixed number of iterations.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgUmFuZG9taXplZFNlYXJjaENWCgojIERlZmluZSB0aGUgbW9kZWwKbW9kZWwgPSBSYW5kb21Gb3Jlc3RDbGFzc2lmaWVyKCkKCiMgRGVmaW5lIHRoZSBncmlkIG9mIGh5cGVycGFyYW1ldGVycwpwYXJhbV9kaXN0ID0gewogICAgJ25fZXN0aW1hdG9ycyc6IFsxMDAsIDIwMCwgMzAwXSwKICAgICdtYXhfZGVwdGgnOiBbMTAsIDIwLCAzMF0sCiAgICAnbWluX3NhbXBsZXNfc3BsaXQnOiBbMiwgNSwgMTBdCn0KCiMgU2V0IHVwIHRoZSByYW5kb20gc2VhcmNoCnJhbmRvbV9zZWFyY2ggPSBSYW5kb21pemVkU2VhcmNoQ1YoZXN0aW1hdG9yPW1vZGVsLCBwYXJhbV9kaXN0cmlidXRpb25zPXBhcmFtX2Rpc3QsIG5faXRlcj0xMCwgY3Y9NSwgc2NvcmluZz0nYWNjdXJhY3knKQoKIyBGaXQgdGhlIHJhbmRvbSBzZWFyY2gKcmFuZG9tX3NlYXJjaC5maXQoWF90cmFpbiwgeV90cmFpbikKCiMgQmVzdCBoeXBlcnBhcmFtZXRlcnMKcHJpbnQoIkJlc3QgSHlwZXJwYXJhbWV0ZXJzOiIsIHJhbmRvbV9zZWFyY2guYmVzdF9wYXJhbXNfKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import RandomizedSearchCV

# Define the model
model = RandomForestClassifier()

# Define the grid of hyperparameters
param_dist = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Set up the random search
random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy')

# Fit the random search
random_search.fit(X_train, y_train)

# Best hyperparameters
print(&quot;Best Hyperparameters:&quot;, random_search.best_params_)</pre></div><div class='content'></div><h2><ol start="3">
<li>Bayesian Optimization</li>
</ol>
</h2>
<div class='content'><p>Bayesian optimization builds a probabilistic model of the objective function and uses it to select the most promising hyperparameters to evaluate.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza29wdCBpbXBvcnQgQmF5ZXNTZWFyY2hDVgoKIyBEZWZpbmUgdGhlIG1vZGVsCm1vZGVsID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpCgojIERlZmluZSB0aGUgc2VhcmNoIHNwYWNlCnNlYXJjaF9zcGFjZSA9IHsKICAgICduX2VzdGltYXRvcnMnOiAoMTAwLCAzMDApLAogICAgJ21heF9kZXB0aCc6ICgxMCwgMzApLAogICAgJ21pbl9zYW1wbGVzX3NwbGl0JzogKDIsIDEwKQp9CgojIFNldCB1cCB0aGUgQmF5ZXNpYW4gc2VhcmNoCmJheWVzX3NlYXJjaCA9IEJheWVzU2VhcmNoQ1YoZXN0aW1hdG9yPW1vZGVsLCBzZWFyY2hfc3BhY2VzPXNlYXJjaF9zcGFjZSwgbl9pdGVyPTEwLCBjdj01LCBzY29yaW5nPSdhY2N1cmFjeScpCgojIEZpdCB0aGUgQmF5ZXNpYW4gc2VhcmNoCmJheWVzX3NlYXJjaC5maXQoWF90cmFpbiwgeV90cmFpbikKCiMgQmVzdCBoeXBlcnBhcmFtZXRlcnMKcHJpbnQoIkJlc3QgSHlwZXJwYXJhbWV0ZXJzOiIsIGJheWVzX3NlYXJjaC5iZXN0X3BhcmFtc18p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from skopt import BayesSearchCV

# Define the model
model = RandomForestClassifier()

# Define the search space
search_space = {
    'n_estimators': (100, 300),
    'max_depth': (10, 30),
    'min_samples_split': (2, 10)
}

# Set up the Bayesian search
bayes_search = BayesSearchCV(estimator=model, search_spaces=search_space, n_iter=10, cv=5, scoring='accuracy')

# Fit the Bayesian search
bayes_search.fit(X_train, y_train)

# Best hyperparameters
print(&quot;Best Hyperparameters:&quot;, bayes_search.best_params_)</pre></div><div class='content'></div><h2><ol start="4">
<li>Hyperband</li>
</ol>
</h2>
<div class='content'><p>Hyperband is an optimization algorithm that uses adaptive resource allocation and early-stopping to find the best hyperparameters efficiently.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrZXJhcy53cmFwcGVycy5zY2lraXRfbGVhcm4gaW1wb3J0IEtlcmFzQ2xhc3NpZmllcgpmcm9tIGtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIGtlcmFzLmxheWVycyBpbXBvcnQgRGVuc2UKZnJvbSBrZXJhcy5vcHRpbWl6ZXJzIGltcG9ydCBBZGFtCmZyb20ga2VyYXN0dW5lci50dW5lcnMgaW1wb3J0IEh5cGVyYmFuZAoKIyBEZWZpbmUgdGhlIG1vZGVsCmRlZiBidWlsZF9tb2RlbChocCk6CiAgICBtb2RlbCA9IFNlcXVlbnRpYWwoKQogICAgbW9kZWwuYWRkKERlbnNlKHVuaXRzPWhwLkludCgndW5pdHMnLCBtaW5fdmFsdWU9MzIsIG1heF92YWx1ZT01MTIsIHN0ZXA9MzIpLCBhY3RpdmF0aW9uPSdyZWx1JykpCiAgICBtb2RlbC5hZGQoRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpKQogICAgbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9QWRhbShocC5DaG9pY2UoJ2xlYXJuaW5nX3JhdGUnLCB2YWx1ZXM9WzFlLTIsIDFlLTMsIDFlLTRdKSksIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSkKICAgIHJldHVybiBtb2RlbAoKIyBTZXQgdXAgdGhlIEh5cGVyYmFuZCB0dW5lcgp0dW5lciA9IEh5cGVyYmFuZChidWlsZF9tb2RlbCwgb2JqZWN0aXZlPSd2YWxfYWNjdXJhY3knLCBtYXhfZXBvY2hzPTEwLCBmYWN0b3I9MywgZGlyZWN0b3J5PSdteV9kaXInLCBwcm9qZWN0X25hbWU9J2h5cGVyYmFuZCcpCgojIFBlcmZvcm0gdGhlIHNlYXJjaAp0dW5lci5zZWFyY2goWF90cmFpbiwgeV90cmFpbiwgZXBvY2hzPTEwLCB2YWxpZGF0aW9uX2RhdGE9KFhfdmFsLCB5X3ZhbCkpCgojIEJlc3QgaHlwZXJwYXJhbWV0ZXJzCmJlc3RfaHBzID0gdHVuZXIuZ2V0X2Jlc3RfaHlwZXJwYXJhbWV0ZXJzKG51bV90cmlhbHM9MSlbMF0KcHJpbnQoIkJlc3QgSHlwZXJwYXJhbWV0ZXJzOiIsIGJlc3RfaHBzKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from kerastuner.tuners import Hyperband

# Define the model
def build_model(hp):
    model = Sequential()
    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Set up the Hyperband tuner
tuner = Hyperband(build_model, objective='val_accuracy', max_epochs=10, factor=3, directory='my_dir', project_name='hyperband')

# Perform the search
tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))

# Best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(&quot;Best Hyperparameters:&quot;, best_hps)</pre></div><div class='content'></div><h1><p>Practical Exercise</p>
</h1>
<div class='content'></div><h2><p>Exercise: Hyperparameter Tuning with Grid Search</p>
</h2>
<div class='content'><p><strong>Task</strong>: Use Grid Search to find the best hyperparameters for a Support Vector Machine (SVM) classifier on the Iris dataset.</p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Load the Iris dataset.</li>
<li>Define the SVM model.</li>
<li>Set up the grid of hyperparameters.</li>
<li>Perform Grid Search.</li>
<li>Print the best hyperparameters.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0cwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0LCBHcmlkU2VhcmNoQ1YKZnJvbSBza2xlYXJuLnN2bSBpbXBvcnQgU1ZDCgojIExvYWQgdGhlIElyaXMgZGF0YXNldAppcmlzID0gZGF0YXNldHMubG9hZF9pcmlzKCkKWCA9IGlyaXMuZGF0YQp5ID0gaXJpcy50YXJnZXQKCiMgU3BsaXQgdGhlIGRhdGFzZXQKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjIsIHJhbmRvbV9zdGF0ZT00MikKCiMgRGVmaW5lIHRoZSBtb2RlbAptb2RlbCA9IFNWQygpCgojIERlZmluZSB0aGUgZ3JpZCBvZiBoeXBlcnBhcmFtZXRlcnMKcGFyYW1fZ3JpZCA9IHsKICAgICdDJzogWzAuMSwgMSwgMTBdLAogICAgJ2dhbW1hJzogWzEsIDAuMSwgMC4wMV0sCiAgICAna2VybmVsJzogWydyYmYnLCAnbGluZWFyJ10KfQoKIyBTZXQgdXAgdGhlIGdyaWQgc2VhcmNoCmdyaWRfc2VhcmNoID0gR3JpZFNlYXJjaENWKGVzdGltYXRvcj1tb2RlbCwgcGFyYW1fZ3JpZD1wYXJhbV9ncmlkLCBjdj01LCBzY29yaW5nPSdhY2N1cmFjeScpCgojIEZpdCB0aGUgZ3JpZCBzZWFyY2gKZ3JpZF9zZWFyY2guZml0KFhfdHJhaW4sIHlfdHJhaW4pCgojIEJlc3QgaHlwZXJwYXJhbWV0ZXJzCnByaW50KCJCZXN0IEh5cGVycGFyYW1ldGVyczoiLCBncmlkX3NlYXJjaC5iZXN0X3BhcmFtc18p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn import datasets
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC

# Load the Iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model
model = SVC()

# Define the grid of hyperparameters
param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [1, 0.1, 0.01],
    'kernel': ['rbf', 'linear']
}

# Set up the grid search
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the grid search
grid_search.fit(X_train, y_train)

# Best hyperparameters
print(&quot;Best Hyperparameters:&quot;, grid_search.best_params_)</pre></div><div class='content'></div><h2><p>Solution</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBCZXN0IEh5cGVycGFyYW1ldGVyczogeydDJzogMSwgJ2dhbW1hJzogMC4xLCAna2VybmVsJzogJ3JiZid9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Best Hyperparameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Overfitting on Validation Set</strong>: Ensure that the validation set is not used for hyperparameter tuning multiple times to avoid overfitting.</li>
<li><strong>Computational Resources</strong>: Be mindful of the computational cost, especially with large datasets and complex models.</li>
<li><strong>Starting Simple</strong>: Begin with simpler models and fewer hyperparameters before moving to more complex ones.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>Hyperparameter optimization is a critical step in building effective machine learning models. By understanding and applying various optimization techniques such as Grid Search, Random Search, Bayesian Optimization, and Hyperband, you can significantly enhance your model's performance. Practice with different datasets and models to gain a deeper understanding and proficiency in hyperparameter tuning.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-03-deep-learning' title="Deep Learning">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-01-frameworks-libraries' title="Popular Frameworks and Libraries">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
