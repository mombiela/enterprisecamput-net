<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Gradient Boosting</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/07-02-gradient-boosting" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/07-02-gradient-boosting" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/07-02-gradient-boosting" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/machine_learning/07-02-gradient-boosting" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/machine_learning/07-02-gradient-boosting" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>All the knowledge within your reach</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					 				<a href="/"><i class="bi bi-house-fill"></i> HOME</a>
											</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-01-ensemble-learning' title="Ensemble Learning">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Gradient Boosting</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-03-deep-learning' title="Deep Learning">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Gradient Boosting is a powerful machine learning technique used for regression and classification problems. It builds models in a sequential manner, where each new model attempts to correct the errors made by the previous models. This method is particularly effective for improving the performance of weak learners, typically decision trees.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ol>
<li><strong>Boosting</strong>: An ensemble technique that combines the predictions of several base estimators to improve robustness over a single estimator.</li>
<li><strong>Gradient Descent</strong>: An optimization algorithm used to minimize the loss function by iteratively moving towards the minimum value.</li>
<li><strong>Loss Function</strong>: A function that measures the difference between the predicted and actual values. Gradient Boosting aims to minimize this function.</li>
</ol>
</div><h1>How Gradient Boosting Works</h1>
<div class='content'><ol>
<li><strong>Initialize the Model</strong>: Start with an initial model, often a simple model like the mean of the target values.</li>
<li><strong>Compute Residuals</strong>: Calculate the residuals (errors) between the actual values and the predictions of the initial model.</li>
<li><strong>Fit a New Model</strong>: Train a new model to predict the residuals.</li>
<li><strong>Update the Model</strong>: Add the predictions of the new model to the initial model to improve the overall prediction.</li>
<li><strong>Repeat</strong>: Repeat steps 2-4 for a specified number of iterations or until the residuals are minimized.</li>
</ol>
</div><h1>Practical Example</h1>
<div class='content'><p>Let's implement a simple Gradient Boosting model using Python and the <code>scikit-learn</code> library.</p>
</div><h2>Step-by-Step Implementation</h2>
<div class='content'><ol>
<li><strong>Import Libraries</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBwYW5kYXMgYXMgcGQKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4uZW5zZW1ibGUgaW1wb3J0IEdyYWRpZW50Qm9vc3RpbmdSZWdyZXNzb3IKZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IG1lYW5fc3F1YXJlZF9lcnJvcg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error</pre></div><div class='content'><ol start="2">
<li><strong>Load Dataset</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGb3IgdGhpcyBleGFtcGxlLCB3ZSdsbCB1c2UgdGhlIEJvc3RvbiBob3VzaW5nIGRhdGFzZXQKZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2Jvc3Rvbgpib3N0b24gPSBsb2FkX2Jvc3RvbigpClggPSBwZC5EYXRhRnJhbWUoYm9zdG9uLmRhdGEsIGNvbHVtbnM9Ym9zdG9uLmZlYXR1cmVfbmFtZXMpCnkgPSBwZC5TZXJpZXMoYm9zdG9uLnRhcmdldCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># For this example, we'll use the Boston housing dataset
from sklearn.datasets import load_boston
boston = load_boston()
X = pd.DataFrame(boston.data, columns=boston.feature_names)
y = pd.Series(boston.target)</pre></div><div class='content'><ol start="3">
<li><strong>Split Data</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("WF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjIsIHJhbmRvbV9zdGF0ZT00Mik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</pre></div><div class='content'><ol start="4">
<li><strong>Initialize and Train the Model</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBJbml0aWFsaXplIHRoZSBHcmFkaWVudCBCb29zdGluZyBSZWdyZXNzb3IKZ2JyID0gR3JhZGllbnRCb29zdGluZ1JlZ3Jlc3NvcihuX2VzdGltYXRvcnM9MTAwLCBsZWFybmluZ19yYXRlPTAuMSwgbWF4X2RlcHRoPTMsIHJhbmRvbV9zdGF0ZT00MikKCiMgVHJhaW4gdGhlIG1vZGVsCmdici5maXQoWF90cmFpbiwgeV90cmFpbik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Initialize the Gradient Boosting Regressor
gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Train the model
gbr.fit(X_train, y_train)</pre></div><div class='content'><ol start="5">
<li><strong>Make Predictions and Evaluate</strong>:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IGdici5wcmVkaWN0KFhfdGVzdCkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCm1zZSA9IG1lYW5fc3F1YXJlZF9lcnJvcih5X3Rlc3QsIHlfcHJlZCkKcHJpbnQoZiJNZWFuIFNxdWFyZWQgRXJyb3I6IHttc2V9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Make predictions
y_pred = gbr.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f&quot;Mean Squared Error: {mse}&quot;)</pre></div><div class='content'></div><h2>Explanation of Parameters</h2>
<div class='content'><ul>
<li><strong>n_estimators</strong>: The number of boosting stages to be run. More stages can improve performance but may lead to overfitting.</li>
<li><strong>learning_rate</strong>: Shrinks the contribution of each tree. There is a trade-off between learning_rate and n_estimators.</li>
<li><strong>max_depth</strong>: The maximum depth of the individual regression estimators. Limits the number of nodes in the tree.</li>
</ul>
</div><h1>Practical Exercise</h1>
<div class='content'></div><h2>Exercise: Implement Gradient Boosting for Classification</h2>
<div class='content'><ol>
<li><strong>Dataset</strong>: Use the Iris dataset from <code>scikit-learn</code>.</li>
<li><strong>Objective</strong>: Train a Gradient Boosting Classifier to classify the species of iris flowers.</li>
<li><strong>Steps</strong>:
<ul>
<li>Load the Iris dataset.</li>
<li>Split the data into training and testing sets.</li>
<li>Initialize and train a <code>GradientBoostingClassifier</code>.</li>
<li>Make predictions and evaluate the model using accuracy.</li>
</ul>
</li>
</ol>
</div><h2>Solution</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBHcmFkaWVudEJvb3N0aW5nQ2xhc3NpZmllcgpmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgYWNjdXJhY3lfc2NvcmUKCiMgTG9hZCB0aGUgSXJpcyBkYXRhc2V0CmlyaXMgPSBsb2FkX2lyaXMoKQpYID0gaXJpcy5kYXRhCnkgPSBpcmlzLnRhcmdldAoKIyBTcGxpdCB0aGUgZGF0YQpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBJbml0aWFsaXplIHRoZSBHcmFkaWVudCBCb29zdGluZyBDbGFzc2lmaWVyCmdiYyA9IEdyYWRpZW50Qm9vc3RpbmdDbGFzc2lmaWVyKG5fZXN0aW1hdG9ycz0xMDAsIGxlYXJuaW5nX3JhdGU9MC4xLCBtYXhfZGVwdGg9MywgcmFuZG9tX3N0YXRlPTQyKQoKIyBUcmFpbiB0aGUgbW9kZWwKZ2JjLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IGdiYy5wcmVkaWN0KFhfdGVzdCkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmFjY3VyYWN5ID0gYWNjdXJhY3lfc2NvcmUoeV90ZXN0LCB5X3ByZWQpCnByaW50KGYiQWNjdXJhY3k6IHthY2N1cmFjeX0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_iris
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Gradient Boosting Classifier
gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Train the model
gbc.fit(X_train, y_train)

# Make predictions
y_pred = gbc.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy: {accuracy}&quot;)</pre></div><div class='content'></div><h2>Common Mistakes and Tips</h2>
<div class='content'><ul>
<li><strong>Overfitting</strong>: Using too many estimators or a high learning rate can lead to overfitting. Use cross-validation to find the optimal parameters.</li>
<li><strong>Learning Rate</strong>: A smaller learning rate requires more estimators to converge, but it can lead to better generalization.</li>
<li><strong>Feature Scaling</strong>: Gradient Boosting is robust to feature scaling, but scaling can still improve performance.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>Gradient Boosting is a versatile and powerful technique for both regression and classification tasks. By iteratively correcting errors, it builds a strong predictive model. Understanding the key parameters and their impact on the model's performance is crucial for effective implementation. In the next section, we will explore another advanced technique: Deep Learning.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-01-ensemble-learning' title="Ensemble Learning">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-03-deep-learning' title="Deep Learning">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			









		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
