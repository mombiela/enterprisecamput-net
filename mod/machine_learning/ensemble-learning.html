<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ensemble Learning</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/ensemble-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/ensemble-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/ensemble-learning" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/machine_learning/ensemble-learning" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/ensemble-learning" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Attention!</b> There has been an error in the course generation, and it may contain translation errors.We are working to resolve this issue, so please use the content with caution.You can check the correct content in another language at the following link:<br>
						<a href="https://campusempresa.com/mod/machine_learning/ensemble-learning">https://campusempresa.com/mod/machine_learning/ensemble-learning</a></p>
					</div>
								<div class='content'></div><h1>Introduction to Ensemble Learning</h1>
<div class='content'><p>Ensemble Learning is a technique in Machine Learning that combines multiple models to improve the accuracy and robustness of predictions. The main idea is that a set of models (an &quot;ensemble&quot;) can outperform the performance of a single model by reducing the risk of individual errors.</p>
</div><h1>Types of Ensemble Learning</h1>
<div class='content'><p>There are several methods of Ensemble Learning, each with its own characteristics and applications. The most common are:</p>
<ul>
<li><strong>Bagging (Bootstrap Aggregating)</strong></li>
<li><strong>Boosting</strong></li>
<li><strong>Stacking</strong></li>
</ul>
</div><h2>Bagging (Bootstrap Aggregating)</h2>
<div class='content'><p>Bagging is a technique that improves model accuracy by reducing variability. It is based on the idea of training multiple models on different subsets of data and then averaging their predictions.</p>
<ul>
<li>
<p><strong>Process</strong>:</p>
<ol>
<li>Create multiple data subsets by sampling with replacement.</li>
<li>Train a model on each subset.</li>
<li>Average the predictions of all models.</li>
</ol>
</li>
<li>
<p><strong>Python code example</strong>:</p>
<pre><code class="language-python">from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create the Bagging model
bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)
bagging.fit(X_train, y_train)

# Predictions and evaluation
y_pred = bagging.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
</code></pre>
</li>
</ul>
</div><h2>Boosting</h2>
<div class='content'><p>Boosting is a technique that sequentially adjusts weak models, correcting the errors of previous models. The goal is to turn weak models into a strong model.</p>
<ul>
<li>
<p><strong>Process</strong>:</p>
<ol>
<li>Train a model on the original data.</li>
<li>Adjust the next model on the errors of the previous model.</li>
<li>Repeat the process and combine the models.</li>
</ol>
</li>
<li>
<p><strong>Python code example</strong>:</p>
<pre><code class="language-python">from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create the Boosting model
boosting = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)
boosting.fit(X_train, y_train)

# Predictions and evaluation
y_pred = boosting.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
</code></pre>
</li>
</ul>
</div><h2>Stacking</h2>
<div class='content'><p>Stacking combines multiple models using a higher-level model (meta-model) that learns to combine the predictions of the base models.</p>
<ul>
<li>
<p><strong>Process</strong>:</p>
<ol>
<li>Train multiple base models on the original data.</li>
<li>Use the predictions of the base models as features for the meta-model.</li>
<li>Train the meta-model on these new features.</li>
</ol>
</li>
<li>
<p><strong>Python code example</strong>:</p>
<pre><code class="language-python">from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create the base models
estimators = [
    ('dt', DecisionTreeClassifier()),
    ('svc', SVC(probability=True))
]

# Create the Stacking model
stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())
stacking.fit(X_train, y_train)

# Predictions and evaluation
y_pred = stacking.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
</code></pre>
</li>
</ul>
</div><h1>Comparison of Methods</h1>
<div class='content'><table>
<thead>
<tr>
<th>Method</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bagging</td>
<td>Reduces variance, improves stability</td>
<td>Does not reduce bias</td>
</tr>
<tr>
<td>Boosting</td>
<td>Reduces both bias and variance</td>
<td>Can overfit if not controlled</td>
</tr>
<tr>
<td>Stacking</td>
<td>Combines multiple models flexibly</td>
<td>More complex, requires more training time</td>
</tr>
</tbody>
</table>
</div><h1>Conclusion</h1>
<div class='content'><p>Ensemble Learning is a powerful technique in Machine Learning that can significantly improve model performance. By combining multiple models, errors can be reduced and prediction accuracy increased. Each Ensemble Learning method has its own advantages and disadvantages, and the choice of the appropriate method depends on the specific problem and the available data.</p>
</div>
			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
