<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Principal Component Analysis (PCA)</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/pca" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/pca" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/pca" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/machine_learning/pca" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/pca" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Attention!</b> There has been an error in the course generation, and it may contain translation errors.We are working to resolve this issue, so please use the content with caution.You can check the correct content in another language at the following link:<br>
						<a href="https://campusempresa.com/mod/machine_learning/pca">https://campusempresa.com/mod/machine_learning/pca</a></p>
					</div>
								<div class='content'></div><h1>Introduction to PCA</h1>
<div class='content'><p>Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform a set of possibly correlated variables into a set of values of uncorrelated variables called principal components. PCA is widely used in Machine Learning to simplify models, reduce noise, and improve data visualization.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Dimensionality Reduction</strong>: Process of reducing the number of variables under consideration.</li>
<li><strong>Principal Components</strong>: New uncorrelated variables obtained as linear combinations of the original variables.</li>
<li><strong>Variance</strong>: Measure of data dispersion; PCA seeks to maximize variance in the principal components.</li>
<li><strong>Eigenvalues and Eigenvectors</strong>: Mathematically, principal components are obtained from the eigenvalues and eigenvectors of the data covariance matrix.</li>
</ul>
</div><h1>Steps to Perform PCA</h1>
<div class='content'><ol>
<li><strong>Standardization of Data</strong>: Normalize the data so that each variable has zero mean and unit variance.</li>
<li><strong>Calculation of Covariance Matrix</strong>: Determine the relationship between variables.</li>
<li><strong>Calculation of Eigenvalues and Eigenvectors</strong>: Obtain the principal components.</li>
<li><strong>Selection of Principal Components</strong>: Choose the components that explain most of the variance.</li>
<li><strong>Transformation of Data</strong>: Project the original data into the space of the principal components.</li>
</ol>
</div><h1>Code Example</h1>
<div class='content'><p>Below is an example of how to perform PCA using Python and the <code>scikit-learn</code> library.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBwYW5kYXMgYXMgcGQKZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyCmZyb20gc2tsZWFybi5kZWNvbXBvc2l0aW9uIGltcG9ydCBQQ0EKaW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdAoKIyBHZW5lcmF0ZSBleGFtcGxlIGRhdGEKbnAucmFuZG9tLnNlZWQoMCkKZGF0YSA9IG5wLnJhbmRvbS5yYW5kKDEwMCwgNSkKZGYgPSBwZC5EYXRhRnJhbWUoZGF0YSwgY29sdW1ucz1bJ0EnLCAnQicsICdDJywgJ0QnLCAnRSddKQoKIyBTdGFuZGFyZGl6YXRpb24gb2YgZGF0YQpzY2FsZXIgPSBTdGFuZGFyZFNjYWxlcigpCnNjYWxlZF9kYXRhID0gc2NhbGVyLmZpdF90cmFuc2Zvcm0oZGYpCgojIEFwcGx5IFBDQQpwY2EgPSBQQ0Eobl9jb21wb25lbnRzPTIpCnByaW5jaXBhbF9jb21wb25lbnRzID0gcGNhLmZpdF90cmFuc2Zvcm0oc2NhbGVkX2RhdGEpCgojIENyZWF0ZSBhIERhdGFGcmFtZSB3aXRoIHRoZSBwcmluY2lwYWwgY29tcG9uZW50cwpwY2FfZGYgPSBwZC5EYXRhRnJhbWUoZGF0YT1wcmluY2lwYWxfY29tcG9uZW50cywgY29sdW1ucz1bJ1BDMScsICdQQzInXSkKCiMgVmlzdWFsaXphdGlvbiBvZiB0aGUgcHJpbmNpcGFsIGNvbXBvbmVudHMKcGx0LmZpZ3VyZShmaWdzaXplPSg4LCA2KSkKcGx0LnNjYXR0ZXIocGNhX2RmWydQQzEnXSwgcGNhX2RmWydQQzInXSkKcGx0LnhsYWJlbCgnUHJpbmNpcGFsIENvbXBvbmVudCAxJykKcGx0LnlsYWJlbCgnUHJpbmNpcGFsIENvbXBvbmVudCAyJykKcGx0LnRpdGxlKCdQQ0Egb2YgRXhhbXBsZSBEYXRhJykKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Generate example data
np.random.seed(0)
data = np.random.rand(100, 5)
df = pd.DataFrame(data, columns=['A', 'B', 'C', 'D', 'E'])

# Standardization of data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)

# Apply PCA
pca = PCA(n_components=2)
principal_components = pca.fit_transform(scaled_data)

# Create a DataFrame with the principal components
pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])

# Visualization of the principal components
plt.figure(figsize=(8, 6))
plt.scatter(pca_df['PC1'], pca_df['PC2'])
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Example Data')
plt.show()</pre></div><div class='content'></div><h1>Interpretation of Results</h1>
<div class='content'><ul>
<li><strong>Explained Variance</strong>: The amount of variance that each principal component explains. This information can be accessed via <code>pca.explained_variance_ratio_</code>.</li>
<li><strong>Component Loadings</strong>: The coefficients of the linear combinations that form the principal components. This information can be accessed via <code>pca.components_</code>.</li>
</ul>
</div><h1>Comparison of Explained Variance</h1>
<div class='content'><p>| Principal Component | Explained Variance |
|---------------------|--------------------|
| PC1                 | 45%                |
| PC2                 | 30%                |
| PC3                 | 15%                |
| PC4                 | 7%                 |
| PC5                 | 3%                 |</p>
</div><h1>Conclusion</h1>
<div class='content'><p>Principal Component Analysis (PCA) is a powerful tool for dimensionality reduction in Machine Learning. By transforming the original variables into principal components, PCA helps simplify models, reduce noise, and improve data visualization. It is crucial to understand the steps and interpretation of the results to effectively apply PCA in Machine Learning projects.</p>
</div>
			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
