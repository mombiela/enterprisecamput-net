<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>K-Nearest Neighbors (K-NN)</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/k-nn" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/k-nn" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/k-nn" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/machine_learning/k-nn" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/k-nn" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introduction</h1>
<div class='content'><p>The K-Nearest Neighbors (K-NN) algorithm is one of the simplest and most effective methods for classification and regression in Machine Learning. This algorithm is an instance-based method that does not make explicit assumptions about the data distribution.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Instance</strong>: A data point in the feature space.</li>
<li><strong>Neighbor</strong>: An instance close to another in the feature space.</li>
<li><strong>K</strong>: The number of nearest neighbors to consider for making a decision.</li>
<li><strong>Distance</strong>: The metric used to determine the closeness between instances (commonly Euclidean distance).</li>
</ul>
</div><h1>How the Algorithm Works</h1>
<div class='content'><ol>
<li><strong>Select the value of K</strong>: Choose the number of nearest neighbors to consider.</li>
<li><strong>Calculate the distance</strong>: Measure the distance between the test instance and all instances in the training set.</li>
<li><strong>Identify the K nearest neighbors</strong>: Select the K instances closest to the test instance.</li>
<li><strong>Classification or regression</strong>:
<ul>
<li><strong>Classification</strong>: Assign the most common class among the K neighbors.</li>
<li><strong>Regression</strong>: Average the values of the K neighbors.</li>
</ul>
</li>
</ol>
</div><h1>Code Example</h1>
<div class='content'><p>Below is an example of implementing the K-NN algorithm using Python and the <code>scikit-learn</code> library.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ubmVpZ2hib3JzIGltcG9ydCBLTmVpZ2hib3JzQ2xhc3NpZmllcgpmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgYWNjdXJhY3lfc2NvcmUKCiMgTG9hZCB0aGUgSXJpcyBkYXRhc2V0CmlyaXMgPSBsb2FkX2lyaXMoKQpYID0gaXJpcy5kYXRhCnkgPSBpcmlzLnRhcmdldAoKIyBTcGxpdCB0aGUgZGF0YXNldCBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0aW5nIHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjMsIHJhbmRvbV9zdGF0ZT00MikKCiMgQ3JlYXRlIHRoZSBLLU5OIGNsYXNzaWZpZXIKayA9IDMKa25uID0gS05laWdoYm9yc0NsYXNzaWZpZXIobl9uZWlnaGJvcnM9aykKCiMgVHJhaW4gdGhlIGNsYXNzaWZpZXIKa25uLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IGtubi5wcmVkaWN0KFhfdGVzdCkKCiMgRXZhbHVhdGUgcGVyZm9ybWFuY2UKYWNjdXJhY3kgPSBhY2N1cmFjeV9zY29yZSh5X3Rlc3QsIHlfcHJlZCkKcHJpbnQoZiJBY2N1cmFjeSBvZiB0aGUgSy1OTiBtb2RlbCB3aXRoIGs9e2t9OiB7YWNjdXJhY3k6LjJmfSIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create the K-NN classifier
k = 3
knn = KNeighborsClassifier(n_neighbors=k)

# Train the classifier
knn.fit(X_train, y_train)

# Make predictions
y_pred = knn.predict(X_test)

# Evaluate performance
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy of the K-NN model with k={k}: {accuracy:.2f}&quot;)</pre></div><div class='content'></div><h1>Selecting the Value of K</h1>
<div class='content'><p>Choosing the value of K is crucial for the algorithm's performance. A very small value of K can make the model sensitive to noise, while a very large value of K can overly smooth the decision.</p>
</div><h2>Comparison of K Values</h2>
<div class='content'><p>| Value of K | Advantages | Disadvantages |
|------------|------------|---------------|
| Small (e.g., K=1) | Captures fine details | Sensitive to noise |
| Large (e.g., K=20) | Smooths the decision | May lose important details |</p>
</div><h1>Distance Metrics</h1>
<div class='content'><ul>
<li><strong>Euclidean Distance</strong>: The most common, suitable for continuous data.</li>
<li><strong>Manhattan Distance</strong>: Suitable for data with categorical features.</li>
<li><strong>Minkowski Distance</strong>: Generalizes Euclidean and Manhattan distances.</li>
</ul>
</div><h1>Advantages and Disadvantages</h1>
<div class='content'><ul>
<li><strong>Advantages</strong>:
<ul>
<li>Easy to understand and implement.</li>
<li>Does not require an explicit training model.</li>
</ul>
</li>
<li><strong>Disadvantages</strong>:
<ul>
<li>Computationally expensive for large datasets.</li>
<li>Sensitive to the scale of features.</li>
</ul>
</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>The K-Nearest Neighbors algorithm is a powerful and simple tool for classification and regression tasks. Its effectiveness largely depends on the appropriate choice of the value of K and the distance metric used. Although computationally intensive, its simplicity and ability to handle non-linear data make it a valuable option in any Machine Learning professional's arsenal.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
