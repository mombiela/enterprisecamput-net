<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Networks</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/04-06-redes-neuronales" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/04-06-redes-neuronales" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/04-06-neural-networks" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/machine_learning/04-06-redes-neuronales" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/04-06-redes-neuronales" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-05-knn' title="K-Nearest Neighbors (K-NN)">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Neural Networks</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-01-clustering-k-means' title="Clustering: K-means">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Neural Networks are a subset of machine learning algorithms modeled after the human brain. They consist of interconnected layers of nodes (neurons) that process data to recognize patterns and make predictions. Neural Networks are particularly powerful for tasks such as image and speech recognition, natural language processing, and more.</p>
</div><h1>Key Concepts</h1>
<div class='content'></div><h2>1. Structure of a Neural Network</h2>
<div class='content'><ul>
<li><strong>Neurons</strong>: Basic units of a neural network, similar to biological neurons.</li>
<li><strong>Layers</strong>:
<ul>
<li><strong>Input Layer</strong>: Receives the input data.</li>
<li><strong>Hidden Layers</strong>: Intermediate layers that process inputs received from the input layer.</li>
<li><strong>Output Layer</strong>: Produces the final output.</li>
</ul>
</li>
</ul>
</div><h2>2. Activation Functions</h2>
<div class='content'><ul>
<li><strong>Sigmoid</strong>: \( \sigma(x) = \frac{1}{1 + e^{-x}} \)</li>
<li><strong>ReLU (Rectified Linear Unit)</strong>: \( \text{ReLU}(x) = \max(0, x) \)</li>
<li><strong>Tanh</strong>: \( \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \)</li>
</ul>
</div><h2>3. Forward Propagation</h2>
<div class='content'><p>The process of passing input data through the network to get the output.</p>
</div><h2>4. Backpropagation</h2>
<div class='content'><p>The process of updating the weights of the network based on the error of the output.</p>
</div><h2>5. Loss Function</h2>
<div class='content'><p>A function that measures the difference between the predicted output and the actual output. Common loss functions include Mean Squared Error (MSE) and Cross-Entropy Loss.</p>
</div><h2>6. Optimization Algorithms</h2>
<div class='content'><p>Methods used to minimize the loss function. Common algorithms include Gradient Descent, Stochastic Gradient Descent (SGD), and Adam.</p>
</div><h1>Practical Example</h1>
<div class='content'></div><h2>Building a Simple Neural Network with Python</h2>
<div class='content'><p>We'll use the popular library <code>TensorFlow</code> to build a simple neural network for binary classification.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZQpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5kYXRhc2V0cyBpbXBvcnQgbWFrZV9jbGFzc2lmaWNhdGlvbgoKIyBHZW5lcmF0ZSBhIHN5bnRoZXRpYyBkYXRhc2V0ClgsIHkgPSBtYWtlX2NsYXNzaWZpY2F0aW9uKG5fc2FtcGxlcz0xMDAwLCBuX2ZlYXR1cmVzPTIwLCBuX2NsYXNzZXM9MiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBTcGxpdCB0aGUgZGF0YXNldCBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0aW5nIHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjIsIHJhbmRvbV9zdGF0ZT00MikKCiMgQnVpbGQgdGhlIG5ldXJhbCBuZXR3b3JrIG1vZGVsCm1vZGVsID0gU2VxdWVudGlhbChbCiAgICBEZW5zZSgzMiwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSgyMCwpKSwKICAgIERlbnNlKDE2LCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykKXSkKCiMgQ29tcGlsZSB0aGUgbW9kZWwKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdiaW5hcnlfY3Jvc3NlbnRyb3B5JywgbWV0cmljcz1bJ2FjY3VyYWN5J10pCgojIFRyYWluIHRoZSBtb2RlbAptb2RlbC5maXQoWF90cmFpbiwgeV90cmFpbiwgZXBvY2hzPTEwLCBiYXRjaF9zaXplPTMyLCB2YWxpZGF0aW9uX3NwbGl0PTAuMikKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmxvc3MsIGFjY3VyYWN5ID0gbW9kZWwuZXZhbHVhdGUoWF90ZXN0LCB5X3Rlc3QpCnByaW50KGYnVGVzdCBBY2N1cmFjeToge2FjY3VyYWN5Oi4yZn0nKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification

# Generate a synthetic dataset
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the neural network model
model = Sequential([
    Dense(32, activation='relu', input_shape=(20,)),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy:.2f}')</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ol>
<li><strong>Data Generation</strong>: We use <code>make_classification</code> to generate a synthetic dataset with 1000 samples and 20 features.</li>
<li><strong>Data Splitting</strong>: The dataset is split into training and testing sets.</li>
<li><strong>Model Building</strong>: We create a <code>Sequential</code> model with three layers:
<ul>
<li>An input layer with 32 neurons and ReLU activation.</li>
<li>A hidden layer with 16 neurons and ReLU activation.</li>
<li>An output layer with 1 neuron and Sigmoid activation for binary classification.</li>
</ul>
</li>
<li><strong>Model Compilation</strong>: The model is compiled with the Adam optimizer and binary cross-entropy loss function.</li>
<li><strong>Model Training</strong>: The model is trained for 10 epochs with a batch size of 32.</li>
<li><strong>Model Evaluation</strong>: The model's accuracy is evaluated on the test set.</li>
</ol>
</div><h1>Practical Exercises</h1>
<div class='content'></div><h2>Exercise 1: Modify the Neural Network</h2>
<div class='content'><p>Modify the neural network to have two hidden layers with 64 and 32 neurons, respectively. Train the model and evaluate its performance.</p>
<h4>Solution</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBCdWlsZCB0aGUgbW9kaWZpZWQgbmV1cmFsIG5ldHdvcmsgbW9kZWwKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDY0LCBhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KDIwLCkpLAogICAgRGVuc2UoMzIsIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIERlbnNlKDEsIGFjdGl2YXRpb249J3NpZ21vaWQnKQpdKQoKIyBDb21waWxlIHRoZSBtb2RlbAptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSkKCiMgVHJhaW4gdGhlIG1vZGVsCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluLCBlcG9jaHM9MTAsIGJhdGNoX3NpemU9MzIsIHZhbGlkYXRpb25fc3BsaXQ9MC4yKQoKIyBFdmFsdWF0ZSB0aGUgbW9kZWwKbG9zcywgYWNjdXJhY3kgPSBtb2RlbC5ldmFsdWF0ZShYX3Rlc3QsIHlfdGVzdCkKcHJpbnQoZidUZXN0IEFjY3VyYWN5OiB7YWNjdXJhY3k6LjJmfScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Build the modified neural network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(20,)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy:.2f}')</pre></div><div class='content'></div><h2>Exercise 2: Change the Activation Function</h2>
<div class='content'><p>Change the activation function of the hidden layers to <code>tanh</code> and observe the impact on the model's performance.</p>
<h4>Solution</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBCdWlsZCB0aGUgbmV1cmFsIG5ldHdvcmsgbW9kZWwgd2l0aCB0YW5oIGFjdGl2YXRpb24KbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDMyLCBhY3RpdmF0aW9uPSd0YW5oJywgaW5wdXRfc2hhcGU9KDIwLCkpLAogICAgRGVuc2UoMTYsIGFjdGl2YXRpb249J3RhbmgnKSwKICAgIERlbnNlKDEsIGFjdGl2YXRpb249J3NpZ21vaWQnKQpdKQoKIyBDb21waWxlIHRoZSBtb2RlbAptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSkKCiMgVHJhaW4gdGhlIG1vZGVsCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluLCBlcG9jaHM9MTAsIGJhdGNoX3NpemU9MzIsIHZhbGlkYXRpb25fc3BsaXQ9MC4yKQoKIyBFdmFsdWF0ZSB0aGUgbW9kZWwKbG9zcywgYWNjdXJhY3kgPSBtb2RlbC5ldmFsdWF0ZShYX3Rlc3QsIHlfdGVzdCkKcHJpbnQoZidUZXN0IEFjY3VyYWN5OiB7YWNjdXJhY3k6LjJmfScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Build the neural network model with tanh activation
model = Sequential([
    Dense(32, activation='tanh', input_shape=(20,)),
    Dense(16, activation='tanh'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy:.2f}')</pre></div><div class='content'></div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Overfitting</strong>: Ensure you monitor the validation loss to detect overfitting. Use techniques like dropout or regularization to mitigate it.</li>
<li><strong>Learning Rate</strong>: Choosing an appropriate learning rate is crucial. Too high can cause the model to converge too quickly to a suboptimal solution, while too low can make the training process very slow.</li>
<li><strong>Data Preprocessing</strong>: Properly preprocess your data (normalization, handling missing values) to improve model performance.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we covered the basics of neural networks, including their structure, key concepts, and practical implementation using TensorFlow. We also provided exercises to reinforce the learned concepts. Understanding neural networks is fundamental for tackling more complex machine learning tasks and advancing in the field of deep learning.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-05-knn' title="K-Nearest Neighbors (K-NN)">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-01-clustering-k-means' title="Clustering: K-means">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
