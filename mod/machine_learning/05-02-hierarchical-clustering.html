<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hierarchical Clustering</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/05-02-clustering-jerarquico" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/05-02-clustering-jerarquico" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/05-02-hierarchical-clustering" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/machine_learning/05-02-clustering-jerarquico" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/05-02-clustering-jerarquico" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-01-clustering-k-means' title="Clustering: K-means">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Hierarchical Clustering</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-03-pca' title="Principal Component Analysis (PCA)">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Hierarchical clustering is a method of cluster analysis which seeks to build a hierarchy of clusters. Unlike other clustering techniques, hierarchical clustering does not require the number of clusters to be specified in advance. It is particularly useful for discovering the underlying structure of the data.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'></div><h2><p>Types of Hierarchical Clustering</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Agglomerative (Bottom-Up) Clustering</strong>:</p>
<ul>
<li>Starts with each data point as a single cluster.</li>
<li>Iteratively merges the closest pairs of clusters until only one cluster remains or a stopping criterion is met.</li>
</ul>
</li>
<li>
<p><strong>Divisive (Top-Down) Clustering</strong>:</p>
<ul>
<li>Starts with all data points in a single cluster.</li>
<li>Iteratively splits the clusters into smaller clusters until each cluster contains a single data point or a stopping criterion is met.</li>
</ul>
</li>
</ol>
</div><h2><p>Dendrogram</p>
</h2>
<div class='content'><ul>
<li>A dendrogram is a tree-like diagram that records the sequences of merges or splits.</li>
<li>The y-axis represents the distance or dissimilarity between clusters.</li>
<li>The x-axis represents the individual data points.</li>
</ul>
</div><h2><p>Linkage Criteria</p>
</h2>
<div class='content'><ul>
<li><strong>Single Linkage</strong>: Distance between the closest points of the clusters.</li>
<li><strong>Complete Linkage</strong>: Distance between the farthest points of the clusters.</li>
<li><strong>Average Linkage</strong>: Average distance between all pairs of points in the clusters.</li>
<li><strong>Ward's Method</strong>: Minimizes the total within-cluster variance.</li>
</ul>
</div><h1><p>Steps in Hierarchical Clustering</p>
</h1>
<div class='content'><ol>
<li>
<p><strong>Calculate the Distance Matrix</strong>:</p>
<ul>
<li>Compute the pairwise distance between all data points using a distance metric (e.g., Euclidean distance).</li>
</ul>
</li>
<li>
<p><strong>Choose a Linkage Criteria</strong>:</p>
<ul>
<li>Decide on the method to measure the distance between clusters (e.g., single, complete, average, Ward's).</li>
</ul>
</li>
<li>
<p><strong>Build the Dendrogram</strong>:</p>
<ul>
<li>Start with each data point as its own cluster.</li>
<li>Merge the closest clusters based on the chosen linkage criteria.</li>
<li>Repeat until all points are merged into a single cluster.</li>
</ul>
</li>
<li>
<p><strong>Cut the Dendrogram</strong>:</p>
<ul>
<li>Determine the number of clusters by cutting the dendrogram at the desired level.</li>
</ul>
</li>
</ol>
</div><h1><p>Practical Example</p>
</h1>
<div class='content'></div><h2><p>Example Data</p>
</h2>
<div class='content'><p>Let's consider a simple dataset with 5 points in a 2D space:</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>B</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>D</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>E</td>
<td>8</td>
<td>8</td>
</tr>
</tbody>
</table>
</div><h2><p>Python Implementation</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBzY2lweS5jbHVzdGVyLmhpZXJhcmNoeSBpbXBvcnQgZGVuZHJvZ3JhbSwgbGlua2FnZQoKIyBTYW1wbGUgZGF0YQpkYXRhID0gbnAuYXJyYXkoW1sxLCAyXSwgWzIsIDNdLCBbMywgNF0sIFs1LCA2XSwgWzgsIDhdXSkKCiMgUGVyZm9ybSBoaWVyYXJjaGljYWwvYWdnbG9tZXJhdGl2ZSBjbHVzdGVyaW5nClogPSBsaW5rYWdlKGRhdGEsIG1ldGhvZD0nd2FyZCcpCgojIFBsb3QgdGhlIGRlbmRyb2dyYW0KcGx0LmZpZ3VyZShmaWdzaXplPSgxMCwgNykpCmRlbmRyb2dyYW0oWiwgbGFiZWxzPVsnQScsICdCJywgJ0MnLCAnRCcsICdFJ10pCnBsdC50aXRsZSgnRGVuZHJvZ3JhbSBmb3IgSGllcmFyY2hpY2FsIENsdXN0ZXJpbmcnKQpwbHQueGxhYmVsKCdEYXRhIFBvaW50cycpCnBsdC55bGFiZWwoJ0Rpc3RhbmNlJykKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

# Sample data
data = np.array([[1, 2], [2, 3], [3, 4], [5, 6], [8, 8]])

# Perform hierarchical/agglomerative clustering
Z = linkage(data, method='ward')

# Plot the dendrogram
plt.figure(figsize=(10, 7))
dendrogram(Z, labels=['A', 'B', 'C', 'D', 'E'])
plt.title('Dendrogram for Hierarchical Clustering')
plt.xlabel('Data Points')
plt.ylabel('Distance')
plt.show()</pre></div><div class='content'></div><h2><p>Explanation</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Data Preparation</strong>:</p>
<ul>
<li>We create a numpy array with our sample data points.</li>
</ul>
</li>
<li>
<p><strong>Linkage Calculation</strong>:</p>
<ul>
<li>We use the <code>linkage</code> function from <code>scipy.cluster.hierarchy</code> to perform hierarchical clustering. Here, we use Ward's method.</li>
</ul>
</li>
<li>
<p><strong>Dendrogram Plotting</strong>:</p>
<ul>
<li>We plot the dendrogram using the <code>dendrogram</code> function. The labels correspond to our data points.</li>
</ul>
</li>
</ol>
</div><h1><p>Practical Exercise</p>
</h1>
<div class='content'></div><h2><p>Exercise</p>
</h2>
<div class='content'><p>Given the following dataset, perform hierarchical clustering using complete linkage and plot the dendrogram.</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody>
<tr>
<td>F</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>G</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>H</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>I</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>J</td>
<td>7</td>
<td>5</td>
</tr>
</tbody>
</table>
</div><h2><p>Solution</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBzY2lweS5jbHVzdGVyLmhpZXJhcmNoeSBpbXBvcnQgZGVuZHJvZ3JhbSwgbGlua2FnZQoKIyBTYW1wbGUgZGF0YQpkYXRhID0gbnAuYXJyYXkoW1sxLCAxXSwgWzIsIDFdLCBbNCwgM10sIFs1LCA0XSwgWzcsIDVdXSkKCiMgUGVyZm9ybSBoaWVyYXJjaGljYWwvYWdnbG9tZXJhdGl2ZSBjbHVzdGVyaW5nClogPSBsaW5rYWdlKGRhdGEsIG1ldGhvZD0nY29tcGxldGUnKQoKIyBQbG90IHRoZSBkZW5kcm9ncmFtCnBsdC5maWd1cmUoZmlnc2l6ZT0oMTAsIDcpKQpkZW5kcm9ncmFtKFosIGxhYmVscz1bJ0YnLCAnRycsICdIJywgJ0knLCAnSiddKQpwbHQudGl0bGUoJ0RlbmRyb2dyYW0gZm9yIEhpZXJhcmNoaWNhbCBDbHVzdGVyaW5nIChDb21wbGV0ZSBMaW5rYWdlKScpCnBsdC54bGFiZWwoJ0RhdGEgUG9pbnRzJykKcGx0LnlsYWJlbCgnRGlzdGFuY2UnKQpwbHQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

# Sample data
data = np.array([[1, 1], [2, 1], [4, 3], [5, 4], [7, 5]])

# Perform hierarchical/agglomerative clustering
Z = linkage(data, method='complete')

# Plot the dendrogram
plt.figure(figsize=(10, 7))
dendrogram(Z, labels=['F', 'G', 'H', 'I', 'J'])
plt.title('Dendrogram for Hierarchical Clustering (Complete Linkage)')
plt.xlabel('Data Points')
plt.ylabel('Distance')
plt.show()</pre></div><div class='content'></div><h2><p>Explanation</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Data Preparation</strong>:</p>
<ul>
<li>We create a numpy array with our sample data points.</li>
</ul>
</li>
<li>
<p><strong>Linkage Calculation</strong>:</p>
<ul>
<li>We use the <code>linkage</code> function from <code>scipy.cluster.hierarchy</code> to perform hierarchical clustering with complete linkage.</li>
</ul>
</li>
<li>
<p><strong>Dendrogram Plotting</strong>:</p>
<ul>
<li>We plot the dendrogram using the <code>dendrogram</code> function. The labels correspond to our data points.</li>
</ul>
</li>
</ol>
</div><h1><p>Summary</p>
</h1>
<div class='content'><p>Hierarchical clustering is a versatile clustering technique that builds a hierarchy of clusters without requiring the number of clusters to be specified in advance. By understanding the different types of hierarchical clustering, linkage criteria, and how to interpret dendrograms, you can effectively apply this method to various datasets.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-01-clustering-k-means' title="Clustering: K-means">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-03-pca' title="Principal Component Analysis (PCA)">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
