<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Hierarchical Clustering</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/05-02-clustering-jerarquico" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/05-02-clustering-jerarquico" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/05-02-hierarchical-clustering" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/machine_learning/05-02-clustering-jerarquico" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/machine_learning/05-02-clustering-jerarquico" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-clustering-k-means' title="Clustering: K-means">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Hierarchical Clustering</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-pca' title="Principal Component Analysis (PCA)">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Hierarchical clustering is a method of cluster analysis which seeks to build a hierarchy of clusters. Unlike other clustering techniques, hierarchical clustering does not require the number of clusters to be specified in advance. It is particularly useful for discovering the underlying structure of the data.</p>
</div><h1>Key Concepts</h1>
<div class='content'></div><h2>Types of Hierarchical Clustering</h2>
<div class='content'><ol>
<li>
<p><strong>Agglomerative (Bottom-Up) Clustering</strong>:</p>
<ul>
<li>Starts with each data point as a single cluster.</li>
<li>Iteratively merges the closest pairs of clusters until only one cluster remains or a stopping criterion is met.</li>
</ul>
</li>
<li>
<p><strong>Divisive (Top-Down) Clustering</strong>:</p>
<ul>
<li>Starts with all data points in a single cluster.</li>
<li>Iteratively splits the clusters into smaller clusters until each cluster contains a single data point or a stopping criterion is met.</li>
</ul>
</li>
</ol>
</div><h2>Dendrogram</h2>
<div class='content'><ul>
<li>A dendrogram is a tree-like diagram that records the sequences of merges or splits.</li>
<li>The y-axis represents the distance or dissimilarity between clusters.</li>
<li>The x-axis represents the individual data points.</li>
</ul>
</div><h2>Linkage Criteria</h2>
<div class='content'><ul>
<li><strong>Single Linkage</strong>: Distance between the closest points of the clusters.</li>
<li><strong>Complete Linkage</strong>: Distance between the farthest points of the clusters.</li>
<li><strong>Average Linkage</strong>: Average distance between all pairs of points in the clusters.</li>
<li><strong>Ward's Method</strong>: Minimizes the total within-cluster variance.</li>
</ul>
</div><h1>Steps in Hierarchical Clustering</h1>
<div class='content'><ol>
<li>
<p><strong>Calculate the Distance Matrix</strong>:</p>
<ul>
<li>Compute the pairwise distance between all data points using a distance metric (e.g., Euclidean distance).</li>
</ul>
</li>
<li>
<p><strong>Choose a Linkage Criteria</strong>:</p>
<ul>
<li>Decide on the method to measure the distance between clusters (e.g., single, complete, average, Ward's).</li>
</ul>
</li>
<li>
<p><strong>Build the Dendrogram</strong>:</p>
<ul>
<li>Start with each data point as its own cluster.</li>
<li>Merge the closest clusters based on the chosen linkage criteria.</li>
<li>Repeat until all points are merged into a single cluster.</li>
</ul>
</li>
<li>
<p><strong>Cut the Dendrogram</strong>:</p>
<ul>
<li>Determine the number of clusters by cutting the dendrogram at the desired level.</li>
</ul>
</li>
</ol>
</div><h1>Practical Example</h1>
<div class='content'></div><h2>Example Data</h2>
<div class='content'><p>Let's consider a simple dataset with 5 points in a 2D space:</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>B</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>D</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>E</td>
<td>8</td>
<td>8</td>
</tr>
</tbody>
</table>
</div><h2>Python Implementation</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBzY2lweS5jbHVzdGVyLmhpZXJhcmNoeSBpbXBvcnQgZGVuZHJvZ3JhbSwgbGlua2FnZQoKIyBTYW1wbGUgZGF0YQpkYXRhID0gbnAuYXJyYXkoW1sxLCAyXSwgWzIsIDNdLCBbMywgNF0sIFs1LCA2XSwgWzgsIDhdXSkKCiMgUGVyZm9ybSBoaWVyYXJjaGljYWwvYWdnbG9tZXJhdGl2ZSBjbHVzdGVyaW5nClogPSBsaW5rYWdlKGRhdGEsIG1ldGhvZD0nd2FyZCcpCgojIFBsb3QgdGhlIGRlbmRyb2dyYW0KcGx0LmZpZ3VyZShmaWdzaXplPSgxMCwgNykpCmRlbmRyb2dyYW0oWiwgbGFiZWxzPVsnQScsICdCJywgJ0MnLCAnRCcsICdFJ10pCnBsdC50aXRsZSgnRGVuZHJvZ3JhbSBmb3IgSGllcmFyY2hpY2FsIENsdXN0ZXJpbmcnKQpwbHQueGxhYmVsKCdEYXRhIFBvaW50cycpCnBsdC55bGFiZWwoJ0Rpc3RhbmNlJykKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

# Sample data
data = np.array([[1, 2], [2, 3], [3, 4], [5, 6], [8, 8]])

# Perform hierarchical/agglomerative clustering
Z = linkage(data, method='ward')

# Plot the dendrogram
plt.figure(figsize=(10, 7))
dendrogram(Z, labels=['A', 'B', 'C', 'D', 'E'])
plt.title('Dendrogram for Hierarchical Clustering')
plt.xlabel('Data Points')
plt.ylabel('Distance')
plt.show()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ol>
<li>
<p><strong>Data Preparation</strong>:</p>
<ul>
<li>We create a numpy array with our sample data points.</li>
</ul>
</li>
<li>
<p><strong>Linkage Calculation</strong>:</p>
<ul>
<li>We use the <code>linkage</code> function from <code>scipy.cluster.hierarchy</code> to perform hierarchical clustering. Here, we use Ward's method.</li>
</ul>
</li>
<li>
<p><strong>Dendrogram Plotting</strong>:</p>
<ul>
<li>We plot the dendrogram using the <code>dendrogram</code> function. The labels correspond to our data points.</li>
</ul>
</li>
</ol>
</div><h1>Practical Exercise</h1>
<div class='content'></div><h2>Exercise</h2>
<div class='content'><p>Given the following dataset, perform hierarchical clustering using complete linkage and plot the dendrogram.</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody>
<tr>
<td>F</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>G</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>H</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>I</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>J</td>
<td>7</td>
<td>5</td>
</tr>
</tbody>
</table>
</div><h2>Solution</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBzY2lweS5jbHVzdGVyLmhpZXJhcmNoeSBpbXBvcnQgZGVuZHJvZ3JhbSwgbGlua2FnZQoKIyBTYW1wbGUgZGF0YQpkYXRhID0gbnAuYXJyYXkoW1sxLCAxXSwgWzIsIDFdLCBbNCwgM10sIFs1LCA0XSwgWzcsIDVdXSkKCiMgUGVyZm9ybSBoaWVyYXJjaGljYWwvYWdnbG9tZXJhdGl2ZSBjbHVzdGVyaW5nClogPSBsaW5rYWdlKGRhdGEsIG1ldGhvZD0nY29tcGxldGUnKQoKIyBQbG90IHRoZSBkZW5kcm9ncmFtCnBsdC5maWd1cmUoZmlnc2l6ZT0oMTAsIDcpKQpkZW5kcm9ncmFtKFosIGxhYmVscz1bJ0YnLCAnRycsICdIJywgJ0knLCAnSiddKQpwbHQudGl0bGUoJ0RlbmRyb2dyYW0gZm9yIEhpZXJhcmNoaWNhbCBDbHVzdGVyaW5nIChDb21wbGV0ZSBMaW5rYWdlKScpCnBsdC54bGFiZWwoJ0RhdGEgUG9pbnRzJykKcGx0LnlsYWJlbCgnRGlzdGFuY2UnKQpwbHQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

# Sample data
data = np.array([[1, 1], [2, 1], [4, 3], [5, 4], [7, 5]])

# Perform hierarchical/agglomerative clustering
Z = linkage(data, method='complete')

# Plot the dendrogram
plt.figure(figsize=(10, 7))
dendrogram(Z, labels=['F', 'G', 'H', 'I', 'J'])
plt.title('Dendrogram for Hierarchical Clustering (Complete Linkage)')
plt.xlabel('Data Points')
plt.ylabel('Distance')
plt.show()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ol>
<li>
<p><strong>Data Preparation</strong>:</p>
<ul>
<li>We create a numpy array with our sample data points.</li>
</ul>
</li>
<li>
<p><strong>Linkage Calculation</strong>:</p>
<ul>
<li>We use the <code>linkage</code> function from <code>scipy.cluster.hierarchy</code> to perform hierarchical clustering with complete linkage.</li>
</ul>
</li>
<li>
<p><strong>Dendrogram Plotting</strong>:</p>
<ul>
<li>We plot the dendrogram using the <code>dendrogram</code> function. The labels correspond to our data points.</li>
</ul>
</li>
</ol>
</div><h1>Summary</h1>
<div class='content'><p>Hierarchical clustering is a versatile clustering technique that builds a hierarchy of clusters without requiring the number of clusters to be specified in advance. By understanding the different types of hierarchical clustering, linkage criteria, and how to interpret dendrograms, you can effectively apply this method to various datasets.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-clustering-k-means' title="Clustering: K-means">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-pca' title="Principal Component Analysis (PCA)">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Machine Learning Course</h1>
<h2>Module 1: Introduction to Machine Learning</h2>
<ul>
<li><a href="01-01-what-is-machine-learning">What is Machine Learning?</a></li>
<li><a href="01-02-history-evolution-machine-learning">History and Evolution of Machine Learning</a></li>
<li><a href="01-03-types-machine-learning">Types of Machine Learning</a></li>
<li><a href="01-04-applications-machine-learning">Applications of Machine Learning</a></li>
</ul>
<h2>Module 2: Fundamentals of Statistics and Probability</h2>
<ul>
<li><a href="02-01-basic-concepts-statistics">Basic Concepts of Statistics</a></li>
<li><a href="02-02-probability-distributions">Probability Distributions</a></li>
<li><a href="02-03-statistical-inference">Statistical Inference</a></li>
<li><a href="02-04-bayes-theorem">Bayes' Theorem</a></li>
</ul>
<h2>Module 3: Data Preprocessing</h2>
<ul>
<li><a href="03-01-data-cleaning">Data Cleaning</a></li>
<li><a href="03-02-data-transformation">Data Transformation</a></li>
<li><a href="03-03-normalization-standardization">Normalization and Standardization</a></li>
<li><a href="03-04-handling-missing-data">Handling Missing Data</a></li>
</ul>
<h2>Module 4: Supervised Machine Learning Algorithms</h2>
<ul>
<li><a href="04-01-linear-regression">Linear Regression</a></li>
<li><a href="04-02-logistic-regression">Logistic Regression</a></li>
<li><a href="04-03-decision-trees">Decision Trees</a></li>
<li><a href="04-04-svm">Support Vector Machines (SVM)</a></li>
<li><a href="04-05-knn">K-Nearest Neighbors (K-NN)</a></li>
<li><a href="04-06-neural-networks">Neural Networks</a></li>
</ul>
<h2>Module 5: Unsupervised Machine Learning Algorithms</h2>
<ul>
<li><a href="05-01-clustering-k-means">Clustering: K-means</a></li>
<li><a href="05-02-hierarchical-clustering">Hierarchical Clustering</a></li>
<li><a href="05-03-pca">Principal Component Analysis (PCA)</a></li>
<li><a href="05-04-dbscan">DBSCAN Clustering Analysis</a></li>
</ul>
<h2>Module 6: Model Evaluation and Validation</h2>
<ul>
<li><a href="06-01-evaluation-metrics">Evaluation Metrics</a></li>
<li><a href="06-02-cross-validation">Cross-Validation</a></li>
<li><a href="06-03-roc-curve-auc">ROC Curve and AUC</a></li>
<li><a href="06-04-overfitting-underfitting">Overfitting and Underfitting</a></li>
</ul>
<h2>Module 7: Advanced Techniques and Optimization</h2>
<ul>
<li><a href="07-01-ensemble-learning">Ensemble Learning</a></li>
<li><a href="07-02-gradient-boosting">Gradient Boosting</a></li>
<li><a href="07-03-deep-learning">Deep Learning</a></li>
<li><a href="07-04-hyperparameter-optimization">Hyperparameter Optimization</a></li>
</ul>
<h2>Module 8: Model Implementation and Deployment</h2>
<ul>
<li><a href="08-01-frameworks-libraries">Popular Frameworks and Libraries</a></li>
<li><a href="08-02-implementation-production">Model Implementation in Production</a></li>
<li><a href="08-03-maintenance-monitoring">Model Maintenance and Monitoring</a></li>
<li><a href="08-04-ethics-privacy">Ethical and Privacy Considerations</a></li>
</ul>
<h2>Module 9: Practical Projects</h2>
<ul>
<li><a href="09-01-project-housing-price-prediction">Project 1: Housing Price Prediction</a></li>
<li><a href="09-02-project-image-classification">Project 2: Image Classification</a></li>
<li><a href="09-03-project-sentiment-analysis">Project 3: Sentiment Analysis on Social Media</a></li>
<li><a href="09-04-project-fraud-detection">Project 4: Fraud Detection</a></li>
</ul>
<h2>Module 10: Additional Resources</h2>
<ul>
<li><a href="10-01-recommended-books">Recommended Books</a></li>
<li><a href="10-02-online-courses">Online Courses</a></li>
<li><a href="10-03-communities-forums">Communities and Forums</a></li>
<li><a href="10-04-tools-software">Tools and Software</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
