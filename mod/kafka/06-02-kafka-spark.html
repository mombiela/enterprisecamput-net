<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka with Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/kafka/06-02-kafka-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/kafka/06-02-kafka-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/kafka/06-02-kafka-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/kafka/06-02-kafka-spark" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/kafka/06-02-kafka-spark" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='06-01-kafka-hadoop' title="Kafka with Hadoop">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Kafka with Spark</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-03-kafka-flink' title="Kafka with Flink">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this module, we will explore how Apache Kafka can be integrated with Apache Spark to build robust, scalable, and real-time data processing pipelines. We will cover the following key concepts:</p>
<ol>
<li><strong>Introduction to Kafka and Spark Integration</strong></li>
<li><strong>Setting Up Kafka and Spark</strong></li>
<li><strong>Reading Data from Kafka in Spark</strong></li>
<li><strong>Processing Data with Spark Streaming</strong></li>
<li><strong>Writing Data to Kafka from Spark</strong></li>
<li><strong>Practical Exercises</strong></li>
</ol>
</div><h1><ol>
<li>Introduction to Kafka and Spark Integration</li>
</ol>
</h1>
<div class='content'><p>Apache Kafka and Apache Spark are two powerful tools for real-time data processing. Kafka is a distributed streaming platform that can handle high-throughput, low-latency data streams. Spark, on the other hand, is a unified analytics engine for large-scale data processing, known for its speed and ease of use.</p>
</div><h2><p>Key Benefits of Integrating Kafka with Spark:</p>
</h2>
<div class='content'><ul>
<li><strong>Real-time Data Processing</strong>: Spark can process data in real-time as it is ingested by Kafka.</li>
<li><strong>Scalability</strong>: Both Kafka and Spark are designed to scale horizontally, making them suitable for large-scale data processing.</li>
<li><strong>Fault Tolerance</strong>: Both systems provide mechanisms for fault tolerance, ensuring data integrity and reliability.</li>
</ul>
</div><h1><ol start="2">
<li>Setting Up Kafka and Spark</li>
</ol>
</h1>
<div class='content'><p>Before we dive into the integration, let's set up Kafka and Spark on your local machine.</p>
</div><h2><p>Prerequisites:</p>
</h2>
<div class='content'><ul>
<li>Java 8 or higher</li>
<li>Apache Kafka</li>
<li>Apache Spark</li>
</ul>
</div><h2><p>Step-by-Step Setup:</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Download and Install Kafka</strong>:</p>
<ul>
<li>Download Kafka from the <a href="https://kafka.apache.org/downloads">official website</a>.</li>
<li>Extract the downloaded file and navigate to the Kafka directory.</li>
<li>Start the ZooKeeper server:
<pre><code class="language-sh">bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>
</li>
<li>Start the Kafka server:
<pre><code class="language-sh">bin/kafka-server-start.sh config/server.properties
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>Download and Install Spark</strong>:</p>
<ul>
<li>Download Spark from the <a href="https://spark.apache.org/downloads.html">official website</a>.</li>
<li>Extract the downloaded file and navigate to the Spark directory.</li>
<li>Start the Spark shell:
<pre><code class="language-sh">bin/spark-shell
</code></pre>
</li>
</ul>
</li>
</ol>
</div><h1><ol start="3">
<li>Reading Data from Kafka in Spark</li>
</ol>
</h1>
<div class='content'><p>To read data from Kafka in Spark, we will use the <code>spark-sql-kafka</code> package. This package allows Spark to read data from Kafka topics.</p>
</div><h2><p>Example Code:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyCiAgLmFwcE5hbWUoIkthZmthU3BhcmtJbnRlZ3JhdGlvbiIpCiAgLm1hc3RlcigibG9jYWxbKl0iKQogIC5nZXRPckNyZWF0ZSgpCgovLyBSZWFkIGRhdGEgZnJvbSBLYWZrYQp2YWwga2Fma2FERiA9IHNwYXJrLnJlYWRTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInN1YnNjcmliZSIsICJ0ZXN0LXRvcGljIikKICAubG9hZCgpCgovLyBDb252ZXJ0IHRoZSBiaW5hcnkgdmFsdWUgdG8gc3RyaW5nCnZhbCBzdHJpbmdERiA9IGthZmthREYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIikKCi8vIFByaW50IHRoZSBzY2hlbWEKc3RyaW5nREYucHJpbnRTY2hlbWEoKQoKLy8gU3RhcnQgdGhlIHN0cmVhbWluZyBxdWVyeQp2YWwgcXVlcnkgPSBzdHJpbmdERi53cml0ZVN0cmVhbQogIC5vdXRwdXRNb2RlKCJhcHBlbmQiKQogIC5mb3JtYXQoImNvbnNvbGUiKQogIC5zdGFydCgpCgpxdWVyeS5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName(&quot;KafkaSparkIntegration&quot;)
  .master(&quot;local[*]&quot;)
  .getOrCreate()

// Read data from Kafka
val kafkaDF = spark.readStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;subscribe&quot;, &quot;test-topic&quot;)
  .load()

// Convert the binary value to string
val stringDF = kafkaDF.selectExpr(&quot;CAST(value AS STRING)&quot;)

// Print the schema
stringDF.printSchema()

// Start the streaming query
val query = stringDF.writeStream
  .outputMode(&quot;append&quot;)
  .format(&quot;console&quot;)
  .start()

query.awaitTermination()</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong>SparkSession</strong>: Entry point to Spark functionality.</li>
<li><strong>kafka.bootstrap.servers</strong>: Kafka broker address.</li>
<li><strong>subscribe</strong>: Kafka topic to read from.</li>
<li><strong>CAST(value AS STRING)</strong>: Convert the binary value to a string for easier processing.</li>
<li><strong>writeStream</strong>: Write the streaming data to the console.</li>
</ul>
</div><h1><ol start="4">
<li>Processing Data with Spark Streaming</li>
</ol>
</h1>
<div class='content'><p>Once we have the data from Kafka, we can process it using Spark Streaming.</p>
</div><h2><p>Example Code:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLmZ1bmN0aW9ucy5fCgp2YWwgcHJvY2Vzc2VkREYgPSBzdHJpbmdERgogIC53aXRoQ29sdW1uKCJ0aW1lc3RhbXAiLCBjdXJyZW50X3RpbWVzdGFtcCgpKQogIC53aXRoQ29sdW1uKCJ2YWx1ZV9sZW5ndGgiLCBsZW5ndGgoY29sKCJ2YWx1ZSIpKSkKCi8vIFByaW50IHRoZSBzY2hlbWEKcHJvY2Vzc2VkREYucHJpbnRTY2hlbWEoKQoKLy8gU3RhcnQgdGhlIHN0cmVhbWluZyBxdWVyeQp2YWwgcXVlcnkgPSBwcm9jZXNzZWRERi53cml0ZVN0cmVhbQogIC5vdXRwdXRNb2RlKCJhcHBlbmQiKQogIC5mb3JtYXQoImNvbnNvbGUiKQogIC5zdGFydCgpCgpxdWVyeS5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.functions._

val processedDF = stringDF
  .withColumn(&quot;timestamp&quot;, current_timestamp())
  .withColumn(&quot;value_length&quot;, length(col(&quot;value&quot;)))

// Print the schema
processedDF.printSchema()

// Start the streaming query
val query = processedDF.writeStream
  .outputMode(&quot;append&quot;)
  .format(&quot;console&quot;)
  .start()

query.awaitTermination()</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong>current_timestamp()</strong>: Add a timestamp column to the data.</li>
<li><strong>length(col(&quot;value&quot;))</strong>: Add a column that contains the length of the value.</li>
</ul>
</div><h1><ol start="5">
<li>Writing Data to Kafka from Spark</li>
</ol>
</h1>
<div class='content'><p>After processing the data, we can write it back to a Kafka topic.</p>
</div><h2><p>Example Code:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIG91dHB1dERGID0gcHJvY2Vzc2VkREYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIEFTIGtleSIsICJDQVNUKHZhbHVlIEFTIFNUUklORykgQVMgdmFsdWUiKQoKb3V0cHV0REYud3JpdGVTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInRvcGljIiwgIm91dHB1dC10b3BpYyIpCiAgLm9wdGlvbigiY2hlY2twb2ludExvY2F0aW9uIiwgIi90bXAvY2hlY2twb2ludCIpCiAgLnN0YXJ0KCkKICAuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val outputDF = processedDF.selectExpr(&quot;CAST(value AS STRING) AS key&quot;, &quot;CAST(value AS STRING) AS value&quot;)

outputDF.writeStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;topic&quot;, &quot;output-topic&quot;)
  .option(&quot;checkpointLocation&quot;, &quot;/tmp/checkpoint&quot;)
  .start()
  .awaitTermination()</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong>selectExpr</strong>: Select and cast the columns to the appropriate types for Kafka.</li>
<li><strong>checkpointLocation</strong>: Directory to store checkpoint data for fault tolerance.</li>
</ul>
</div><h1><ol start="6">
<li>Practical Exercises</li>
</ol>
</h1>
<div class='content'></div><h2><p>Exercise 1: Basic Kafka-Spark Integration</p>
</h2>
<div class='content'><ol>
<li>Set up a Kafka topic named <code>exercise-topic</code>.</li>
<li>Write a Spark application to read data from <code>exercise-topic</code>, process it by converting the value to uppercase, and write it to a new Kafka topic named <code>exercise-output</code>.</li>
</ol>
</div><h2><p>Solution:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyCiAgLmFwcE5hbWUoIkthZmthU3BhcmtFeGVyY2lzZSIpCiAgLm1hc3RlcigibG9jYWxbKl0iKQogIC5nZXRPckNyZWF0ZSgpCgp2YWwga2Fma2FERiA9IHNwYXJrLnJlYWRTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInN1YnNjcmliZSIsICJleGVyY2lzZS10b3BpYyIpCiAgLmxvYWQoKQoKdmFsIHN0cmluZ0RGID0ga2Fma2FERi5zZWxlY3RFeHByKCJDQVNUKHZhbHVlIEFTIFNUUklORykiKQoKdmFsIHByb2Nlc3NlZERGID0gc3RyaW5nREYud2l0aENvbHVtbigidmFsdWUiLCB1cHBlcihjb2woInZhbHVlIikpKQoKdmFsIG91dHB1dERGID0gcHJvY2Vzc2VkREYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIEFTIGtleSIsICJDQVNUKHZhbHVlIEFTIFNUUklORykgQVMgdmFsdWUiKQoKb3V0cHV0REYud3JpdGVTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInRvcGljIiwgImV4ZXJjaXNlLW91dHB1dCIpCiAgLm9wdGlvbigiY2hlY2twb2ludExvY2F0aW9uIiwgIi90bXAvZXhlcmNpc2UtY2hlY2twb2ludCIpCiAgLnN0YXJ0KCkKICAuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName(&quot;KafkaSparkExercise&quot;)
  .master(&quot;local[*]&quot;)
  .getOrCreate()

val kafkaDF = spark.readStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;subscribe&quot;, &quot;exercise-topic&quot;)
  .load()

val stringDF = kafkaDF.selectExpr(&quot;CAST(value AS STRING)&quot;)

val processedDF = stringDF.withColumn(&quot;value&quot;, upper(col(&quot;value&quot;)))

val outputDF = processedDF.selectExpr(&quot;CAST(value AS STRING) AS key&quot;, &quot;CAST(value AS STRING) AS value&quot;)

outputDF.writeStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;topic&quot;, &quot;exercise-output&quot;)
  .option(&quot;checkpointLocation&quot;, &quot;/tmp/exercise-checkpoint&quot;)
  .start()
  .awaitTermination()</pre></div><div class='content'></div><h2><p>Exercise 2: Advanced Processing</p>
</h2>
<div class='content'><ol>
<li>Set up a Kafka topic named <code>advanced-topic</code>.</li>
<li>Write a Spark application to read data from <code>advanced-topic</code>, filter out messages that contain the word &quot;error&quot;, and write the filtered data to a new Kafka topic named <code>filtered-output</code>.</li>
</ol>
</div><h2><p>Solution:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyCiAgLmFwcE5hbWUoIkthZmthU3BhcmtBZHZhbmNlZEV4ZXJjaXNlIikKICAubWFzdGVyKCJsb2NhbFsqXSIpCiAgLmdldE9yQ3JlYXRlKCkKCnZhbCBrYWZrYURGID0gc3BhcmsucmVhZFN0cmVhbQogIC5mb3JtYXQoImthZmthIikKICAub3B0aW9uKCJrYWZrYS5ib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpCiAgLm9wdGlvbigic3Vic2NyaWJlIiwgImFkdmFuY2VkLXRvcGljIikKICAubG9hZCgpCgp2YWwgc3RyaW5nREYgPSBrYWZrYURGLnNlbGVjdEV4cHIoIkNBU1QodmFsdWUgQVMgU1RSSU5HKSIpCgp2YWwgZmlsdGVyZWRERiA9IHN0cmluZ0RGLmZpbHRlcighY29sKCJ2YWx1ZSIpLmNvbnRhaW5zKCJlcnJvciIpKQoKdmFsIG91dHB1dERGID0gZmlsdGVyZWRERi5zZWxlY3RFeHByKCJDQVNUKHZhbHVlIEFTIFNUUklORykgQVMga2V5IiwgIkNBU1QodmFsdWUgQVMgU1RSSU5HKSBBUyB2YWx1ZSIpCgpvdXRwdXRERi53cml0ZVN0cmVhbQogIC5mb3JtYXQoImthZmthIikKICAub3B0aW9uKCJrYWZrYS5ib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpCiAgLm9wdGlvbigidG9waWMiLCAiZmlsdGVyZWQtb3V0cHV0IikKICAub3B0aW9uKCJjaGVja3BvaW50TG9jYXRpb24iLCAiL3RtcC9hZHZhbmNlZC1jaGVja3BvaW50IikKICAuc3RhcnQoKQogIC5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName(&quot;KafkaSparkAdvancedExercise&quot;)
  .master(&quot;local[*]&quot;)
  .getOrCreate()

val kafkaDF = spark.readStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;subscribe&quot;, &quot;advanced-topic&quot;)
  .load()

val stringDF = kafkaDF.selectExpr(&quot;CAST(value AS STRING)&quot;)

val filteredDF = stringDF.filter(!col(&quot;value&quot;).contains(&quot;error&quot;))

val outputDF = filteredDF.selectExpr(&quot;CAST(value AS STRING) AS key&quot;, &quot;CAST(value AS STRING) AS value&quot;)

outputDF.writeStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;topic&quot;, &quot;filtered-output&quot;)
  .option(&quot;checkpointLocation&quot;, &quot;/tmp/advanced-checkpoint&quot;)
  .start()
  .awaitTermination()</pre></div><div class='content'></div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this module, we have learned how to integrate Apache Kafka with Apache Spark to build real-time data processing pipelines. We covered the setup of Kafka and Spark, reading data from Kafka in Spark, processing the data using Spark Streaming, and writing the processed data back to Kafka. We also provided practical exercises to reinforce the learned concepts. This integration is powerful for building scalable and fault-tolerant data processing applications.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='06-01-kafka-hadoop' title="Kafka with Hadoop">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-03-kafka-flink' title="Kafka with Flink">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
