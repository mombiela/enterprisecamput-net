<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-World Kafka Use Cases</title>

    <link rel="alternate" href="https://campusempresa.com/mod/kafka/07-01-real-world-kafka-use-cases" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/kafka/07-01-real-world-kafka-use-cases" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/kafka/07-01-real-world-kafka-use-cases" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/kafka/07-01-real-world-kafka-use-cases" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/kafka/07-01-real-world-kafka-use-cases" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='06-04-kafka-elasticsearch' title="Kafka with Elasticsearch">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Real-World Kafka Use Cases</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='07-02-kafka-best-practices' title="Kafka Best Practices">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we will explore various real-world use cases of Apache Kafka. Understanding these use cases will help you appreciate the versatility and power of Kafka in handling different types of data streaming and processing scenarios.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ol>
<li><strong>Event Streaming</strong>: Kafka is designed to handle real-time data streams, making it ideal for applications that require continuous data processing.</li>
<li><strong>Scalability</strong>: Kafka's architecture allows it to scale horizontally, making it suitable for large-scale data processing.</li>
<li><strong>Durability</strong>: Kafka ensures data durability and fault tolerance, which is crucial for mission-critical applications.</li>
</ol>
</div><h1>Use Cases</h1>
<div class='content'></div><h2>1. Log Aggregation</h2>
<div class='content'><p><strong>Description</strong>: Kafka is commonly used for collecting and aggregating log data from various sources. This data can then be processed and analyzed for monitoring and troubleshooting purposes.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Scenario</strong>: A company wants to collect logs from multiple microservices running in a distributed environment.</li>
<li><strong>Solution</strong>: Each microservice produces log messages to a Kafka topic. A consumer application reads these logs and stores them in a centralized logging system like Elasticsearch for analysis.</li>
</ul>
<p><strong>Code Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Ly8gUHJvZHVjZXIgY29kZSB0byBzZW5kIGxvZyBtZXNzYWdlcyB0byBLYWZrYQpQcm9wZXJ0aWVzIHByb3BzID0gbmV3IFByb3BlcnRpZXMoKTsKcHJvcHMucHV0KCJib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpOwpwcm9wcy5wdXQoImtleS5zZXJpYWxpemVyIiwgIm9yZy5hcGFjaGUua2Fma2EuY29tbW9uLnNlcmlhbGl6YXRpb24uU3RyaW5nU2VyaWFsaXplciIpOwpwcm9wcy5wdXQoInZhbHVlLnNlcmlhbGl6ZXIiLCAib3JnLmFwYWNoZS5rYWZrYS5jb21tb24uc2VyaWFsaXphdGlvbi5TdHJpbmdTZXJpYWxpemVyIik7CgpLYWZrYVByb2R1Y2VyPFN0cmluZywgU3RyaW5nPiBwcm9kdWNlciA9IG5ldyBLYWZrYVByb2R1Y2VyPD4ocHJvcHMpOwpmb3IgKGludCBpID0gMDsgaSA8IDEwMDsgaSsrKSB7CiAgICBwcm9kdWNlci5zZW5kKG5ldyBQcm9kdWNlclJlY29yZDw+KCJsb2dzIiwgSW50ZWdlci50b1N0cmluZyhpKSwgIkxvZyBtZXNzYWdlICIgKyBpKSk7Cn0KcHJvZHVjZXIuY2xvc2UoKTs="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>// Producer code to send log messages to Kafka
Properties props = new Properties();
props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
for (int i = 0; i &lt; 100; i++) {
    producer.send(new ProducerRecord&lt;&gt;(&quot;logs&quot;, Integer.toString(i), &quot;Log message &quot; + i));
}
producer.close();</pre></div><div class='content'></div><h2>2. Real-Time Analytics</h2>
<div class='content'><p><strong>Description</strong>: Kafka is used to process and analyze data in real-time, enabling businesses to make quick decisions based on current data.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Scenario</strong>: An e-commerce platform wants to analyze user behavior in real-time to provide personalized recommendations.</li>
<li><strong>Solution</strong>: User activity data is sent to Kafka topics. A real-time analytics engine like Apache Spark reads the data from Kafka, processes it, and updates the recommendation system.</li>
</ul>
<p><strong>Code Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5zcWwuZnVuY3Rpb25zIGltcG9ydCBmcm9tX2pzb24sIGNvbAoKc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlciBcCiAgICAuYXBwTmFtZSgiUmVhbFRpbWVBbmFseXRpY3MiKSBcCiAgICAuZ2V0T3JDcmVhdGUoKQoKIyBSZWFkIGRhdGEgZnJvbSBLYWZrYQpkZiA9IHNwYXJrIFwKICAgIC5yZWFkU3RyZWFtIFwKICAgIC5mb3JtYXQoImthZmthIikgXAogICAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKSBcCiAgICAub3B0aW9uKCJzdWJzY3JpYmUiLCAidXNlci1hY3Rpdml0eSIpIFwKICAgIC5sb2FkKCkKCiMgUHJvY2VzcyBkYXRhCmpzb25fc2NoZW1hID0gInVzZXJJZCBTVFJJTkcsIGFjdGl2aXR5IFNUUklORywgdGltZXN0YW1wIExPTkciCmRmID0gZGYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIikgXAogICAgLnNlbGVjdChmcm9tX2pzb24oY29sKCJ2YWx1ZSIpLCBqc29uX3NjaGVtYSkuYWxpYXMoImRhdGEiKSkgXAogICAgLnNlbGVjdCgiZGF0YS4qIikKCiMgV3JpdGUgcHJvY2Vzc2VkIGRhdGEgdG8gY29uc29sZSAob3IgYW55IG90aGVyIHNpbmspCnF1ZXJ5ID0gZGYud3JpdGVTdHJlYW0gXAogICAgLm91dHB1dE1vZGUoImFwcGVuZCIpIFwKICAgIC5mb3JtYXQoImNvbnNvbGUiKSBcCiAgICAuc3RhcnQoKQoKcXVlcnkuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col

spark = SparkSession.builder \
    .appName(&quot;RealTimeAnalytics&quot;) \
    .getOrCreate()

# Read data from Kafka
df = spark \
    .readStream \
    .format(&quot;kafka&quot;) \
    .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;) \
    .option(&quot;subscribe&quot;, &quot;user-activity&quot;) \
    .load()

# Process data
json_schema = &quot;userId STRING, activity STRING, timestamp LONG&quot;
df = df.selectExpr(&quot;CAST(value AS STRING)&quot;) \
    .select(from_json(col(&quot;value&quot;), json_schema).alias(&quot;data&quot;)) \
    .select(&quot;data.*&quot;)

# Write processed data to console (or any other sink)
query = df.writeStream \
    .outputMode(&quot;append&quot;) \
    .format(&quot;console&quot;) \
    .start()

query.awaitTermination()</pre></div><div class='content'></div><h2>3. Data Integration</h2>
<div class='content'><p><strong>Description</strong>: Kafka acts as a central hub for integrating data from various sources and distributing it to different destinations.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Scenario</strong>: A financial institution needs to integrate data from multiple databases and make it available to various downstream systems.</li>
<li><strong>Solution</strong>: Kafka Connect is used to ingest data from databases into Kafka topics. Consumers then read the data and process it as needed.</li>
</ul>
<p><strong>Code Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ewogICJuYW1lIjogImpkYmMtc291cmNlLWNvbm5lY3RvciIsCiAgImNvbmZpZyI6IHsKICAgICJjb25uZWN0b3IuY2xhc3MiOiAiaW8uY29uZmx1ZW50LmNvbm5lY3QuamRiYy5KZGJjU291cmNlQ29ubmVjdG9yIiwKICAgICJ0YXNrcy5tYXgiOiAiMSIsCiAgICAiY29ubmVjdGlvbi51cmwiOiAiamRiYzpteXNxbDovL2xvY2FsaG9zdDozMzA2L215ZGIiLAogICAgImNvbm5lY3Rpb24udXNlciI6ICJ1c2VyIiwKICAgICJjb25uZWN0aW9uLnBhc3N3b3JkIjogInBhc3N3b3JkIiwKICAgICJ0YWJsZS53aGl0ZWxpc3QiOiAidHJhbnNhY3Rpb25zIiwKICAgICJtb2RlIjogImluY3JlbWVudGluZyIsCiAgICAiaW5jcmVtZW50aW5nLmNvbHVtbi5uYW1lIjogImlkIiwKICAgICJ0b3BpYy5wcmVmaXgiOiAiamRiYy0iCiAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>{
  &quot;name&quot;: &quot;jdbc-source-connector&quot;,
  &quot;config&quot;: {
    &quot;connector.class&quot;: &quot;io.confluent.connect.jdbc.JdbcSourceConnector&quot;,
    &quot;tasks.max&quot;: &quot;1&quot;,
    &quot;connection.url&quot;: &quot;jdbc:mysql://localhost:3306/mydb&quot;,
    &quot;connection.user&quot;: &quot;user&quot;,
    &quot;connection.password&quot;: &quot;password&quot;,
    &quot;table.whitelist&quot;: &quot;transactions&quot;,
    &quot;mode&quot;: &quot;incrementing&quot;,
    &quot;incrementing.column.name&quot;: &quot;id&quot;,
    &quot;topic.prefix&quot;: &quot;jdbc-&quot;
  }
}</pre></div><div class='content'></div><h2>4. Stream Processing</h2>
<div class='content'><p><strong>Description</strong>: Kafka Streams API allows for building real-time stream processing applications that transform or aggregate data.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Scenario</strong>: A social media platform wants to detect trending topics in real-time.</li>
<li><strong>Solution</strong>: Kafka Streams application reads messages from a topic containing user posts, processes the data to identify trending topics, and writes the results to another topic.</li>
</ul>
<p><strong>Code Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("UHJvcGVydGllcyBwcm9wcyA9IG5ldyBQcm9wZXJ0aWVzKCk7CnByb3BzLnB1dChTdHJlYW1zQ29uZmlnLkFQUExJQ0FUSU9OX0lEX0NPTkZJRywgInRyZW5kaW5nLXRvcGljcyIpOwpwcm9wcy5wdXQoU3RyZWFtc0NvbmZpZy5CT09UU1RSQVBfU0VSVkVSU19DT05GSUcsICJsb2NhbGhvc3Q6OTA5MiIpOwpwcm9wcy5wdXQoU3RyZWFtc0NvbmZpZy5ERUZBVUxUX0tFWV9TRVJERV9DTEFTU19DT05GSUcsIFNlcmRlcy5TdHJpbmcoKS5nZXRDbGFzcygpKTsKcHJvcHMucHV0KFN0cmVhbXNDb25maWcuREVGQVVMVF9WQUxVRV9TRVJERV9DTEFTU19DT05GSUcsIFNlcmRlcy5TdHJpbmcoKS5nZXRDbGFzcygpKTsKClN0cmVhbXNCdWlsZGVyIGJ1aWxkZXIgPSBuZXcgU3RyZWFtc0J1aWxkZXIoKTsKS1N0cmVhbTxTdHJpbmcsIFN0cmluZz4gcG9zdHMgPSBidWlsZGVyLnN0cmVhbSgidXNlci1wb3N0cyIpOwoKS1RhYmxlPFN0cmluZywgTG9uZz4gdHJlbmRpbmdUb3BpY3MgPSBwb3N0cwogICAgLmZsYXRNYXBWYWx1ZXModmFsdWUgLT4gQXJyYXlzLmFzTGlzdCh2YWx1ZS50b0xvd2VyQ2FzZSgpLnNwbGl0KCJcXFcrIikpKQogICAgLmdyb3VwQnkoKGtleSwgd29yZCkgLT4gd29yZCkKICAgIC5jb3VudChNYXRlcmlhbGl6ZWQuYXMoImNvdW50cy1zdG9yZSIpKTsKCnRyZW5kaW5nVG9waWNzLnRvU3RyZWFtKCkudG8oInRyZW5kaW5nLXRvcGljcyIsIFByb2R1Y2VkLndpdGgoU2VyZGVzLlN0cmluZygpLCBTZXJkZXMuTG9uZygpKSk7CgpLYWZrYVN0cmVhbXMgc3RyZWFtcyA9IG5ldyBLYWZrYVN0cmVhbXMoYnVpbGRlci5idWlsZCgpLCBwcm9wcyk7CnN0cmVhbXMuc3RhcnQoKTs="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;trending-topics&quot;);
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

StreamsBuilder builder = new StreamsBuilder();
KStream&lt;String, String&gt; posts = builder.stream(&quot;user-posts&quot;);

KTable&lt;String, Long&gt; trendingTopics = posts
    .flatMapValues(value -&gt; Arrays.asList(value.toLowerCase().split(&quot;\\W+&quot;)))
    .groupBy((key, word) -&gt; word)
    .count(Materialized.as(&quot;counts-store&quot;));

trendingTopics.toStream().to(&quot;trending-topics&quot;, Produced.with(Serdes.String(), Serdes.Long()));

KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();</pre></div><div class='content'></div><h1>Summary</h1>
<div class='content'><p>In this section, we explored several real-world use cases of Apache Kafka, including log aggregation, real-time analytics, data integration, and stream processing. Each use case demonstrated Kafka's ability to handle different types of data streaming and processing scenarios effectively. Understanding these use cases will help you leverage Kafka's capabilities in your own projects.</p>
<p>Next, we will delve into Kafka best practices to ensure you can implement Kafka solutions efficiently and effectively.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='06-04-kafka-elasticsearch' title="Kafka with Elasticsearch">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='07-02-kafka-best-practices' title="Kafka Best Practices">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
