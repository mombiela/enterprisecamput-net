<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Implementation</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/project-implementation" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/project-implementation" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/project-implementation" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/hadoop/project-implementation" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/project-implementation" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='project-requirements'>&#x25C4;Project Requirements</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Project Implementation</a>
	</div>
	<div class='col-4 text-end'>
					<a href='project-presentation'>Project Presentation &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we will cover the practical aspects of implementing a project using Hadoop. This will include setting up the environment, writing and running MapReduce jobs, and using other Hadoop ecosystem tools like Hive and Pig. By the end of this section, you should be able to implement a complete data processing pipeline using Hadoop.</p>
</div><h1>Setting Up the Environment</h1>
<div class='content'><p>Before we dive into writing code, we need to set up our Hadoop environment. This involves installing Hadoop and configuring it for both single-node and multi-node clusters.</p>
</div><h2>Single-Node Setup</h2>
<div class='content'><p>A single-node setup is ideal for development and testing purposes.</p>
<ol>
<li><strong>Download Hadoop</strong>: Download the latest stable version of Hadoop from the official website.</li>
<li><strong>Extract Hadoop</strong>: Extract the downloaded tarball to a directory of your choice.</li>
<li><strong>Configure Hadoop</strong>: Edit the configuration files located in the <code>etc/hadoop</code> directory.
<ul>
<li><code>core-site.xml</code></li>
<li><code>hdfs-site.xml</code></li>
<li><code>mapred-site.xml</code></li>
<li><code>yarn-site.xml</code></li>
</ul>
</li>
<li><strong>Start Hadoop</strong>: Use the following commands to start Hadoop services:
<pre><code class="language-sh">start-dfs.sh
start-yarn.sh
</code></pre>
</li>
</ol>
</div><h2>Multi-Node Setup</h2>
<div class='content'><p>A multi-node setup is used for production environments.</p>
<ol>
<li><strong>Prerequisites</strong>: Ensure SSH is installed and configured for password-less login between nodes.</li>
<li><strong>Install Hadoop</strong>: Install Hadoop on all nodes.</li>
<li><strong>Configure Master and Slave Nodes</strong>: Edit the <code>masters</code> and <code>slaves</code> files to specify the master and slave nodes.</li>
<li><strong>Distribute Configuration</strong>: Copy the configuration files from the master node to all slave nodes.</li>
<li><strong>Start Hadoop</strong>: Start Hadoop services on all nodes using the same commands as in the single-node setup.</li>
</ol>
</div><h1>Writing and Running MapReduce Jobs</h1>
<div class='content'><p>MapReduce is the core component of Hadoop for processing large data sets.</p>
</div><h2>Writing a MapReduce Job</h2>
<div class='content'><p>A MapReduce job consists of a Mapper and a Reducer.</p>
<ul>
<li><strong>Mapper</strong>: Processes input data and produces intermediate key-value pairs.</li>
<li><strong>Reducer</strong>: Processes intermediate key-value pairs and produces the final output.</li>
</ul>
<p>Here is a simple example of a MapReduce job in Java that counts the number of occurrences of each word in a text file:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String[] tokens = value.toString().split(&quot;\\s+&quot;);
            for (String token : tokens) {
                word.set(token);
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            context.write(key, new IntWritable(sum));
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h2>Running a MapReduce Job</h2>
<div class='content'><ol>
<li><strong>Compile the Code</strong>: Compile the Java code using <code>javac</code>.
<pre><code class="language-sh">javac -classpath `hadoop classpath` -d wordcount_classes WordCount.java
</code></pre>
</li>
<li><strong>Create a JAR File</strong>: Package the compiled classes into a JAR file.
<pre><code class="language-sh">jar -cvf wordcount.jar -C wordcount_classes/ .
</code></pre>
</li>
<li><strong>Run the Job</strong>: Submit the job to the Hadoop cluster.
<pre><code class="language-sh">hadoop jar wordcount.jar WordCount /input /output
</code></pre>
</li>
</ol>
</div><h1>Using Hive and Pig</h1>
<div class='content'><p>Hive and Pig are high-level tools in the Hadoop ecosystem that simplify the process of writing data processing jobs.</p>
</div><h2>Hive</h2>
<div class='content'><p>Hive provides a SQL-like interface to query data stored in Hadoop.</p>
<ul>
<li><strong>Create a Table</strong>:
<pre><code class="language-sql">CREATE TABLE word_counts (word STRING, count INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
</code></pre>
</li>
<li><strong>Load Data</strong>:
<pre><code class="language-sql">LOAD DATA INPATH '/output' INTO TABLE word_counts;
</code></pre>
</li>
<li><strong>Query Data</strong>:
<pre><code class="language-sql">SELECT word, count FROM word_counts WHERE count &gt; 10;
</code></pre>
</li>
</ul>
</div><h2>Pig</h2>
<div class='content'><p>Pig uses a scripting language called Pig Latin to process data.</p>
<ul>
<li><strong>Load Data</strong>:
<pre><code class="language-pig">word_counts = LOAD '/output' USING PigStorage('\t') AS (word:chararray, count:int);
</code></pre>
</li>
<li><strong>Filter Data</strong>:
<pre><code class="language-pig">filtered_word_counts = FILTER word_counts BY count &gt; 10;
</code></pre>
</li>
<li><strong>Store Data</strong>:
<pre><code class="language-pig">STORE filtered_word_counts INTO '/filtered_output';
</code></pre>
</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we covered the essential steps for implementing a project using Hadoop. We started with setting up the environment, then moved on to writing and running MapReduce jobs, and finally explored high-level tools like Hive and Pig. With this knowledge, you should be well-equipped to tackle real-world data processing tasks using Hadoop.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='project-requirements'>&#x25C4;Project Requirements</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Project Implementation</a>
	</div>
	<div class='col-4 text-end'>
					<a href='project-presentation'>Project Presentation &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
