<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Project 2: Building a Data Pipeline with Hadoop Ecosystem</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=3" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/hadoop/08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/hadoop/08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>Building today's and tomorrow's society</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Languages</a>
				 					<a href="/categ/frameworks">Frameworks</a>
				 					<a href="/categ/tech-tools">Tools</a>
				 					<a href="/categ/foundations">Foundations</a>
				 					<a href="/categ/soft-skills">Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='08-01-project-1-analyzing-big-data-with-hadoop' title="Project 1: Analyzing Big Data with Hadoop">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Project 2: Building a Data Pipeline with Hadoop Ecosystem</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-03-project-3-real-time-data-processing-with-hadoop' title="Project 3: Real-Time Data Processing with Hadoop">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this project, you will learn how to build a data pipeline using various tools from the Hadoop ecosystem. This project will cover the end-to-end process of data ingestion, storage, processing, and analysis.</p>
</div><h1><p>Objectives</p>
</h1>
<div class='content'><ul>
<li>Understand the components of a data pipeline.</li>
<li>Learn how to use Apache Sqoop for data ingestion.</li>
<li>Use HDFS for data storage.</li>
<li>Process data using Apache Hive and Apache Pig.</li>
<li>Schedule and manage workflows with Apache Oozie.</li>
</ul>
</div><h1><p>Prerequisites</p>
</h1>
<div class='content'><ul>
<li>Basic understanding of Hadoop and its ecosystem.</li>
<li>Familiarity with HDFS, Hive, Pig, and Oozie.</li>
<li>A working Hadoop environment.</li>
</ul>
</div><h1><p>Steps to Build the Data Pipeline</p>
</h1>
<div class='content'></div><h2><p>Step 1: Data Ingestion with Apache Sqoop</p>
</h2>
<div class='content'><p>Apache Sqoop is a tool designed for efficiently transferring bulk data between Apache Hadoop and structured datastores such as relational databases.</p>
<h4>Example: Importing Data from MySQL to HDFS</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("c3Fvb3AgaW1wb3J0IFwKLS1jb25uZWN0IGpkYmM6bXlzcWw6Ly9sb2NhbGhvc3QvZW1wbG95ZWVzIFwKLS11c2VybmFtZSByb290IFwKLS1wYXNzd29yZCBwYXNzd29yZCBcCi0tdGFibGUgZW1wbG95ZWVzIFwKLS10YXJnZXQtZGlyIC91c2VyL2hhZG9vcC9lbXBsb3llZXM="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>sqoop import \
--connect jdbc:mysql://localhost/employees \
--username root \
--password password \
--table employees \
--target-dir /user/hadoop/employees</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>--connect</code>: JDBC URL to connect to the MySQL database.</li>
<li><code>--username</code> and <code>--password</code>: Credentials for the database.</li>
<li><code>--table</code>: The table to import.</li>
<li><code>--target-dir</code>: The HDFS directory where the data will be stored.</li>
</ul>
</div><h2><p>Step 2: Storing Data in HDFS</p>
</h2>
<div class='content'><p>HDFS is the primary storage system used by Hadoop applications. The data imported using Sqoop is now stored in HDFS.</p>
<h4>Verify Data in HDFS</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aGRmcyBkZnMgLWxzIC91c2VyL2hhZG9vcC9lbXBsb3llZXM="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>hdfs dfs -ls /user/hadoop/employees</pre></div><div class='content'></div><h2><p>Step 3: Data Processing with Apache Hive</p>
</h2>
<div class='content'><p>Apache Hive is a data warehouse infrastructure built on top of Hadoop for providing data summarization, query, and analysis.</p>
<h4>Example: Creating a Hive Table</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Q1JFQVRFIEVYVEVSTkFMIFRBQkxFIGVtcGxveWVlcyAoCiAgZW1wX25vIElOVCwKICBiaXJ0aF9kYXRlIFNUUklORywKICBmaXJzdF9uYW1lIFNUUklORywKICBsYXN0X25hbWUgU1RSSU5HLAogIGdlbmRlciBTVFJJTkcsCiAgaGlyZV9kYXRlIFNUUklORwopClJPVyBGT1JNQVQgREVMSU1JVEVECkZJRUxEUyBURVJNSU5BVEVEIEJZICcsJwpTVE9SRUQgQVMgVEVYVEZJTEUKTE9DQVRJT04gJy91c2VyL2hhZG9vcC9lbXBsb3llZXMnOw=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>CREATE EXTERNAL TABLE employees (
  emp_no INT,
  birth_date STRING,
  first_name STRING,
  last_name STRING,
  gender STRING,
  hire_date STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/user/hadoop/employees';</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>CREATE EXTERNAL TABLE</code>: Creates an external table in Hive.</li>
<li><code>ROW FORMAT DELIMITED FIELDS TERMINATED BY ','</code>: Specifies the format of the data.</li>
<li><code>STORED AS TEXTFILE LOCATION</code>: Specifies the storage format and location in HDFS.</li>
</ul>
<h4>Example: Querying Data in Hive</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("U0VMRUNUICogRlJPTSBlbXBsb3llZXMgV0hFUkUgZ2VuZGVyID0gJ00nOw=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>SELECT * FROM employees WHERE gender = 'M';</pre></div><div class='content'></div><h2><p>Step 4: Data Processing with Apache Pig</p>
</h2>
<div class='content'><p>Apache Pig is a high-level platform for creating programs that run on Hadoop. The language for this platform is called Pig Latin.</p>
<h4>Example: Processing Data with Pig</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZW1wbG95ZWVzID0gTE9BRCAnL3VzZXIvaGFkb29wL2VtcGxveWVlcycgVVNJTkcgUGlnU3RvcmFnZSgnLCcpIEFTIChlbXBfbm86aW50LCBiaXJ0aF9kYXRlOmNoYXJhcnJheSwgZmlyc3RfbmFtZTpjaGFyYXJyYXksIGxhc3RfbmFtZTpjaGFyYXJyYXksIGdlbmRlcjpjaGFyYXJyYXksIGhpcmVfZGF0ZTpjaGFyYXJyYXkpOwptYWxlX2VtcGxveWVlcyA9IEZJTFRFUiBlbXBsb3llZXMgQlkgZ2VuZGVyID09ICdNJzsKRFVNUCBtYWxlX2VtcGxveWVlczs="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>employees = LOAD '/user/hadoop/employees' USING PigStorage(',') AS (emp_no:int, birth_date:chararray, first_name:chararray, last_name:chararray, gender:chararray, hire_date:chararray);
male_employees = FILTER employees BY gender == 'M';
DUMP male_employees;</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>LOAD</code>: Loads data from HDFS.</li>
<li><code>FILTER</code>: Filters the data based on the condition.</li>
</ul>
</div><h2><p>Step 5: Workflow Management with Apache Oozie</p>
</h2>
<div class='content'><p>Apache Oozie is a workflow scheduler system to manage Hadoop jobs.</p>
<h4>Example: Creating an Oozie Workflow</h4>
<p>Create a workflow XML file (<code>workflow.xml</code>):</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PHdvcmtmbG93LWFwcCBuYW1lPSJkYXRhLXBpcGVsaW5lIiB4bWxucz0idXJpOm9vemllOndvcmtmbG93OjAuNSI+CiAgICA8c3RhcnQgdG89InNxb29wLW5vZGUiLz4KICAgIDxhY3Rpb24gbmFtZT0ic3Fvb3Atbm9kZSI+CiAgICAgICAgPHNxb29wIHhtbG5zPSJ1cmk6b296aWU6c3Fvb3AtYWN0aW9uOjAuMiI+CiAgICAgICAgICAgIDxqb2ItdHJhY2tlcj4ke2pvYlRyYWNrZXJ9PC9qb2ItdHJhY2tlcj4KICAgICAgICAgICAgPG5hbWUtbm9kZT4ke25hbWVOb2RlfTwvbmFtZS1ub2RlPgogICAgICAgICAgICA8Y29tbWFuZD5pbXBvcnQgLS1jb25uZWN0IGpkYmM6bXlzcWw6Ly9sb2NhbGhvc3QvZW1wbG95ZWVzIC0tdXNlcm5hbWUgcm9vdCAtLXBhc3N3b3JkIHBhc3N3b3JkIC0tdGFibGUgZW1wbG95ZWVzIC0tdGFyZ2V0LWRpciAvdXNlci9oYWRvb3AvZW1wbG95ZWVzPC9jb21tYW5kPgogICAgICAgIDwvc3Fvb3A+CiAgICAgICAgPG9rIHRvPSJoaXZlLW5vZGUiLz4KICAgICAgICA8ZXJyb3IgdG89ImZhaWwiLz4KICAgIDwvYWN0aW9uPgogICAgPGFjdGlvbiBuYW1lPSJoaXZlLW5vZGUiPgogICAgICAgIDxoaXZlIHhtbG5zPSJ1cmk6b296aWU6aGl2ZS1hY3Rpb246MC41Ij4KICAgICAgICAgICAgPGpvYi10cmFja2VyPiR7am9iVHJhY2tlcn08L2pvYi10cmFja2VyPgogICAgICAgICAgICA8bmFtZS1ub2RlPiR7bmFtZU5vZGV9PC9uYW1lLW5vZGU+CiAgICAgICAgICAgIDxzY3JpcHQ+aGl2ZS1zY3JpcHQucTwvc2NyaXB0PgogICAgICAgIDwvaGl2ZT4KICAgICAgICA8b2sgdG89ImVuZCIvPgogICAgICAgIDxlcnJvciB0bz0iZmFpbCIvPgogICAgPC9hY3Rpb24+CiAgICA8a2lsbCBuYW1lPSJmYWlsIj4KICAgICAgICA8bWVzc2FnZT5Xb3JrZmxvdyBmYWlsZWQsIGVycm9yIG1lc3NhZ2VbJHt3ZjplcnJvck1lc3NhZ2Uod2Y6bGFzdEVycm9yTm9kZSgpKX1dPC9tZXNzYWdlPgogICAgPC9raWxsPgogICAgPGVuZCBuYW1lPSJlbmQiLz4KPC93b3JrZmxvdy1hcHA+"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;workflow-app name=&quot;data-pipeline&quot; xmlns=&quot;uri:oozie:workflow:0.5&quot;&gt;
    &lt;start to=&quot;sqoop-node&quot;/&gt;
    &lt;action name=&quot;sqoop-node&quot;&gt;
        &lt;sqoop xmlns=&quot;uri:oozie:sqoop-action:0.2&quot;&gt;
            &lt;job-tracker&gt;${jobTracker}&lt;/job-tracker&gt;
            &lt;name-node&gt;${nameNode}&lt;/name-node&gt;
            &lt;command&gt;import --connect jdbc:mysql://localhost/employees --username root --password password --table employees --target-dir /user/hadoop/employees&lt;/command&gt;
        &lt;/sqoop&gt;
        &lt;ok to=&quot;hive-node&quot;/&gt;
        &lt;error to=&quot;fail&quot;/&gt;
    &lt;/action&gt;
    &lt;action name=&quot;hive-node&quot;&gt;
        &lt;hive xmlns=&quot;uri:oozie:hive-action:0.5&quot;&gt;
            &lt;job-tracker&gt;${jobTracker}&lt;/job-tracker&gt;
            &lt;name-node&gt;${nameNode}&lt;/name-node&gt;
            &lt;script&gt;hive-script.q&lt;/script&gt;
        &lt;/hive&gt;
        &lt;ok to=&quot;end&quot;/&gt;
        &lt;error to=&quot;fail&quot;/&gt;
    &lt;/action&gt;
    &lt;kill name=&quot;fail&quot;&gt;
        &lt;message&gt;Workflow failed, error message[${wf:errorMessage(wf:lastErrorNode())}]&lt;/message&gt;
    &lt;/kill&gt;
    &lt;end name=&quot;end&quot;/&gt;
&lt;/workflow-app&gt;</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>&lt;workflow-app&gt;</code>: Defines the workflow application.</li>
<li><code>&lt;start&gt;</code>: Defines the start node.</li>
<li><code>&lt;action&gt;</code>: Defines an action node.</li>
<li><code>&lt;sqoop&gt;</code>: Defines a Sqoop action.</li>
<li><code>&lt;hive&gt;</code>: Defines a Hive action.</li>
<li><code>&lt;kill&gt;</code>: Defines a kill node for error handling.</li>
<li><code>&lt;end&gt;</code>: Defines the end node.</li>
</ul>
</div><h2><p>Step 6: Running the Oozie Workflow</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("b296aWUgam9iIC1vb3ppZSBodHRwOi8vbG9jYWxob3N0OjExMDAwL29vemllIC1jb25maWcgam9iLnByb3BlcnRpZXMgLXJ1bg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>oozie job -oozie http://localhost:11000/oozie -config job.properties -run</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>-oozie</code>: Oozie server URL.</li>
<li><code>-config</code>: Configuration file for the job.</li>
<li><code>-run</code>: Runs the job.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this project, you have learned how to build a data pipeline using various tools from the Hadoop ecosystem. You have covered data ingestion with Apache Sqoop, data storage in HDFS, data processing with Apache Hive and Apache Pig, and workflow management with Apache Oozie. This project provides a comprehensive understanding of how to build and manage data pipelines in a Hadoop environment.</p>
</div><h2><p>Summary</p>
</h2>
<div class='content'><ul>
<li><strong>Data Ingestion</strong>: Used Apache Sqoop to import data from MySQL to HDFS.</li>
<li><strong>Data Storage</strong>: Stored data in HDFS.</li>
<li><strong>Data Processing</strong>: Processed data using Apache Hive and Apache Pig.</li>
<li><strong>Workflow Management</strong>: Managed workflows using Apache Oozie.</li>
</ul>
</div><h2><p>Next Steps</p>
</h2>
<div class='content'><ul>
<li>Explore more advanced features of each tool.</li>
<li>Experiment with different data sources and processing techniques.</li>
<li>Implement additional workflows and scheduling strategies with Oozie.</li>
</ul>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='08-01-project-1-analyzing-big-data-with-hadoop' title="Project 1: Analyzing Big Data with Hadoop">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-03-project-3-real-time-data-processing-with-hadoop' title="Project 3: Real-Time Data Processing with Hadoop">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
