<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>What is Hadoop?</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/01-01-what-is-hadoop" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/01-01-what-is-hadoop" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/01-01-what-is-hadoop" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/hadoop/01-01-what-is-hadoop" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/01-01-what-is-hadoop" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='index' title="INDEX">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">What is Hadoop?</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='01-02-hadoop-ecosystem-overview' title="Hadoop Ecosystem Overview">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Hadoop is an open-source framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from a single server to thousands of machines, each offering local computation and storage.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ol>
<li><strong>Big Data</strong>: Refers to extremely large data sets that may be analyzed computationally to reveal patterns, trends, and associations, especially relating to human behavior and interactions.</li>
<li><strong>Distributed Computing</strong>: A field of computer science that studies distributed systems. A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another.</li>
<li><strong>Scalability</strong>: The capability of a system, network, or process to handle a growing amount of work, or its potential to accommodate growth.</li>
</ol>
</div><h1>Core Components of Hadoop</h1>
<div class='content'><p>Hadoop consists of four main modules:</p>
<ol>
<li><strong>Hadoop Common</strong>: The common utilities that support the other Hadoop modules.</li>
<li><strong>Hadoop Distributed File System (HDFS)</strong>: A distributed file system that provides high-throughput access to application data.</li>
<li><strong>Hadoop YARN</strong>: A framework for job scheduling and cluster resource management.</li>
<li><strong>Hadoop MapReduce</strong>: A YARN-based system for parallel processing of large data sets.</li>
</ol>
</div><h1>Why Use Hadoop?</h1>
<div class='content'></div><h2>Advantages</h2>
<div class='content'><ul>
<li><strong>Scalability</strong>: Hadoop can easily scale from a single server to thousands of machines.</li>
<li><strong>Cost-Effective</strong>: It uses commodity hardware, which is cheaper than specialized hardware.</li>
<li><strong>Flexibility</strong>: Hadoop can process structured, semi-structured, and unstructured data.</li>
<li><strong>Fault Tolerance</strong>: Data is automatically replicated across multiple nodes, ensuring data availability even if some nodes fail.</li>
</ul>
</div><h2>Disadvantages</h2>
<div class='content'><ul>
<li><strong>Complexity</strong>: Setting up and managing a Hadoop cluster can be complex.</li>
<li><strong>Latency</strong>: Hadoop is designed for batch processing and may not be suitable for real-time data processing.</li>
<li><strong>Resource Intensive</strong>: Requires significant computational resources and storage.</li>
</ul>
</div><h1>Practical Example</h1>
<div class='content'><p>Let's look at a simple example to understand how Hadoop works. Suppose you have a large text file containing millions of lines, and you want to count the number of occurrences of each word.</p>
</div><h2>Traditional Approach</h2>
<div class='content'><p>In a traditional approach, you might write a program that reads the file line by line, splits each line into words, and then counts the occurrences of each word. This approach works fine for small files but becomes impractical for very large files due to memory and processing constraints.</p>
</div><h2>Hadoop Approach</h2>
<div class='content'><p>With Hadoop, you can distribute the file across multiple nodes in a cluster and process each part of the file in parallel. Here's a simplified version of how this would work using the MapReduce framework:</p>
<ol>
<li><strong>Map Phase</strong>: Each node processes a portion of the file and produces a list of key-value pairs (word, 1).</li>
<li><strong>Shuffle and Sort Phase</strong>: The framework sorts and groups the key-value pairs by key (word).</li>
<li><strong>Reduce Phase</strong>: Each node processes the grouped key-value pairs and sums the values to get the total count for each word.</li>
</ol>
</div><h2>Code Example</h2>
<div class='content'><p>Here is a simple MapReduce program in Java to count word occurrences:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
      String[] words = value.toString().split(&quot;\\s+&quot;);
      for (String str : words) {
        word.set(str);
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, &quot;word count&quot;);
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>TokenizerMapper</strong>: This class extends the <code>Mapper</code> class and overrides the <code>map</code> method. It splits each line into words and writes each word with a count of 1 to the context.</li>
<li><strong>IntSumReducer</strong>: This class extends the <code>Reducer</code> class and overrides the <code>reduce</code> method. It sums the counts for each word and writes the result to the context.</li>
<li><strong>Main Method</strong>: Configures and runs the MapReduce job.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we introduced Hadoop, its core components, and its advantages and disadvantages. We also provided a practical example of how Hadoop can be used to process large data sets efficiently. Understanding these basics will prepare you for more advanced topics in the subsequent modules.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='index' title="INDEX">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='01-02-hadoop-ecosystem-overview' title="Hadoop Ecosystem Overview">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
