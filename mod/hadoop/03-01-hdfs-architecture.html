<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>HDFS Architecture</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/03-01-hdfs-architecture" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/03-01-hdfs-architecture" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/03-01-hdfs-architecture" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/hadoop/03-01-hdfs-architecture" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/hadoop/03-01-hdfs-architecture" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-04-yarn' title="YARN (Yet Another Resource Negotiator)">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">HDFS Architecture</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-02-hdfs-commands' title="HDFS Commands">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>HDFS (Hadoop Distributed File System) is the primary storage system used by Hadoop applications. It is designed to store large datasets reliably and to stream those data sets at high bandwidth to user applications. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware.</p>
</div><h1>Key Concepts of HDFS Architecture</h1>
<div class='content'></div><h2><ol>
<li><strong>Blocks</strong></li>
</ol></h2>
<div class='content'><ul>
<li><strong>Definition</strong>: HDFS splits large files into smaller fixed-size blocks (default 128 MB).</li>
<li><strong>Purpose</strong>: This allows HDFS to store large files across multiple nodes in a cluster.</li>
<li><strong>Example</strong>: A 512 MB file will be split into four 128 MB blocks.</li>
</ul>
</div><h2><ol start="2">
<li><strong>NameNode</strong></li>
</ol></h2>
<div class='content'><ul>
<li><strong>Role</strong>: The master server that manages the file system namespace and regulates access to files by clients.</li>
<li><strong>Responsibilities</strong>:
<ul>
<li>Maintains the directory tree of all files in the file system.</li>
<li>Tracks the location of blocks across DataNodes.</li>
<li>Handles metadata operations like opening, closing, and renaming files and directories.</li>
</ul>
</li>
</ul>
</div><h2><ol start="3">
<li><strong>DataNode</strong></li>
</ol></h2>
<div class='content'><ul>
<li><strong>Role</strong>: The worker nodes that store the actual data.</li>
<li><strong>Responsibilities</strong>:
<ul>
<li>Serve read and write requests from the file systemâ€™s clients.</li>
<li>Perform block creation, deletion, and replication upon instruction from the NameNode.</li>
</ul>
</li>
</ul>
</div><h2><ol start="4">
<li><strong>Secondary NameNode</strong></li>
</ol></h2>
<div class='content'><ul>
<li><strong>Role</strong>: Assists the primary NameNode.</li>
<li><strong>Responsibilities</strong>:
<ul>
<li>Periodically merges the namespace image with the edit log to prevent the edit log from becoming too large.</li>
<li>Acts as a checkpointing mechanism but not a failover NameNode.</li>
</ul>
</li>
</ul>
</div><h2><ol start="5">
<li><strong>Replication</strong></li>
</ol></h2>
<div class='content'><ul>
<li><strong>Definition</strong>: HDFS stores multiple copies of data blocks to ensure reliability and fault tolerance.</li>
<li><strong>Default Replication Factor</strong>: 3 (can be configured).</li>
<li><strong>Example</strong>: Each block of a file is replicated on three different DataNodes.</li>
</ul>
</div><h2><ol start="6">
<li><strong>Rack Awareness</strong></li>
</ol></h2>
<div class='content'><ul>
<li><strong>Definition</strong>: HDFS is aware of the rack topology of the cluster.</li>
<li><strong>Purpose</strong>: To improve data reliability, availability, and network bandwidth utilization.</li>
<li><strong>Example</strong>: HDFS places one replica on a different rack to ensure data availability even if an entire rack fails.</li>
</ul>
</div><h1>HDFS Architecture Diagram</h1>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Ky0tLS0tLS0tLS0tLS0tLS0tLS0rCnwgICAgIE5hbWVOb2RlICAgICAgfAp8IChNYXN0ZXIgTm9kZSkgICAgIHwKKy0tLS0tLS0tLS0tLS0tLS0tLS0rCiAgICAgICAgIHwKICAgICAgICAgfCBNZXRhZGF0YSBPcGVyYXRpb25zCiAgICAgICAgIHwKKy0tLS0tLS0tLS0tLS0tLS0tLS0rICAgKy0tLS0tLS0tLS0tLS0tLS0tLS0rICAgKy0tLS0tLS0tLS0tLS0tLS0tLS0rCnwgICAgRGF0YU5vZGUgMSAgICAgfCAgIHwgICAgRGF0YU5vZGUgMiAgICAgfCAgIHwgICAgRGF0YU5vZGUgMyAgICAgfAp8IChXb3JrZXIgTm9kZSkgICAgIHwgICB8IChXb3JrZXIgTm9kZSkgICAgIHwgICB8IChXb3JrZXIgTm9kZSkgICAgIHwKKy0tLS0tLS0tLS0tLS0tLS0tLS0rICAgKy0tLS0tLS0tLS0tLS0tLS0tLS0rICAgKy0tLS0tLS0tLS0tLS0tLS0tLS0rCnwgQmxvY2sgMSwgQmxvY2sgMiAgfCAgIHwgQmxvY2sgMiwgQmxvY2sgMyAgfCAgIHwgQmxvY2sgMSwgQmxvY2sgMyAgfAorLS0tLS0tLS0tLS0tLS0tLS0tLSsgICArLS0tLS0tLS0tLS0tLS0tLS0tLSsgICArLS0tLS0tLS0tLS0tLS0tLS0tLSs="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>+-------------------+
|     NameNode      |
| (Master Node)     |
+-------------------+
         |
         | Metadata Operations
         |
+-------------------+   +-------------------+   +-------------------+
|    DataNode 1     |   |    DataNode 2     |   |    DataNode 3     |
| (Worker Node)     |   | (Worker Node)     |   | (Worker Node)     |
+-------------------+   +-------------------+   +-------------------+
| Block 1, Block 2  |   | Block 2, Block 3  |   | Block 1, Block 3  |
+-------------------+   +-------------------+   +-------------------+</pre></div><div class='content'></div><h1>Practical Example</h1>
<div class='content'></div><h2>Example: Writing a File to HDFS</h2>
<div class='content'><ol>
<li><strong>Client Request</strong>: A client wants to write a file <code>example.txt</code> to HDFS.</li>
<li><strong>File Splitting</strong>: The file is split into blocks (e.g., <code>example.txt</code> is 256 MB, split into two 128 MB blocks).</li>
<li><strong>Metadata Update</strong>: The NameNode updates its metadata to include the new file and its blocks.</li>
<li><strong>Block Placement</strong>: The NameNode instructs DataNodes to store the blocks with replication.</li>
<li><strong>Data Storage</strong>: DataNodes store the blocks and replicate them as per the replication factor.</li>
</ol>
</div><h2>Code Example: Using HDFS Commands</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYSBkaXJlY3RvcnkgaW4gSERGUwpoZGZzIGRmcyAtbWtkaXIgL3VzZXIvaGFkb29wL2V4YW1wbGUKCiMgQ29weSBhIGxvY2FsIGZpbGUgdG8gSERGUwpoZGZzIGRmcyAtcHV0IGV4YW1wbGUudHh0IC91c2VyL2hhZG9vcC9leGFtcGxlLwoKIyBMaXN0IGZpbGVzIGluIHRoZSBIREZTIGRpcmVjdG9yeQpoZGZzIGRmcyAtbHMgL3VzZXIvaGFkb29wL2V4YW1wbGUv"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create a directory in HDFS
hdfs dfs -mkdir /user/hadoop/example

# Copy a local file to HDFS
hdfs dfs -put example.txt /user/hadoop/example/

# List files in the HDFS directory
hdfs dfs -ls /user/hadoop/example/</pre></div><div class='content'></div><h1>Exercises</h1>
<div class='content'></div><h2>Exercise 1: Understanding HDFS Block Storage</h2>
<div class='content'><p><strong>Task</strong>: Given a file of size 512 MB and a default block size of 128 MB, determine how many blocks will be created and how they will be replicated.</p>
<p><strong>Solution</strong>:</p>
<ul>
<li>The file will be split into 4 blocks (512 MB / 128 MB).</li>
<li>Each block will be replicated 3 times (default replication factor).</li>
<li>Total blocks stored = 4 blocks * 3 replicas = 12 blocks.</li>
</ul>
</div><h2>Exercise 2: Basic HDFS Commands</h2>
<div class='content'><p><strong>Task</strong>: Perform the following operations using HDFS commands:</p>
<ol>
<li>Create a directory <code>/user/student/data</code>.</li>
<li>Upload a file <code>data.txt</code> from the local filesystem to the HDFS directory.</li>
<li>List the contents of the HDFS directory.</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYSBkaXJlY3RvcnkgaW4gSERGUwpoZGZzIGRmcyAtbWtkaXIgL3VzZXIvc3R1ZGVudC9kYXRhCgojIFVwbG9hZCBhIGZpbGUgdG8gSERGUwpoZGZzIGRmcyAtcHV0IGRhdGEudHh0IC91c2VyL3N0dWRlbnQvZGF0YS8KCiMgTGlzdCBmaWxlcyBpbiB0aGUgSERGUyBkaXJlY3RvcnkKaGRmcyBkZnMgLWxzIC91c2VyL3N0dWRlbnQvZGF0YS8="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create a directory in HDFS
hdfs dfs -mkdir /user/student/data

# Upload a file to HDFS
hdfs dfs -put data.txt /user/student/data/

# List files in the HDFS directory
hdfs dfs -ls /user/student/data/</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this section, we explored the architecture of HDFS, including its key components such as NameNode, DataNode, and Secondary NameNode. We also discussed the concepts of blocks, replication, and rack awareness. Understanding these fundamentals is crucial for working effectively with HDFS and leveraging its capabilities for big data storage and processing. In the next section, we will delve deeper into HDFS commands and their practical applications.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-04-yarn' title="YARN (Yet Another Resource Negotiator)">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-02-hdfs-commands' title="HDFS Commands">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Hadoop Course</h1>
<h2>Module 1: Introduction to Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">What is Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Hadoop Ecosystem Overview</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Traditional Databases</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Setting Up Hadoop Environment</a></li>
</ul>
<h2>Module 2: Hadoop Architecture</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Hadoop Core Components</a></li>
<li><a href="02-02-hdfs">HDFS (Hadoop Distributed File System)</a></li>
<li><a href="02-03-mapreduce-framework">MapReduce Framework</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Module 3: HDFS (Hadoop Distributed File System)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">HDFS Architecture</a></li>
<li><a href="03-02-hdfs-commands">HDFS Commands</a></li>
<li><a href="03-03-data-replication-in-hdfs">Data Replication in HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">HDFS Fault Tolerance</a></li>
</ul>
<h2>Module 4: MapReduce Programming</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introduction to MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">MapReduce Job Workflow</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Writing a MapReduce Program</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">MapReduce Optimization Techniques</a></li>
</ul>
<h2>Module 5: Hadoop Ecosystem Tools</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Module 6: Advanced Hadoop Concepts</h2>
<ul>
<li><a href="06-01-hadoop-security">Hadoop Security</a></li>
<li><a href="06-02-hadoop-cluster-management">Hadoop Cluster Management</a></li>
<li><a href="06-03-hadoop-performance-tuning">Hadoop Performance Tuning</a></li>
<li><a href="06-04-hadoop-data-serialization">Hadoop Data Serialization</a></li>
</ul>
<h2>Module 7: Real-World Applications and Case Studies</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop in Data Warehousing</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop in Machine Learning</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop in Real-Time Data Processing</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Case Studies of Hadoop Implementations</a></li>
</ul>
<h2>Module 8: Hands-On Projects</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Project 1: Analyzing Big Data with Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Project 2: Building a Data Pipeline with Hadoop Ecosystem</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Project 3: Real-Time Data Processing with Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Project 4: Machine Learning with Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
