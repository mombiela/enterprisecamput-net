<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hadoop Data Processing</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/hadoop-data-processing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/hadoop-data-processing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/hadoop-data-processing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/hadoop/hadoop-data-processing" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/hadoop-data-processing" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='hadoop-data-ingestion'>&#x25C4;Hadoop Data Ingestion</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Hadoop Data Processing</a>
	</div>
	<div class='col-4 text-end'>
					<a href='hadoop-data-storage'>Hadoop Data Storage &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to Hadoop Data Processing</h1>
<div class='content'><p>Hadoop is an open-source framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. This section will introduce the fundamental concepts of Hadoop and its ecosystem.</p>
<ul>
<li><strong>Hadoop Distributed File System (HDFS)</strong>: A distributed file system that provides high-throughput access to application data.</li>
<li><strong>MapReduce</strong>: A programming model for processing large data sets with a distributed algorithm on a Hadoop cluster.</li>
<li><strong>YARN (Yet Another Resource Negotiator)</strong>: Manages resources and scheduling of jobs in Hadoop.</li>
</ul>
</div><h1>HDFS: The Foundation of Hadoop</h1>
<div class='content'><p>HDFS is designed to store very large data sets reliably and to stream those data sets at high bandwidth to user applications.</p>
<ul>
<li><strong>Blocks</strong>: HDFS breaks files into large blocks (typically 128 MB), and distributes them across nodes in a cluster.</li>
<li><strong>Replication</strong>: Each block is replicated across multiple nodes to ensure fault tolerance.</li>
<li><strong>NameNode and DataNode</strong>: The NameNode manages the file system namespace and regulates access to files by clients. DataNodes manage storage attached to the nodes that they run on.</li>
</ul>
</div><h2>Example: Writing and Reading Files in HDFS</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBVcGxvYWQgYSBmaWxlIHRvIEhERlMKaGRmcyBkZnMgLXB1dCBsb2NhbGZpbGUudHh0IC91c2VyL2hhZG9vcC8KCiMgTGlzdCBmaWxlcyBpbiBIREZTIGRpcmVjdG9yeQpoZGZzIGRmcyAtbHMgL3VzZXIvaGFkb29wLwoKIyBSZWFkIGEgZmlsZSBmcm9tIEhERlMKaGRmcyBkZnMgLWNhdCAvdXNlci9oYWRvb3AvbG9jYWxmaWxlLnR4dA=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Upload a file to HDFS
hdfs dfs -put localfile.txt /user/hadoop/

# List files in HDFS directory
hdfs dfs -ls /user/hadoop/

# Read a file from HDFS
hdfs dfs -cat /user/hadoop/localfile.txt</pre></div><div class='content'></div><h1>MapReduce: Processing Data in Hadoop</h1>
<div class='content'><p>MapReduce is a programming model and an associated implementation for processing and generating large data sets.</p>
<ul>
<li><strong>Map Function</strong>: Processes input data and produces a set of intermediate key/value pairs.</li>
<li><strong>Reduce Function</strong>: Merges all intermediate values associated with the same intermediate key.</li>
</ul>
</div><h2>Example: Word Count Program</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {
    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h1>YARN: Resource Management in Hadoop</h1>
<div class='content'><p>YARN is the resource management layer of Hadoop. It allows multiple data processing engines such as batch processing, stream processing, interactive processing, and graph processing to run and process data stored in HDFS.</p>
<ul>
<li><strong>ResourceManager</strong>: Manages resources and schedules applications.</li>
<li><strong>NodeManager</strong>: Manages resources on a single node.</li>
<li><strong>ApplicationMaster</strong>: Manages the lifecycle of applications.</li>
</ul>
</div><h1>Advanced Data Processing with Hadoop Ecosystem</h1>
<div class='content'><p>Hadoop's ecosystem includes several tools and technologies that enhance its capabilities.</p>
<ul>
<li><strong>Hive</strong>: Data warehouse infrastructure built on top of Hadoop for providing data summarization, query, and analysis.</li>
<li><strong>Pig</strong>: High-level platform for creating MapReduce programs used with Hadoop.</li>
<li><strong>HBase</strong>: Distributed, scalable, big data store, modeled after Google's Bigtable.</li>
<li><strong>Spark</strong>: Fast and general engine for large-scale data processing.</li>
</ul>
</div><h2>Example: Using Hive for Data Querying</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("LS0gQ3JlYXRlIGEgdGFibGUgaW4gSGl2ZQpDUkVBVEUgVEFCTEUgZW1wbG95ZWUgKGlkIElOVCwgbmFtZSBTVFJJTkcsIHNhbGFyeSBGTE9BVCkKUk9XIEZPUk1BVCBERUxJTUlURUQKRklFTERTIFRFUk1JTkFURUQgQlkgJywnCkxJTkVTIFRFUk1JTkFURUQgQlkgJ1xuJzsKCi0tIExvYWQgZGF0YSBpbnRvIHRoZSB0YWJsZQpMT0FEIERBVEEgTE9DQUwgSU5QQVRIICcvcGF0aC90by9lbXBsb3llZS5jc3YnIElOVE8gVEFCTEUgZW1wbG95ZWU7CgotLSBRdWVyeSB0aGUgdGFibGUKU0VMRUNUIG5hbWUsIHNhbGFyeSBGUk9NIGVtcGxveWVlIFdIRVJFIHNhbGFyeSA+IDUwMDAwOw=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>-- Create a table in Hive
CREATE TABLE employee (id INT, name STRING, salary FLOAT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n';

-- Load data into the table
LOAD DATA LOCAL INPATH '/path/to/employee.csv' INTO TABLE employee;

-- Query the table
SELECT name, salary FROM employee WHERE salary &gt; 50000;</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>Hadoop provides a robust framework for processing large data sets in a distributed computing environment. Understanding HDFS, MapReduce, and YARN is crucial for leveraging Hadoop's full potential. Additionally, tools like Hive, Pig, HBase, and Spark extend Hadoop's capabilities, making it a versatile solution for big data processing. By mastering these components, you can efficiently manage and analyze vast amounts of data.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='hadoop-data-ingestion'>&#x25C4;Hadoop Data Ingestion</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Hadoop Data Processing</a>
	</div>
	<div class='col-4 text-end'>
					<a href='hadoop-data-storage'>Hadoop Data Storage &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
