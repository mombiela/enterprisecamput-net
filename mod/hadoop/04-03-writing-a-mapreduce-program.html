<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Writing a MapReduce Program</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/04-03-writing-a-mapreduce-program" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/04-03-writing-a-mapreduce-program" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/04-03-writing-a-mapreduce-program" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 px-0 py-2 py-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 px-0 py-2 py-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/hadoop/04-03-writing-a-mapreduce-program" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/04-03-writing-a-mapreduce-program" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-02-mapreduce-job-workflow' title="MapReduce Job Workflow">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Writing a MapReduce Program</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='04-04-mapreduce-optimization-techniques' title="MapReduce Optimization Techniques">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we will delve into the process of writing a MapReduce program. MapReduce is a programming model used for processing large data sets with a distributed algorithm on a Hadoop cluster. This section will cover the following:</p>
<ol>
<li><strong>Understanding the MapReduce Programming Model</strong></li>
<li><strong>Components of a MapReduce Program</strong></li>
<li><strong>Writing a Simple MapReduce Program</strong></li>
<li><strong>Running and Testing the MapReduce Program</strong></li>
<li><strong>Common Mistakes and Tips</strong></li>
</ol>
</div><h1>1. Understanding the MapReduce Programming Model</h1>
<div class='content'><p>The MapReduce model consists of two main functions:</p>
<ul>
<li><strong>Map Function</strong>: Processes input data and produces a set of intermediate key-value pairs.</li>
<li><strong>Reduce Function</strong>: Merges all intermediate values associated with the same intermediate key.</li>
</ul>
</div><h2>Example Workflow</h2>
<div class='content'><ol>
<li><strong>Input</strong>: A large dataset split into smaller chunks.</li>
<li><strong>Map Phase</strong>: Each chunk is processed by a map function to produce key-value pairs.</li>
<li><strong>Shuffle and Sort</strong>: The framework sorts and groups the key-value pairs by key.</li>
<li><strong>Reduce Phase</strong>: The reduce function processes each group of key-value pairs to produce the final output.</li>
</ol>
</div><h1>2. Components of a MapReduce Program</h1>
<div class='content'><p>A typical MapReduce program in Hadoop consists of the following components:</p>
<ul>
<li><strong>Mapper Class</strong>: Defines the map function.</li>
<li><strong>Reducer Class</strong>: Defines the reduce function.</li>
<li><strong>Driver Class</strong>: Configures and runs the MapReduce job.</li>
</ul>
</div><h1>3. Writing a Simple MapReduce Program</h1>
<div class='content'><p>Let's write a simple MapReduce program to count the frequency of words in a text file.</p>
</div><h2>Step 1: Mapper Class</h2>
<div class='content'><p>The Mapper class processes input data and produces key-value pairs.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkludFdyaXRhYmxlOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuaW8uTG9uZ1dyaXRhYmxlOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuaW8uVGV4dDsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLm1hcHJlZHVjZS5NYXBwZXI7CgppbXBvcnQgamF2YS5pby5JT0V4Y2VwdGlvbjsKCnB1YmxpYyBjbGFzcyBXb3JkQ291bnRNYXBwZXIgZXh0ZW5kcyBNYXBwZXI8TG9uZ1dyaXRhYmxlLCBUZXh0LCBUZXh0LCBJbnRXcml0YWJsZT4gewogICAgcHJpdmF0ZSBmaW5hbCBzdGF0aWMgSW50V3JpdGFibGUgb25lID0gbmV3IEludFdyaXRhYmxlKDEpOwogICAgcHJpdmF0ZSBUZXh0IHdvcmQgPSBuZXcgVGV4dCgpOwoKICAgIEBPdmVycmlkZQogICAgcHJvdGVjdGVkIHZvaWQgbWFwKExvbmdXcml0YWJsZSBrZXksIFRleHQgdmFsdWUsIENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgICAgU3RyaW5nW10gd29yZHMgPSB2YWx1ZS50b1N0cmluZygpLnNwbGl0KCJcXHMrIik7CiAgICAgICAgZm9yIChTdHJpbmcgc3RyIDogd29yZHMpIHsKICAgICAgICAgICAgd29yZC5zZXQoc3RyKTsKICAgICAgICAgICAgY29udGV4dC53cml0ZSh3b3JkLCBvbmUpOwogICAgICAgIH0KICAgIH0KfQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String[] words = value.toString().split(&quot;\\s+&quot;);
        for (String str : words) {
            word.set(str);
            context.write(word, one);
        }
    }
}</pre></div><div class='content'></div><h2>Step 2: Reducer Class</h2>
<div class='content'><p>The Reducer class processes the intermediate key-value pairs and produces the final output.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkludFdyaXRhYmxlOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuaW8uVGV4dDsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLm1hcHJlZHVjZS5SZWR1Y2VyOwoKaW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CgpwdWJsaWMgY2xhc3MgV29yZENvdW50UmVkdWNlciBleHRlbmRzIFJlZHVjZXI8VGV4dCwgSW50V3JpdGFibGUsIFRleHQsIEludFdyaXRhYmxlPiB7CiAgICBAT3ZlcnJpZGUKICAgIHByb3RlY3RlZCB2b2lkIHJlZHVjZShUZXh0IGtleSwgSXRlcmFibGU8SW50V3JpdGFibGU+IHZhbHVlcywgQ29udGV4dCBjb250ZXh0KSB0aHJvd3MgSU9FeGNlcHRpb24sIEludGVycnVwdGVkRXhjZXB0aW9uIHsKICAgICAgICBpbnQgc3VtID0gMDsKICAgICAgICBmb3IgKEludFdyaXRhYmxlIHZhbCA6IHZhbHVlcykgewogICAgICAgICAgICBzdW0gKz0gdmFsLmdldCgpOwogICAgICAgIH0KICAgICAgICBjb250ZXh0LndyaXRlKGtleSwgbmV3IEludFdyaXRhYmxlKHN1bSkpOwogICAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        context.write(key, new IntWritable(sum));
    }
}</pre></div><div class='content'></div><h2>Step 3: Driver Class</h2>
<div class='content'><p>The Driver class configures and runs the MapReduce job.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmNvbmYuQ29uZmlndXJhdGlvbjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLlBhdGg7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuSm9iOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLmxpYi5pbnB1dC5GaWxlSW5wdXRGb3JtYXQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UubGliLm91dHB1dC5GaWxlT3V0cHV0Rm9ybWF0OwoKcHVibGljIGNsYXNzIFdvcmRDb3VudERyaXZlciB7CiAgICBwdWJsaWMgc3RhdGljIHZvaWQgbWFpbihTdHJpbmdbXSBhcmdzKSB0aHJvd3MgRXhjZXB0aW9uIHsKICAgICAgICBDb25maWd1cmF0aW9uIGNvbmYgPSBuZXcgQ29uZmlndXJhdGlvbigpOwogICAgICAgIEpvYiBqb2IgPSBKb2IuZ2V0SW5zdGFuY2UoY29uZiwgIndvcmQgY291bnQiKTsKICAgICAgICBqb2Iuc2V0SmFyQnlDbGFzcyhXb3JkQ291bnREcml2ZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRNYXBwZXJDbGFzcyhXb3JkQ291bnRNYXBwZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRDb21iaW5lckNsYXNzKFdvcmRDb3VudFJlZHVjZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRSZWR1Y2VyQ2xhc3MoV29yZENvdW50UmVkdWNlci5jbGFzcyk7CiAgICAgICAgam9iLnNldE91dHB1dEtleUNsYXNzKFRleHQuY2xhc3MpOwogICAgICAgIGpvYi5zZXRPdXRwdXRWYWx1ZUNsYXNzKEludFdyaXRhYmxlLmNsYXNzKTsKICAgICAgICBGaWxlSW5wdXRGb3JtYXQuYWRkSW5wdXRQYXRoKGpvYiwgbmV3IFBhdGgoYXJnc1swXSkpOwogICAgICAgIEZpbGVPdXRwdXRGb3JtYXQuc2V0T3V0cHV0UGF0aChqb2IsIG5ldyBQYXRoKGFyZ3NbMV0pKTsKICAgICAgICBTeXN0ZW0uZXhpdChqb2Iud2FpdEZvckNvbXBsZXRpb24odHJ1ZSkgPyAwIDogMSk7CiAgICB9Cn0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCountDriver {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCountDriver.class);
        job.setMapperClass(WordCountMapper.class);
        job.setCombinerClass(WordCountReducer.class);
        job.setReducerClass(WordCountReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h1>4. Running and Testing the MapReduce Program</h1>
<div class='content'></div><h2>Step 1: Compile the Program</h2>
<div class='content'><p>Compile the Java files using the following command:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("amF2YWMgLWNsYXNzcGF0aCBgaGFkb29wIGNsYXNzcGF0aGAgLWQgd29yZGNvdW50X2NsYXNzZXMgV29yZENvdW50TWFwcGVyLmphdmEgV29yZENvdW50UmVkdWNlci5qYXZhIFdvcmRDb3VudERyaXZlci5qYXZh"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>javac -classpath `hadoop classpath` -d wordcount_classes WordCountMapper.java WordCountReducer.java WordCountDriver.java</pre></div><div class='content'></div><h2>Step 2: Create a JAR File</h2>
<div class='content'><p>Create a JAR file from the compiled classes:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("amFyIC1jdmYgd29yZGNvdW50LmphciAtQyB3b3JkY291bnRfY2xhc3Nlcy8gLg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>jar -cvf wordcount.jar -C wordcount_classes/ .</pre></div><div class='content'></div><h2>Step 3: Run the Program</h2>
<div class='content'><p>Run the MapReduce job using the Hadoop command:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aGFkb29wIGphciB3b3JkY291bnQuamFyIFdvcmRDb3VudERyaXZlciAvaW5wdXQvcGF0aCAvb3V0cHV0L3BhdGg="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>hadoop jar wordcount.jar WordCountDriver /input/path /output/path</pre></div><div class='content'></div><h1>5. Common Mistakes and Tips</h1>
<div class='content'></div><h2>Common Mistakes</h2>
<div class='content'><ul>
<li><strong>Incorrect Input/Output Paths</strong>: Ensure the input and output paths are correctly specified.</li>
<li><strong>ClassNotFoundException</strong>: Ensure all classes are included in the JAR file.</li>
<li><strong>Incorrect Data Types</strong>: Ensure the data types in the Mapper and Reducer classes match the job configuration.</li>
</ul>
</div><h2>Tips</h2>
<div class='content'><ul>
<li><strong>Use Combiner</strong>: If possible, use a combiner to reduce the amount of data transferred between the map and reduce phases.</li>
<li><strong>Debugging</strong>: Use the Hadoop logs to debug issues. The logs provide detailed information about the job execution.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we covered the basics of writing a MapReduce program, including the Mapper, Reducer, and Driver classes. We also discussed how to compile, package, and run the program on a Hadoop cluster. By understanding these concepts, you can start developing your own MapReduce programs to process large datasets efficiently. In the next section, we will explore optimization techniques to improve the performance of your MapReduce jobs.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-02-mapreduce-job-workflow' title="MapReduce Job Workflow">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='04-04-mapreduce-optimization-techniques' title="MapReduce Optimization Techniques">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
