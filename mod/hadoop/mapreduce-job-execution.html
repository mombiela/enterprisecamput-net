<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MapReduce Job Execution</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/mapreduce-job-execution" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/mapreduce-job-execution" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/mapreduce-job-execution" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/hadoop/mapreduce-job-execution" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/mapreduce-job-execution" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='writing-a-mapreduce-program'>&#x25C4;Writing a MapReduce Program</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">MapReduce Job Execution</a>
	</div>
	<div class='col-4 text-end'>
					<a href='optimizing-mapreduce-jobs'>Optimizing MapReduce Jobs &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to MapReduce</h1>
<div class='content'><p>MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster. It is a core component of Hadoop and is used to process vast amounts of data in a reliable, fault-tolerant manner.</p>
</div><h1>Key Concepts of MapReduce</h1>
<div class='content'><ul>
<li><strong>Map Function</strong>: Processes input key-value pairs to generate a set of intermediate key-value pairs.</li>
<li><strong>Reduce Function</strong>: Merges all intermediate values associated with the same intermediate key.</li>
<li><strong>Job</strong>: A complete MapReduce computation, consisting of multiple tasks.</li>
<li><strong>Task</strong>: An individual unit of work, either a map task or a reduce task.</li>
<li><strong>Job Tracker</strong>: Manages the jobs and resources in the Hadoop cluster.</li>
<li><strong>Task Tracker</strong>: Executes the tasks as directed by the Job Tracker.</li>
</ul>
</div><h1>MapReduce Job Execution Flow</h1>
<div class='content'><ol>
<li><strong>Input Splits</strong>: The input data is split into fixed-size pieces called input splits.</li>
<li><strong>Map Phase</strong>: Each split is processed by a map task, which outputs intermediate key-value pairs.</li>
<li><strong>Shuffle and Sort</strong>: The intermediate data is shuffled and sorted to group all values by key.</li>
<li><strong>Reduce Phase</strong>: The grouped data is processed by reduce tasks to produce the final output.</li>
<li><strong>Output</strong>: The final output is written to the distributed file system.</li>
</ol>
</div><h1>Detailed Steps of MapReduce Job Execution</h1>
<div class='content'></div><h2>Input Splits</h2>
<div class='content'><ul>
<li>The input data is divided into splits, which are processed in parallel by map tasks.</li>
<li>Example:
<pre><code class="language-java">FileInputFormat.addInputPath(job, new Path(&quot;input&quot;));
</code></pre>
</li>
</ul>
</div><h2>Map Phase</h2>
<div class='content'><ul>
<li>Each map task processes a split and generates intermediate key-value pairs.</li>
<li>Example:
<pre><code class="language-java">public class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        StringTokenizer itr = new StringTokenizer(value.toString());
        while (itr.hasMoreTokens()) {
            word.set(itr.nextToken());
            context.write(word, one);
        }
    }
}
</code></pre>
</li>
</ul>
</div><h2>Shuffle and Sort</h2>
<div class='content'><ul>
<li>Intermediate key-value pairs are shuffled and sorted by key.</li>
<li>This step ensures that all values for a given key are sent to the same reducer.</li>
</ul>
</div><h2>Reduce Phase</h2>
<div class='content'><ul>
<li>Reduce tasks process the grouped data and generate the final output.</li>
<li>Example:
<pre><code class="language-java">public class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        result.set(sum);
        context.write(key, result);
    }
}
</code></pre>
</li>
</ul>
</div><h2>Output</h2>
<div class='content'><ul>
<li>The final output is written to the distributed file system.</li>
<li>Example:
<pre><code class="language-java">FileOutputFormat.setOutputPath(job, new Path(&quot;output&quot;));
</code></pre>
</li>
</ul>
</div><h1>Example: Word Count Program</h1>
<div class='content'><p>Here is a complete example of a MapReduce program that counts the occurrences of each word in a text file.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;
import java.util.StringTokenizer;

public class WordCount {

    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>MapReduce is a powerful tool for processing large data sets in a distributed manner. Understanding the job execution flow, from input splits to the final output, is crucial for writing efficient MapReduce programs. By mastering these concepts and practicing with examples like the Word Count program, you can leverage Hadoop's full potential to handle big data challenges.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='writing-a-mapreduce-program'>&#x25C4;Writing a MapReduce Program</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">MapReduce Job Execution</a>
	</div>
	<div class='col-4 text-end'>
					<a href='optimizing-mapreduce-jobs'>Optimizing MapReduce Jobs &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
