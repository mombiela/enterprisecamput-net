<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model Tuning and Optimization</title>

    <link rel="alternate" href="https://campusempresa.com/mod/analisis_datos/05-03-ajuste-optimizacion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/analisis_datos/05-03-ajust-optimitzacio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/analisis_datos/05-03-tuning-optimization" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/analisis_datos/05-03-ajuste-optimizacion" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/analisis_datos/05-03-ajust-optimitzacio" class="px-2">CA</a>
<br>
			<cite>Building today's and tomorrow's society</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
									<a href="./">Course Content</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Technical Skills</a>
				<a href="/all/conocimientos">Knowledge</a>
				<a href="/all/soft_skills">Social Skills</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-cross-validation' title="Cross-Validation and Validation Techniques">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Model Tuning and Optimization</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-implementation-production' title="Model Implementation in Production">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will explore the techniques and methods used to improve the performance of machine learning models. Model tuning and optimization are crucial steps in the data analysis process to ensure that the models are as accurate and efficient as possible.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'><ol>
<li>
<p><strong>Hyperparameters vs. Parameters</strong>:</p>
<ul>
<li><strong>Parameters</strong>: These are the internal coefficients or weights that the model learns from the training data.</li>
<li><strong>Hyperparameters</strong>: These are the external settings that need to be set before the training process begins, such as learning rate, number of trees in a random forest, or the number of layers in a neural network.</li>
</ul>
</li>
<li>
<p><strong>Grid Search</strong>:</p>
<ul>
<li>A method to systematically work through multiple combinations of hyperparameter values, cross-validating as it goes to determine which combination gives the best performance.</li>
</ul>
</li>
<li>
<p><strong>Random Search</strong>:</p>
<ul>
<li>Instead of searching all combinations, it randomly selects a subset of hyperparameter combinations to evaluate.</li>
</ul>
</li>
<li>
<p><strong>Bayesian Optimization</strong>:</p>
<ul>
<li>A more sophisticated method that builds a probabilistic model of the objective function and uses it to select the most promising hyperparameters to evaluate.</li>
</ul>
</li>
<li>
<p><strong>Early Stopping</strong>:</p>
<ul>
<li>A technique to stop training when the model's performance on a validation set starts to degrade, preventing overfitting.</li>
</ul>
</li>
</ol>
</div><h1><p>Practical Examples</p>
</h1>
<div class='content'></div><h2><p>Example 1: Grid Search</p>
</h2>
<div class='content'><p>Let's consider a simple example using <code>GridSearchCV</code> from the <code>scikit-learn</code> library to tune hyperparameters for a Support Vector Machine (SVM) classifier.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0cwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCBHcmlkU2VhcmNoQ1YKZnJvbSBza2xlYXJuLnN2bSBpbXBvcnQgU1ZDCgojIExvYWQgZGF0YXNldAppcmlzID0gZGF0YXNldHMubG9hZF9pcmlzKCkKWCwgeSA9IGlyaXMuZGF0YSwgaXJpcy50YXJnZXQKCiMgRGVmaW5lIHRoZSBtb2RlbAptb2RlbCA9IFNWQygpCgojIERlZmluZSB0aGUgcGFyYW1ldGVyIGdyaWQKcGFyYW1fZ3JpZCA9IHsKICAgICdDJzogWzAuMSwgMSwgMTAsIDEwMF0sCiAgICAnZ2FtbWEnOiBbMSwgMC4xLCAwLjAxLCAwLjAwMV0sCiAgICAna2VybmVsJzogWydyYmYnXQp9CgojIFBlcmZvcm0gZ3JpZCBzZWFyY2gKZ3JpZF9zZWFyY2ggPSBHcmlkU2VhcmNoQ1YobW9kZWwsIHBhcmFtX2dyaWQsIHJlZml0PVRydWUsIHZlcmJvc2U9MikKZ3JpZF9zZWFyY2guZml0KFgsIHkpCgojIFByaW50IHRoZSBiZXN0IHBhcmFtZXRlcnMKcHJpbnQoIkJlc3QgcGFyYW1ldGVycyBmb3VuZDogIiwgZ3JpZF9zZWFyY2guYmVzdF9wYXJhbXNfKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn import datasets
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

# Load dataset
iris = datasets.load_iris()
X, y = iris.data, iris.target

# Define the model
model = SVC()

# Define the parameter grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf']
}

# Perform grid search
grid_search = GridSearchCV(model, param_grid, refit=True, verbose=2)
grid_search.fit(X, y)

# Print the best parameters
print(&quot;Best parameters found: &quot;, grid_search.best_params_)</pre></div><div class='content'></div><h2><p>Example 2: Random Search</p>
</h2>
<div class='content'><p>Using <code>RandomizedSearchCV</code> for hyperparameter tuning.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgUmFuZG9taXplZFNlYXJjaENWCmZyb20gc2NpcHkuc3RhdHMgaW1wb3J0IHVuaWZvcm0KCiMgRGVmaW5lIHRoZSBwYXJhbWV0ZXIgZGlzdHJpYnV0aW9uCnBhcmFtX2Rpc3QgPSB7CiAgICAnQyc6IHVuaWZvcm0oMC4xLCAxMCksCiAgICAnZ2FtbWEnOiB1bmlmb3JtKDAuMDAxLCAxKSwKICAgICdrZXJuZWwnOiBbJ3JiZiddCn0KCiMgUGVyZm9ybSByYW5kb20gc2VhcmNoCnJhbmRvbV9zZWFyY2ggPSBSYW5kb21pemVkU2VhcmNoQ1YobW9kZWwsIHBhcmFtX2Rpc3QsIG5faXRlcj0xMDAsIHJlZml0PVRydWUsIHZlcmJvc2U9MikKcmFuZG9tX3NlYXJjaC5maXQoWCwgeSkKCiMgUHJpbnQgdGhlIGJlc3QgcGFyYW1ldGVycwpwcmludCgiQmVzdCBwYXJhbWV0ZXJzIGZvdW5kOiAiLCByYW5kb21fc2VhcmNoLmJlc3RfcGFyYW1zXyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform

# Define the parameter distribution
param_dist = {
    'C': uniform(0.1, 10),
    'gamma': uniform(0.001, 1),
    'kernel': ['rbf']
}

# Perform random search
random_search = RandomizedSearchCV(model, param_dist, n_iter=100, refit=True, verbose=2)
random_search.fit(X, y)

# Print the best parameters
print(&quot;Best parameters found: &quot;, random_search.best_params_)</pre></div><div class='content'></div><h2><p>Example 3: Early Stopping</p>
</h2>
<div class='content'><p>Using early stopping with a gradient boosting classifier.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBHcmFkaWVudEJvb3N0aW5nQ2xhc3NpZmllcgpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBhY2N1cmFjeV9zY29yZQoKIyBTcGxpdCB0aGUgZGF0YQpYX3RyYWluLCBYX3ZhbCwgeV90cmFpbiwgeV92YWwgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjIsIHJhbmRvbV9zdGF0ZT00MikKCiMgRGVmaW5lIHRoZSBtb2RlbCB3aXRoIGVhcmx5IHN0b3BwaW5nCm1vZGVsID0gR3JhZGllbnRCb29zdGluZ0NsYXNzaWZpZXIobl9lc3RpbWF0b3JzPTEwMDAsIGxlYXJuaW5nX3JhdGU9MC4wMSwgdmFsaWRhdGlvbl9mcmFjdGlvbj0wLjEsIG5faXRlcl9ub19jaGFuZ2U9MTApCgojIFRyYWluIHRoZSBtb2RlbAptb2RlbC5maXQoWF90cmFpbiwgeV90cmFpbikKCiMgUHJlZGljdCBhbmQgZXZhbHVhdGUKeV9wcmVkID0gbW9kZWwucHJlZGljdChYX3ZhbCkKcHJpbnQoIlZhbGlkYXRpb24gYWNjdXJhY3k6ICIsIGFjY3VyYWN5X3Njb3JlKHlfdmFsLCB5X3ByZWQpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Split the data
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model with early stopping
model = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01, validation_fraction=0.1, n_iter_no_change=10)

# Train the model
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_val)
print(&quot;Validation accuracy: &quot;, accuracy_score(y_val, y_pred))</pre></div><div class='content'></div><h1><p>Practical Exercises</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: Grid Search with Decision Trees</p>
</h2>
<div class='content'><p><strong>Task</strong>: Use <code>GridSearchCV</code> to find the best hyperparameters for a Decision Tree classifier on the Iris dataset.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLnRyZWUgaW1wb3J0IERlY2lzaW9uVHJlZUNsYXNzaWZpZXIKCiMgRGVmaW5lIHRoZSBtb2RlbAptb2RlbCA9IERlY2lzaW9uVHJlZUNsYXNzaWZpZXIoKQoKIyBEZWZpbmUgdGhlIHBhcmFtZXRlciBncmlkCnBhcmFtX2dyaWQgPSB7CiAgICAnbWF4X2RlcHRoJzogW05vbmUsIDEwLCAyMCwgMzBdLAogICAgJ21pbl9zYW1wbGVzX3NwbGl0JzogWzIsIDUsIDEwXSwKICAgICdtaW5fc2FtcGxlc19sZWFmJzogWzEsIDIsIDRdCn0KCiMgUGVyZm9ybSBncmlkIHNlYXJjaApncmlkX3NlYXJjaCA9IEdyaWRTZWFyY2hDVihtb2RlbCwgcGFyYW1fZ3JpZCwgcmVmaXQ9VHJ1ZSwgdmVyYm9zZT0yKQpncmlkX3NlYXJjaC5maXQoWCwgeSkKCiMgUHJpbnQgdGhlIGJlc3QgcGFyYW1ldGVycwpwcmludCgiQmVzdCBwYXJhbWV0ZXJzIGZvdW5kOiAiLCBncmlkX3NlYXJjaC5iZXN0X3BhcmFtc18p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.tree import DecisionTreeClassifier

# Define the model
model = DecisionTreeClassifier()

# Define the parameter grid
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Perform grid search
grid_search = GridSearchCV(model, param_grid, refit=True, verbose=2)
grid_search.fit(X, y)

# Print the best parameters
print(&quot;Best parameters found: &quot;, grid_search.best_params_)</pre></div><div class='content'></div><h2><p>Exercise 2: Random Search with Random Forest</p>
</h2>
<div class='content'><p><strong>Task</strong>: Use <code>RandomizedSearchCV</code> to find the best hyperparameters for a Random Forest classifier on the Iris dataset.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBSYW5kb21Gb3Jlc3RDbGFzc2lmaWVyCgojIERlZmluZSB0aGUgbW9kZWwKbW9kZWwgPSBSYW5kb21Gb3Jlc3RDbGFzc2lmaWVyKCkKCiMgRGVmaW5lIHRoZSBwYXJhbWV0ZXIgZGlzdHJpYnV0aW9uCnBhcmFtX2Rpc3QgPSB7CiAgICAnbl9lc3RpbWF0b3JzJzogWzEwLCA1MCwgMTAwLCAyMDBdLAogICAgJ21heF9mZWF0dXJlcyc6IFsnYXV0bycsICdzcXJ0JywgJ2xvZzInXSwKICAgICdtYXhfZGVwdGgnOiBbTm9uZSwgMTAsIDIwLCAzMF0sCiAgICAnbWluX3NhbXBsZXNfc3BsaXQnOiBbMiwgNSwgMTBdLAogICAgJ21pbl9zYW1wbGVzX2xlYWYnOiBbMSwgMiwgNF0KfQoKIyBQZXJmb3JtIHJhbmRvbSBzZWFyY2gKcmFuZG9tX3NlYXJjaCA9IFJhbmRvbWl6ZWRTZWFyY2hDVihtb2RlbCwgcGFyYW1fZGlzdCwgbl9pdGVyPTEwMCwgcmVmaXQ9VHJ1ZSwgdmVyYm9zZT0yKQpyYW5kb21fc2VhcmNoLmZpdChYLCB5KQoKIyBQcmludCB0aGUgYmVzdCBwYXJhbWV0ZXJzCnByaW50KCJCZXN0IHBhcmFtZXRlcnMgZm91bmQ6ICIsIHJhbmRvbV9zZWFyY2guYmVzdF9wYXJhbXNfKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import RandomForestClassifier

# Define the model
model = RandomForestClassifier()

# Define the parameter distribution
param_dist = {
    'n_estimators': [10, 50, 100, 200],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Perform random search
random_search = RandomizedSearchCV(model, param_dist, n_iter=100, refit=True, verbose=2)
random_search.fit(X, y)

# Print the best parameters
print(&quot;Best parameters found: &quot;, random_search.best_params_)</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Overfitting</strong>: Be cautious of overfitting when tuning hyperparameters. Use cross-validation to ensure that the model generalizes well to unseen data.</li>
<li><strong>Computational Cost</strong>: Grid search can be computationally expensive. Random search or Bayesian optimization can be more efficient alternatives.</li>
<li><strong>Validation Set</strong>: Always use a separate validation set to evaluate the performance of the tuned model to avoid biased results.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we covered the importance of model tuning and optimization, explored different methods such as grid search, random search, and early stopping, and provided practical examples and exercises. By carefully tuning hyperparameters, you can significantly improve the performance of your machine learning models, ensuring they are both accurate and efficient.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-cross-validation' title="Cross-Validation and Validation Techniques">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-implementation-production' title="Model Implementation in Production">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
