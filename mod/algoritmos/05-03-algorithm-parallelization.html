<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithm Parallelization</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos/05-03-paralelizacion-de-algoritmos" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos/05-03-paralelizacion-de-algoritmos" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos/05-03-algorithm-parallelization" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/algoritmos/05-03-paralelizacion-de-algoritmos" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos/05-03-paralelizacion-de-algoritmos" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-efficient-memory-usage' title="Efficient Memory Usage">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Algorithm Parallelization</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-complexity-exercises' title="Time and Space Complexity Exercises">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Algorithm parallelization is a technique used to improve the performance of algorithms by dividing tasks into smaller sub-tasks that can be executed simultaneously on multiple processors. This section will cover the basic concepts, types of parallelism, and practical examples to help you understand and implement parallel algorithms.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'><ol>
<li><strong>Parallel Computing</strong>: The simultaneous use of multiple compute resources to solve a computational problem.</li>
<li><strong>Concurrency vs. Parallelism</strong>: Concurrency is about dealing with multiple tasks at once, while parallelism is about doing multiple tasks simultaneously.</li>
<li><strong>Granularity</strong>: The size of the tasks into which a problem is divided. Fine-grained parallelism involves small tasks, while coarse-grained parallelism involves larger tasks.</li>
<li><strong>Speedup</strong>: The ratio of the time taken to solve a problem on a single processor to the time taken on multiple processors.</li>
<li><strong>Amdahl's Law</strong>: A formula used to find the maximum improvement in performance using multiple processors.</li>
</ol>
</div><h1><p>Types of Parallelism</p>
</h1>
<div class='content'><ol>
<li><strong>Data Parallelism</strong>: Distributing subsets of the same data across multiple processors and performing the same operation on each subset.</li>
<li><strong>Task Parallelism</strong>: Distributing different tasks (or threads) across multiple processors.</li>
<li><strong>Pipeline Parallelism</strong>: Dividing a task into stages and processing different stages in parallel.</li>
</ol>
</div><h1><p>Practical Examples</p>
</h1>
<div class='content'></div><h2><p>Example 1: Parallel Sum of an Array</p>
</h2>
<div class='content'><p>Let's start with a simple example of summing the elements of an array in parallel using Python's <code>multiprocessing</code> module.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG11bHRpcHJvY2Vzc2luZwoKZGVmIHBhcmFsbGVsX3N1bShhcnIsIHN0YXJ0LCBlbmQsIHJlc3VsdCwgaW5kZXgpOgogICAgdG90YWwgPSBzdW0oYXJyW3N0YXJ0OmVuZF0pCiAgICByZXN1bHRbaW5kZXhdID0gdG90YWwKCmlmIF9fbmFtZV9fID09ICJfX21haW5fXyI6CiAgICBhcnIgPSBbaSBmb3IgaSBpbiByYW5nZSgxMDAwMDAwKV0KICAgIG51bV9wcm9jZXNzZXMgPSA0CiAgICBjaHVua19zaXplID0gbGVuKGFycikgLy8gbnVtX3Byb2Nlc3NlcwogICAgcHJvY2Vzc2VzID0gW10KICAgIHJlc3VsdCA9IG11bHRpcHJvY2Vzc2luZy5BcnJheSgnaScsIG51bV9wcm9jZXNzZXMpCgogICAgZm9yIGkgaW4gcmFuZ2UobnVtX3Byb2Nlc3Nlcyk6CiAgICAgICAgc3RhcnQgPSBpICogY2h1bmtfc2l6ZQogICAgICAgIGVuZCA9IChpICsgMSkgKiBjaHVua19zaXplIGlmIGkgIT0gbnVtX3Byb2Nlc3NlcyAtIDEgZWxzZSBsZW4oYXJyKQogICAgICAgIHByb2Nlc3MgPSBtdWx0aXByb2Nlc3NpbmcuUHJvY2Vzcyh0YXJnZXQ9cGFyYWxsZWxfc3VtLCBhcmdzPShhcnIsIHN0YXJ0LCBlbmQsIHJlc3VsdCwgaSkpCiAgICAgICAgcHJvY2Vzc2VzLmFwcGVuZChwcm9jZXNzKQogICAgICAgIHByb2Nlc3Muc3RhcnQoKQoKICAgIGZvciBwcm9jZXNzIGluIHByb2Nlc3NlczoKICAgICAgICBwcm9jZXNzLmpvaW4oKQoKICAgIHRvdGFsX3N1bSA9IHN1bShyZXN1bHQpCiAgICBwcmludChmIlRvdGFsIFN1bToge3RvdGFsX3N1bX0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import multiprocessing

def parallel_sum(arr, start, end, result, index):
    total = sum(arr[start:end])
    result[index] = total

if __name__ == &quot;__main__&quot;:
    arr = [i for i in range(1000000)]
    num_processes = 4
    chunk_size = len(arr) // num_processes
    processes = []
    result = multiprocessing.Array('i', num_processes)

    for i in range(num_processes):
        start = i * chunk_size
        end = (i + 1) * chunk_size if i != num_processes - 1 else len(arr)
        process = multiprocessing.Process(target=parallel_sum, args=(arr, start, end, result, i))
        processes.append(process)
        process.start()

    for process in processes:
        process.join()

    total_sum = sum(result)
    print(f&quot;Total Sum: {total_sum}&quot;)</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li>We divide the array into chunks and assign each chunk to a separate process.</li>
<li>Each process calculates the sum of its chunk and stores the result in a shared array.</li>
<li>Finally, we sum the partial results to get the total sum.</li>
</ul>
</div><h2><p>Example 2: Parallel Matrix Multiplication</p>
</h2>
<div class='content'><p>Matrix multiplication can also be parallelized. Here is an example using Python's <code>concurrent.futures</code> module.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGNvbmN1cnJlbnQuZnV0dXJlcwppbXBvcnQgbnVtcHkgYXMgbnAKCmRlZiBtYXRyaXhfbXVsdGlwbHkoQSwgQiwgcmVzdWx0LCByb3cpOgogICAgZm9yIGogaW4gcmFuZ2UobGVuKEJbMF0pKToKICAgICAgICByZXN1bHRbcm93XVtqXSA9IHN1bShBW3Jvd11ba10gKiBCW2tdW2pdIGZvciBrIGluIHJhbmdlKGxlbihCKSkpCgppZiBfX25hbWVfXyA9PSAiX19tYWluX18iOgogICAgQSA9IG5wLnJhbmRvbS5yYW5kKDEwMCwgMTAwKQogICAgQiA9IG5wLnJhbmRvbS5yYW5kKDEwMCwgMTAwKQogICAgcmVzdWx0ID0gbnAuemVyb3MoKDEwMCwgMTAwKSkKCiAgICB3aXRoIGNvbmN1cnJlbnQuZnV0dXJlcy5UaHJlYWRQb29sRXhlY3V0b3IoKSBhcyBleGVjdXRvcjoKICAgICAgICBmdXR1cmVzID0gW2V4ZWN1dG9yLnN1Ym1pdChtYXRyaXhfbXVsdGlwbHksIEEsIEIsIHJlc3VsdCwgaSkgZm9yIGkgaW4gcmFuZ2UobGVuKEEpKV0KICAgICAgICBjb25jdXJyZW50LmZ1dHVyZXMud2FpdChmdXR1cmVzKQoKICAgIHByaW50KCJSZXN1bHRhbnQgTWF0cml4OiIpCiAgICBwcmludChyZXN1bHQp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import concurrent.futures
import numpy as np

def matrix_multiply(A, B, result, row):
    for j in range(len(B[0])):
        result[row][j] = sum(A[row][k] * B[k][j] for k in range(len(B)))

if __name__ == &quot;__main__&quot;:
    A = np.random.rand(100, 100)
    B = np.random.rand(100, 100)
    result = np.zeros((100, 100))

    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = [executor.submit(matrix_multiply, A, B, result, i) for i in range(len(A))]
        concurrent.futures.wait(futures)

    print(&quot;Resultant Matrix:&quot;)
    print(result)</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li>We use a thread pool to parallelize the multiplication of each row of matrix A with matrix B.</li>
<li>Each thread computes one row of the resultant matrix.</li>
</ul>
</div><h1><p>Practical Exercises</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: Parallel Array Maximum</p>
</h2>
<div class='content'><p>Write a parallel algorithm to find the maximum element in an array using Python's <code>multiprocessing</code> module.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG11bHRpcHJvY2Vzc2luZwoKZGVmIHBhcmFsbGVsX21heChhcnIsIHN0YXJ0LCBlbmQsIHJlc3VsdCwgaW5kZXgpOgogICAgcmVzdWx0W2luZGV4XSA9IG1heChhcnJbc3RhcnQ6ZW5kXSkKCmlmIF9fbmFtZV9fID09ICJfX21haW5fXyI6CiAgICBhcnIgPSBbaSBmb3IgaSBpbiByYW5nZSgxMDAwMDAwKV0KICAgIG51bV9wcm9jZXNzZXMgPSA0CiAgICBjaHVua19zaXplID0gbGVuKGFycikgLy8gbnVtX3Byb2Nlc3NlcwogICAgcHJvY2Vzc2VzID0gW10KICAgIHJlc3VsdCA9IG11bHRpcHJvY2Vzc2luZy5BcnJheSgnaScsIG51bV9wcm9jZXNzZXMpCgogICAgZm9yIGkgaW4gcmFuZ2UobnVtX3Byb2Nlc3Nlcyk6CiAgICAgICAgc3RhcnQgPSBpICogY2h1bmtfc2l6ZQogICAgICAgIGVuZCA9IChpICsgMSkgKiBjaHVua19zaXplIGlmIGkgIT0gbnVtX3Byb2Nlc3NlcyAtIDEgZWxzZSBsZW4oYXJyKQogICAgICAgIHByb2Nlc3MgPSBtdWx0aXByb2Nlc3NpbmcuUHJvY2Vzcyh0YXJnZXQ9cGFyYWxsZWxfbWF4LCBhcmdzPShhcnIsIHN0YXJ0LCBlbmQsIHJlc3VsdCwgaSkpCiAgICAgICAgcHJvY2Vzc2VzLmFwcGVuZChwcm9jZXNzKQogICAgICAgIHByb2Nlc3Muc3RhcnQoKQoKICAgIGZvciBwcm9jZXNzIGluIHByb2Nlc3NlczoKICAgICAgICBwcm9jZXNzLmpvaW4oKQoKICAgIG1heF92YWx1ZSA9IG1heChyZXN1bHQpCiAgICBwcmludChmIk1heGltdW0gVmFsdWU6IHttYXhfdmFsdWV9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import multiprocessing

def parallel_max(arr, start, end, result, index):
    result[index] = max(arr[start:end])

if __name__ == &quot;__main__&quot;:
    arr = [i for i in range(1000000)]
    num_processes = 4
    chunk_size = len(arr) // num_processes
    processes = []
    result = multiprocessing.Array('i', num_processes)

    for i in range(num_processes):
        start = i * chunk_size
        end = (i + 1) * chunk_size if i != num_processes - 1 else len(arr)
        process = multiprocessing.Process(target=parallel_max, args=(arr, start, end, result, i))
        processes.append(process)
        process.start()

    for process in processes:
        process.join()

    max_value = max(result)
    print(f&quot;Maximum Value: {max_value}&quot;)</pre></div><div class='content'></div><h2><p>Exercise 2: Parallel Merge Sort</p>
</h2>
<div class='content'><p>Implement a parallel version of the merge sort algorithm.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import multiprocessing

def merge_sort(arr):
    if len(arr) &gt; 1:
        mid = len(arr) // 2
        L = arr[:mid]
        R = arr[mid:]

        merge_sort(L)
        merge_sort(R)

        i = j = k = 0

        while i &lt; len(L) and j &lt; len(R):
            if L[i] &lt; R[j]:
                arr[k] = L[i]
                i += 1
            else:
                arr[k] = R[j]
                j += 1
            k += 1

        while i &lt; len(L):
            arr[k] = L[i]
            i += 1
            k += 1

        while j &lt; len(R):
            arr[k] = R[j]
            j += 1
            k += 1

def parallel_merge_sort(arr):
    if len(arr) &lt;= 1000:
        merge_sort(arr)
    else:
        mid = len(arr) // 2
        L = arr[:mid]
        R = arr[mid:]

        p1 = multiprocessing.Process(target=parallel_merge_sort, args=(L,))
        p2 = multiprocessing.Process(target=parallel_merge_sort, args=(R,))

        p1.start()
        p2.start()
        p1.join()
        p2.join()

        i = j = k = 0

        while i &lt; len(L) and j &lt; len(R):
            if L[i] &lt; R[j]:
                arr[k] = L[i]
                i += 1
            else:
                arr[k] = R[j]
                j += 1
            k += 1

        while i &lt; len(L):
            arr[k] = L[i]
            i += 1
            k += 1

        while j &lt; len(R):
            arr[k] = R[j]
            j += 1
            k += 1

if __name__ == &quot;__main__&quot;:
    arr = [i for i in range(1000000, 0, -1)]
    parallel_merge_sort(arr)
    print(&quot;Sorted Array:&quot;)
    print(arr[:100])  # Print first 100 elements to verify</pre></div><div class='content'></div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we covered the basics of algorithm parallelization, including key concepts, types of parallelism, and practical examples. We also provided exercises to help you practice and reinforce your understanding of parallel algorithms. By leveraging parallel computing, you can significantly improve the performance of your algorithms, making them more efficient and scalable.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-efficient-memory-usage' title="Efficient Memory Usage">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-complexity-exercises' title="Time and Space Complexity Exercises">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
