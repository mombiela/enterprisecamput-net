<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Networks and Deep Learning</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos_avanzados/redes-neuronales-y-deep-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos_avanzados/redes-neuronales-y-deep-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos_avanzados/redes-neuronales-y-deep-learning" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/algoritmos_avanzados/redes-neuronales-y-deep-learning" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos_avanzados/redes-neuronales-y-deep-learning" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introduction to Neural Networks</h1>
<div class='content'><p>Neural networks are a set of algorithms designed to recognize patterns. They are inspired by the structure and functioning of the human brain. Neural networks are the foundation of Deep Learning, a subdiscipline of machine learning.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Artificial Neurons</strong>: Basic units of a neural network, also known as perceptrons.</li>
<li><strong>Layers</strong>: Set of neurons. Neural networks usually have an input layer, one or more hidden layers, and an output layer.</li>
<li><strong>Weights and Biases</strong>: Adjustable parameters that determine the output of a neuron.</li>
<li><strong>Activation Function</strong>: Function that introduces non-linearity into the network. Common examples include ReLU, Sigmoid, and Tanh.</li>
<li><strong>Forward Propagation</strong>: Process of calculating the output of the neural network.</li>
<li><strong>Backpropagation</strong>: Algorithm used to adjust the weights and biases of the neural network during training.</li>
</ul>
</div><h2>Code Example: Simple Neuron</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIFNpZ21vaWQgYWN0aXZhdGlvbiBmdW5jdGlvbgpkZWYgc2lnbW9pZCh4KToKICAgIHJldHVybiAxIC8gKDEgKyBucC5leHAoLXgpKQoKIyBEZXJpdmF0aXZlIG9mIHRoZSBTaWdtb2lkIGZ1bmN0aW9uCmRlZiBzaWdtb2lkX2Rlcml2YXRpdmUoeCk6CiAgICByZXR1cm4geCAqICgxIC0geCkKCiMgVHJhaW5pbmcgYSBzaW1wbGUgbmV1cm9uCmlucHV0cyA9IG5wLmFycmF5KFtbMCwgMF0sIFswLCAxXSwgWzEsIDBdLCBbMSwgMV1dKQpvdXRwdXRzID0gbnAuYXJyYXkoW1swXSwgWzFdLCBbMV0sIFswXV0pCgojIEluaXRpYWxpemF0aW9uIG9mIHdlaWdodHMgYW5kIGJpYXNlcwp3ZWlnaHRzID0gbnAucmFuZG9tLnJhbmQoMiwgMSkKYmlhcyA9IG5wLnJhbmRvbS5yYW5kKDEpCgojIExlYXJuaW5nIHJhdGUKbGVhcm5pbmdfcmF0ZSA9IDAuMQoKIyBUcmFpbmluZwpmb3IgZXBvY2ggaW4gcmFuZ2UoMTAwMDApOgogICAgIyBGb3J3YXJkIHByb3BhZ2F0aW9uCiAgICBpbnB1dF9sYXllciA9IGlucHV0cwogICAgd2VpZ2h0ZWRfc3VtID0gbnAuZG90KGlucHV0X2xheWVyLCB3ZWlnaHRzKSArIGJpYXMKICAgIGFjdGl2YXRlZF9vdXRwdXQgPSBzaWdtb2lkKHdlaWdodGVkX3N1bSkKICAgIAogICAgIyBFcnJvciBjYWxjdWxhdGlvbgogICAgZXJyb3IgPSBvdXRwdXRzIC0gYWN0aXZhdGVkX291dHB1dAogICAgCiAgICAjIEJhY2twcm9wYWdhdGlvbgogICAgYWRqdXN0bWVudHMgPSBlcnJvciAqIHNpZ21vaWRfZGVyaXZhdGl2ZShhY3RpdmF0ZWRfb3V0cHV0KQogICAgd2VpZ2h0cyArPSBucC5kb3QoaW5wdXRfbGF5ZXIuVCwgYWRqdXN0bWVudHMpICogbGVhcm5pbmdfcmF0ZQogICAgYmlhcyArPSBucC5zdW0oYWRqdXN0bWVudHMpICogbGVhcm5pbmdfcmF0ZQoKcHJpbnQoIldlaWdodHMgYWRqdXN0ZWQgYWZ0ZXIgdHJhaW5pbmc6IikKcHJpbnQod2VpZ2h0cykKcHJpbnQoIkJpYXMgYWRqdXN0ZWQgYWZ0ZXIgdHJhaW5pbmc6IikKcHJpbnQoYmlhcyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Sigmoid activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivative of the Sigmoid function
def sigmoid_derivative(x):
    return x * (1 - x)

# Training a simple neuron
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
outputs = np.array([[0], [1], [1], [0]])

# Initialization of weights and biases
weights = np.random.rand(2, 1)
bias = np.random.rand(1)

# Learning rate
learning_rate = 0.1

# Training
for epoch in range(10000):
    # Forward propagation
    input_layer = inputs
    weighted_sum = np.dot(input_layer, weights) + bias
    activated_output = sigmoid(weighted_sum)
    
    # Error calculation
    error = outputs - activated_output
    
    # Backpropagation
    adjustments = error * sigmoid_derivative(activated_output)
    weights += np.dot(input_layer.T, adjustments) * learning_rate
    bias += np.sum(adjustments) * learning_rate

print(&quot;Weights adjusted after training:&quot;)
print(weights)
print(&quot;Bias adjusted after training:&quot;)
print(bias)</pre></div><div class='content'></div><h1>Deep Learning</h1>
<div class='content'><p>Deep Learning is a branch of machine learning that uses deep neural networks, i.e., networks with multiple hidden layers. These networks are capable of learning hierarchical representations of data.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Convolutional Neural Networks (CNNs)</strong>: Mainly used for image and video processing.</li>
<li><strong>Recurrent Neural Networks (RNNs)</strong>: Suitable for sequence processing, such as text and time series.</li>
<li><strong>Autoencoders</strong>: Neural networks used for dimensionality reduction and anomaly detection.</li>
<li><strong>Generative Adversarial Networks (GANs)</strong>: Networks used to generate synthetic data that appears real.</li>
</ul>
</div><h2>Code Example: Convolutional Neural Network (CNN) with Keras</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBsYXllcnMsIG1vZGVscwoKIyBNb2RlbCBkZWZpbml0aW9uCm1vZGVsID0gbW9kZWxzLlNlcXVlbnRpYWwoKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgzMiwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KDI4LCAyOCwgMSkpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg2NCwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JykpCm1vZGVsLmFkZChsYXllcnMuTWF4UG9vbGluZzJEKCgyLCAyKSkpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDY0LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnKSkKCiMgQWRkIGRlbnNlIGxheWVycwptb2RlbC5hZGQobGF5ZXJzLkZsYXR0ZW4oKSkKbW9kZWwuYWRkKGxheWVycy5EZW5zZSg2NCwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDEwLCBhY3RpdmF0aW9uPSdzb2Z0bWF4JykpCgojIE1vZGVsIGNvbXBpbGF0aW9uCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywKICAgICAgICAgICAgICBsb3NzPSdzcGFyc2VfY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5JywKICAgICAgICAgICAgICBtZXRyaWNzPVsnYWNjdXJhY3knXSkKCiMgTW9kZWwgc3VtbWFyeQptb2RlbC5zdW1tYXJ5KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers, models

# Model definition
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

# Add dense layers
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

# Model compilation
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Model summary
model.summary()</pre></div><div class='content'></div><h1>Comparison of Types of Neural Networks</h1>
<div class='content'><p>| Network Type | Main Applications | Advantages | Disadvantages |
|--------------|--------------------|------------|---------------|
| CNN          | Image and video processing | Efficient in extracting spatial features | Requires a large amount of labeled data |
| RNN          | Sequence processing, text, time series | Captures temporal dependencies | Gradient vanishing problems |
| Autoencoders | Dimensionality reduction, anomaly detection | Efficient in data compression | Does not always capture all important features |
| GANs         | Synthetic data generation | Ability to generate realistic data | Difficult to train, stability issues |</p>
</div><h1>Conclusion</h1>
<div class='content'><p>Neural networks and Deep Learning have revolutionized the field of machine learning, enabling significant advances in areas such as image recognition, natural language processing, and synthetic data generation. Understanding the basic concepts and different architectures of neural networks is essential for any professional who wishes to specialize in advanced algorithms and machine learning.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
