<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Regression Algorithms</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos_avanzados/algoritmos-de-regresion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos_avanzados/algoritmos-de-regresion" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos_avanzados/algoritmos-de-regresion" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/algoritmos_avanzados/algoritmos-de-regresion" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos_avanzados/algoritmos-de-regresion" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introduction to Regression</h1>
<div class='content'><p>Regression is a supervised learning technique used to predict continuous values. Unlike classification, which predicts categories, regression focuses on predicting a dependent variable based on one or more independent variables.</p>
</div><h1>Types of Regression Algorithms</h1>
<div class='content'><p>There are several types of regression algorithms, each with its own characteristics and applications. Below are some of the most common ones:</p>
</div><h2>Linear Regression</h2>
<div class='content'><p>Linear regression is one of the simplest and most widely used methods for modeling the relationship between a dependent variable and one or more independent variables.</p>
<ul>
<li><strong>Formula</strong>: \( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon \)</li>
<li><strong>Objective</strong>: Minimize the sum of squared errors (MSE).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgoKIyBFeGFtcGxlIGRhdGEKWCA9IG5wLmFycmF5KFtbMV0sIFsyXSwgWzNdLCBbNF0sIFs1XV0pCnkgPSBucC5hcnJheShbMSwgMywgMiwgNSwgNF0pCgojIENyZWF0ZSB0aGUgbGluZWFyIHJlZ3Jlc3Npb24gbW9kZWwKbW9kZWwgPSBMaW5lYXJSZWdyZXNzaW9uKCkKbW9kZWwuZml0KFgsIHkpCgojIFByZWRpY3Rpb25zCnlfcHJlZCA9IG1vZGVsLnByZWRpY3QoWCkKCiMgVmlzdWFsaXphdGlvbgpwbHQuc2NhdHRlcihYLCB5LCBjb2xvcj0nYmx1ZScpCnBsdC5wbG90KFgsIHlfcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCd5JykKcGx0LnRpdGxlKCdMaW5lYXIgUmVncmVzc2lvbicpCnBsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Example data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Create the linear regression model
model = LinearRegression()
model.fit(X, y)

# Predictions
y_pred = model.predict(X)

# Visualization
plt.scatter(X, y, color='blue')
plt.plot(X, y_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression')
plt.show()</pre></div><div class='content'></div><h2>Polynomial Regression</h2>
<div class='content'><p>Polynomial regression is an extension of linear regression that allows modeling non-linear relationships between variables.</p>
<ul>
<li><strong>Formula</strong>: \( y = \beta_0 + \beta_1 x + \beta_2 x^2 + \ldots + \beta_n x^n + \epsilon \)</li>
<li><strong>Objective</strong>: Minimize the sum of squared errors (MSE).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFBvbHlub21pYWxGZWF0dXJlcwpmcm9tIHNrbGVhcm4ucGlwZWxpbmUgaW1wb3J0IG1ha2VfcGlwZWxpbmUKCiMgRXhhbXBsZSBkYXRhClggPSBucC5hcnJheShbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV1dKQp5ID0gbnAuYXJyYXkoWzEsIDMsIDIsIDUsIDRdKQoKIyBDcmVhdGUgdGhlIHBvbHlub21pYWwgcmVncmVzc2lvbiBtb2RlbApwb2x5X21vZGVsID0gbWFrZV9waXBlbGluZShQb2x5bm9taWFsRmVhdHVyZXMoZGVncmVlPTIpLCBMaW5lYXJSZWdyZXNzaW9uKCkpCnBvbHlfbW9kZWwuZml0KFgsIHkpCgojIFByZWRpY3Rpb25zCnlfcG9seV9wcmVkID0gcG9seV9tb2RlbC5wcmVkaWN0KFgpCgojIFZpc3VhbGl6YXRpb24KcGx0LnNjYXR0ZXIoWCwgeSwgY29sb3I9J2JsdWUnKQpwbHQucGxvdChYLCB5X3BvbHlfcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCd5JykKcGx0LnRpdGxlKCdQb2x5bm9taWFsIFJlZ3Jlc3Npb24nKQpwbHQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Example data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Create the polynomial regression model
poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
poly_model.fit(X, y)

# Predictions
y_poly_pred = poly_model.predict(X)

# Visualization
plt.scatter(X, y, color='blue')
plt.plot(X, y_poly_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Polynomial Regression')
plt.show()</pre></div><div class='content'></div><h2>Ridge Regression</h2>
<div class='content'><p>Ridge regression is a regularization technique that introduces a penalty on the coefficients of linear regression to avoid overfitting.</p>
<ul>
<li><strong>Formula</strong>: \( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon \)</li>
<li><strong>Penalty</strong>: \( \lambda \sum_{i=1}^{n} \beta_i^2 \)</li>
<li><strong>Objective</strong>: Minimize the sum of squared errors (MSE) plus the penalty.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgUmlkZ2UKCiMgRXhhbXBsZSBkYXRhClggPSBucC5hcnJheShbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV1dKQp5ID0gbnAuYXJyYXkoWzEsIDMsIDIsIDUsIDRdKQoKIyBDcmVhdGUgdGhlIFJpZGdlIHJlZ3Jlc3Npb24gbW9kZWwKcmlkZ2VfbW9kZWwgPSBSaWRnZShhbHBoYT0xLjApCnJpZGdlX21vZGVsLmZpdChYLCB5KQoKIyBQcmVkaWN0aW9ucwp5X3JpZGdlX3ByZWQgPSByaWRnZV9tb2RlbC5wcmVkaWN0KFgpCgojIFZpc3VhbGl6YXRpb24KcGx0LnNjYXR0ZXIoWCwgeSwgY29sb3I9J2JsdWUnKQpwbHQucGxvdChYLCB5X3JpZGdlX3ByZWQsIGNvbG9yPSdyZWQnKQpwbHQueGxhYmVsKCdYJykKcGx0LnlsYWJlbCgneScpCnBsdC50aXRsZSgnUmlkZ2UgUmVncmVzc2lvbicpCnBsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.linear_model import Ridge

# Example data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Create the Ridge regression model
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X, y)

# Predictions
y_ridge_pred = ridge_model.predict(X)

# Visualization
plt.scatter(X, y, color='blue')
plt.plot(X, y_ridge_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Ridge Regression')
plt.show()</pre></div><div class='content'></div><h2>Lasso Regression</h2>
<div class='content'><p>Lasso regression is another regularization technique that introduces a penalty on the coefficients of linear regression, but uses the L1 norm instead of the L2 norm.</p>
<ul>
<li><strong>Formula</strong>: \( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon \)</li>
<li><strong>Penalty</strong>: \( \lambda \sum_{i=1}^{n} |\beta_i| \)</li>
<li><strong>Objective</strong>: Minimize the sum of squared errors (MSE) plus the penalty.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGFzc28KCiMgRXhhbXBsZSBkYXRhClggPSBucC5hcnJheShbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV1dKQp5ID0gbnAuYXJyYXkoWzEsIDMsIDIsIDUsIDRdKQoKIyBDcmVhdGUgdGhlIExhc3NvIHJlZ3Jlc3Npb24gbW9kZWwKbGFzc29fbW9kZWwgPSBMYXNzbyhhbHBoYT0wLjEpCmxhc3NvX21vZGVsLmZpdChYLCB5KQoKIyBQcmVkaWN0aW9ucwp5X2xhc3NvX3ByZWQgPSBsYXNzb19tb2RlbC5wcmVkaWN0KFgpCgojIFZpc3VhbGl6YXRpb24KcGx0LnNjYXR0ZXIoWCwgeSwgY29sb3I9J2JsdWUnKQpwbHQucGxvdChYLCB5X2xhc3NvX3ByZWQsIGNvbG9yPSdyZWQnKQpwbHQueGxhYmVsKCdYJykKcGx0LnlsYWJlbCgneScpCnBsdC50aXRsZSgnTGFzc28gUmVncmVzc2lvbicpCnBsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.linear_model import Lasso

# Example data
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Create the Lasso regression model
lasso_model = Lasso(alpha=0.1)
lasso_model.fit(X, y)

# Predictions
y_lasso_pred = lasso_model.predict(X)

# Visualization
plt.scatter(X, y, color='blue')
plt.plot(X, y_lasso_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Lasso Regression')
plt.show()</pre></div><div class='content'></div><h1>Comparison of Regression Algorithms</h1>
<div class='content'><p>Below is a comparative table of the different regression algorithms discussed:</p>
<p>| Algorithm           | Penalty     | Advantages                                    | Disadvantages                             |
|---------------------|-------------|-----------------------------------------------|-------------------------------------------|
| Linear Regression   | None        | Simple, easy to interpret                     | Can overfit if there are many variables   |
| Polynomial Regression| None       | Captures non-linear relationships             | Can easily overfit                        |
| Ridge Regression    | L2          | Reduces overfitting, useful for many variables| Does not perform variable selection       |
| Lasso Regression    | L1          | Performs variable selection, reduces overfitting| Can eliminate important variables         |</p>
</div><h1>Conclusion</h1>
<div class='content'><p>Regression algorithms are powerful tools for predicting continuous values. Each type of regression has its own advantages and disadvantages, and the choice of the appropriate algorithm depends on the specific problem and the available data. Understanding these algorithms and their correct application is essential for any professional working in the field of data analysis and machine learning.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
