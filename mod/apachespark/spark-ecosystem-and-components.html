<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark Ecosystem and Components</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/spark-ecosystem-and-components" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/spark-ecosystem-and-components" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/spark-ecosystem-and-components" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/spark-ecosystem-and-components" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/spark-ecosystem-and-components" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='history-and-evolution-of-apache-spark'>&#x25C4;History and Evolution of Apache Spark</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Spark Ecosystem and Components</a>
	</div>
	<div class='col-4 text-end'>
					<a href='installing-and-setting-up-spark'>Installing and Setting Up Spark &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Apache Spark is a powerful open-source unified analytics engine designed for large-scale data processing. It provides high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. In this topic, we will explore the Spark ecosystem and its key components.</p>
</div><h1>Spark Core</h1>
<div class='content'><p>Spark Core is the foundation of the Apache Spark ecosystem. It provides essential functionalities such as task scheduling, memory management, fault recovery, and interaction with storage systems.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Resilient Distributed Datasets (RDDs)</strong>: The fundamental data structure of Spark, which is immutable and distributed across the cluster.</li>
<li><strong>Transformations and Actions</strong>: Operations on RDDs. Transformations create new RDDs, while actions compute a result based on an RDD.</li>
<li><strong>Lazy Evaluation</strong>: Transformations are not executed immediately but are recorded in a lineage graph. Actions trigger the execution.</li>
</ul>
</div><h2>Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJTaW1wbGUgQXBwIikKZGF0YSA9IFsxLCAyLCAzLCA0LCA1XQpyZGQgPSBzYy5wYXJhbGxlbGl6ZShkYXRhKQoKIyBUcmFuc2Zvcm1hdGlvbjogbWFwCnNxdWFyZWRfcmRkID0gcmRkLm1hcChsYW1iZGEgeDogeCAqIHgpCgojIEFjdGlvbjogY29sbGVjdApyZXN1bHQgPSBzcXVhcmVkX3JkZC5jb2xsZWN0KCkKcHJpbnQocmVzdWx0KSAgIyBPdXRwdXQ6IFsxLCA0LCA5LCAxNiwgMjVd"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

sc = SparkContext(&quot;local&quot;, &quot;Simple App&quot;)
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Transformation: map
squared_rdd = rdd.map(lambda x: x * x)

# Action: collect
result = squared_rdd.collect()
print(result)  # Output: [1, 4, 9, 16, 25]</pre></div><div class='content'></div><h1>Spark SQL</h1>
<div class='content'><p>Spark SQL is a module for structured data processing. It allows querying data via SQL as well as the DataFrame API.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>DataFrames</strong>: Distributed collections of data organized into named columns, similar to a table in a relational database.</li>
<li><strong>Datasets</strong>: Extension of DataFrames providing type safety and object-oriented programming interface.</li>
<li><strong>Catalyst Optimizer</strong>: An extensible query optimizer used by Spark SQL.</li>
</ul>
</div><h2>Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIlNwYXJrIFNRTCBFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQpkYXRhID0gWygiQWxpY2UiLCAxKSwgKCJCb2IiLCAyKSwgKCJDYXRoeSIsIDMpXQpjb2x1bW5zID0gWyJOYW1lIiwgIlZhbHVlIl0KCmRmID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKGRhdGEsIGNvbHVtbnMpCmRmLnNob3coKQoKIyBTUUwgUXVlcnkKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnNxbERGID0gc3Bhcmsuc3FsKCJTRUxFQ1QgKiBGUk9NIHBlb3BsZSBXSEVSRSBWYWx1ZSA+IDEiKQpzcWxERi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Spark SQL Example&quot;).getOrCreate()
data = [(&quot;Alice&quot;, 1), (&quot;Bob&quot;, 2), (&quot;Cathy&quot;, 3)]
columns = [&quot;Name&quot;, &quot;Value&quot;]

df = spark.createDataFrame(data, columns)
df.show()

# SQL Query
df.createOrReplaceTempView(&quot;people&quot;)
sqlDF = spark.sql(&quot;SELECT * FROM people WHERE Value &gt; 1&quot;)
sqlDF.show()</pre></div><div class='content'></div><h1>Spark Streaming</h1>
<div class='content'><p>Spark Streaming enables scalable and fault-tolerant stream processing of live data streams.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>DStreams (Discretized Streams)</strong>: The basic abstraction in Spark Streaming, representing a continuous stream of data.</li>
<li><strong>Window Operations</strong>: Operations over a sliding window of data.</li>
</ul>
</div><h2>Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBweXNwYXJrLnN0cmVhbWluZyBpbXBvcnQgU3RyZWFtaW5nQ29udGV4dAoKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsWzJdIiwgIk5ldHdvcmtXb3JkQ291bnQiKQpzc2MgPSBTdHJlYW1pbmdDb250ZXh0KHNjLCAxKQoKbGluZXMgPSBzc2Muc29ja2V0VGV4dFN0cmVhbSgibG9jYWxob3N0IiwgOTk5OSkKd29yZHMgPSBsaW5lcy5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpCndvcmRDb3VudHMgPSB3b3Jkcy5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQoKd29yZENvdW50cy5wcHJpbnQoKQoKc3NjLnN0YXJ0KCkKc3NjLmF3YWl0VGVybWluYXRpb24oKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from pyspark.streaming import StreamingContext

sc = SparkContext(&quot;local[2]&quot;, &quot;NetworkWordCount&quot;)
ssc = StreamingContext(sc, 1)

lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
words = lines.flatMap(lambda line: line.split(&quot; &quot;))
wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)

wordCounts.pprint()

ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h1>MLlib (Machine Learning Library)</h1>
<div class='content'><p>MLlib is Spark's scalable machine learning library, providing various algorithms and utilities.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Algorithms</strong>: Classification, regression, clustering, collaborative filtering, etc.</li>
<li><strong>Pipelines</strong>: Tools for constructing, evaluating, and tuning machine learning workflows.</li>
</ul>
</div><h2>Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmNsYXNzaWZpY2F0aW9uIGltcG9ydCBMb2dpc3RpY1JlZ3Jlc3Npb24KZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIk1MbGliIEV4YW1wbGUiKS5nZXRPckNyZWF0ZSgpCmRhdGEgPSBzcGFyay5yZWFkLmZvcm1hdCgibGlic3ZtIikubG9hZCgic2FtcGxlX2xpYnN2bV9kYXRhLnR4dCIpCgpsciA9IExvZ2lzdGljUmVncmVzc2lvbihtYXhJdGVyPTEwLCByZWdQYXJhbT0wLjMsIGVsYXN0aWNOZXRQYXJhbT0wLjgpCmxyTW9kZWwgPSBsci5maXQoZGF0YSkKCnByaW50KCJDb2VmZmljaWVudHM6ICIgKyBzdHIobHJNb2RlbC5jb2VmZmljaWVudHMpKQpwcmludCgiSW50ZXJjZXB0OiAiICsgc3RyKGxyTW9kZWwuaW50ZXJjZXB0KSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.classification import LogisticRegression
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;MLlib Example&quot;).getOrCreate()
data = spark.read.format(&quot;libsvm&quot;).load(&quot;sample_libsvm_data.txt&quot;)

lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)
lrModel = lr.fit(data)

print(&quot;Coefficients: &quot; + str(lrModel.coefficients))
print(&quot;Intercept: &quot; + str(lrModel.intercept))</pre></div><div class='content'></div><h1>GraphX</h1>
<div class='content'><p>GraphX is Spark's API for graphs and graph-parallel computation.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Property Graph</strong>: A directed multigraph with properties attached to each vertex and edge.</li>
<li><strong>Pregel API</strong>: An API for iterative graph algorithms.</li>
</ul>
</div><h2>Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5ncmFwaHggaW1wb3J0IEdyYXBoCgpzYyA9IFNwYXJrQ29udGV4dCgibG9jYWwiLCAiR3JhcGhYIEV4YW1wbGUiKQp2ZXJ0aWNlcyA9IHNjLnBhcmFsbGVsaXplKFsoMSwgIkFsaWNlIiksICgyLCAiQm9iIiksICgzLCAiQ2F0aHkiKV0pCmVkZ2VzID0gc2MucGFyYWxsZWxpemUoWygxLCAyLCAiZnJpZW5kIiksICgyLCAzLCAiZm9sbG93IildKQoKZ3JhcGggPSBHcmFwaCh2ZXJ0aWNlcywgZWRnZXMpCnByaW50KGdyYXBoLnZlcnRpY2VzLmNvbGxlY3QoKSkKcHJpbnQoZ3JhcGguZWRnZXMuY29sbGVjdCgpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.graphx import Graph

sc = SparkContext(&quot;local&quot;, &quot;GraphX Example&quot;)
vertices = sc.parallelize([(1, &quot;Alice&quot;), (2, &quot;Bob&quot;), (3, &quot;Cathy&quot;)])
edges = sc.parallelize([(1, 2, &quot;friend&quot;), (2, 3, &quot;follow&quot;)])

graph = Graph(vertices, edges)
print(graph.vertices.collect())
print(graph.edges.collect())</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>The Apache Spark ecosystem is vast and powerful, providing tools for various data processing needs. From the core functionalities of Spark Core to the specialized modules like Spark SQL, Spark Streaming, MLlib, and GraphX, Spark offers a comprehensive suite for big data analytics. Understanding these components and their interactions is crucial for leveraging Spark's full potential in real-world applications.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='history-and-evolution-of-apache-spark'>&#x25C4;History and Evolution of Apache Spark</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Spark Ecosystem and Components</a>
	</div>
	<div class='col-4 text-end'>
					<a href='installing-and-setting-up-spark'>Installing and Setting Up Spark &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
