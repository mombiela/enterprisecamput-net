<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Data Processing</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/07-01-real-time-data-processing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/07-01-real-time-data-processing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/07-01-real-time-data-processing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/07-01-real-time-data-processing" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/07-01-real-time-data-processing" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='06-04-spark-kubernetes' title="Spark with Kubernetes">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Real-Time Data Processing</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='07-02-big-data-analytics' title="Big Data Analytics">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Real-time data processing is a critical aspect of modern data engineering and analytics. Apache Spark provides robust capabilities for processing streaming data in real-time, enabling businesses to make timely decisions based on the latest data. In this section, we will explore the concepts, tools, and techniques for real-time data processing using Apache Spark.</p>
</div><h1>Key Concepts</h1>
<div class='content'></div><h2>1. Real-Time Data Processing</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Real-time data processing involves the continuous input, processing, and output of data with minimal latency.</li>
<li><strong>Use Cases</strong>: Fraud detection, real-time analytics, monitoring systems, recommendation engines.</li>
</ul>
</div><h2>2. Spark Streaming</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams.</li>
<li><strong>Components</strong>: DStreams (Discretized Streams), Receivers, Window operations.</li>
</ul>
</div><h2>3. Structured Streaming</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Structured Streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine.</li>
<li><strong>Features</strong>: Declarative API, event-time processing, stateful operations.</li>
</ul>
</div><h1>Setting Up Spark Streaming</h1>
<div class='content'></div><h2>1. Environment Setup</h2>
<div class='content'><p>Ensure you have Apache Spark installed and configured. You can follow the setup instructions from Module 1.</p>
</div><h2>2. Dependencies</h2>
<div class='content'><p>Add the necessary dependencies to your project. For example, if you are using Maven, include the following in your <code>pom.xml</code>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PGRlcGVuZGVuY3k+CiAgICA8Z3JvdXBJZD5vcmcuYXBhY2hlLnNwYXJrPC9ncm91cElkPgogICAgPGFydGlmYWN0SWQ+c3Bhcmstc3RyZWFtaW5nXzIuMTI8L2FydGlmYWN0SWQ+CiAgICA8dmVyc2lvbj4zLjEuMjwvdmVyc2lvbj4KPC9kZXBlbmRlbmN5Pg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
    &lt;artifactId&gt;spark-streaming_2.12&lt;/artifactId&gt;
    &lt;version&gt;3.1.2&lt;/version&gt;
&lt;/dependency&gt;</pre></div><div class='content'></div><h1>Example: Word Count with Spark Streaming</h1>
<div class='content'></div><h2>1. Code Example</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3BhcmsuU3BhcmtDb25mCmltcG9ydCBvcmcuYXBhY2hlLnNwYXJrLnN0cmVhbWluZy57U2Vjb25kcywgU3RyZWFtaW5nQ29udGV4dH0KCm9iamVjdCBOZXR3b3JrV29yZENvdW50IHsKICBkZWYgbWFpbihhcmdzOiBBcnJheVtTdHJpbmddKTogVW5pdCA9IHsKICAgIC8vIENyZWF0ZSBhIGxvY2FsIFN0cmVhbWluZ0NvbnRleHQgd2l0aCB0d28gd29ya2luZyB0aHJlYWRzIGFuZCBiYXRjaCBpbnRlcnZhbCBvZiAxIHNlY29uZC4KICAgIHZhbCBjb25mID0gbmV3IFNwYXJrQ29uZigpLnNldE1hc3RlcigibG9jYWxbMl0iKS5zZXRBcHBOYW1lKCJOZXR3b3JrV29yZENvdW50IikKICAgIHZhbCBzc2MgPSBuZXcgU3RyZWFtaW5nQ29udGV4dChjb25mLCBTZWNvbmRzKDEpKQoKICAgIC8vIENyZWF0ZSBhIERTdHJlYW0gdGhhdCB3aWxsIGNvbm5lY3QgdG8gaG9zdG5hbWU6cG9ydCwgbGlrZSBsb2NhbGhvc3Q6OTk5OQogICAgdmFsIGxpbmVzID0gc3NjLnNvY2tldFRleHRTdHJlYW0oImxvY2FsaG9zdCIsIDk5OTkpCgogICAgLy8gU3BsaXQgZWFjaCBsaW5lIGludG8gd29yZHMKICAgIHZhbCB3b3JkcyA9IGxpbmVzLmZsYXRNYXAoXy5zcGxpdCgiICIpKQoKICAgIC8vIENvdW50IGVhY2ggd29yZCBpbiBlYWNoIGJhdGNoCiAgICB2YWwgcGFpcnMgPSB3b3Jkcy5tYXAod29yZCA9PiAod29yZCwgMSkpCiAgICB2YWwgd29yZENvdW50cyA9IHBhaXJzLnJlZHVjZUJ5S2V5KF8gKyBfKQoKICAgIC8vIFByaW50IHRoZSBmaXJzdCB0ZW4gZWxlbWVudHMgb2YgZWFjaCBSREQgZ2VuZXJhdGVkIGluIHRoaXMgRFN0cmVhbSB0byB0aGUgY29uc29sZQogICAgd29yZENvdW50cy5wcmludCgpCgogICAgc3NjLnN0YXJ0KCkgICAgICAgICAgICAgLy8gU3RhcnQgdGhlIGNvbXB1dGF0aW9uCiAgICBzc2MuYXdhaXRUZXJtaW5hdGlvbigpICAvLyBXYWl0IGZvciB0aGUgY29tcHV0YXRpb24gdG8gdGVybWluYXRlCiAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.SparkConf
import org.apache.spark.streaming.{Seconds, StreamingContext}

object NetworkWordCount {
  def main(args: Array[String]): Unit = {
    // Create a local StreamingContext with two working threads and batch interval of 1 second.
    val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;NetworkWordCount&quot;)
    val ssc = new StreamingContext(conf, Seconds(1))

    // Create a DStream that will connect to hostname:port, like localhost:9999
    val lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)

    // Split each line into words
    val words = lines.flatMap(_.split(&quot; &quot;))

    // Count each word in each batch
    val pairs = words.map(word =&gt; (word, 1))
    val wordCounts = pairs.reduceByKey(_ + _)

    // Print the first ten elements of each RDD generated in this DStream to the console
    wordCounts.print()

    ssc.start()             // Start the computation
    ssc.awaitTermination()  // Wait for the computation to terminate
  }
}</pre></div><div class='content'></div><h2>2. Explanation</h2>
<div class='content'><ul>
<li><strong>SparkConf</strong>: Configuration for the Spark application.</li>
<li><strong>StreamingContext</strong>: Main entry point for Spark Streaming functionality.</li>
<li><strong>socketTextStream</strong>: Connects to a TCP source (e.g., <code>localhost:9999</code>).</li>
<li><strong>flatMap</strong>: Splits each line into words.</li>
<li><strong>map</strong>: Maps each word to a pair (word, 1).</li>
<li><strong>reduceByKey</strong>: Reduces pairs by key (word) to count occurrences.</li>
<li><strong>print</strong>: Prints the first ten elements of each RDD to the console.</li>
</ul>
</div><h2>3. Running the Example</h2>
<div class='content'><ol>
<li>Start a TCP server on port 9999 (e.g., using <code>nc -lk 9999</code>).</li>
<li>Run the Spark Streaming application.</li>
<li>Type words into the TCP server and observe the word counts in the console.</li>
</ol>
</div><h1>Structured Streaming Example</h1>
<div class='content'></div><h2>1. Code Example</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuc3RyZWFtaW5nLlRyaWdnZXIKCm9iamVjdCBTdHJ1Y3R1cmVkTmV0d29ya1dvcmRDb3VudCB7CiAgZGVmIG1haW4oYXJnczogQXJyYXlbU3RyaW5nXSk6IFVuaXQgPSB7CiAgICB2YWwgc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlcgogICAgICAuYXBwTmFtZSgiU3RydWN0dXJlZE5ldHdvcmtXb3JkQ291bnQiKQogICAgICAubWFzdGVyKCJsb2NhbFsyXSIpCiAgICAgIC5nZXRPckNyZWF0ZSgpCgogICAgaW1wb3J0IHNwYXJrLmltcGxpY2l0cy5fCgogICAgLy8gQ3JlYXRlIERhdGFGcmFtZSByZXByZXNlbnRpbmcgdGhlIHN0cmVhbSBvZiBpbnB1dCBsaW5lcyBmcm9tIGNvbm5lY3Rpb24gdG8gbG9jYWxob3N0Ojk5OTkKICAgIHZhbCBsaW5lcyA9IHNwYXJrLnJlYWRTdHJlYW0KICAgICAgLmZvcm1hdCgic29ja2V0IikKICAgICAgLm9wdGlvbigiaG9zdCIsICJsb2NhbGhvc3QiKQogICAgICAub3B0aW9uKCJwb3J0IiwgOTk5OSkKICAgICAgLmxvYWQoKQoKICAgIC8vIFNwbGl0IHRoZSBsaW5lcyBpbnRvIHdvcmRzCiAgICB2YWwgd29yZHMgPSBsaW5lcy5hc1tTdHJpbmddLmZsYXRNYXAoXy5zcGxpdCgiICIpKQoKICAgIC8vIEdlbmVyYXRlIHJ1bm5pbmcgd29yZCBjb3VudAogICAgdmFsIHdvcmRDb3VudHMgPSB3b3Jkcy5ncm91cEJ5KCJ2YWx1ZSIpLmNvdW50KCkKCiAgICAvLyBTdGFydCBydW5uaW5nIHRoZSBxdWVyeSB0aGF0IHByaW50cyB0aGUgcnVubmluZyBjb3VudHMgdG8gdGhlIGNvbnNvbGUKICAgIHZhbCBxdWVyeSA9IHdvcmRDb3VudHMud3JpdGVTdHJlYW0KICAgICAgLm91dHB1dE1vZGUoImNvbXBsZXRlIikKICAgICAgLmZvcm1hdCgiY29uc29sZSIpCiAgICAgIC50cmlnZ2VyKFRyaWdnZXIuUHJvY2Vzc2luZ1RpbWUoIjEgc2Vjb25kIikpCiAgICAgIC5zdGFydCgpCgogICAgcXVlcnkuYXdhaXRUZXJtaW5hdGlvbigpCiAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.streaming.Trigger

object StructuredNetworkWordCount {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder
      .appName(&quot;StructuredNetworkWordCount&quot;)
      .master(&quot;local[2]&quot;)
      .getOrCreate()

    import spark.implicits._

    // Create DataFrame representing the stream of input lines from connection to localhost:9999
    val lines = spark.readStream
      .format(&quot;socket&quot;)
      .option(&quot;host&quot;, &quot;localhost&quot;)
      .option(&quot;port&quot;, 9999)
      .load()

    // Split the lines into words
    val words = lines.as[String].flatMap(_.split(&quot; &quot;))

    // Generate running word count
    val wordCounts = words.groupBy(&quot;value&quot;).count()

    // Start running the query that prints the running counts to the console
    val query = wordCounts.writeStream
      .outputMode(&quot;complete&quot;)
      .format(&quot;console&quot;)
      .trigger(Trigger.ProcessingTime(&quot;1 second&quot;))
      .start()

    query.awaitTermination()
  }
}</pre></div><div class='content'></div><h2>2. Explanation</h2>
<div class='content'><ul>
<li><strong>SparkSession</strong>: Entry point for DataFrame and SQL functionality.</li>
<li><strong>readStream</strong>: Reads streaming data from a source.</li>
<li><strong>format(&quot;socket&quot;)</strong>: Specifies the source format as socket.</li>
<li><strong>option(&quot;host&quot;, &quot;localhost&quot;)</strong>: Specifies the host.</li>
<li><strong>option(&quot;port&quot;, 9999)</strong>: Specifies the port.</li>
<li><strong>as[String]</strong>: Converts DataFrame to Dataset of String.</li>
<li><strong>flatMap</strong>: Splits each line into words.</li>
<li><strong>groupBy(&quot;value&quot;)</strong>: Groups words.</li>
<li><strong>count()</strong>: Counts occurrences of each word.</li>
<li><strong>writeStream</strong>: Specifies the output mode and format.</li>
<li><strong>trigger(Trigger.ProcessingTime(&quot;1 second&quot;))</strong>: Sets the trigger interval.</li>
<li><strong>start()</strong>: Starts the streaming query.</li>
</ul>
</div><h2>3. Running the Example</h2>
<div class='content'><ol>
<li>Start a TCP server on port 9999 (e.g., using <code>nc -lk 9999</code>).</li>
<li>Run the Structured Streaming application.</li>
<li>Type words into the TCP server and observe the word counts in the console.</li>
</ol>
</div><h1>Practical Exercises</h1>
<div class='content'></div><h2>Exercise 1: Real-Time Log Monitoring</h2>
<div class='content'><p><strong>Task</strong>: Create a Spark Streaming application that monitors a directory for new log files and counts the number of ERROR messages in real-time.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3BhcmsuU3BhcmtDb25mCmltcG9ydCBvcmcuYXBhY2hlLnNwYXJrLnN0cmVhbWluZy57U2Vjb25kcywgU3RyZWFtaW5nQ29udGV4dH0KCm9iamVjdCBMb2dFcnJvckNvdW50IHsKICBkZWYgbWFpbihhcmdzOiBBcnJheVtTdHJpbmddKTogVW5pdCA9IHsKICAgIHZhbCBjb25mID0gbmV3IFNwYXJrQ29uZigpLnNldE1hc3RlcigibG9jYWxbMl0iKS5zZXRBcHBOYW1lKCJMb2dFcnJvckNvdW50IikKICAgIHZhbCBzc2MgPSBuZXcgU3RyZWFtaW5nQ29udGV4dChjb25mLCBTZWNvbmRzKDEpKQoKICAgIHZhbCBsb2dEYXRhID0gc3NjLnRleHRGaWxlU3RyZWFtKCJwYXRoL3RvL2xvZy9kaXJlY3RvcnkiKQoKICAgIHZhbCBlcnJvckxpbmVzID0gbG9nRGF0YS5maWx0ZXIoXy5jb250YWlucygiRVJST1IiKSkKCiAgICB2YWwgZXJyb3JDb3VudCA9IGVycm9yTGluZXMuY291bnQoKQoKICAgIGVycm9yQ291bnQucHJpbnQoKQoKICAgIHNzYy5zdGFydCgpCiAgICBzc2MuYXdhaXRUZXJtaW5hdGlvbigpCiAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.SparkConf
import org.apache.spark.streaming.{Seconds, StreamingContext}

object LogErrorCount {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;LogErrorCount&quot;)
    val ssc = new StreamingContext(conf, Seconds(1))

    val logData = ssc.textFileStream(&quot;path/to/log/directory&quot;)

    val errorLines = logData.filter(_.contains(&quot;ERROR&quot;))

    val errorCount = errorLines.count()

    errorCount.print()

    ssc.start()
    ssc.awaitTermination()
  }
}</pre></div><div class='content'></div><h2>Exercise 2: Real-Time Stock Price Analysis</h2>
<div class='content'><p><strong>Task</strong>: Create a Structured Streaming application that reads stock price data from a socket and calculates the moving average price for each stock symbol.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCm9iamVjdCBTdG9ja1ByaWNlQW5hbHlzaXMgewogIGRlZiBtYWluKGFyZ3M6IEFycmF5W1N0cmluZ10pOiBVbml0ID0gewogICAgdmFsIHNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIKICAgICAgLmFwcE5hbWUoIlN0b2NrUHJpY2VBbmFseXNpcyIpCiAgICAgIC5tYXN0ZXIoImxvY2FsWzJdIikKICAgICAgLmdldE9yQ3JlYXRlKCkKCiAgICBpbXBvcnQgc3BhcmsuaW1wbGljaXRzLl8KCiAgICB2YWwgc3RvY2tEYXRhID0gc3BhcmsucmVhZFN0cmVhbQogICAgICAuZm9ybWF0KCJzb2NrZXQiKQogICAgICAub3B0aW9uKCJob3N0IiwgImxvY2FsaG9zdCIpCiAgICAgIC5vcHRpb24oInBvcnQiLCA5OTk5KQogICAgICAubG9hZCgpCiAgICAgIC5hc1tTdHJpbmddCiAgICAgIC5tYXAobGluZSA9PiB7CiAgICAgICAgdmFsIHBhcnRzID0gbGluZS5zcGxpdCgiLCIpCiAgICAgICAgKHBhcnRzKDApLCBwYXJ0cygxKS50b0RvdWJsZSkKICAgICAgfSkudG9ERigic3ltYm9sIiwgInByaWNlIikKCiAgICB2YWwgbW92aW5nQXZnID0gc3RvY2tEYXRhCiAgICAgIC5ncm91cEJ5KCQic3ltYm9sIiwgd2luZG93KCQidGltZXN0YW1wIiwgIjEgbWludXRlIikpCiAgICAgIC5hZ2coYXZnKCQicHJpY2UiKS5hcygiYXZnX3ByaWNlIikpCgogICAgdmFsIHF1ZXJ5ID0gbW92aW5nQXZnLndyaXRlU3RyZWFtCiAgICAgIC5vdXRwdXRNb2RlKCJjb21wbGV0ZSIpCiAgICAgIC5mb3JtYXQoImNvbnNvbGUiKQogICAgICAuc3RhcnQoKQoKICAgIHF1ZXJ5LmF3YWl0VGVybWluYXRpb24oKQogIH0KfQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

object StockPriceAnalysis {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder
      .appName(&quot;StockPriceAnalysis&quot;)
      .master(&quot;local[2]&quot;)
      .getOrCreate()

    import spark.implicits._

    val stockData = spark.readStream
      .format(&quot;socket&quot;)
      .option(&quot;host&quot;, &quot;localhost&quot;)
      .option(&quot;port&quot;, 9999)
      .load()
      .as[String]
      .map(line =&gt; {
        val parts = line.split(&quot;,&quot;)
        (parts(0), parts(1).toDouble)
      }).toDF(&quot;symbol&quot;, &quot;price&quot;)

    val movingAvg = stockData
      .groupBy($&quot;symbol&quot;, window($&quot;timestamp&quot;, &quot;1 minute&quot;))
      .agg(avg($&quot;price&quot;).as(&quot;avg_price&quot;))

    val query = movingAvg.writeStream
      .outputMode(&quot;complete&quot;)
      .format(&quot;console&quot;)
      .start()

    query.awaitTermination()
  }
}</pre></div><div class='content'></div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Incorrect Configuration</strong>: Ensure Spark is correctly configured and dependencies are properly included.</li>
<li><strong>Network Issues</strong>: Verify that the TCP server is running and accessible.</li>
<li><strong>Batch Interval</strong>: Choose an appropriate batch interval for your use case to balance latency and throughput.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we explored the fundamentals of real-time data processing with Apache Spark, including Spark Streaming and Structured Streaming. We provided practical examples and exercises to help you get hands-on experience with real-time data processing. In the next section, we will delve into Big Data Analytics with Spark, building on the concepts learned here.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='06-04-spark-kubernetes' title="Spark with Kubernetes">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='07-02-big-data-analytics' title="Big Data Analytics">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
