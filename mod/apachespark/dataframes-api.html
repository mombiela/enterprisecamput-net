<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DataFrames API in Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/dataframes-api" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/dataframes-api" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/dataframes-api" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/dataframes-api" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/dataframes-api" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='introduction-to-spark-sql'>&#x25C4;Introduction to Spark SQL</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">DataFrames API in Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='running-sql-queries-programmatically'>Running SQL Queries Programmatically &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to DataFrames</h1>
<div class='content'><p>DataFrames are a fundamental data structure in Apache Spark, designed to handle large-scale data processing with ease. They are similar to tables in a relational database or data frames in R/Python but optimized for distributed computing.</p>
<ul>
<li><strong>Definition</strong>: A DataFrame is a distributed collection of data organized into named columns.</li>
<li><strong>Key Features</strong>:
<ul>
<li>Schema enforcement</li>
<li>Optimized execution plans</li>
<li>Support for a wide range of data sources</li>
</ul>
</li>
</ul>
</div><h1>Creating DataFrames</h1>
<div class='content'><p>Creating DataFrames is the first step in working with them. You can create DataFrames from various data sources like CSV, JSON, Parquet, and more.</p>
</div><h2>From Existing RDDs</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5zcWwgaW1wb3J0IFJvdwoKc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJEYXRhRnJhbWVFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQoKIyBDcmVhdGUgYW4gUkRECnJkZCA9IHNwYXJrLnNwYXJrQ29udGV4dC5wYXJhbGxlbGl6ZShbCiAgICBSb3cobmFtZT0iQWxpY2UiLCBhZ2U9MjkpLAogICAgUm93KG5hbWU9IkJvYiIsIGFnZT0zNSkKXSkKCiMgQ29udmVydCBSREQgdG8gRGF0YUZyYW1lCmRmID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKHJkZCkKZGYuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from pyspark.sql import Row

spark = SparkSession.builder.appName(&quot;DataFrameExample&quot;).getOrCreate()

# Create an RDD
rdd = spark.sparkContext.parallelize([
    Row(name=&quot;Alice&quot;, age=29),
    Row(name=&quot;Bob&quot;, age=35)
])

# Convert RDD to DataFrame
df = spark.createDataFrame(rdd)
df.show()</pre></div><div class='content'></div><h2>From CSV File</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYgPSBzcGFyay5yZWFkLmNzdigicGF0aC90by9jc3ZmaWxlLmNzdiIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df = spark.read.csv(&quot;path/to/csvfile.csv&quot;, header=True, inferSchema=True)
df.show()</pre></div><div class='content'></div><h2>From JSON File</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYgPSBzcGFyay5yZWFkLmpzb24oInBhdGgvdG8vanNvbmZpbGUuanNvbiIpCmRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df = spark.read.json(&quot;path/to/jsonfile.json&quot;)
df.show()</pre></div><div class='content'></div><h2>From Parquet File</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYgPSBzcGFyay5yZWFkLnBhcnF1ZXQoInBhdGgvdG8vcGFycXVldGZpbGUucGFycXVldCIpCmRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df = spark.read.parquet(&quot;path/to/parquetfile.parquet&quot;)
df.show()</pre></div><div class='content'></div><h1>Basic Operations on DataFrames</h1>
<div class='content'><p>Once you have a DataFrame, you can perform various operations on it.</p>
</div><h2>Viewing Data</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuc2hvdygpICAjIERpc3BsYXlzIHRoZSBmaXJzdCAyMCByb3dzCmRmLnByaW50U2NoZW1hKCkgICMgUHJpbnRzIHRoZSBzY2hlbWEgb2YgdGhlIERhdGFGcmFtZQpkZi5oZWFkKDUpICAjIFJldHVybnMgdGhlIGZpcnN0IDUgcm93cyBhcyBhIGxpc3Q="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.show()  # Displays the first 20 rows
df.printSchema()  # Prints the schema of the DataFrame
df.head(5)  # Returns the first 5 rows as a list</pre></div><div class='content'></div><h2>Selecting Columns</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuc2VsZWN0KCJuYW1lIiwgImFnZSIpLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.select(&quot;name&quot;, &quot;age&quot;).show()</pre></div><div class='content'></div><h2>Filtering Rows</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuZmlsdGVyKGRmLmFnZSA+IDMwKS5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.filter(df.age &gt; 30).show()</pre></div><div class='content'></div><h2>Adding New Columns</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGNvbAoKZGYgPSBkZi53aXRoQ29sdW1uKCJhZ2VfYWZ0ZXJfNV95ZWFycyIsIGNvbCgiYWdlIikgKyA1KQpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import col

df = df.withColumn(&quot;age_after_5_years&quot;, col(&quot;age&quot;) + 5)
df.show()</pre></div><div class='content'></div><h2>Grouping and Aggregation</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuZ3JvdXBCeSgiYWdlIikuY291bnQoKS5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.groupBy(&quot;age&quot;).count().show()</pre></div><div class='content'></div><h1>Advanced DataFrame Operations</h1>
<div class='content'><p>As you become more comfortable with basic operations, you can explore more advanced functionalities.</p>
</div><h2>Joins</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYxID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKFsoMSwgIkFsaWNlIiksICgyLCAiQm9iIildLCBbImlkIiwgIm5hbWUiXSkKZGYyID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKFsoMSwgIkhSIiksICgyLCAiRW5naW5lZXJpbmciKV0sIFsiaWQiLCAiZGVwYXJ0bWVudCJdKQoKZGZfam9pbmVkID0gZGYxLmpvaW4oZGYyLCBkZjEuaWQgPT0gZGYyLmlkKQpkZl9qb2luZWQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df1 = spark.createDataFrame([(1, &quot;Alice&quot;), (2, &quot;Bob&quot;)], [&quot;id&quot;, &quot;name&quot;])
df2 = spark.createDataFrame([(1, &quot;HR&quot;), (2, &quot;Engineering&quot;)], [&quot;id&quot;, &quot;department&quot;])

df_joined = df1.join(df2, df1.id == df2.id)
df_joined.show()</pre></div><div class='content'></div><h2>Window Functions</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC53aW5kb3cgaW1wb3J0IFdpbmRvdwpmcm9tIHB5c3Bhcmsuc3FsLmZ1bmN0aW9ucyBpbXBvcnQgcmFuaywgY29sCgp3aW5kb3dTcGVjID0gV2luZG93LnBhcnRpdGlvbkJ5KCJkZXBhcnRtZW50Iikub3JkZXJCeShjb2woInNhbGFyeSIpLmRlc2MoKSkKZGYgPSBkZi53aXRoQ29sdW1uKCJyYW5rIiwgcmFuaygpLm92ZXIod2luZG93U3BlYykpCmRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.window import Window
from pyspark.sql.functions import rank, col

windowSpec = Window.partitionBy(&quot;department&quot;).orderBy(col(&quot;salary&quot;).desc())
df = df.withColumn(&quot;rank&quot;, rank().over(windowSpec))
df.show()</pre></div><div class='content'></div><h2>User-Defined Functions (UDFs)</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IHVkZgpmcm9tIHB5c3Bhcmsuc3FsLnR5cGVzIGltcG9ydCBTdHJpbmdUeXBlCgpkZWYgdXBwZXJfY2FzZShuYW1lKToKICAgIHJldHVybiBuYW1lLnVwcGVyKCkKCnVwcGVyX2Nhc2VfdWRmID0gdWRmKHVwcGVyX2Nhc2UsIFN0cmluZ1R5cGUoKSkKCmRmID0gZGYud2l0aENvbHVtbigidXBwZXJfbmFtZSIsIHVwcGVyX2Nhc2VfdWRmKGRmLm5hbWUpKQpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import udf
from pyspark.sql.types import StringType

def upper_case(name):
    return name.upper()

upper_case_udf = udf(upper_case, StringType())

df = df.withColumn(&quot;upper_name&quot;, upper_case_udf(df.name))
df.show()</pre></div><div class='content'></div><h1>Performance Tuning</h1>
<div class='content'><p>Optimizing the performance of DataFrame operations is crucial for handling large datasets efficiently.</p>
<ul>
<li><strong>Caching</strong>: Use <code>df.cache()</code> to cache DataFrames in memory.</li>
<li><strong>Broadcast Joins</strong>: Use <code>broadcast(df)</code> for small DataFrames to optimize join operations.</li>
<li><strong>Partitioning</strong>: Repartition DataFrames using <code>df.repartition(num_partitions)</code> to balance the load.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>The DataFrames API in Apache Spark provides a powerful and flexible way to work with structured data. From basic operations like selecting and filtering to advanced techniques like joins and window functions, mastering DataFrames is essential for efficient data processing in Spark. Remember to leverage performance tuning techniques to optimize your workflows and handle large datasets effectively.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='introduction-to-spark-sql'>&#x25C4;Introduction to Spark SQL</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">DataFrames API in Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='running-sql-queries-programmatically'>Running SQL Queries Programmatically &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
