<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Sources and Sinks</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/data-sources-and-sinks" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/data-sources-and-sinks" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/data-sources-and-sinks" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/data-sources-and-sinks" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/data-sources-and-sinks" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='running-sql-queries-programmatically'>&#x25C4;Running SQL Queries Programmatically</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Data Sources and Sinks</a>
	</div>
	<div class='col-4 text-end'>
					<a href='user-defined-functions'>User-Defined Functions (UDFs) &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we'll explore how Apache Spark interacts with various data sources and sinks. This is crucial for understanding how to read data into Spark, process it, and then write it back to a storage system.</p>
</div><h1>Introduction to Data Sources and Sinks</h1>
<div class='content'><ul>
<li><strong>Data Sources</strong>: These are the origins from where data is read into Spark. Examples include HDFS, S3, JDBC, and local files.</li>
<li><strong>Data Sinks</strong>: These are the destinations where processed data is written. Examples include HDFS, S3, JDBC, and local files.</li>
</ul>
</div><h1>Reading Data from Various Sources</h1>
<div class='content'></div><h2>Reading from HDFS</h2>
<div class='content'><p>HDFS (Hadoop Distributed File System) is a common data source for Spark.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaXRpYWxpemUgU3Bhcmsgc2Vzc2lvbgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIkhERlMgRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKCiMgUmVhZCBkYXRhIGZyb20gSERGUwpkZiA9IHNwYXJrLnJlYWQuY3N2KCJoZGZzOi8vbmFtZW5vZGU6ODAyMC9wYXRoL3RvL2ZpbGUuY3N2IiwgaGVhZGVyPVRydWUsIGluZmVyU2NoZW1hPVRydWUpCgojIFNob3cgdGhlIGRhdGEKZGYuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName(&quot;HDFS Example&quot;).getOrCreate()

# Read data from HDFS
df = spark.read.csv(&quot;hdfs://namenode:8020/path/to/file.csv&quot;, header=True, inferSchema=True)

# Show the data
df.show()</pre></div><div class='content'></div><h2>Reading from S3</h2>
<div class='content'><p>Amazon S3 is another popular data source.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWFkIGRhdGEgZnJvbSBTMwpkZiA9IHNwYXJrLnJlYWQuY3N2KCJzM2E6Ly9idWNrZXQtbmFtZS9wYXRoL3RvL2ZpbGUuY3N2IiwgaGVhZGVyPVRydWUsIGluZmVyU2NoZW1hPVRydWUpCgojIFNob3cgdGhlIGRhdGEKZGYuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Read data from S3
df = spark.read.csv(&quot;s3a://bucket-name/path/to/file.csv&quot;, header=True, inferSchema=True)

# Show the data
df.show()</pre></div><div class='content'></div><h2>Reading from JDBC</h2>
<div class='content'><p>JDBC allows Spark to read data from relational databases.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWFkIGRhdGEgZnJvbSBhIEpEQkMgc291cmNlCmRmID0gc3BhcmsucmVhZC5mb3JtYXQoImpkYmMiKS5vcHRpb25zKAogICAgdXJsPSJqZGJjOm15c3FsOi8vaG9zdG5hbWU6cG9ydC9kYm5hbWUiLAogICAgZHJpdmVyPSJjb20ubXlzcWwuamRiYy5Ecml2ZXIiLAogICAgZGJ0YWJsZT0idGFibGVuYW1lIiwKICAgIHVzZXI9InVzZXJuYW1lIiwKICAgIHBhc3N3b3JkPSJwYXNzd29yZCIKKS5sb2FkKCkKCiMgU2hvdyB0aGUgZGF0YQpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Read data from a JDBC source
df = spark.read.format(&quot;jdbc&quot;).options(
    url=&quot;jdbc:mysql://hostname:port/dbname&quot;,
    driver=&quot;com.mysql.jdbc.Driver&quot;,
    dbtable=&quot;tablename&quot;,
    user=&quot;username&quot;,
    password=&quot;password&quot;
).load()

# Show the data
df.show()</pre></div><div class='content'></div><h2>Reading from Local Files</h2>
<div class='content'><p>Reading data from local files is straightforward and useful for development and testing.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWFkIGRhdGEgZnJvbSBhIGxvY2FsIGZpbGUKZGYgPSBzcGFyay5yZWFkLmNzdigiZmlsZTovLy9wYXRoL3RvL2xvY2FsL2ZpbGUuY3N2IiwgaGVhZGVyPVRydWUsIGluZmVyU2NoZW1hPVRydWUpCgojIFNob3cgdGhlIGRhdGEKZGYuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Read data from a local file
df = spark.read.csv(&quot;file:///path/to/local/file.csv&quot;, header=True, inferSchema=True)

# Show the data
df.show()</pre></div><div class='content'></div><h1>Writing Data to Various Sinks</h1>
<div class='content'></div><h2>Writing to HDFS</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBXcml0ZSBkYXRhIHRvIEhERlMKZGYud3JpdGUuY3N2KCJoZGZzOi8vbmFtZW5vZGU6ODAyMC9wYXRoL3RvL291dHB1dC5jc3YiLCBoZWFkZXI9VHJ1ZSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Write data to HDFS
df.write.csv(&quot;hdfs://namenode:8020/path/to/output.csv&quot;, header=True)</pre></div><div class='content'></div><h2>Writing to S3</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBXcml0ZSBkYXRhIHRvIFMzCmRmLndyaXRlLmNzdigiczNhOi8vYnVja2V0LW5hbWUvcGF0aC90by9vdXRwdXQuY3N2IiwgaGVhZGVyPVRydWUp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Write data to S3
df.write.csv(&quot;s3a://bucket-name/path/to/output.csv&quot;, header=True)</pre></div><div class='content'></div><h2>Writing to JDBC</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBXcml0ZSBkYXRhIHRvIGEgSkRCQyBzaW5rCmRmLndyaXRlLmZvcm1hdCgiamRiYyIpLm9wdGlvbnMoCiAgICB1cmw9ImpkYmM6bXlzcWw6Ly9ob3N0bmFtZTpwb3J0L2RibmFtZSIsCiAgICBkcml2ZXI9ImNvbS5teXNxbC5qZGJjLkRyaXZlciIsCiAgICBkYnRhYmxlPSJvdXRwdXRfdGFibGUiLAogICAgdXNlcj0idXNlcm5hbWUiLAogICAgcGFzc3dvcmQ9InBhc3N3b3JkIgopLnNhdmUoKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Write data to a JDBC sink
df.write.format(&quot;jdbc&quot;).options(
    url=&quot;jdbc:mysql://hostname:port/dbname&quot;,
    driver=&quot;com.mysql.jdbc.Driver&quot;,
    dbtable=&quot;output_table&quot;,
    user=&quot;username&quot;,
    password=&quot;password&quot;
).save()</pre></div><div class='content'></div><h2>Writing to Local Files</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBXcml0ZSBkYXRhIHRvIGEgbG9jYWwgZmlsZQpkZi53cml0ZS5jc3YoImZpbGU6Ly8vcGF0aC90by9sb2NhbC9vdXRwdXQuY3N2IiwgaGVhZGVyPVRydWUp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Write data to a local file
df.write.csv(&quot;file:///path/to/local/output.csv&quot;, header=True)</pre></div><div class='content'></div><h1>Advanced Topics</h1>
<div class='content'></div><h2>Partitioning and Bucketing</h2>
<div class='content'><p>Partitioning and bucketing can improve the performance of read and write operations.</p>
<ul>
<li><strong>Partitioning</strong>: Divides data into smaller, manageable pieces based on a column.</li>
<li><strong>Bucketing</strong>: Divides data into a fixed number of buckets, which can be useful for joins.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBXcml0ZSBkYXRhIHdpdGggcGFydGl0aW9uaW5nCmRmLndyaXRlLnBhcnRpdGlvbkJ5KCJjb2x1bW5fbmFtZSIpLmNzdigiaGRmczovL25hbWVub2RlOjgwMjAvcGF0aC90by9vdXRwdXQuY3N2IiwgaGVhZGVyPVRydWUpCgojIFdyaXRlIGRhdGEgd2l0aCBidWNrZXRpbmcKZGYud3JpdGUuYnVja2V0QnkoMTAsICJjb2x1bW5fbmFtZSIpLnNhdmVBc1RhYmxlKCJidWNrZXRlZF90YWJsZSIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Write data with partitioning
df.write.partitionBy(&quot;column_name&quot;).csv(&quot;hdfs://namenode:8020/path/to/output.csv&quot;, header=True)

# Write data with bucketing
df.write.bucketBy(10, &quot;column_name&quot;).saveAsTable(&quot;bucketed_table&quot;)</pre></div><div class='content'></div><h2>Handling Different File Formats</h2>
<div class='content'><p>Spark supports various file formats like Parquet, ORC, JSON, and Avro.</p>
<ul>
<li><strong>Parquet</strong>: Columnar storage format that is highly efficient for read-heavy operations.</li>
<li><strong>ORC</strong>: Optimized Row Columnar format, similar to Parquet but often used in Hive.</li>
<li><strong>JSON</strong>: Lightweight data-interchange format.</li>
<li><strong>Avro</strong>: Row-based storage format that is compact and efficient for write-heavy operations.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBXcml0ZSBkYXRhIGluIFBhcnF1ZXQgZm9ybWF0CmRmLndyaXRlLnBhcnF1ZXQoImhkZnM6Ly9uYW1lbm9kZTo4MDIwL3BhdGgvdG8vb3V0cHV0LnBhcnF1ZXQiKQoKIyBXcml0ZSBkYXRhIGluIE9SQyBmb3JtYXQKZGYud3JpdGUub3JjKCJoZGZzOi8vbmFtZW5vZGU6ODAyMC9wYXRoL3RvL291dHB1dC5vcmMiKQoKIyBXcml0ZSBkYXRhIGluIEpTT04gZm9ybWF0CmRmLndyaXRlLmpzb24oImhkZnM6Ly9uYW1lbm9kZTo4MDIwL3BhdGgvdG8vb3V0cHV0Lmpzb24iKQoKIyBXcml0ZSBkYXRhIGluIEF2cm8gZm9ybWF0CmRmLndyaXRlLmZvcm1hdCgiYXZybyIpLnNhdmUoImhkZnM6Ly9uYW1lbm9kZTo4MDIwL3BhdGgvdG8vb3V0cHV0LmF2cm8iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Write data in Parquet format
df.write.parquet(&quot;hdfs://namenode:8020/path/to/output.parquet&quot;)

# Write data in ORC format
df.write.orc(&quot;hdfs://namenode:8020/path/to/output.orc&quot;)

# Write data in JSON format
df.write.json(&quot;hdfs://namenode:8020/path/to/output.json&quot;)

# Write data in Avro format
df.write.format(&quot;avro&quot;).save(&quot;hdfs://namenode:8020/path/to/output.avro&quot;)</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>Understanding how to read from and write to various data sources and sinks is fundamental for working with Apache Spark. This knowledge allows you to integrate Spark with different storage systems, making it a versatile tool for big data processing. By mastering these concepts, you can efficiently manage data flow in your Spark applications, ensuring optimal performance and scalability.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='running-sql-queries-programmatically'>&#x25C4;Running SQL Queries Programmatically</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Data Sources and Sinks</a>
	</div>
	<div class='col-4 text-end'>
					<a href='user-defined-functions'>User-Defined Functions (UDFs) &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
