<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark SQL</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/02-04-spark-sql" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/02-04-spark-sql" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/02-04-spark-sql" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 px-0 py-2 py-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 px-0 py-2 py-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/02-04-spark-sql" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/02-04-spark-sql" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='02-03-spark-dataframes' title="Spark DataFrames">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Spark SQL</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='03-01-loading-saving-data' title="Loading and Saving Data">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Spark SQL is a module for structured data processing in Apache Spark. It provides a programming abstraction called DataFrames and can also act as a distributed SQL query engine. Spark SQL integrates relational processing with Spark's functional programming API, allowing you to run SQL queries alongside complex analytics.</p>
</div><h1>Key Concepts</h1>
<div class='content'></div><h2>1. DataFrames</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: A DataFrame is a distributed collection of data organized into named columns, similar to a table in a relational database.</li>
<li><strong>Creation</strong>: DataFrames can be created from various data sources such as JSON, Parquet, JDBC, and more.</li>
</ul>
</div><h2>2. SQLContext and SparkSession</h2>
<div class='content'><ul>
<li><strong>SQLContext</strong>: The entry point for working with structured data (DataFrames) in Spark 1.x.</li>
<li><strong>SparkSession</strong>: Introduced in Spark 2.0, it combines SQLContext, HiveContext, and StreamingContext into a single object.</li>
</ul>
</div><h2>3. Running SQL Queries</h2>
<div class='content'><ul>
<li><strong>SQL Queries</strong>: You can run SQL queries directly on DataFrames using the <code>sql</code> method of SparkSession.</li>
</ul>
</div><h1>Practical Examples</h1>
<div class='content'></div><h2>Creating a SparkSession</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWF0ZSBhIFNwYXJrU2Vzc2lvbgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyIFwKICAgIC5hcHBOYW1lKCJTcGFyayBTUUwgRXhhbXBsZSIpIFwKICAgIC5nZXRPckNyZWF0ZSgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Create a SparkSession
spark = SparkSession.builder \
    .appName(&quot;Spark SQL Example&quot;) \
    .getOrCreate()</pre></div><div class='content'><p><strong>Explanation</strong>: This code initializes a SparkSession, which is the entry point for using Spark SQL.</p>
</div><h2>Creating a DataFrame</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTYW1wbGUgZGF0YQpkYXRhID0gWygiSmFtZXMiLCAiU21pdGgiLCAiVVNBIiwgIkNBIiksCiAgICAgICAgKCJNaWNoYWVsIiwgIlJvc2UiLCAiVVNBIiwgIk5ZIiksCiAgICAgICAgKCJSb2JlcnQiLCAiV2lsbGlhbXMiLCAiVVNBIiwgIkNBIiksCiAgICAgICAgKCJNYXJpYSIsICJKb25lcyIsICJVU0EiLCAiRkwiKV0KCiMgRGVmaW5lIHNjaGVtYQpjb2x1bW5zID0gWyJmaXJzdG5hbWUiLCAibGFzdG5hbWUiLCAiY291bnRyeSIsICJzdGF0ZSJdCgojIENyZWF0ZSBEYXRhRnJhbWUKZGYgPSBzcGFyay5jcmVhdGVEYXRhRnJhbWUoZGF0YSwgc2NoZW1hPWNvbHVtbnMpCmRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Sample data
data = [(&quot;James&quot;, &quot;Smith&quot;, &quot;USA&quot;, &quot;CA&quot;),
        (&quot;Michael&quot;, &quot;Rose&quot;, &quot;USA&quot;, &quot;NY&quot;),
        (&quot;Robert&quot;, &quot;Williams&quot;, &quot;USA&quot;, &quot;CA&quot;),
        (&quot;Maria&quot;, &quot;Jones&quot;, &quot;USA&quot;, &quot;FL&quot;)]

# Define schema
columns = [&quot;firstname&quot;, &quot;lastname&quot;, &quot;country&quot;, &quot;state&quot;]

# Create DataFrame
df = spark.createDataFrame(data, schema=columns)
df.show()</pre></div><div class='content'><p><strong>Explanation</strong>: This code creates a DataFrame from a list of tuples and a schema. The <code>show</code> method displays the DataFrame content.</p>
</div><h2>Running SQL Queries</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWdpc3RlciB0aGUgRGF0YUZyYW1lIGFzIGEgU1FMIHRlbXBvcmFyeSB2aWV3CmRmLmNyZWF0ZU9yUmVwbGFjZVRlbXBWaWV3KCJwZW9wbGUiKQoKIyBSdW4gYW4gU1FMIHF1ZXJ5CnJlc3VsdCA9IHNwYXJrLnNxbCgiU0VMRUNUIGZpcnN0bmFtZSwgbGFzdG5hbWUgRlJPTSBwZW9wbGUgV0hFUkUgc3RhdGUgPSAnQ0EnIikKcmVzdWx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Register the DataFrame as a SQL temporary view
df.createOrReplaceTempView(&quot;people&quot;)

# Run an SQL query
result = spark.sql(&quot;SELECT firstname, lastname FROM people WHERE state = 'CA'&quot;)
result.show()</pre></div><div class='content'><p><strong>Explanation</strong>: This code registers the DataFrame as a temporary SQL view and runs an SQL query to select people from California.</p>
</div><h1>Practical Exercises</h1>
<div class='content'></div><h2>Exercise 1: Creating and Querying DataFrames</h2>
<div class='content'><ol>
<li><strong>Task</strong>: Create a DataFrame from a CSV file and run an SQL query to filter data.</li>
<li><strong>Steps</strong>:
<ul>
<li>Load a CSV file into a DataFrame.</li>
<li>Register the DataFrame as a temporary view.</li>
<li>Run an SQL query to filter rows based on a condition.</li>
</ul>
</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIENTViBmaWxlIGludG8gRGF0YUZyYW1lCmRmID0gc3BhcmsucmVhZC5jc3YoInBhdGgvdG8veW91ci9jc3ZmaWxlLmNzdiIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQoKIyBSZWdpc3RlciBEYXRhRnJhbWUgYXMgYSB0ZW1wb3JhcnkgdmlldwpkZi5jcmVhdGVPclJlcGxhY2VUZW1wVmlldygiZGF0YSIpCgojIFJ1biBTUUwgcXVlcnkKcmVzdWx0ID0gc3Bhcmsuc3FsKCJTRUxFQ1QgKiBGUk9NIGRhdGEgV0hFUkUgc29tZV9jb2x1bW4gPSAnc29tZV92YWx1ZSciKQpyZXN1bHQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load CSV file into DataFrame
df = spark.read.csv(&quot;path/to/your/csvfile.csv&quot;, header=True, inferSchema=True)

# Register DataFrame as a temporary view
df.createOrReplaceTempView(&quot;data&quot;)

# Run SQL query
result = spark.sql(&quot;SELECT * FROM data WHERE some_column = 'some_value'&quot;)
result.show()</pre></div><div class='content'></div><h2>Exercise 2: Aggregation and Grouping</h2>
<div class='content'><ol>
<li><strong>Task</strong>: Perform aggregation and grouping operations using SQL queries.</li>
<li><strong>Steps</strong>:
<ul>
<li>Create a DataFrame with sample data.</li>
<li>Register the DataFrame as a temporary view.</li>
<li>Run an SQL query to group data and calculate aggregates.</li>
</ul>
</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTYW1wbGUgZGF0YQpkYXRhID0gWygiSmFtZXMiLCAiU2FsZXMiLCAzMDAwKSwKICAgICAgICAoIk1pY2hhZWwiLCAiU2FsZXMiLCA0NjAwKSwKICAgICAgICAoIlJvYmVydCIsICJTYWxlcyIsIDQxMDApLAogICAgICAgICgiTWFyaWEiLCAiRmluYW5jZSIsIDMwMDApLAogICAgICAgICgiSmFtZXMiLCAiRmluYW5jZSIsIDMwMDApLAogICAgICAgICgiU2NvdHQiLCAiRmluYW5jZSIsIDMzMDApLAogICAgICAgICgiSmVuIiwgIkZpbmFuY2UiLCAzOTAwKSwKICAgICAgICAoIkplZmYiLCAiTWFya2V0aW5nIiwgMzAwMCksCiAgICAgICAgKCJLdW1hciIsICJNYXJrZXRpbmciLCAyMDAwKV0KCiMgRGVmaW5lIHNjaGVtYQpjb2x1bW5zID0gWyJlbXBsb3llZV9uYW1lIiwgImRlcGFydG1lbnQiLCAic2FsYXJ5Il0KCiMgQ3JlYXRlIERhdGFGcmFtZQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBzY2hlbWE9Y29sdW1ucykKCiMgUmVnaXN0ZXIgRGF0YUZyYW1lIGFzIGEgdGVtcG9yYXJ5IHZpZXcKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoImVtcGxveWVlcyIpCgojIFJ1biBTUUwgcXVlcnkgZm9yIGFnZ3JlZ2F0aW9uIGFuZCBncm91cGluZwpyZXN1bHQgPSBzcGFyay5zcWwoIlNFTEVDVCBkZXBhcnRtZW50LCBTVU0oc2FsYXJ5KSBhcyB0b3RhbF9zYWxhcnkgRlJPTSBlbXBsb3llZXMgR1JPVVAgQlkgZGVwYXJ0bWVudCIpCnJlc3VsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Sample data
data = [(&quot;James&quot;, &quot;Sales&quot;, 3000),
        (&quot;Michael&quot;, &quot;Sales&quot;, 4600),
        (&quot;Robert&quot;, &quot;Sales&quot;, 4100),
        (&quot;Maria&quot;, &quot;Finance&quot;, 3000),
        (&quot;James&quot;, &quot;Finance&quot;, 3000),
        (&quot;Scott&quot;, &quot;Finance&quot;, 3300),
        (&quot;Jen&quot;, &quot;Finance&quot;, 3900),
        (&quot;Jeff&quot;, &quot;Marketing&quot;, 3000),
        (&quot;Kumar&quot;, &quot;Marketing&quot;, 2000)]

# Define schema
columns = [&quot;employee_name&quot;, &quot;department&quot;, &quot;salary&quot;]

# Create DataFrame
df = spark.createDataFrame(data, schema=columns)

# Register DataFrame as a temporary view
df.createOrReplaceTempView(&quot;employees&quot;)

# Run SQL query for aggregation and grouping
result = spark.sql(&quot;SELECT department, SUM(salary) as total_salary FROM employees GROUP BY department&quot;)
result.show()</pre></div><div class='content'></div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Mistake</strong>: Forgetting to register the DataFrame as a temporary view before running SQL queries.
<ul>
<li><strong>Tip</strong>: Always use <code>createOrReplaceTempView</code> to register your DataFrame.</li>
</ul>
</li>
<li><strong>Mistake</strong>: Not specifying the schema when loading data, leading to incorrect data types.
<ul>
<li><strong>Tip</strong>: Use <code>inferSchema=True</code> or define the schema explicitly.</li>
</ul>
</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, you learned about Spark SQL, including how to create DataFrames, run SQL queries, and perform data manipulations. You also practiced creating and querying DataFrames with practical exercises. In the next module, you will dive deeper into data processing with Spark, including loading and saving data, and performing DataFrame operations.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='02-03-spark-dataframes' title="Spark DataFrames">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='03-01-loading-saving-data' title="Loading and Saving Data">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
