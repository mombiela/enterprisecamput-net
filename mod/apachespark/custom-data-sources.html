<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Custom Data Sources in Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/custom-data-sources" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/custom-data-sources" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/custom-data-sources" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/custom-data-sources" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/custom-data-sources" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='advanced-rdd-operations'>&#x25C4;Advanced RDD Operations</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Custom Data Sources in Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='advanced-spark-sql'>Advanced Spark SQL &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Apache Spark is a powerful distributed computing system that allows for processing large datasets efficiently. One of its core features is the ability to read from and write to various data sources. While Spark provides built-in support for many common data sources like CSV, JSON, Parquet, and JDBC, there are scenarios where you might need to work with custom data sources. This section will guide you through the process of creating and using custom data sources in Apache Spark.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Data Source API</strong>: The API provided by Spark to integrate custom data sources.</li>
<li><strong>DataFrame</strong>: A distributed collection of data organized into named columns.</li>
<li><strong>Schema</strong>: The structure that defines the data types of the columns in a DataFrame.</li>
<li><strong>Partitioning</strong>: Dividing data into smaller, manageable chunks for parallel processing.</li>
</ul>
</div><h1>Why Custom Data Sources?</h1>
<div class='content'><ul>
<li><strong>Specialized Formats</strong>: Your data might be in a format not natively supported by Spark.</li>
<li><strong>Optimized Performance</strong>: Custom data sources can be optimized for specific use cases.</li>
<li><strong>Integration</strong>: Seamlessly integrate with proprietary or legacy systems.</li>
</ul>
</div><h1>Implementing a Custom Data Source</h1>
<div class='content'><p>To implement a custom data source in Spark, you need to extend the <code>DataSourceV2</code> API. Below is a step-by-step guide to creating a simple custom data source.</p>
</div><h2>Step 1: Define the Data Source</h2>
<div class='content'><p>Create a class that extends <code>DataSourceV2</code> and <code>ReadSupport</code>. This class will define the capabilities of your data source.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLnNvdXJjZXMudjIuXwppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuc291cmNlcy52Mi5yZWFkZXIuXwppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwudHlwZXMuXwoKY2xhc3MgU2ltcGxlRGF0YVNvdXJjZSBleHRlbmRzIERhdGFTb3VyY2VWMiB3aXRoIFJlYWRTdXBwb3J0IHsKICBvdmVycmlkZSBkZWYgY3JlYXRlUmVhZGVyKG9wdGlvbnM6IERhdGFTb3VyY2VPcHRpb25zKTogRGF0YVNvdXJjZVJlYWRlciA9IHsKICAgIG5ldyBTaW1wbGVEYXRhU291cmNlUmVhZGVyCiAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.sources.v2._
import org.apache.spark.sql.sources.v2.reader._
import org.apache.spark.sql.types._

class SimpleDataSource extends DataSourceV2 with ReadSupport {
  override def createReader(options: DataSourceOptions): DataSourceReader = {
    new SimpleDataSourceReader
  }
}</pre></div><div class='content'></div><h2>Step 2: Define the Data Source Reader</h2>
<div class='content'><p>The <code>DataSourceReader</code> is responsible for reading data and providing schema information.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgU2ltcGxlRGF0YVNvdXJjZVJlYWRlciBleHRlbmRzIERhdGFTb3VyY2VSZWFkZXIgewogIG92ZXJyaWRlIGRlZiByZWFkU2NoZW1hKCk6IFN0cnVjdFR5cGUgPSB7CiAgICBTdHJ1Y3RUeXBlKEFycmF5KAogICAgICBTdHJ1Y3RGaWVsZCgiaWQiLCBJbnRlZ2VyVHlwZSwgbnVsbGFibGUgPSBmYWxzZSksCiAgICAgIFN0cnVjdEZpZWxkKCJ2YWx1ZSIsIFN0cmluZ1R5cGUsIG51bGxhYmxlID0gdHJ1ZSkKICAgICkpCiAgfQoKICBvdmVycmlkZSBkZWYgY3JlYXRlRGF0YVJlYWRlckZhY3RvcmllcygpOiBqYXZhLnV0aWwuTGlzdFtEYXRhUmVhZGVyRmFjdG9yeVtSb3ddXSA9IHsKICAgIGphdmEudXRpbC5Db2xsZWN0aW9ucy5zaW5nbGV0b25MaXN0KG5ldyBTaW1wbGVEYXRhUmVhZGVyRmFjdG9yeSkKICB9Cn0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class SimpleDataSourceReader extends DataSourceReader {
  override def readSchema(): StructType = {
    StructType(Array(
      StructField(&quot;id&quot;, IntegerType, nullable = false),
      StructField(&quot;value&quot;, StringType, nullable = true)
    ))
  }

  override def createDataReaderFactories(): java.util.List[DataReaderFactory[Row]] = {
    java.util.Collections.singletonList(new SimpleDataReaderFactory)
  }
}</pre></div><div class='content'></div><h2>Step 3: Define the Data Reader Factory</h2>
<div class='content'><p>The <code>DataReaderFactory</code> creates instances of <code>DataReader</code> which actually read the data.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgU2ltcGxlRGF0YVJlYWRlckZhY3RvcnkgZXh0ZW5kcyBEYXRhUmVhZGVyRmFjdG9yeVtSb3ddIHsKICBvdmVycmlkZSBkZWYgY3JlYXRlRGF0YVJlYWRlcigpOiBEYXRhUmVhZGVyW1Jvd10gPSBuZXcgU2ltcGxlRGF0YVJlYWRlcgp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class SimpleDataReaderFactory extends DataReaderFactory[Row] {
  override def createDataReader(): DataReader[Row] = new SimpleDataReader
}</pre></div><div class='content'></div><h2>Step 4: Define the Data Reader</h2>
<div class='content'><p>The <code>DataReader</code> reads the data and converts it into Spark's internal <code>Row</code> format.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgU2ltcGxlRGF0YVJlYWRlciBleHRlbmRzIERhdGFSZWFkZXJbUm93XSB7CiAgcHJpdmF0ZSB2YWwgZGF0YSA9IExpc3QoCiAgICBSb3coMSwgInZhbHVlMSIpLAogICAgUm93KDIsICJ2YWx1ZTIiKQogICkuaXRlcmF0b3IKCiAgb3ZlcnJpZGUgZGVmIG5leHQoKTogQm9vbGVhbiA9IGRhdGEuaGFzTmV4dAoKICBvdmVycmlkZSBkZWYgZ2V0KCk6IFJvdyA9IGRhdGEubmV4dCgpCgogIG92ZXJyaWRlIGRlZiBjbG9zZSgpOiBVbml0ID0ge30KfQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class SimpleDataReader extends DataReader[Row] {
  private val data = List(
    Row(1, &quot;value1&quot;),
    Row(2, &quot;value2&quot;)
  ).iterator

  override def next(): Boolean = data.hasNext

  override def get(): Row = data.next()

  override def close(): Unit = {}
}</pre></div><div class='content'></div><h2>Using the Custom Data Source</h2>
<div class='content'><p>Once your custom data source is implemented, you can use it in your Spark application as follows:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIoKQogIC5hcHBOYW1lKCJDdXN0b20gRGF0YSBTb3VyY2UgRXhhbXBsZSIpCiAgLmdldE9yQ3JlYXRlKCkKCnZhbCBkZiA9IHNwYXJrLnJlYWQKICAuZm9ybWF0KCJjb20uZXhhbXBsZS5TaW1wbGVEYXRhU291cmNlIikKICAubG9hZCgpCgpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val spark = SparkSession.builder()
  .appName(&quot;Custom Data Source Example&quot;)
  .getOrCreate()

val df = spark.read
  .format(&quot;com.example.SimpleDataSource&quot;)
  .load()

df.show()</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>Creating custom data sources in Apache Spark allows you to extend its capabilities to handle specialized data formats and integrate with various systems. By following the steps outlined in this section, you can implement and use custom data sources in your Spark applications. This flexibility ensures that Spark can be adapted to meet the unique requirements of your data processing tasks.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='advanced-rdd-operations'>&#x25C4;Advanced RDD Operations</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Custom Data Sources in Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='advanced-spark-sql'>Advanced Spark SQL &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
