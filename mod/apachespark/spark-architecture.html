<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark Architecture</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/spark-architecture" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/spark-architecture" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/spark-architecture" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/spark-architecture" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/spark-architecture" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='installing-and-setting-up-spark'>&#x25C4;Installing and Setting Up Spark</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Spark Architecture</a>
	</div>
	<div class='col-4 text-end'>
					<a href='rdds'>RDDs (Resilient Distributed Datasets) &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Apache Spark is a powerful open-source processing engine designed for large-scale data processing and analytics. Understanding its architecture is crucial for effectively utilizing its capabilities. This topic will cover the core components and concepts of Spark's architecture, from the basics to more advanced aspects.</p>
</div><h1>Key Components of Spark Architecture</h1>
<div class='content'></div><h2>Driver Program</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: The driver program is the main control process that coordinates the execution of tasks on the Spark cluster.</li>
<li><strong>Responsibilities</strong>:
<ul>
<li>Converts user code into a directed acyclic graph (DAG) of stages.</li>
<li>Schedules tasks on the cluster.</li>
<li>Collects and displays the results.</li>
</ul>
</li>
</ul>
</div><h2>Cluster Manager</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: The cluster manager is responsible for managing resources across the cluster.</li>
<li><strong>Types</strong>:
<ul>
<li><strong>Standalone</strong>: Spark's built-in cluster manager.</li>
<li><strong>Apache Mesos</strong>: A general cluster manager that can manage resources for multiple frameworks.</li>
<li><strong>Hadoop YARN</strong>: The resource manager for Hadoop clusters.</li>
<li><strong>Kubernetes</strong>: A container orchestration system that can also manage Spark resources.</li>
</ul>
</li>
</ul>
</div><h2>Executors</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Executors are distributed agents responsible for executing tasks and storing data.</li>
<li><strong>Responsibilities</strong>:
<ul>
<li>Execute code assigned by the driver.</li>
<li>Store data in memory or disk storage.</li>
<li>Report the status and results back to the driver.</li>
</ul>
</li>
</ul>
</div><h2>Tasks</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Tasks are the smallest units of work in Spark, representing a single operation on a partition of data.</li>
<li><strong>Execution</strong>: Tasks are executed by the executors.</li>
</ul>
</div><h1>Spark Execution Model</h1>
<div class='content'></div><h2>Jobs and Stages</h2>
<div class='content'><ul>
<li><strong>Job</strong>: A job is triggered by an action (e.g., <code>count()</code>, <code>collect()</code>) and consists of multiple stages.</li>
<li><strong>Stage</strong>: A stage is a set of tasks that can be executed in parallel, divided by shuffle boundaries.</li>
</ul>
</div><h2>Directed Acyclic Graph (DAG)</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: A DAG is a representation of the sequence of computations performed on the data.</li>
<li><strong>Importance</strong>: It helps in optimizing the execution plan by breaking it into stages.</li>
</ul>
</div><h2>Example: Simple Word Count</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgSW5pdGlhbGl6ZSBTcGFya0NvbnRleHQKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsIiwgIldvcmRDb3VudCIpCgojIFJlYWQgaW5wdXQgZmlsZQp0ZXh0X2ZpbGUgPSBzYy50ZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vaW5wdXQudHh0IikKCiMgUGVyZm9ybSB3b3JkIGNvdW50CmNvdW50cyA9IHRleHRfZmlsZS5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpIFwKICAgICAgICAgICAgICAgICAgLm1hcChsYW1iZGEgd29yZDogKHdvcmQsIDEpKSBcCiAgICAgICAgICAgICAgICAgIC5yZWR1Y2VCeUtleShsYW1iZGEgYSwgYjogYSArIGIpCgojIFNhdmUgdGhlIHJlc3VsdApjb3VudHMuc2F2ZUFzVGV4dEZpbGUoImhkZnM6Ly9wYXRoL3RvL291dHB1dCIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Initialize SparkContext
sc = SparkContext(&quot;local&quot;, &quot;WordCount&quot;)

# Read input file
text_file = sc.textFile(&quot;hdfs://path/to/input.txt&quot;)

# Perform word count
counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)

# Save the result
counts.saveAsTextFile(&quot;hdfs://path/to/output&quot;)</pre></div><div class='content'><ul>
<li><strong>Explanation</strong>:
<ul>
<li><strong>flatMap</strong>: Splits each line into words.</li>
<li><strong>map</strong>: Maps each word to a (word, 1) pair.</li>
<li><strong>reduceByKey</strong>: Aggregates the counts for each word.</li>
<li><strong>saveAsTextFile</strong>: Saves the result to HDFS.</li>
</ul>
</li>
</ul>
</div><h1>Advanced Concepts</h1>
<div class='content'></div><h2>Resilient Distributed Datasets (RDDs)</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: RDDs are the fundamental data structure of Spark, representing an immutable distributed collection of objects.</li>
<li><strong>Properties</strong>:
<ul>
<li><strong>Immutability</strong>: Once created, RDDs cannot be changed.</li>
<li><strong>Fault Tolerance</strong>: RDDs can be recomputed in case of node failures.</li>
<li><strong>Lazy Evaluation</strong>: Transformations on RDDs are not executed until an action is called.</li>
</ul>
</li>
</ul>
</div><h2>DataFrames and Datasets</h2>
<div class='content'><ul>
<li><strong>DataFrame</strong>: A distributed collection of data organized into named columns, similar to a table in a relational database.</li>
<li><strong>Dataset</strong>: A strongly-typed collection of objects, providing the benefits of RDDs with the optimizations of DataFrames.</li>
</ul>
</div><h2>Spark SQL</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Spark SQL is a module for structured data processing, allowing querying of data via SQL as well as the DataFrame API.</li>
<li><strong>Example</strong>:</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaXRpYWxpemUgU3BhcmtTZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiU3BhcmtTUUxFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQoKIyBMb2FkIGRhdGEgaW50byBEYXRhRnJhbWUKZGYgPSBzcGFyay5yZWFkLmpzb24oImhkZnM6Ly9wYXRoL3RvL2lucHV0Lmpzb24iKQoKIyBSZWdpc3RlciBEYXRhRnJhbWUgYXMgYSBTUUwgdGVtcG9yYXJ5IHZpZXcKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCgojIEV4ZWN1dGUgU1FMIHF1ZXJ5CnNxbERGID0gc3Bhcmsuc3FsKCJTRUxFQ1QgbmFtZSBGUk9NIHBlb3BsZSBXSEVSRSBhZ2UgPiAyMSIpCgojIFNob3cgdGhlIHJlc3VsdApzcWxERi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Initialize SparkSession
spark = SparkSession.builder.appName(&quot;SparkSQLExample&quot;).getOrCreate()

# Load data into DataFrame
df = spark.read.json(&quot;hdfs://path/to/input.json&quot;)

# Register DataFrame as a SQL temporary view
df.createOrReplaceTempView(&quot;people&quot;)

# Execute SQL query
sqlDF = spark.sql(&quot;SELECT name FROM people WHERE age &gt; 21&quot;)

# Show the result
sqlDF.show()</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>Understanding Spark's architecture is essential for leveraging its full potential in big data processing. The driver program, cluster manager, executors, and tasks form the core components, while the DAG execution model ensures efficient task scheduling and execution. Advanced concepts like RDDs, DataFrames, and Spark SQL provide powerful abstractions for handling complex data processing tasks. By mastering these components and concepts, you can build robust and scalable data processing applications with Apache Spark.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='installing-and-setting-up-spark'>&#x25C4;Installing and Setting Up Spark</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Spark Architecture</a>
	</div>
	<div class='col-4 text-end'>
					<a href='rdds'>RDDs (Resilient Distributed Datasets) &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
