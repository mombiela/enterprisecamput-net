<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clustering in Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/clustering" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/clustering" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/clustering" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/clustering" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/clustering" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='classification-and-regression'>&#x25C4;Classification and Regression</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Clustering in Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='collaborative-filtering'>Collaborative Filtering &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to Clustering</h1>
<div class='content'><p>Clustering is a type of unsupervised learning that involves grouping a set of objects in such a way that objects in the same group (or cluster) are more similar to each other than to those in other groups. In Apache Spark, clustering can be efficiently performed using the MLlib library.</p>
<ul>
<li><strong>Unsupervised Learning</strong>: No labeled data is provided; the algorithm tries to learn the patterns and the structure from the data itself.</li>
<li><strong>Applications</strong>: Market segmentation, social network analysis, image compression, etc.</li>
</ul>
</div><h1>K-Means Clustering</h1>
<div class='content'><p>K-Means is one of the simplest and most popular clustering algorithms. It partitions the data into K clusters, where each data point belongs to the cluster with the nearest mean.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Centroid</strong>: The center of a cluster.</li>
<li><strong>Inertia</strong>: The sum of squared distances of samples to their closest cluster center.</li>
</ul>
</div><h2>Steps in K-Means Algorithm</h2>
<div class='content'><ol>
<li>Initialize K centroids randomly.</li>
<li>Assign each data point to the nearest centroid.</li>
<li>Recalculate the centroids as the mean of all points in the cluster.</li>
<li>Repeat steps 2 and 3 until convergence (centroids do not change).</li>
</ol>
</div><h2>Code Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmNsdXN0ZXJpbmcgaW1wb3J0IEtNZWFucwpmcm9tIHB5c3BhcmsubWwuZXZhbHVhdGlvbiBpbXBvcnQgQ2x1c3RlcmluZ0V2YWx1YXRvcgpmcm9tIHB5c3Bhcmsuc3FsIGltcG9ydCBTcGFya1Nlc3Npb24KCiMgSW5pdGlhbGl6ZSBTcGFyayBzZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiS01lYW5zRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKCiMgTG9hZCBkYXRhCmRhdGFzZXQgPSBzcGFyay5yZWFkLmZvcm1hdCgibGlic3ZtIikubG9hZCgiZGF0YS9tbGxpYi9zYW1wbGVfa21lYW5zX2RhdGEudHh0IikKCiMgVHJhaW4gYSBLTWVhbnMgbW9kZWwKa21lYW5zID0gS01lYW5zKCkuc2V0SygyKS5zZXRTZWVkKDEpCm1vZGVsID0ga21lYW5zLmZpdChkYXRhc2V0KQoKIyBNYWtlIHByZWRpY3Rpb25zCnByZWRpY3Rpb25zID0gbW9kZWwudHJhbnNmb3JtKGRhdGFzZXQpCgojIEV2YWx1YXRlIGNsdXN0ZXJpbmcgYnkgY29tcHV0aW5nIFNpbGhvdWV0dGUgc2NvcmUKZXZhbHVhdG9yID0gQ2x1c3RlcmluZ0V2YWx1YXRvcigpCgpzaWxob3VldHRlID0gZXZhbHVhdG9yLmV2YWx1YXRlKHByZWRpY3Rpb25zKQpwcmludChmIlNpbGhvdWV0dGUgd2l0aCBzcXVhcmVkIGV1Y2xpZGVhbiBkaXN0YW5jZSA9IHtzaWxob3VldHRlfSIpCgojIFNob3cgdGhlIHJlc3VsdApjZW50ZXJzID0gbW9kZWwuY2x1c3RlckNlbnRlcnMoKQpwcmludCgiQ2x1c3RlciBDZW50ZXJzOiAiKQpmb3IgY2VudGVyIGluIGNlbnRlcnM6CiAgICBwcmludChjZW50ZXIpCgojIFN0b3AgU3Bhcmsgc2Vzc2lvbgpzcGFyay5zdG9wKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator
from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName(&quot;KMeansExample&quot;).getOrCreate()

# Load data
dataset = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_kmeans_data.txt&quot;)

# Train a KMeans model
kmeans = KMeans().setK(2).setSeed(1)
model = kmeans.fit(dataset)

# Make predictions
predictions = model.transform(dataset)

# Evaluate clustering by computing Silhouette score
evaluator = ClusteringEvaluator()

silhouette = evaluator.evaluate(predictions)
print(f&quot;Silhouette with squared euclidean distance = {silhouette}&quot;)

# Show the result
centers = model.clusterCenters()
print(&quot;Cluster Centers: &quot;)
for center in centers:
    print(center)

# Stop Spark session
spark.stop()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>SparkSession</strong>: Entry point to programming with Spark.</li>
<li><strong>KMeans</strong>: The KMeans class is used to create a KMeans model.</li>
<li><strong>fit()</strong>: Trains the model.</li>
<li><strong>transform()</strong>: Makes predictions.</li>
<li><strong>ClusteringEvaluator</strong>: Evaluates the clustering model using metrics like Silhouette score.</li>
</ul>
</div><h1>Gaussian Mixture Model (GMM)</h1>
<div class='content'><p>Gaussian Mixture Model is a probabilistic model that assumes all the data points are generated from a mixture of several Gaussian distributions with unknown parameters.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Expectation-Maximization (EM)</strong>: Algorithm used to find the maximum likelihood estimates of parameters in GMM.</li>
<li><strong>Covariance Matrix</strong>: Describes the shape of the Gaussian distributions.</li>
</ul>
</div><h2>Code Example</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmNsdXN0ZXJpbmcgaW1wb3J0IEdhdXNzaWFuTWl4dHVyZQoKIyBJbml0aWFsaXplIFNwYXJrIHNlc3Npb24Kc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJHTU1FeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQoKIyBMb2FkIGRhdGEKZGF0YXNldCA9IHNwYXJrLnJlYWQuZm9ybWF0KCJsaWJzdm0iKS5sb2FkKCJkYXRhL21sbGliL3NhbXBsZV9rbWVhbnNfZGF0YS50eHQiKQoKIyBUcmFpbiBhIEdhdXNzaWFuTWl4dHVyZSBtb2RlbApnbW0gPSBHYXVzc2lhbk1peHR1cmUoKS5zZXRLKDIpLnNldFNlZWQoMSkKbW9kZWwgPSBnbW0uZml0KGRhdGFzZXQpCgojIE1ha2UgcHJlZGljdGlvbnMKcHJlZGljdGlvbnMgPSBtb2RlbC50cmFuc2Zvcm0oZGF0YXNldCkKCiMgU2hvdyB0aGUgcmVzdWx0CnByaW50KCJHYXVzc2lhbnMgc2hvd24gYXMgYSBEYXRhRnJhbWU6ICIpCm1vZGVsLmdhdXNzaWFuc0RGLnNob3codHJ1bmNhdGU9RmFsc2UpCgojIFN0b3AgU3Bhcmsgc2Vzc2lvbgpzcGFyay5zdG9wKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.clustering import GaussianMixture

# Initialize Spark session
spark = SparkSession.builder.appName(&quot;GMMExample&quot;).getOrCreate()

# Load data
dataset = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_kmeans_data.txt&quot;)

# Train a GaussianMixture model
gmm = GaussianMixture().setK(2).setSeed(1)
model = gmm.fit(dataset)

# Make predictions
predictions = model.transform(dataset)

# Show the result
print(&quot;Gaussians shown as a DataFrame: &quot;)
model.gaussiansDF.show(truncate=False)

# Stop Spark session
spark.stop()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>GaussianMixture</strong>: The GaussianMixture class is used to create a GMM model.</li>
<li><strong>gaussiansDF</strong>: DataFrame containing the parameters for each Gaussian distribution.</li>
</ul>
</div><h1>Hierarchical Clustering</h1>
<div class='content'><p>Hierarchical clustering builds a hierarchy of clusters either by merging small clusters into larger ones (agglomerative) or by splitting large clusters into smaller ones (divisive).</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Dendrogram</strong>: A tree-like diagram that records the sequences of merges or splits.</li>
<li><strong>Linkage Criteria</strong>: Determines the distance between sets of observations (single, complete, average).</li>
</ul>
</div><h2>Code Example</h2>
<div class='content'><p>Hierarchical clustering is not directly supported in Spark MLlib, but can be implemented using third-party libraries or custom code.</p>
</div><h1>Conclusion</h1>
<div class='content'><p>Clustering is a powerful technique for discovering patterns and structures in data. Apache Spark provides robust tools for implementing clustering algorithms like K-Means and Gaussian Mixture Models. Understanding these algorithms and their implementation in Spark can significantly enhance your ability to analyze and interpret large datasets.</p>
<ul>
<li><strong>K-Means</strong>: Simple and efficient, but requires the number of clusters to be specified.</li>
<li><strong>GMM</strong>: More flexible, can model clusters with different shapes and sizes.</li>
<li><strong>Hierarchical Clustering</strong>: Useful for creating a hierarchy of clusters, though not natively supported in Spark MLlib.</li>
</ul>
<p>By mastering these clustering techniques, you can apply them to a wide range of real-world problems, from market segmentation to image analysis.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='classification-and-regression'>&#x25C4;Classification and Regression</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Clustering in Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='collaborative-filtering'>Collaborative Filtering &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
