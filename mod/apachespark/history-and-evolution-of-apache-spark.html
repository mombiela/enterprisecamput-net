<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>History and Evolution of Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/history-and-evolution-of-apache-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/history-and-evolution-of-apache-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/history-and-evolution-of-apache-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/apachespark/history-and-evolution-of-apache-spark" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/history-and-evolution-of-apache-spark" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='what-is-apache-spark'>&#x25C4;What is Apache Spark?</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">History and Evolution of Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='spark-ecosystem-and-components'>Spark Ecosystem and Components &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Apache Spark is a powerful open-source unified analytics engine for large-scale data processing. It was developed to overcome the limitations of Hadoop MapReduce and has since become a cornerstone in the big data ecosystem. This section will cover the history and evolution of Apache Spark, highlighting key milestones and developments.</p>
</div><h1>Origins of Apache Spark</h1>
<div class='content'><ul>
<li><strong>Development at UC Berkeley</strong>: Apache Spark was originally developed in 2009 by Matei Zaharia at UC Berkeley's AMPLab as a part of his PhD dissertation.</li>
<li><strong>Initial Release</strong>: The first version of Spark was open-sourced in 2010 under a BSD license.</li>
<li><strong>Apache Incubation</strong>: In June 2013, Spark was donated to the Apache Software Foundation and entered the Apache Incubator.</li>
</ul>
</div><h1>Key Milestones</h1>
<div class='content'><ul>
<li><strong>Apache Top-Level Project</strong>: In February 2014, Spark became an Apache Top-Level Project.</li>
<li><strong>Spark 1.0 Release</strong>: In May 2014, Spark 1.0 was released, marking the first stable version.</li>
<li><strong>Spark 2.0 Release</strong>: In July 2016, Spark 2.0 was released, introducing significant improvements in performance and usability.</li>
<li><strong>Spark 3.0 Release</strong>: In June 2020, Spark 3.0 was released, featuring enhancements like Adaptive Query Execution and better support for Kubernetes.</li>
</ul>
</div><h1>Evolution of Features</h1>
<h2>Early Features</h2>
<div class='content'><ul>
<li><strong>RDD (Resilient Distributed Dataset)</strong>: The core abstraction in Spark, allowing for fault-tolerant and distributed data processing.</li>
<li><strong>In-Memory Processing</strong>: Unlike Hadoop MapReduce, Spark processes data in memory, significantly speeding up data processing tasks.</li>
</ul>
</div><h2>Advanced Features</h2>
<div class='content'><ul>
<li><strong>DataFrames and Datasets</strong>: Introduced in Spark 1.3 and 1.6 respectively, these abstractions provide more efficient and user-friendly APIs for data manipulation.</li>
<li><strong>Spark SQL</strong>: Introduced in Spark 1.0, Spark SQL allows for querying data using SQL and provides a unified interface for working with structured data.</li>
<li><strong>Machine Learning Library (MLlib)</strong>: A library for scalable machine learning algorithms, introduced in Spark 1.0.</li>
<li><strong>GraphX</strong>: A library for graph processing, introduced in Spark 0.9.</li>
<li><strong>Structured Streaming</strong>: Introduced in Spark 2.0, this feature allows for real-time stream processing using the same API as batch processing.</li>
</ul>
</div><h1>Comparison with Hadoop MapReduce</h1>
<div class='content'><p>| Feature              | Apache Spark                          | Hadoop MapReduce                      |
|----------------------|---------------------------------------|---------------------------------------|
| Processing Model     | In-memory processing                  | Disk-based processing                 |
| Speed                | Faster due to in-memory computation   | Slower due to disk I/O                |
| Ease of Use          | High-level APIs (DataFrames, Datasets)| Low-level APIs                        |
| Libraries            | Rich set of libraries (MLlib, GraphX) | Limited built-in libraries            |
| Real-time Processing | Supported (Structured Streaming)      | Not natively supported                |</p>
</div><h1>Code Example: Basic Spark Application</h1>
<div class='content'><p>Here's a simple example of a Spark application that counts the number of lines in a text file:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgSW5pdGlhbGl6ZSBhIFNwYXJrQ29udGV4dApzYyA9IFNwYXJrQ29udGV4dCgibG9jYWwiLCAiTGluZSBDb3VudCBBcHAiKQoKIyBSZWFkIGEgdGV4dCBmaWxlCnRleHRfZmlsZSA9IHNjLnRleHRGaWxlKCJleGFtcGxlLnR4dCIpCgojIENvdW50IHRoZSBudW1iZXIgb2YgbGluZXMKbGluZV9jb3VudCA9IHRleHRfZmlsZS5jb3VudCgpCgpwcmludChmIk51bWJlciBvZiBsaW5lczoge2xpbmVfY291bnR9IikKCiMgU3RvcCB0aGUgU3BhcmtDb250ZXh0CnNjLnN0b3AoKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Initialize a SparkContext
sc = SparkContext(&quot;local&quot;, &quot;Line Count App&quot;)

# Read a text file
text_file = sc.textFile(&quot;example.txt&quot;)

# Count the number of lines
line_count = text_file.count()

print(f&quot;Number of lines: {line_count}&quot;)

# Stop the SparkContext
sc.stop()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>SparkContext</strong>: The entry point for any Spark application. It allows Spark to connect to a cluster.</li>
<li><strong>textFile</strong>: Reads a text file and returns an RDD of strings.</li>
<li><strong>count</strong>: An action that returns the number of elements in the RDD.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>The history and evolution of Apache Spark demonstrate its rapid development and widespread adoption in the big data community. From its origins at UC Berkeley to becoming an Apache Top-Level Project, Spark has continually evolved to include advanced features like DataFrames, Spark SQL, and Structured Streaming. Its ability to process data in memory and its rich set of libraries make it a powerful tool for data processing and analytics. Understanding this history provides context for the capabilities and design choices of Spark, setting the stage for deeper exploration in subsequent sections of this course.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='what-is-apache-spark'>&#x25C4;What is Apache Spark?</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">History and Evolution of Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='spark-ecosystem-and-components'>Spark Ecosystem and Components &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
