<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Distributed File Systems</title>

    <link rel="alternate" href="https://campusempresa.com/mod/procesamiento_datos_masivos/02-01-sistemas-archivos-distribuidos" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/procesamiento_datos_masivos/02-01-sistemes-fitxers-distribuits" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/procesamiento_datos_masivos/02-01-distributed-file-systems" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/procesamiento_datos_masivos/02-01-sistemas-archivos-distribuidos" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/procesamiento_datos_masivos/02-01-sistemes-fitxers-distribuits" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='01-03-challenges' title="Challenges of Massive Data Processing">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Distributed File Systems</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='02-02-nosql-databases' title="NoSQL Databases">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1><p>Introduction</p>
</h1>
<div class='content'><p>Distributed File Systems (DFS) are a critical component in the architecture of massive data processing. They allow data to be stored across multiple machines, providing scalability, fault tolerance, and high availability. This section will cover the basic concepts, key features, and popular implementations of distributed file systems.</p>
</div><h1><p>Basic Concepts</p>
</h1>
<div class='content'></div><h2><p>What is a Distributed File System?</p>
</h2>
<div class='content'><p>A Distributed File System is a file system that manages files and directories spread across multiple physical machines. It provides a unified view of the data, making it appear as if it is stored on a single machine.</p>
</div><h2><p>Key Features</p>
</h2>
<div class='content'><ul>
<li><strong>Scalability</strong>: Ability to handle increasing amounts of data by adding more machines.</li>
<li><strong>Fault Tolerance</strong>: Ensures data availability even if some machines fail.</li>
<li><strong>High Availability</strong>: Data is accessible at all times, even during maintenance or failures.</li>
<li><strong>Data Replication</strong>: Copies of data are stored on multiple machines to prevent data loss.</li>
</ul>
</div><h1><p>Popular Distributed File Systems</p>
</h1>
<div class='content'></div><h2><p>Hadoop Distributed File System (HDFS)</p>
</h2>
<div class='content'><p>HDFS is a highly scalable and fault-tolerant file system designed for large-scale data processing. It is a core component of the Apache Hadoop ecosystem.</p>
<h4>Key Features</h4>
<ul>
<li><strong>Block Storage</strong>: Files are split into large blocks (default 128MB) and distributed across the cluster.</li>
<li><strong>Replication</strong>: Each block is replicated across multiple nodes (default replication factor is 3).</li>
<li><strong>Master-Slave Architecture</strong>: Consists of a single NameNode (master) and multiple DataNodes (slaves).</li>
</ul>
<h4>Example</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Ly8gSmF2YSBjb2RlIHRvIHJlYWQgYSBmaWxlIGZyb20gSERGUwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuY29uZi5Db25maWd1cmF0aW9uOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuZnMuRmlsZVN5c3RlbTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLlBhdGg7CmltcG9ydCBqYXZhLmlvLkJ1ZmZlcmVkUmVhZGVyOwppbXBvcnQgamF2YS5pby5JbnB1dFN0cmVhbVJlYWRlcjsKCnB1YmxpYyBjbGFzcyBIREZTUmVhZEV4YW1wbGUgewogICAgcHVibGljIHN0YXRpYyB2b2lkIG1haW4oU3RyaW5nW10gYXJncykgdGhyb3dzIEV4Y2VwdGlvbiB7CiAgICAgICAgQ29uZmlndXJhdGlvbiBjb25mID0gbmV3IENvbmZpZ3VyYXRpb24oKTsKICAgICAgICBGaWxlU3lzdGVtIGZzID0gRmlsZVN5c3RlbS5nZXQoY29uZik7CiAgICAgICAgUGF0aCBmaWxlUGF0aCA9IG5ldyBQYXRoKCIvdXNlci9oYWRvb3AvaW5wdXQudHh0Iik7CiAgICAgICAgCiAgICAgICAgQnVmZmVyZWRSZWFkZXIgYnIgPSBuZXcgQnVmZmVyZWRSZWFkZXIobmV3IElucHV0U3RyZWFtUmVhZGVyKGZzLm9wZW4oZmlsZVBhdGgpKSk7CiAgICAgICAgU3RyaW5nIGxpbmU7CiAgICAgICAgd2hpbGUgKChsaW5lID0gYnIucmVhZExpbmUoKSkgIT0gbnVsbCkgewogICAgICAgICAgICBTeXN0ZW0ub3V0LnByaW50bG4obGluZSk7CiAgICAgICAgfQogICAgICAgIGJyLmNsb3NlKCk7CiAgICB9Cn0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>// Java code to read a file from HDFS
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.BufferedReader;
import java.io.InputStreamReader;

public class HDFSReadExample {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(conf);
        Path filePath = new Path(&quot;/user/hadoop/input.txt&quot;);
        
        BufferedReader br = new BufferedReader(new InputStreamReader(fs.open(filePath)));
        String line;
        while ((line = br.readLine()) != null) {
            System.out.println(line);
        }
        br.close();
    }
}</pre></div><div class='content'><p>Explanation:</p>
<ul>
<li><code>Configuration conf = new Configuration();</code>: Initializes the Hadoop configuration.</li>
<li><code>FileSystem fs = FileSystem.get(conf);</code>: Gets the HDFS instance.</li>
<li><code>Path filePath = new Path(&quot;/user/hadoop/input.txt&quot;);</code>: Specifies the file path in HDFS.</li>
<li>The rest of the code reads the file line by line and prints it to the console.</li>
</ul>
</div><h2><p>Google File System (GFS)</p>
</h2>
<div class='content'><p>GFS is a proprietary distributed file system developed by Google to handle large-scale data processing.</p>
<h4>Key Features</h4>
<ul>
<li><strong>Chunk Storage</strong>: Files are divided into fixed-size chunks (64MB) and stored across the cluster.</li>
<li><strong>Replication</strong>: Each chunk is replicated across multiple chunk servers.</li>
<li><strong>Master-Slave Architecture</strong>: Consists of a single Master and multiple Chunk Servers.</li>
</ul>
</div><h2><p>Amazon S3</p>
</h2>
<div class='content'><p>Amazon S3 (Simple Storage Service) is a scalable object storage service provided by AWS.</p>
<h4>Key Features</h4>
<ul>
<li><strong>Object Storage</strong>: Data is stored as objects within buckets.</li>
<li><strong>Scalability</strong>: Automatically scales to handle large amounts of data.</li>
<li><strong>High Availability</strong>: Provides 99.999999999% durability and 99.99% availability.</li>
</ul>
<h4>Example</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQeXRob24gY29kZSB0byB1cGxvYWQgYSBmaWxlIHRvIEFtYXpvbiBTMwppbXBvcnQgYm90bzMKCnMzID0gYm90bzMuY2xpZW50KCdzMycpCmJ1Y2tldF9uYW1lID0gJ215LWJ1Y2tldCcKZmlsZV9wYXRoID0gJ3BhdGgvdG8vbG9jYWwvZmlsZS50eHQnCnMzX2tleSA9ICd1cGxvYWRlZC1maWxlLnR4dCcKCnMzLnVwbG9hZF9maWxlKGZpbGVfcGF0aCwgYnVja2V0X25hbWUsIHMzX2tleSkKcHJpbnQoZidGaWxlIHtmaWxlX3BhdGh9IHVwbG9hZGVkIHRvIHtidWNrZXRfbmFtZX0ve3MzX2tleX0nKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Python code to upload a file to Amazon S3
import boto3

s3 = boto3.client('s3')
bucket_name = 'my-bucket'
file_path = 'path/to/local/file.txt'
s3_key = 'uploaded-file.txt'

s3.upload_file(file_path, bucket_name, s3_key)
print(f'File {file_path} uploaded to {bucket_name}/{s3_key}')</pre></div><div class='content'><p>Explanation:</p>
<ul>
<li><code>import boto3</code>: Imports the Boto3 library for AWS services.</li>
<li><code>s3 = boto3.client('s3');</code>: Initializes the S3 client.</li>
<li><code>s3.upload_file(file_path, bucket_name, s3_key);</code>: Uploads the file to the specified S3 bucket.</li>
</ul>
</div><h1><p>Practical Exercise</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: Setting Up HDFS</p>
</h2>
<div class='content'><ol>
<li><strong>Install Hadoop</strong>: Follow the official <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html">Hadoop installation guide</a>.</li>
<li><strong>Start HDFS</strong>: Use the following commands to start HDFS.
<pre><code class="language-bash">start-dfs.sh
</code></pre>
</li>
<li><strong>Create a Directory</strong>: Create a new directory in HDFS.
<pre><code class="language-bash">hdfs dfs -mkdir /user/student
</code></pre>
</li>
<li><strong>Upload a File</strong>: Upload a local file to the HDFS directory.
<pre><code class="language-bash">hdfs dfs -put localfile.txt /user/student/
</code></pre>
</li>
<li><strong>List Files</strong>: List the files in the HDFS directory.
<pre><code class="language-bash">hdfs dfs -ls /user/student/
</code></pre>
</li>
</ol>
</div><h2><p>Solution</p>
</h2>
<div class='content'><ol>
<li><strong>Install Hadoop</strong>: Follow the steps in the official guide.</li>
<li><strong>Start HDFS</strong>:
<pre><code class="language-bash">start-dfs.sh
</code></pre>
</li>
<li><strong>Create a Directory</strong>:
<pre><code class="language-bash">hdfs dfs -mkdir /user/student
</code></pre>
</li>
<li><strong>Upload a File</strong>:
<pre><code class="language-bash">hdfs dfs -put localfile.txt /user/student/
</code></pre>
</li>
<li><strong>List Files</strong>:
<pre><code class="language-bash">hdfs dfs -ls /user/student/
</code></pre>
</li>
</ol>
</div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Configuration Issues</strong>: Ensure Hadoop is correctly configured, especially the <code>core-site.xml</code> and <code>hdfs-site.xml</code> files.</li>
<li><strong>Permissions</strong>: Check file and directory permissions in HDFS.</li>
<li><strong>Replication Factor</strong>: Adjust the replication factor based on the cluster size and fault tolerance requirements.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>Distributed File Systems are essential for handling massive volumes of data in a scalable and fault-tolerant manner. HDFS, GFS, and Amazon S3 are popular implementations, each with unique features and use cases. Understanding these systems is crucial for efficient data storage and processing in big data environments.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='01-03-challenges' title="Challenges of Massive Data Processing">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='02-02-nosql-databases' title="NoSQL Databases">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
