<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/big_data/03-02-apache-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/big_data/03-02-apache-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/big_data/03-02-apache-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=3" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/big_data/03-02-apache-spark" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/big_data/03-02-apache-spark" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>Building today's and tomorrow's society</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Languages</a>
				 					<a href="/categ/frameworks">Frameworks</a>
				 					<a href="/categ/tech-tools">Tools</a>
				 					<a href="/categ/foundations">Foundations</a>
				 					<a href="/categ/soft-skills">Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce and Hadoop">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Apache Spark</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-03-real-time-processing' title="Real-Time Processing">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Apache Spark is an open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. It is designed to be fast for both batch and streaming data processing, making it a versatile tool in the Big Data ecosystem.</p>
</div><h1><p>Key Concepts of Apache Spark</p>
</h1>
<div class='content'></div><h2><ol>
<li>Unified Analytics Engine</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Batch Processing</strong>: Spark can handle large-scale data processing jobs in a batch mode.</li>
<li><strong>Streaming Processing</strong>: Spark Streaming allows for real-time data processing.</li>
<li><strong>Interactive Queries</strong>: Spark supports interactive queries using Spark SQL.</li>
<li><strong>Machine Learning</strong>: Spark includes MLlib for scalable machine learning algorithms.</li>
<li><strong>Graph Processing</strong>: GraphX is Sparkâ€™s API for graph and graph-parallel computation.</li>
</ul>
</div><h2><ol start="2">
<li>Resilient Distributed Datasets (RDDs)</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Immutable</strong>: Once created, RDDs cannot be modified.</li>
<li><strong>Distributed</strong>: RDDs are distributed across multiple nodes in a cluster.</li>
<li><strong>Fault-Tolerant</strong>: RDDs can recover from node failures.</li>
</ul>
</div><h2><ol start="3">
<li>DataFrames and Datasets</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>DataFrames</strong>: Distributed collections of data organized into named columns, similar to a table in a relational database.</li>
<li><strong>Datasets</strong>: Strongly-typed, distributed collections of data that provide the benefits of RDDs with the optimizations of DataFrames.</li>
</ul>
</div><h2><ol start="4">
<li>Lazy Evaluation</li>
</ol>
</h2>
<div class='content'><ul>
<li>Spark uses lazy evaluation to optimize the execution plan. Transformations on RDDs, DataFrames, or Datasets are not executed immediately but are recorded in a lineage graph.</li>
</ul>
</div><h2><ol start="5">
<li>In-Memory Processing</li>
</ol>
</h2>
<div class='content'><ul>
<li>Spark performs computations in memory, which significantly speeds up processing compared to disk-based systems like Hadoop MapReduce.</li>
</ul>
</div><h1><p>Apache Spark Architecture</p>
</h1>
<div class='content'></div><h2><ol>
<li>Driver Program</li>
</ol>
</h2>
<div class='content'><ul>
<li>The driver program runs the main function of the application and creates the SparkContext, which coordinates the execution of tasks on the cluster.</li>
</ul>
</div><h2><ol start="2">
<li>Cluster Manager</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Standalone</strong>: Spark's built-in cluster manager.</li>
<li><strong>Apache Mesos</strong>: A general cluster manager that can also run Hadoop MapReduce and other applications.</li>
<li><strong>Hadoop YARN</strong>: The resource manager in Hadoop 2.</li>
</ul>
</div><h2><ol start="3">
<li>Executors</li>
</ol>
</h2>
<div class='content'><ul>
<li>Executors are worker nodes that run individual tasks and store data for the application.</li>
</ul>
</div><h2><ol start="4">
<li>Tasks</li>
</ol>
</h2>
<div class='content'><ul>
<li>Tasks are units of work that are sent to executors by the driver program.</li>
</ul>
</div><h1><p>Practical Example: Word Count in Apache Spark</p>
</h1>
<div class='content'></div><h2><p>Code Example</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKIyBDcmVhdGUgYSBTcGFyayBjb25maWd1cmF0aW9uIGFuZCBjb250ZXh0CmNvbmYgPSBTcGFya0NvbmYoKS5zZXRBcHBOYW1lKCJXb3JkQ291bnQiKS5zZXRNYXN0ZXIoImxvY2FsIikKc2MgPSBTcGFya0NvbnRleHQoY29uZj1jb25mKQoKIyBSZWFkIHRoZSBpbnB1dCBmaWxlCmlucHV0X2ZpbGUgPSBzYy50ZXh0RmlsZSgicGF0aC90by9pbnB1dC50eHQiKQoKIyBTcGxpdCBlYWNoIGxpbmUgaW50byB3b3Jkcwp3b3JkcyA9IGlucHV0X2ZpbGUuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKQoKIyBNYXAgZWFjaCB3b3JkIHRvIGEgdHVwbGUgKHdvcmQsIDEpCndvcmRfdHVwbGVzID0gd29yZHMubWFwKGxhbWJkYSB3b3JkOiAod29yZCwgMSkpCgojIFJlZHVjZSBieSBrZXkgdG8gY291bnQgb2NjdXJyZW5jZXMgb2YgZWFjaCB3b3JkCndvcmRfY291bnRzID0gd29yZF90dXBsZXMucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQoKIyBDb2xsZWN0IHRoZSByZXN1bHRzIGFuZCBwcmludCB0aGVtCmZvciB3b3JkLCBjb3VudCBpbiB3b3JkX2NvdW50cy5jb2xsZWN0KCk6CiAgICBwcmludChmInt3b3JkfToge2NvdW50fSIpCgojIFN0b3AgdGhlIFNwYXJrIGNvbnRleHQKc2Muc3RvcCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

# Create a Spark configuration and context
conf = SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

# Read the input file
input_file = sc.textFile(&quot;path/to/input.txt&quot;)

# Split each line into words
words = input_file.flatMap(lambda line: line.split(&quot; &quot;))

# Map each word to a tuple (word, 1)
word_tuples = words.map(lambda word: (word, 1))

# Reduce by key to count occurrences of each word
word_counts = word_tuples.reduceByKey(lambda a, b: a + b)

# Collect the results and print them
for word, count in word_counts.collect():
    print(f&quot;{word}: {count}&quot;)

# Stop the Spark context
sc.stop()</pre></div><div class='content'></div><h2><p>Explanation</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Spark Configuration and Context</strong>:</p>
<ul>
<li><code>SparkConf</code> is used to configure the application name and master URL.</li>
<li><code>SparkContext</code> initializes the Spark application.</li>
</ul>
</li>
<li>
<p><strong>Reading Input File</strong>:</p>
<ul>
<li><code>textFile</code> reads the input text file and creates an RDD.</li>
</ul>
</li>
<li>
<p><strong>Splitting Lines into Words</strong>:</p>
<ul>
<li><code>flatMap</code> transforms each line into a list of words.</li>
</ul>
</li>
<li>
<p><strong>Mapping Words to Tuples</strong>:</p>
<ul>
<li><code>map</code> transforms each word into a tuple (word, 1).</li>
</ul>
</li>
<li>
<p><strong>Reducing by Key</strong>:</p>
<ul>
<li><code>reduceByKey</code> aggregates the counts for each word.</li>
</ul>
</li>
<li>
<p><strong>Collecting and Printing Results</strong>:</p>
<ul>
<li><code>collect</code> gathers the results from the RDD and prints them.</li>
</ul>
</li>
</ol>
</div><h1><p>Exercises</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: Basic Transformations and Actions</p>
</h2>
<div class='content'><p><strong>Task</strong>: Create an RDD from a list of numbers and perform the following operations:</p>
<ol>
<li>Filter out even numbers.</li>
<li>Multiply each remaining number by 2.</li>
<li>Collect and print the results.</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKY29uZiA9IFNwYXJrQ29uZigpLnNldEFwcE5hbWUoIkJhc2ljVHJhbnNmb3JtYXRpb25zIikuc2V0TWFzdGVyKCJsb2NhbCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCm51bWJlcnMgPSBzYy5wYXJhbGxlbGl6ZShbMSwgMiwgMywgNCwgNSwgNiwgNywgOCwgOSwgMTBdKQoKIyBGaWx0ZXIgb3V0IGV2ZW4gbnVtYmVycwpvZGRfbnVtYmVycyA9IG51bWJlcnMuZmlsdGVyKGxhbWJkYSB4OiB4ICUgMiAhPSAwKQoKIyBNdWx0aXBseSBlYWNoIHJlbWFpbmluZyBudW1iZXIgYnkgMgpkb3VibGVkX251bWJlcnMgPSBvZGRfbnVtYmVycy5tYXAobGFtYmRhIHg6IHggKiAyKQoKIyBDb2xsZWN0IGFuZCBwcmludCB0aGUgcmVzdWx0cwpyZXN1bHRzID0gZG91YmxlZF9udW1iZXJzLmNvbGxlY3QoKQpwcmludChyZXN1bHRzKQoKc2Muc3RvcCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

conf = SparkConf().setAppName(&quot;BasicTransformations&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# Filter out even numbers
odd_numbers = numbers.filter(lambda x: x % 2 != 0)

# Multiply each remaining number by 2
doubled_numbers = odd_numbers.map(lambda x: x * 2)

# Collect and print the results
results = doubled_numbers.collect()
print(results)

sc.stop()</pre></div><div class='content'></div><h2><p>Exercise 2: Word Count with DataFrames</p>
</h2>
<div class='content'><p><strong>Task</strong>: Rewrite the word count example using DataFrames.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWF0ZSBhIFNwYXJrIHNlc3Npb24Kc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJXb3JkQ291bnRERiIpLmdldE9yQ3JlYXRlKCkKCiMgUmVhZCB0aGUgaW5wdXQgZmlsZSBpbnRvIGEgRGF0YUZyYW1lCmRmID0gc3BhcmsucmVhZC50ZXh0KCJwYXRoL3RvL2lucHV0LnR4dCIpCgojIFNwbGl0IGVhY2ggbGluZSBpbnRvIHdvcmRzCndvcmRzID0gZGYuc2VsZWN0RXhwcigiZXhwbG9kZShzcGxpdCh2YWx1ZSwgJyAnKSkgYXMgd29yZCIpCgojIEdyb3VwIGJ5IHdvcmQgYW5kIGNvdW50IG9jY3VycmVuY2VzCndvcmRfY291bnRzID0gd29yZHMuZ3JvdXBCeSgid29yZCIpLmNvdW50KCkKCiMgU2hvdyB0aGUgcmVzdWx0cwp3b3JkX2NvdW50cy5zaG93KCkKCiMgU3RvcCB0aGUgU3Bhcmsgc2Vzc2lvbgpzcGFyay5zdG9wKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Create a Spark session
spark = SparkSession.builder.appName(&quot;WordCountDF&quot;).getOrCreate()

# Read the input file into a DataFrame
df = spark.read.text(&quot;path/to/input.txt&quot;)

# Split each line into words
words = df.selectExpr(&quot;explode(split(value, ' ')) as word&quot;)

# Group by word and count occurrences
word_counts = words.groupBy(&quot;word&quot;).count()

# Show the results
word_counts.show()

# Stop the Spark session
spark.stop()</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ol>
<li><strong>Not Using Lazy Evaluation</strong>: Remember that transformations are lazy and actions trigger the execution. Plan your transformations accordingly.</li>
<li><strong>Ignoring Data Skew</strong>: Be mindful of data skew, where some partitions may have significantly more data than others, leading to performance bottlenecks.</li>
<li><strong>Inadequate Resource Allocation</strong>: Properly allocate resources (memory, CPU) to avoid out-of-memory errors and ensure efficient execution.</li>
</ol>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we covered the fundamental concepts of Apache Spark, its architecture, and practical examples of using Spark for data processing. We also provided exercises to reinforce the learned concepts. Understanding Spark's capabilities and how to use it effectively is crucial for handling large-scale data processing tasks in the Big Data ecosystem.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce and Hadoop">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-03-real-time-processing' title="Real-Time Processing">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
