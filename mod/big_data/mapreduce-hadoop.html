<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MapReduce and Hadoop</title>

    <link rel="alternate" href="https://campusempresa.com/mod/big_data/mapreduce-hadoop" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/big_data/mapreduce-hadoop" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/big_data/mapreduce-hadoop" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/big_data/mapreduce-hadoop" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/big_data/mapreduce-hadoop" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introduction to MapReduce and Hadoop</h1>
<div class='content'><p>In the world of Big Data, MapReduce and Hadoop are fundamental technologies for processing and analyzing large volumes of data. This topic will cover the basic concepts, architecture, and practical examples of how to use MapReduce and Hadoop.</p>
</div><h1>What is MapReduce?</h1>
<div class='content'><p>MapReduce is a programming model for processing large datasets with a parallel and distributed algorithm. It was developed by Google and consists of two main functions:</p>
<ul>
<li><strong>Map</strong>: Processes and transforms input data into key-value pairs.</li>
<li><strong>Reduce</strong>: Aggregates and combines the results from the Map step to produce the final output.</li>
</ul>
</div><h2>Example of MapReduce</h2>
<div class='content'><p>Suppose we want to count the frequency of words in a set of documents. The process can be divided into the following steps:</p>
<ol>
<li><strong>Map</strong>: Read each document and emit key-value pairs (word, 1).</li>
<li><strong>Shuffle and Sort</strong>: Group all identical keys.</li>
<li><strong>Reduce</strong>: Sum the values for each key.</li>
</ol>
<h4>Example Code in Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBjb2xsZWN0aW9ucyBpbXBvcnQgZGVmYXVsdGRpY3QKCiMgTWFwIFN0ZXAKZGVmIG1hcF9mdW5jdGlvbihkb2N1bWVudCk6CiAgICBmb3Igd29yZCBpbiBkb2N1bWVudC5zcGxpdCgpOgogICAgICAgIHlpZWxkICh3b3JkLCAxKQoKIyBSZWR1Y2UgU3RlcApkZWYgcmVkdWNlX2Z1bmN0aW9uKHBhaXJzKToKICAgIHdvcmRfY291bnQgPSBkZWZhdWx0ZGljdChpbnQpCiAgICBmb3Igd29yZCwgY291bnQgaW4gcGFpcnM6CiAgICAgICAgd29yZF9jb3VudFt3b3JkXSArPSBjb3VudAogICAgcmV0dXJuIHdvcmRfY291bnQKCiMgRXhhbXBsZSBEb2N1bWVudHMKZG9jdW1lbnRzID0gWyJoZWxsbyB3b3JsZCIsICJoZWxsbyBIYWRvb3AiLCAiaGVsbG8gTWFwUmVkdWNlIl0KCiMgQXBwbHkgTWFwCm1hcHBlZCA9IFtdCmZvciBkb2MgaW4gZG9jdW1lbnRzOgogICAgbWFwcGVkLmV4dGVuZChtYXBfZnVuY3Rpb24oZG9jKSkKCiMgQXBwbHkgUmVkdWNlCnJlZHVjZWQgPSByZWR1Y2VfZnVuY3Rpb24obWFwcGVkKQpwcmludChyZWR1Y2VkKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from collections import defaultdict

# Map Step
def map_function(document):
    for word in document.split():
        yield (word, 1)

# Reduce Step
def reduce_function(pairs):
    word_count = defaultdict(int)
    for word, count in pairs:
        word_count[word] += count
    return word_count

# Example Documents
documents = [&quot;hello world&quot;, &quot;hello Hadoop&quot;, &quot;hello MapReduce&quot;]

# Apply Map
mapped = []
for doc in documents:
    mapped.extend(map_function(doc))

# Apply Reduce
reduced = reduce_function(mapped)
print(reduced)</pre></div><div class='content'></div><h1>What is Hadoop?</h1>
<div class='content'><p>Hadoop is an open-source framework that allows for the distributed processing of large datasets across clusters of computers using simple programming models. Hadoop is composed of several modules:</p>
<ul>
<li><strong>Hadoop Common</strong>: The common utilities that support the other Hadoop modules.</li>
<li><strong>HDFS (Hadoop Distributed File System)</strong>: A distributed file system that provides high-performance access to data.</li>
<li><strong>YARN (Yet Another Resource Negotiator)</strong>: A resource management system for clusters.</li>
<li><strong>Hadoop MapReduce</strong>: A YARN-based system for parallel processing of large datasets.</li>
</ul>
</div><h2>Hadoop Architecture</h2>
<div class='content'><p>| Component | Description |
|-----------|-------------|
| HDFS      | Distributed file system that stores data in blocks distributed across multiple nodes. |
| YARN      | Framework for resource management and job scheduling. |
| MapReduce | Programming model for distributed data processing. |</p>
</div><h1>Example of a MapReduce Job in Hadoop</h1>
<div class='content'><p>To run a MapReduce job in Hadoop, the following steps must be followed:</p>
<ol>
<li><strong>Write the MapReduce code</strong>: Implement the Map and Reduce functions.</li>
<li><strong>Compile and package the code</strong>: Create a JAR file if using Java.</li>
<li><strong>Upload the data to HDFS</strong>: Place the input data in the distributed file system.</li>
<li><strong>Run the MapReduce job</strong>: Use the <code>hadoop jar</code> command to execute the job.</li>
<li><strong>Retrieve the results</strong>: Get the results from HDFS.</li>
</ol>
</div><h2>Example Code in Java</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;
import java.util.StringTokenizer;

public class WordCount {

  public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, &quot;word count&quot;);
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>MapReduce and Hadoop are powerful tools for efficiently and distributedly processing large volumes of data. Understanding how they work and how to implement them is essential for any IT professional working in the field of Big Data. Through practical examples and exercises, students can acquire valuable skills to handle large-scale data.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
