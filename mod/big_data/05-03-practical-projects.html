<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Practical Projects</title>

    <link rel="alternate" href="https://campusempresa.com/mod/big_data/05-03-proyectos-practicos" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/big_data/05-03-proyectos-practicos" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/big_data/05-03-practical-projects" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 px-0 py-2 py-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 px-0 py-2 py-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/big_data/05-03-proyectos-practicos" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/big_data/05-03-proyectos-practicos" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-case-studies' title="Case Studies in Different Industries">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Practical Projects</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-apache-hadoop-ecosystem' title="Apache Hadoop Ecosystem">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we will focus on practical projects that will help you apply the concepts and technologies learned throughout the Big Data course. These projects are designed to give you hands-on experience with real-world data and scenarios. Each project includes a detailed explanation, step-by-step instructions, and code examples to guide you through the process.</p>
</div><h1>Project 1: Analyzing Social Media Data</h1>
<div class='content'></div><h2>Objective</h2>
<div class='content'><p>Analyze social media data to extract insights about user behavior, trends, and sentiment.</p>
</div><h2>Steps</h2>
<div class='content'><ol>
<li>
<p><strong>Data Collection</strong></p>
<ul>
<li>Use APIs (e.g., Twitter API) to collect social media data.</li>
<li>Store the collected data in a NoSQL database (e.g., MongoDB).</li>
</ul>
</li>
<li>
<p><strong>Data Processing</strong></p>
<ul>
<li>Use Apache Spark to process the collected data.</li>
<li>Perform data cleaning and transformation.</li>
</ul>
</li>
<li>
<p><strong>Data Analysis</strong></p>
<ul>
<li>Use Spark MLlib to perform sentiment analysis on the data.</li>
<li>Identify trends and patterns in user behavior.</li>
</ul>
</li>
<li>
<p><strong>Data Visualization</strong></p>
<ul>
<li>Use tools like Tableau or Matplotlib to visualize the results.</li>
</ul>
</li>
</ol>
</div><h2>Example Code</h2>
<div class='content'><h4>Data Collection</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHR3ZWVweQppbXBvcnQganNvbgpmcm9tIHB5bW9uZ28gaW1wb3J0IE1vbmdvQ2xpZW50CgojIFR3aXR0ZXIgQVBJIGNyZWRlbnRpYWxzCmNvbnN1bWVyX2tleSA9ICd5b3VyX2NvbnN1bWVyX2tleScKY29uc3VtZXJfc2VjcmV0ID0gJ3lvdXJfY29uc3VtZXJfc2VjcmV0JwphY2Nlc3NfdG9rZW4gPSAneW91cl9hY2Nlc3NfdG9rZW4nCmFjY2Vzc190b2tlbl9zZWNyZXQgPSAneW91cl9hY2Nlc3NfdG9rZW5fc2VjcmV0JwoKIyBTZXQgdXAgVHdpdHRlciBBUEkgY2xpZW50CmF1dGggPSB0d2VlcHkuT0F1dGgxVXNlckhhbmRsZXIoY29uc3VtZXJfa2V5LCBjb25zdW1lcl9zZWNyZXQsIGFjY2Vzc190b2tlbiwgYWNjZXNzX3Rva2VuX3NlY3JldCkKYXBpID0gdHdlZXB5LkFQSShhdXRoKQoKIyBTZXQgdXAgTW9uZ29EQiBjbGllbnQKY2xpZW50ID0gTW9uZ29DbGllbnQoJ2xvY2FsaG9zdCcsIDI3MDE3KQpkYiA9IGNsaWVudFsnc29jaWFsX21lZGlhJ10KY29sbGVjdGlvbiA9IGRiWyd0d2VldHMnXQoKIyBDb2xsZWN0IHR3ZWV0cwpmb3IgdHdlZXQgaW4gdHdlZXB5LkN1cnNvcihhcGkuc2VhcmNoLCBxPSdiaWcgZGF0YScsIGxhbmc9J2VuJykuaXRlbXMoMTAwKToKICAgIGNvbGxlY3Rpb24uaW5zZXJ0X29uZSh0d2VldC5fanNvbik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tweepy
import json
from pymongo import MongoClient

# Twitter API credentials
consumer_key = 'your_consumer_key'
consumer_secret = 'your_consumer_secret'
access_token = 'your_access_token'
access_token_secret = 'your_access_token_secret'

# Set up Twitter API client
auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
api = tweepy.API(auth)

# Set up MongoDB client
client = MongoClient('localhost', 27017)
db = client['social_media']
collection = db['tweets']

# Collect tweets
for tweet in tweepy.Cursor(api.search, q='big data', lang='en').items(100):
    collection.insert_one(tweet._json)</pre></div><div class='content'><h4>Data Processing</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5zcWwuZnVuY3Rpb25zIGltcG9ydCBjb2wsIGxvd2VyLCByZWdleHBfcmVwbGFjZQoKIyBJbml0aWFsaXplIFNwYXJrIHNlc3Npb24Kc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJTb2NpYWxNZWRpYUFuYWx5c2lzIikuZ2V0T3JDcmVhdGUoKQoKIyBMb2FkIGRhdGEgZnJvbSBNb25nb0RCCmRmID0gc3BhcmsucmVhZC5mb3JtYXQoIm1vbmdvIikub3B0aW9uKCJ1cmkiLCAibW9uZ29kYjovL2xvY2FsaG9zdDoyNzAxNy9zb2NpYWxfbWVkaWEudHdlZXRzIikubG9hZCgpCgojIERhdGEgY2xlYW5pbmcKZGZfY2xlYW5lZCA9IGRmLndpdGhDb2x1bW4oInRleHQiLCBsb3dlcihjb2woInRleHQiKSkpCmRmX2NsZWFuZWQgPSBkZl9jbGVhbmVkLndpdGhDb2x1bW4oInRleHQiLCByZWdleHBfcmVwbGFjZShjb2woInRleHQiKSwgIlteYS16QS1aMC05XHNdIiwgIiIpKQoKIyBTaG93IGNsZWFuZWQgZGF0YQpkZl9jbGVhbmVkLnNlbGVjdCgidGV4dCIpLnNob3coNSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lower, regexp_replace

# Initialize Spark session
spark = SparkSession.builder.appName(&quot;SocialMediaAnalysis&quot;).getOrCreate()

# Load data from MongoDB
df = spark.read.format(&quot;mongo&quot;).option(&quot;uri&quot;, &quot;mongodb://localhost:27017/social_media.tweets&quot;).load()

# Data cleaning
df_cleaned = df.withColumn(&quot;text&quot;, lower(col(&quot;text&quot;)))
df_cleaned = df_cleaned.withColumn(&quot;text&quot;, regexp_replace(col(&quot;text&quot;), &quot;[^a-zA-Z0-9\s]&quot;, &quot;&quot;))

# Show cleaned data
df_cleaned.select(&quot;text&quot;).show(5)</pre></div><div class='content'><h4>Data Analysis</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IFRva2VuaXplciwgU3RvcFdvcmRzUmVtb3ZlciwgQ291bnRWZWN0b3JpemVyCmZyb20gcHlzcGFyay5tbC5jbGFzc2lmaWNhdGlvbiBpbXBvcnQgTG9naXN0aWNSZWdyZXNzaW9uCmZyb20gcHlzcGFyay5tbCBpbXBvcnQgUGlwZWxpbmUKCiMgVG9rZW5pemUgdGV4dAp0b2tlbml6ZXIgPSBUb2tlbml6ZXIoaW5wdXRDb2w9InRleHQiLCBvdXRwdXRDb2w9IndvcmRzIikKcmVtb3ZlciA9IFN0b3BXb3Jkc1JlbW92ZXIoaW5wdXRDb2w9IndvcmRzIiwgb3V0cHV0Q29sPSJmaWx0ZXJlZCIpCnZlY3Rvcml6ZXIgPSBDb3VudFZlY3Rvcml6ZXIoaW5wdXRDb2w9ImZpbHRlcmVkIiwgb3V0cHV0Q29sPSJmZWF0dXJlcyIpCgojIFNlbnRpbWVudCBhbmFseXNpcyBtb2RlbApsciA9IExvZ2lzdGljUmVncmVzc2lvbihtYXhJdGVyPTEwLCByZWdQYXJhbT0wLjAwMSkKCiMgUGlwZWxpbmUKcGlwZWxpbmUgPSBQaXBlbGluZShzdGFnZXM9W3Rva2VuaXplciwgcmVtb3ZlciwgdmVjdG9yaXplciwgbHJdKQoKIyBUcmFpbiBtb2RlbAptb2RlbCA9IHBpcGVsaW5lLmZpdChkZl9jbGVhbmVkKQoKIyBQcmVkaWN0IHNlbnRpbWVudApwcmVkaWN0aW9ucyA9IG1vZGVsLnRyYW5zZm9ybShkZl9jbGVhbmVkKQpwcmVkaWN0aW9ucy5zZWxlY3QoInRleHQiLCAicHJlZGljdGlvbiIpLnNob3coNSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer
from pyspark.ml.classification import LogisticRegression
from pyspark.ml import Pipeline

# Tokenize text
tokenizer = Tokenizer(inputCol=&quot;text&quot;, outputCol=&quot;words&quot;)
remover = StopWordsRemover(inputCol=&quot;words&quot;, outputCol=&quot;filtered&quot;)
vectorizer = CountVectorizer(inputCol=&quot;filtered&quot;, outputCol=&quot;features&quot;)

# Sentiment analysis model
lr = LogisticRegression(maxIter=10, regParam=0.001)

# Pipeline
pipeline = Pipeline(stages=[tokenizer, remover, vectorizer, lr])

# Train model
model = pipeline.fit(df_cleaned)

# Predict sentiment
predictions = model.transform(df_cleaned)
predictions.select(&quot;text&quot;, &quot;prediction&quot;).show(5)</pre></div><div class='content'><h4>Data Visualization</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdAoKIyBDb252ZXJ0IHByZWRpY3Rpb25zIHRvIFBhbmRhcyBEYXRhRnJhbWUKcHJlZGljdGlvbnNfcGQgPSBwcmVkaWN0aW9ucy5zZWxlY3QoInRleHQiLCAicHJlZGljdGlvbiIpLnRvUGFuZGFzKCkKCiMgUGxvdCBzZW50aW1lbnQgZGlzdHJpYnV0aW9uCnByZWRpY3Rpb25zX3BkWydwcmVkaWN0aW9uJ10udmFsdWVfY291bnRzKCkucGxvdChraW5kPSdiYXInKQpwbHQueGxhYmVsKCdTZW50aW1lbnQnKQpwbHQueWxhYmVsKCdDb3VudCcpCnBsdC50aXRsZSgnU2VudGltZW50IEFuYWx5c2lzIG9mIFNvY2lhbCBNZWRpYSBEYXRhJykKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import matplotlib.pyplot as plt

# Convert predictions to Pandas DataFrame
predictions_pd = predictions.select(&quot;text&quot;, &quot;prediction&quot;).toPandas()

# Plot sentiment distribution
predictions_pd['prediction'].value_counts().plot(kind='bar')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Sentiment Analysis of Social Media Data')
plt.show()</pre></div><div class='content'></div><h1>Project 2: Real-Time Data Processing with Apache Kafka and Spark Streaming</h1>
<div class='content'></div><h2>Objective</h2>
<div class='content'><p>Implement a real-time data processing pipeline using Apache Kafka and Spark Streaming.</p>
</div><h2>Steps</h2>
<div class='content'><ol>
<li>
<p><strong>Set Up Kafka</strong></p>
<ul>
<li>Install and configure Apache Kafka.</li>
<li>Create a Kafka topic for data ingestion.</li>
</ul>
</li>
<li>
<p><strong>Data Ingestion</strong></p>
<ul>
<li>Use a Kafka producer to send data to the Kafka topic.</li>
</ul>
</li>
<li>
<p><strong>Real-Time Processing</strong></p>
<ul>
<li>Use Spark Streaming to process data from the Kafka topic in real-time.</li>
</ul>
</li>
<li>
<p><strong>Data Storage</strong></p>
<ul>
<li>Store the processed data in a distributed file system (e.g., HDFS).</li>
</ul>
</li>
</ol>
</div><h2>Example Code</h2>
<div class='content'><h4>Kafka Producer</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrYWZrYSBpbXBvcnQgS2Fma2FQcm9kdWNlcgppbXBvcnQganNvbgppbXBvcnQgdGltZQoKcHJvZHVjZXIgPSBLYWZrYVByb2R1Y2VyKGJvb3RzdHJhcF9zZXJ2ZXJzPSdsb2NhbGhvc3Q6OTA5MicsIHZhbHVlX3NlcmlhbGl6ZXI9bGFtYmRhIHY6IGpzb24uZHVtcHModikuZW5jb2RlKCd1dGYtOCcpKQoKIyBTaW11bGF0ZSBkYXRhIGluZ2VzdGlvbgpmb3IgaSBpbiByYW5nZSgxMDApOgogICAgZGF0YSA9IHsnaWQnOiBpLCAndmFsdWUnOiBpICogMn0KICAgIHByb2R1Y2VyLnNlbmQoJ2RhdGFfdG9waWMnLCBkYXRhKQogICAgdGltZS5zbGVlcCgxKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from kafka import KafkaProducer
import json
import time

producer = KafkaProducer(bootstrap_servers='localhost:9092', value_serializer=lambda v: json.dumps(v).encode('utf-8'))

# Simulate data ingestion
for i in range(100):
    data = {'id': i, 'value': i * 2}
    producer.send('data_topic', data)
    time.sleep(1)</pre></div><div class='content'><h4>Spark Streaming</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5zcWwuZnVuY3Rpb25zIGltcG9ydCBmcm9tX2pzb24sIGNvbApmcm9tIHB5c3Bhcmsuc3FsLnR5cGVzIGltcG9ydCBTdHJ1Y3RUeXBlLCBTdHJ1Y3RGaWVsZCwgSW50ZWdlclR5cGUKCiMgSW5pdGlhbGl6ZSBTcGFyayBzZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiUmVhbFRpbWVQcm9jZXNzaW5nIikuZ2V0T3JDcmVhdGUoKQoKIyBEZWZpbmUgc2NoZW1hCnNjaGVtYSA9IFN0cnVjdFR5cGUoWwogICAgU3RydWN0RmllbGQoImlkIiwgSW50ZWdlclR5cGUoKSwgVHJ1ZSksCiAgICBTdHJ1Y3RGaWVsZCgidmFsdWUiLCBJbnRlZ2VyVHlwZSgpLCBUcnVlKQpdKQoKIyBSZWFkIGRhdGEgZnJvbSBLYWZrYQpkZiA9IHNwYXJrLnJlYWRTdHJlYW0uZm9ybWF0KCJrYWZrYSIpLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKS5vcHRpb24oInN1YnNjcmliZSIsICJkYXRhX3RvcGljIikubG9hZCgpCgojIFBhcnNlIEpTT04gZGF0YQpkZl9wYXJzZWQgPSBkZi5zZWxlY3RFeHByKCJDQVNUKHZhbHVlIEFTIFNUUklORykiKS5zZWxlY3QoZnJvbV9qc29uKGNvbCgidmFsdWUiKSwgc2NoZW1hKS5hbGlhcygiZGF0YSIpKS5zZWxlY3QoImRhdGEuKiIpCgojIFByb2Nlc3MgZGF0YQpkZl9wcm9jZXNzZWQgPSBkZl9wYXJzZWQud2l0aENvbHVtbigicHJvY2Vzc2VkX3ZhbHVlIiwgY29sKCJ2YWx1ZSIpICogMTApCgojIFdyaXRlIGRhdGEgdG8gSERGUwpkZl9wcm9jZXNzZWQud3JpdGVTdHJlYW0uZm9ybWF0KCJwYXJxdWV0Iikub3B0aW9uKCJwYXRoIiwgIi9wYXRoL3RvL2hkZnMiKS5vcHRpb24oImNoZWNrcG9pbnRMb2NhdGlvbiIsICIvcGF0aC90by9jaGVja3BvaW50Iikuc3RhcnQoKS5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col
from pyspark.sql.types import StructType, StructField, IntegerType

# Initialize Spark session
spark = SparkSession.builder.appName(&quot;RealTimeProcessing&quot;).getOrCreate()

# Define schema
schema = StructType([
    StructField(&quot;id&quot;, IntegerType(), True),
    StructField(&quot;value&quot;, IntegerType(), True)
])

# Read data from Kafka
df = spark.readStream.format(&quot;kafka&quot;).option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;).option(&quot;subscribe&quot;, &quot;data_topic&quot;).load()

# Parse JSON data
df_parsed = df.selectExpr(&quot;CAST(value AS STRING)&quot;).select(from_json(col(&quot;value&quot;), schema).alias(&quot;data&quot;)).select(&quot;data.*&quot;)

# Process data
df_processed = df_parsed.withColumn(&quot;processed_value&quot;, col(&quot;value&quot;) * 10)

# Write data to HDFS
df_processed.writeStream.format(&quot;parquet&quot;).option(&quot;path&quot;, &quot;/path/to/hdfs&quot;).option(&quot;checkpointLocation&quot;, &quot;/path/to/checkpoint&quot;).start().awaitTermination()</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>By completing these practical projects, you will gain valuable hands-on experience with Big Data technologies and practices. These projects will help you understand how to collect, process, analyze, and visualize large volumes of data in real-world scenarios. Additionally, you will learn how to implement real-time data processing pipelines, which are essential for modern data-driven applications.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-case-studies' title="Case Studies in Different Industries">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-apache-hadoop-ecosystem' title="Apache Hadoop Ecosystem">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
