<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unsupervised Learning</title>

    <link rel="alternate" href="https://campusempresa.com/mod/r/07-04-unsupervised-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/r/07-04-unsupervised-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/r/07-04-unsupervised-learning" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=2" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/r/07-04-unsupervised-learning" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/r/07-04-unsupervised-learning" class="px-2">CA</a>
<br>
			<cite>Building today's and tomorrow's society</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Programming Languages</a>
				 					<a href="/categ/frameworks">Frameworks and Libraries</a>
				 					<a href="/categ/tech-tools">Technical Tools</a>
				 					<a href="/categ/foundations">Theoretical Foundations</a>
				 					<a href="/categ/soft-skills">Social Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-03-supervised-learning' title="Supervised Learning">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Unsupervised Learning</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-05-model-evaluation-tuning' title="Model Evaluation and Tuning">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Unsupervised learning is a type of machine learning where the algorithm is trained on unlabeled data. The goal is to find hidden patterns or intrinsic structures in the input data. Unlike supervised learning, there are no predefined labels or outcomes to guide the learning process.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'><ol>
<li>
<p><strong>Clustering</strong>: Grouping a set of objects in such a way that objects in the same group (cluster) are more similar to each other than to those in other groups.</p>
<ul>
<li><strong>K-Means Clustering</strong></li>
<li><strong>Hierarchical Clustering</strong></li>
<li><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</strong></li>
</ul>
</li>
<li>
<p><strong>Dimensionality Reduction</strong>: Reducing the number of random variables under consideration by obtaining a set of principal variables.</p>
<ul>
<li><strong>Principal Component Analysis (PCA)</strong></li>
<li><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong></li>
<li><strong>Independent Component Analysis (ICA)</strong></li>
</ul>
</li>
<li>
<p><strong>Association Rule Learning</strong>: Discovering interesting relations between variables in large databases.</p>
<ul>
<li><strong>Apriori Algorithm</strong></li>
<li><strong>Eclat Algorithm</strong></li>
</ul>
</li>
</ol>
</div><h1><p>Practical Examples</p>
</h1>
<div class='content'></div><h2><p>K-Means Clustering</p>
</h2>
<div class='content'><p>K-Means is one of the simplest and most popular unsupervised learning algorithms. It partitions the data into K clusters, where each data point belongs to the cluster with the nearest mean.</p>
<h4>Example Code</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIG5lY2Vzc2FyeSBsaWJyYXJ5CmxpYnJhcnkoZ2dwbG90MikKCiMgR2VuZXJhdGUgc2FtcGxlIGRhdGEKc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApKQoKIyBBcHBseSBLLU1lYW5zIENsdXN0ZXJpbmcKc2V0LnNlZWQoMTIzKQprbWVhbnNfcmVzdWx0IDwtIGttZWFucyhkYXRhLCBjZW50ZXJzID0gMykKCiMgQWRkIGNsdXN0ZXIgcmVzdWx0cyB0byB0aGUgZGF0YQpkYXRhJGNsdXN0ZXIgPC0gYXMuZmFjdG9yKGttZWFuc19yZXN1bHQkY2x1c3RlcikKCiMgUGxvdCB0aGUgY2x1c3RlcnMKZ2dwbG90KGRhdGEsIGFlcyh4ID0geCwgeSA9IHksIGNvbG9yID0gY2x1c3RlcikpICsKICBnZW9tX3BvaW50KHNpemUgPSAzKSArCiAgbGFicyh0aXRsZSA9ICJLLU1lYW5zIENsdXN0ZXJpbmciLCB4ID0gIlgtYXhpcyIsIHkgPSAiWS1heGlzIik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load necessary library
library(ggplot2)

# Generate sample data
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100))

# Apply K-Means Clustering
set.seed(123)
kmeans_result &lt;- kmeans(data, centers = 3)

# Add cluster results to the data
data$cluster &lt;- as.factor(kmeans_result$cluster)

# Plot the clusters
ggplot(data, aes(x = x, y = y, color = cluster)) +
  geom_point(size = 3) +
  labs(title = &quot;K-Means Clustering&quot;, x = &quot;X-axis&quot;, y = &quot;Y-axis&quot;)</pre></div><div class='content'><h4>Explanation</h4>
<ol>
<li><strong>Data Generation</strong>: We generate a sample dataset with 100 points.</li>
<li><strong>K-Means Clustering</strong>: We apply the <code>kmeans</code> function to partition the data into 3 clusters.</li>
<li><strong>Visualization</strong>: We use <code>ggplot2</code> to visualize the clusters.</li>
</ol>
</div><h2><p>Principal Component Analysis (PCA)</p>
</h2>
<div class='content'><p>PCA is a technique used to emphasize variation and bring out strong patterns in a dataset. It reduces the dimensionality of the data while retaining most of the variation.</p>
<h4>Example Code</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIG5lY2Vzc2FyeSBsaWJyYXJ5CmxpYnJhcnkoZ2dwbG90MikKCiMgTG9hZCB0aGUgaXJpcyBkYXRhc2V0CmRhdGEoaXJpcykKCiMgQXBwbHkgUENBCnBjYV9yZXN1bHQgPC0gcHJjb21wKGlyaXNbLCAxOjRdLCBzY2FsZS4gPSBUUlVFKQoKIyBDcmVhdGUgYSBkYXRhIGZyYW1lIHdpdGggUENBIHJlc3VsdHMKcGNhX2RhdGEgPC0gZGF0YS5mcmFtZShwY2FfcmVzdWx0JHgsIFNwZWNpZXMgPSBpcmlzJFNwZWNpZXMpCgojIFBsb3QgdGhlIGZpcnN0IHR3byBwcmluY2lwYWwgY29tcG9uZW50cwpnZ3Bsb3QocGNhX2RhdGEsIGFlcyh4ID0gUEMxLCB5ID0gUEMyLCBjb2xvciA9IFNwZWNpZXMpKSArCiAgZ2VvbV9wb2ludChzaXplID0gMykgKwogIGxhYnModGl0bGUgPSAiUENBIG9mIElyaXMgRGF0YXNldCIsIHggPSAiUHJpbmNpcGFsIENvbXBvbmVudCAxIiwgeSA9ICJQcmluY2lwYWwgQ29tcG9uZW50IDIiKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load necessary library
library(ggplot2)

# Load the iris dataset
data(iris)

# Apply PCA
pca_result &lt;- prcomp(iris[, 1:4], scale. = TRUE)

# Create a data frame with PCA results
pca_data &lt;- data.frame(pca_result$x, Species = iris$Species)

# Plot the first two principal components
ggplot(pca_data, aes(x = PC1, y = PC2, color = Species)) +
  geom_point(size = 3) +
  labs(title = &quot;PCA of Iris Dataset&quot;, x = &quot;Principal Component 1&quot;, y = &quot;Principal Component 2&quot;)</pre></div><div class='content'><h4>Explanation</h4>
<ol>
<li><strong>Data Loading</strong>: We use the built-in <code>iris</code> dataset.</li>
<li><strong>PCA Application</strong>: We apply the <code>prcomp</code> function to perform PCA on the first four columns of the dataset.</li>
<li><strong>Visualization</strong>: We visualize the first two principal components using <code>ggplot2</code>.</li>
</ol>
</div><h1><p>Practical Exercises</p>
</h1>
<div class='content'></div><h2><p>Exercise 1: K-Means Clustering</p>
</h2>
<div class='content'><p><strong>Task</strong>: Apply K-Means clustering to the <code>mtcars</code> dataset and visualize the clusters.</p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Load the <code>mtcars</code> dataset.</li>
<li>Apply K-Means clustering with 4 clusters.</li>
<li>Visualize the clusters using <code>ggplot2</code>.</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIG5lY2Vzc2FyeSBsaWJyYXJ5CmxpYnJhcnkoZ2dwbG90MikKCiMgTG9hZCB0aGUgbXRjYXJzIGRhdGFzZXQKZGF0YShtdGNhcnMpCgojIEFwcGx5IEstTWVhbnMgQ2x1c3RlcmluZwpzZXQuc2VlZCgxMjMpCmttZWFuc19yZXN1bHQgPC0ga21lYW5zKG10Y2FycywgY2VudGVycyA9IDQpCgojIEFkZCBjbHVzdGVyIHJlc3VsdHMgdG8gdGhlIGRhdGEKbXRjYXJzJGNsdXN0ZXIgPC0gYXMuZmFjdG9yKGttZWFuc19yZXN1bHQkY2x1c3RlcikKCiMgUGxvdCB0aGUgY2x1c3RlcnMKZ2dwbG90KG10Y2FycywgYWVzKHggPSBtcGcsIHkgPSBocCwgY29sb3IgPSBjbHVzdGVyKSkgKwogIGdlb21fcG9pbnQoc2l6ZSA9IDMpICsKICBsYWJzKHRpdGxlID0gIkstTWVhbnMgQ2x1c3RlcmluZyBvbiBtdGNhcnMgRGF0YXNldCIsIHggPSAiTWlsZXMgUGVyIEdhbGxvbiAobXBnKSIsIHkgPSAiSG9yc2Vwb3dlciAoaHApIik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load necessary library
library(ggplot2)

# Load the mtcars dataset
data(mtcars)

# Apply K-Means Clustering
set.seed(123)
kmeans_result &lt;- kmeans(mtcars, centers = 4)

# Add cluster results to the data
mtcars$cluster &lt;- as.factor(kmeans_result$cluster)

# Plot the clusters
ggplot(mtcars, aes(x = mpg, y = hp, color = cluster)) +
  geom_point(size = 3) +
  labs(title = &quot;K-Means Clustering on mtcars Dataset&quot;, x = &quot;Miles Per Gallon (mpg)&quot;, y = &quot;Horsepower (hp)&quot;)</pre></div><div class='content'></div><h2><p>Exercise 2: PCA</p>
</h2>
<div class='content'><p><strong>Task</strong>: Perform PCA on the <code>mtcars</code> dataset and visualize the first two principal components.</p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Load the <code>mtcars</code> dataset.</li>
<li>Apply PCA.</li>
<li>Visualize the first two principal components using <code>ggplot2</code>.</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIG5lY2Vzc2FyeSBsaWJyYXJ5CmxpYnJhcnkoZ2dwbG90MikKCiMgTG9hZCB0aGUgbXRjYXJzIGRhdGFzZXQKZGF0YShtdGNhcnMpCgojIEFwcGx5IFBDQQpwY2FfcmVzdWx0IDwtIHByY29tcChtdGNhcnMsIHNjYWxlLiA9IFRSVUUpCgojIENyZWF0ZSBhIGRhdGEgZnJhbWUgd2l0aCBQQ0EgcmVzdWx0cwpwY2FfZGF0YSA8LSBkYXRhLmZyYW1lKHBjYV9yZXN1bHQkeCkKCiMgUGxvdCB0aGUgZmlyc3QgdHdvIHByaW5jaXBhbCBjb21wb25lbnRzCmdncGxvdChwY2FfZGF0YSwgYWVzKHggPSBQQzEsIHkgPSBQQzIpKSArCiAgZ2VvbV9wb2ludChzaXplID0gMykgKwogIGxhYnModGl0bGUgPSAiUENBIG9mIG10Y2FycyBEYXRhc2V0IiwgeCA9ICJQcmluY2lwYWwgQ29tcG9uZW50IDEiLCB5ID0gIlByaW5jaXBhbCBDb21wb25lbnQgMiIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load necessary library
library(ggplot2)

# Load the mtcars dataset
data(mtcars)

# Apply PCA
pca_result &lt;- prcomp(mtcars, scale. = TRUE)

# Create a data frame with PCA results
pca_data &lt;- data.frame(pca_result$x)

# Plot the first two principal components
ggplot(pca_data, aes(x = PC1, y = PC2)) +
  geom_point(size = 3) +
  labs(title = &quot;PCA of mtcars Dataset&quot;, x = &quot;Principal Component 1&quot;, y = &quot;Principal Component 2&quot;)</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Choosing the Number of Clusters</strong>: In K-Means clustering, choosing the right number of clusters (K) is crucial. Use methods like the Elbow Method or Silhouette Analysis to determine the optimal number of clusters.</li>
<li><strong>Scaling Data</strong>: Always scale your data before applying PCA or K-Means clustering to ensure that each feature contributes equally to the result.</li>
<li><strong>Interpreting PCA Results</strong>: PCA results can be tricky to interpret. Focus on the explained variance to understand how much information is retained in the principal components.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we explored the basics of unsupervised learning, focusing on clustering and dimensionality reduction techniques. We covered practical examples of K-Means clustering and PCA, and provided exercises to reinforce the concepts. Understanding these techniques is essential for uncovering hidden patterns in data and preparing for more advanced machine learning tasks.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-03-supervised-learning' title="Supervised Learning">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-05-model-evaluation-tuning' title="Model Evaluation and Tuning">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
