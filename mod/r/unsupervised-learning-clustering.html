<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unsupervised Learning: Clustering</title>

    <link rel="alternate" href="https://campusempresa.com/mod/r/unsupervised-learning-clustering" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/r/unsupervised-learning-clustering" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/r/unsupervised-learning-clustering" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/r/unsupervised-learning-clustering" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/r/unsupervised-learning-clustering" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='supervised-learning-classification'>&#x25C4;Supervised Learning: Classification</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Unsupervised Learning: Clustering</a>
	</div>
	<div class='col-4 text-end'>
					<a href='model-evaluation-and-tuning'>Model Evaluation and Tuning &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to Clustering</h1>
<div class='content'><p>Clustering is a type of unsupervised learning that involves grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar to each other than to those in other groups. Clustering is widely used in various fields such as data mining, pattern recognition, and image analysis.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Unsupervised Learning</strong>: Learning from data without labeled responses.</li>
<li><strong>Cluster</strong>: A collection of data points aggregated together because of certain similarities.</li>
<li><strong>Centroid</strong>: The center of a cluster.</li>
<li><strong>Distance Metrics</strong>: Methods to measure the similarity or dissimilarity between data points (e.g., Euclidean distance).</li>
</ul>
</div><h1>Types of Clustering Algorithms</h1>
<div class='content'><p>There are several clustering algorithms, each with its own strengths and weaknesses. Here, we will focus on two popular methods: K-Means and Hierarchical Clustering.</p>
</div><h2>K-Means Clustering</h2>
<div class='content'><p>K-Means is a partitioning method that divides the dataset into K clusters, where each cluster is represented by its centroid.</p>
<h4>Steps of K-Means Algorithm</h4>
<ol>
<li>Choose the number of clusters, K.</li>
<li>Initialize the centroids randomly.</li>
<li>Assign each data point to the nearest centroid.</li>
<li>Recalculate the centroids based on the assigned points.</li>
<li>Repeat steps 3 and 4 until convergence (i.e., the centroids no longer change).</li>
</ol>
<h4>Example Code</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIG5lY2Vzc2FyeSBsaWJyYXJ5CmxpYnJhcnkoZ2dwbG90MikKCiMgR2VuZXJhdGUgc2FtcGxlIGRhdGEKc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApKQoKIyBQZXJmb3JtIEstTWVhbnMgY2x1c3RlcmluZwprbWVhbnNfcmVzdWx0IDwtIGttZWFucyhkYXRhLCBjZW50ZXJzID0gMykKCiMgQWRkIGNsdXN0ZXIgYXNzaWdubWVudCB0byB0aGUgZGF0YQpkYXRhJGNsdXN0ZXIgPC0gYXMuZmFjdG9yKGttZWFuc19yZXN1bHQkY2x1c3RlcikKCiMgUGxvdCB0aGUgY2x1c3RlcnMKZ2dwbG90KGRhdGEsIGFlcyh4ID0geCwgeSA9IHksIGNvbG9yID0gY2x1c3RlcikpICsKICBnZW9tX3BvaW50KCkgKwogIGxhYnModGl0bGUgPSAiSy1NZWFucyBDbHVzdGVyaW5nIiwgeCA9ICJYLWF4aXMiLCB5ID0gIlktYXhpcyIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load necessary library
library(ggplot2)

# Generate sample data
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100))

# Perform K-Means clustering
kmeans_result &lt;- kmeans(data, centers = 3)

# Add cluster assignment to the data
data$cluster &lt;- as.factor(kmeans_result$cluster)

# Plot the clusters
ggplot(data, aes(x = x, y = y, color = cluster)) +
  geom_point() +
  labs(title = &quot;K-Means Clustering&quot;, x = &quot;X-axis&quot;, y = &quot;Y-axis&quot;)</pre></div><div class='content'></div><h2>Hierarchical Clustering</h2>
<div class='content'><p>Hierarchical clustering builds a tree of clusters. It can be either agglomerative (bottom-up) or divisive (top-down).</p>
<h4>Steps of Agglomerative Hierarchical Clustering</h4>
<ol>
<li>Start with each data point as its own cluster.</li>
<li>Merge the two closest clusters.</li>
<li>Repeat step 2 until only one cluster remains.</li>
</ol>
<h4>Example Code</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMb2FkIG5lY2Vzc2FyeSBsaWJyYXJ5CmxpYnJhcnkoZ2dwbG90MikKCiMgR2VuZXJhdGUgc2FtcGxlIGRhdGEKc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApKQoKIyBDb21wdXRlIHRoZSBkaXN0YW5jZSBtYXRyaXgKZGlzdF9tYXRyaXggPC0gZGlzdChkYXRhKQoKIyBQZXJmb3JtIGhpZXJhcmNoaWNhbCBjbHVzdGVyaW5nCmhjbHVzdF9yZXN1bHQgPC0gaGNsdXN0KGRpc3RfbWF0cml4LCBtZXRob2QgPSAiY29tcGxldGUiKQoKIyBDdXQgdGhlIHRyZWUgdG8gZm9ybSBjbHVzdGVycwpkYXRhJGNsdXN0ZXIgPC0gY3V0cmVlKGhjbHVzdF9yZXN1bHQsIGsgPSAzKQoKIyBQbG90IHRoZSBjbHVzdGVycwpnZ3Bsb3QoZGF0YSwgYWVzKHggPSB4LCB5ID0geSwgY29sb3IgPSBhcy5mYWN0b3IoY2x1c3RlcikpKSArCiAgZ2VvbV9wb2ludCgpICsKICBsYWJzKHRpdGxlID0gIkhpZXJhcmNoaWNhbCBDbHVzdGVyaW5nIiwgeCA9ICJYLWF4aXMiLCB5ID0gIlktYXhpcyIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Load necessary library
library(ggplot2)

# Generate sample data
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100))

# Compute the distance matrix
dist_matrix &lt;- dist(data)

# Perform hierarchical clustering
hclust_result &lt;- hclust(dist_matrix, method = &quot;complete&quot;)

# Cut the tree to form clusters
data$cluster &lt;- cutree(hclust_result, k = 3)

# Plot the clusters
ggplot(data, aes(x = x, y = y, color = as.factor(cluster))) +
  geom_point() +
  labs(title = &quot;Hierarchical Clustering&quot;, x = &quot;X-axis&quot;, y = &quot;Y-axis&quot;)</pre></div><div class='content'></div><h1>Comparing K-Means and Hierarchical Clustering</h1>
<div class='content'><p>| Feature                | K-Means                        | Hierarchical Clustering       |
|------------------------|--------------------------------|-------------------------------|
| Number of Clusters     | Must be specified in advance   | Can be determined by the dendrogram |
| Complexity             | O(n * K * I)                   | O(n^3)                        |
| Scalability            | Suitable for large datasets    | Suitable for smaller datasets |
| Cluster Shape          | Assumes spherical clusters     | Can find clusters of arbitrary shape |</p>
</div><h1>Practical Considerations</h1>
<div class='content'><ul>
<li><strong>Choosing the number of clusters</strong>: Methods like the Elbow Method or Silhouette Analysis can help determine the optimal number of clusters.</li>
<li><strong>Scaling data</strong>: Standardizing or normalizing data can improve clustering performance.</li>
<li><strong>Distance metrics</strong>: The choice of distance metric (e.g., Euclidean, Manhattan) can affect the clustering results.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>Clustering is a powerful tool in unsupervised learning for discovering patterns and structures in data. K-Means and Hierarchical Clustering are two widely used methods, each with its own advantages and limitations. Understanding these algorithms and their practical considerations will enable you to apply clustering effectively in various scenarios.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='supervised-learning-classification'>&#x25C4;Supervised Learning: Classification</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Unsupervised Learning: Clustering</a>
	</div>
	<div class='col-4 text-end'>
					<a href='model-evaluation-and-tuning'>Model Evaluation and Tuning &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
