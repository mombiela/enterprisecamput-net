<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Creating a Simple Neural Network</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/02-02-creating-simple-neural-network" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/02-02-creating-simple-neural-network" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/02-02-creating-simple-neural-network" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/pytorch/02-02-creating-simple-neural-network" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/pytorch/02-02-creating-simple-neural-network" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>All the knowledge within your reach</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					 				<a href="/"><i class="bi bi-house-fill"></i> HOME</a>
											</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-01-introduction-to-neural-networks' title="Introduction to Neural Networks">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Creating a Simple Neural Network</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='02-03-activation-functions' title="Activation Functions">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will learn how to create a simple neural network using PyTorch. We will cover the following steps:</p>
<ol>
<li><strong>Defining the Network Architecture</strong></li>
<li><strong>Initializing the Network</strong></li>
<li><strong>Forward Pass</strong></li>
<li><strong>Backward Pass and Optimization</strong></li>
</ol>
</div><h1><ol>
<li>Defining the Network Architecture</li>
</ol></h1>
<div class='content'><p>A neural network in PyTorch is defined by creating a class that inherits from <code>torch.nn.Module</code>. This class will contain the layers of the network and the forward pass logic.</p>
</div><h2>Example:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gubm4uZnVuY3Rpb25hbCBhcyBGCgpjbGFzcyBTaW1wbGVOZXVyYWxOZXR3b3JrKG5uLk1vZHVsZSk6CiAgICBkZWYgX19pbml0X18oc2VsZik6CiAgICAgICAgc3VwZXIoU2ltcGxlTmV1cmFsTmV0d29yaywgc2VsZikuX19pbml0X18oKQogICAgICAgICMgRGVmaW5lIGxheWVycwogICAgICAgIHNlbGYuZmMxID0gbm4uTGluZWFyKDc4NCwgMTI4KSAgIyBJbnB1dCBsYXllciB0byBoaWRkZW4gbGF5ZXIKICAgICAgICBzZWxmLmZjMiA9IG5uLkxpbmVhcigxMjgsIDY0KSAgICMgSGlkZGVuIGxheWVyIHRvIGFub3RoZXIgaGlkZGVuIGxheWVyCiAgICAgICAgc2VsZi5mYzMgPSBubi5MaW5lYXIoNjQsIDEwKSAgICAjIEhpZGRlbiBsYXllciB0byBvdXRwdXQgbGF5ZXIKCiAgICBkZWYgZm9yd2FyZChzZWxmLCB4KToKICAgICAgICAjIERlZmluZSBmb3J3YXJkIHBhc3MKICAgICAgICB4ID0gRi5yZWx1KHNlbGYuZmMxKHgpKSAgIyBBcHBseSBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgICAgICB4ID0gRi5yZWx1KHNlbGYuZmMyKHgpKSAgIyBBcHBseSBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgICAgICB4ID0gc2VsZi5mYzMoeCkgICAgICAgICAgIyBPdXRwdXQgbGF5ZXIKICAgICAgICByZXR1cm4geA=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleNeuralNetwork(nn.Module):
    def __init__(self):
        super(SimpleNeuralNetwork, self).__init__()
        # Define layers
        self.fc1 = nn.Linear(784, 128)  # Input layer to hidden layer
        self.fc2 = nn.Linear(128, 64)   # Hidden layer to another hidden layer
        self.fc3 = nn.Linear(64, 10)    # Hidden layer to output layer

    def forward(self, x):
        # Define forward pass
        x = F.relu(self.fc1(x))  # Apply ReLU activation function
        x = F.relu(self.fc2(x))  # Apply ReLU activation function
        x = self.fc3(x)          # Output layer
        return x</pre></div><div class='content'></div><h2>Explanation:</h2>
<div class='content'><ul>
<li><strong><code>__init__</code> Method</strong>: This method initializes the layers of the network. We use <code>nn.Linear</code> to create fully connected layers.</li>
<li><strong><code>forward</code> Method</strong>: This method defines the forward pass of the network. We use <code>F.relu</code> to apply the ReLU activation function to the outputs of the layers.</li>
</ul>
</div><h1><ol start="2">
<li>Initializing the Network</li>
</ol></h1>
<div class='content'><p>Once the network architecture is defined, we need to create an instance of the network.</p>
</div><h2>Example:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYW4gaW5zdGFuY2Ugb2YgdGhlIG5ldHdvcmsKbW9kZWwgPSBTaW1wbGVOZXVyYWxOZXR3b3JrKCkKcHJpbnQobW9kZWwp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create an instance of the network
model = SimpleNeuralNetwork()
print(model)</pre></div><div class='content'></div><h2>Explanation:</h2>
<div class='content'><ul>
<li><strong><code>model</code></strong>: This variable holds the instance of the <code>SimpleNeuralNetwork</code> class. Printing the model will display the architecture of the network.</li>
</ul>
</div><h1><ol start="3">
<li>Forward Pass</li>
</ol></h1>
<div class='content'><p>The forward pass involves passing input data through the network to get the output.</p>
</div><h2>Example:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYSByYW5kb20gdGVuc29yIHdpdGggc2hhcGUgKDEsIDc4NCkgdG8gc2ltdWxhdGUgYSBzaW5nbGUgaW5wdXQKaW5wdXRfZGF0YSA9IHRvcmNoLnJhbmRuKDEsIDc4NCkKCiMgUGVyZm9ybSBhIGZvcndhcmQgcGFzcwpvdXRwdXQgPSBtb2RlbChpbnB1dF9kYXRhKQpwcmludChvdXRwdXQp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create a random tensor with shape (1, 784) to simulate a single input
input_data = torch.randn(1, 784)

# Perform a forward pass
output = model(input_data)
print(output)</pre></div><div class='content'></div><h2>Explanation:</h2>
<div class='content'><ul>
<li><strong><code>input_data</code></strong>: This tensor simulates a single input to the network. The shape <code>(1, 784)</code> represents a batch size of 1 and 784 input features.</li>
<li><strong><code>output</code></strong>: This tensor contains the output of the network after the forward pass.</li>
</ul>
</div><h1><ol start="4">
<li>Backward Pass and Optimization</li>
</ol></h1>
<div class='content'><p>To train the network, we need to define a loss function and an optimizer. The backward pass involves computing the gradients and updating the weights.</p>
</div><h2>Example:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgojIERlZmluZSBhIGxvc3MgZnVuY3Rpb24KY3JpdGVyaW9uID0gbm4uQ3Jvc3NFbnRyb3B5TG9zcygpCgojIERlZmluZSBhbiBvcHRpbWl6ZXIKb3B0aW1pemVyID0gb3B0aW0uU0dEKG1vZGVsLnBhcmFtZXRlcnMoKSwgbHI9MC4wMSkKCiMgU2ltdWxhdGUgYSB0YXJnZXQgb3V0cHV0CnRhcmdldCA9IHRvcmNoLnRlbnNvcihbM10pICAjIEFzc3VtZSB0aGUgY29ycmVjdCBjbGFzcyBpcyAzCgojIFplcm8gdGhlIGdyYWRpZW50cwpvcHRpbWl6ZXIuemVyb19ncmFkKCkKCiMgUGVyZm9ybSBhIGZvcndhcmQgcGFzcwpvdXRwdXQgPSBtb2RlbChpbnB1dF9kYXRhKQoKIyBDb21wdXRlIHRoZSBsb3NzCmxvc3MgPSBjcml0ZXJpb24ob3V0cHV0LCB0YXJnZXQpCgojIFBlcmZvcm0gYSBiYWNrd2FyZCBwYXNzCmxvc3MuYmFja3dhcmQoKQoKIyBVcGRhdGUgdGhlIHdlaWdodHMKb3B0aW1pemVyLnN0ZXAoKQoKcHJpbnQoZidMb3NzOiB7bG9zcy5pdGVtKCl9Jyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

# Define a loss function
criterion = nn.CrossEntropyLoss()

# Define an optimizer
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Simulate a target output
target = torch.tensor([3])  # Assume the correct class is 3

# Zero the gradients
optimizer.zero_grad()

# Perform a forward pass
output = model(input_data)

# Compute the loss
loss = criterion(output, target)

# Perform a backward pass
loss.backward()

# Update the weights
optimizer.step()

print(f'Loss: {loss.item()}')</pre></div><div class='content'></div><h2>Explanation:</h2>
<div class='content'><ul>
<li><strong><code>criterion</code></strong>: This variable holds the loss function. We use <code>nn.CrossEntropyLoss</code> for classification tasks.</li>
<li><strong><code>optimizer</code></strong>: This variable holds the optimizer. We use stochastic gradient descent (SGD) with a learning rate of 0.01.</li>
<li><strong><code>target</code></strong>: This tensor contains the correct class for the input data.</li>
<li><strong><code>optimizer.zero_grad()</code></strong>: This method clears the gradients of all optimized tensors.</li>
<li><strong><code>loss.backward()</code></strong>: This method computes the gradient of the loss with respect to the network parameters.</li>
<li><strong><code>optimizer.step()</code></strong>: This method updates the network parameters based on the computed gradients.</li>
</ul>
</div><h1>Practical Exercise</h1>
<div class='content'></div><h2>Task:</h2>
<div class='content'><ol>
<li>
<p>Define a neural network with the following architecture:</p>
<ul>
<li>Input layer: 784 units</li>
<li>Hidden layer 1: 256 units, ReLU activation</li>
<li>Hidden layer 2: 128 units, ReLU activation</li>
<li>Output layer: 10 units</li>
</ul>
</li>
<li>
<p>Initialize the network and print its architecture.</p>
</li>
<li>
<p>Create a random input tensor with shape <code>(1, 784)</code> and perform a forward pass.</p>
</li>
<li>
<p>Define a loss function and an optimizer.</p>
</li>
<li>
<p>Simulate a target output and perform a backward pass and optimization step.</p>
</li>
</ol>
</div><h2>Solution:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gubm4uZnVuY3Rpb25hbCBhcyBGCmltcG9ydCB0b3JjaC5vcHRpbSBhcyBvcHRpbQoKY2xhc3MgQ3VzdG9tTmV1cmFsTmV0d29yayhubi5Nb2R1bGUpOgogICAgZGVmIF9faW5pdF9fKHNlbGYpOgogICAgICAgIHN1cGVyKEN1c3RvbU5ldXJhbE5ldHdvcmssIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmZjMSA9IG5uLkxpbmVhcig3ODQsIDI1NikKICAgICAgICBzZWxmLmZjMiA9IG5uLkxpbmVhcigyNTYsIDEyOCkKICAgICAgICBzZWxmLmZjMyA9IG5uLkxpbmVhcigxMjgsIDEwKQoKICAgIGRlZiBmb3J3YXJkKHNlbGYsIHgpOgogICAgICAgIHggPSBGLnJlbHUoc2VsZi5mYzEoeCkpCiAgICAgICAgeCA9IEYucmVsdShzZWxmLmZjMih4KSkKICAgICAgICB4ID0gc2VsZi5mYzMoeCkKICAgICAgICByZXR1cm4geAoKIyBJbml0aWFsaXplIHRoZSBuZXR3b3JrCm1vZGVsID0gQ3VzdG9tTmV1cmFsTmV0d29yaygpCnByaW50KG1vZGVsKQoKIyBDcmVhdGUgYSByYW5kb20gaW5wdXQgdGVuc29yCmlucHV0X2RhdGEgPSB0b3JjaC5yYW5kbigxLCA3ODQpCgojIFBlcmZvcm0gYSBmb3J3YXJkIHBhc3MKb3V0cHV0ID0gbW9kZWwoaW5wdXRfZGF0YSkKcHJpbnQob3V0cHV0KQoKIyBEZWZpbmUgYSBsb3NzIGZ1bmN0aW9uIGFuZCBhbiBvcHRpbWl6ZXIKY3JpdGVyaW9uID0gbm4uQ3Jvc3NFbnRyb3B5TG9zcygpCm9wdGltaXplciA9IG9wdGltLlNHRChtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEpCgojIFNpbXVsYXRlIGEgdGFyZ2V0IG91dHB1dAp0YXJnZXQgPSB0b3JjaC50ZW5zb3IoWzNdKQoKIyBaZXJvIHRoZSBncmFkaWVudHMKb3B0aW1pemVyLnplcm9fZ3JhZCgpCgojIENvbXB1dGUgdGhlIGxvc3MKbG9zcyA9IGNyaXRlcmlvbihvdXRwdXQsIHRhcmdldCkKCiMgUGVyZm9ybSBhIGJhY2t3YXJkIHBhc3MKbG9zcy5iYWNrd2FyZCgpCgojIFVwZGF0ZSB0aGUgd2VpZ2h0cwpvcHRpbWl6ZXIuc3RlcCgpCgpwcmludChmJ0xvc3M6IHtsb3NzLml0ZW0oKX0nKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

class CustomNeuralNetwork(nn.Module):
    def __init__(self):
        super(CustomNeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Initialize the network
model = CustomNeuralNetwork()
print(model)

# Create a random input tensor
input_data = torch.randn(1, 784)

# Perform a forward pass
output = model(input_data)
print(output)

# Define a loss function and an optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Simulate a target output
target = torch.tensor([3])

# Zero the gradients
optimizer.zero_grad()

# Compute the loss
loss = criterion(output, target)

# Perform a backward pass
loss.backward()

# Update the weights
optimizer.step()

print(f'Loss: {loss.item()}')</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this section, we learned how to create a simple neural network in PyTorch. We covered defining the network architecture, initializing the network, performing a forward pass, and executing the backward pass and optimization. These steps form the foundation for building and training more complex neural networks. In the next section, we will delve deeper into activation functions and their role in neural networks.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-01-introduction-to-neural-networks' title="Introduction to Neural Networks">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='02-03-activation-functions' title="Activation Functions">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			









		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
