<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Loading and Preprocessing</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/03-01-data-loading-preprocessing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/03-01-data-loading-preprocessing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/03-01-data-loading-preprocessing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/pytorch/03-01-data-loading-preprocessing" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/pytorch/03-01-data-loading-preprocessing" class="px-2">CA</a>
<br>
			<cite>Building today's and tomorrow's society</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Programming Languages</a>
				 					<a href="/categ/frameworks">Frameworks and Libraries</a>
				 					<a href="/categ/tech-tools">Technical Tools</a>
				 					<a href="/categ/foundations">Theoretical Foundations</a>
				 					<a href="/categ/soft-skills">Social Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-04-loss-functions-optimization' title="Loss Functions and Optimization">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Data Loading and Preprocessing</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-02-training-loop' title="Training Loop">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will cover the essential steps for loading and preprocessing data in PyTorch. Proper data handling is crucial for training effective neural networks. We will explore the following topics:</p>
<ol>
<li><strong>Introduction to Data Loading and Preprocessing</strong></li>
<li><strong>Using <code>torchvision</code> Datasets and Transforms</strong></li>
<li><strong>Creating Custom Datasets</strong></li>
<li><strong>DataLoader for Efficient Data Loading</strong></li>
<li><strong>Practical Example: Loading and Preprocessing CIFAR-10 Dataset</strong></li>
<li><strong>Exercises</strong></li>
</ol>
</div><h1><ol>
<li>Introduction to Data Loading and Preprocessing</li>
</ol>
</h1>
<div class='content'><p>Data loading and preprocessing are critical steps in the machine learning pipeline. They involve:</p>
<ul>
<li><strong>Loading</strong>: Reading data from files or databases.</li>
<li><strong>Preprocessing</strong>: Transforming raw data into a format suitable for training (e.g., normalization, augmentation).</li>
</ul>
</div><h1><ol start="2">
<li>Using <code>torchvision</code> Datasets and Transforms</li>
</ol>
</h1>
<div class='content'><p><code>torchvision</code> is a PyTorch package that provides popular datasets and common image transformations. It simplifies the process of loading and preprocessing image data.</p>
</div><h2><p>Example: Loading CIFAR-10 Dataset</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaHZpc2lvbgppbXBvcnQgdG9yY2h2aXNpb24udHJhbnNmb3JtcyBhcyB0cmFuc2Zvcm1zCgojIERlZmluZSBhIHRyYW5zZm9ybSB0byBub3JtYWxpemUgdGhlIGRhdGEKdHJhbnNmb3JtID0gdHJhbnNmb3Jtcy5Db21wb3NlKFsKICAgIHRyYW5zZm9ybXMuVG9UZW5zb3IoKSwKICAgIHRyYW5zZm9ybXMuTm9ybWFsaXplKCgwLjUsIDAuNSwgMC41KSwgKDAuNSwgMC41LCAwLjUpKQpdKQoKIyBEb3dubG9hZCBhbmQgbG9hZCB0aGUgdHJhaW5pbmcgZGF0YQp0cmFpbnNldCA9IHRvcmNodmlzaW9uLmRhdGFzZXRzLkNJRkFSMTAocm9vdD0nLi9kYXRhJywgdHJhaW49VHJ1ZSwgZG93bmxvYWQ9VHJ1ZSwgdHJhbnNmb3JtPXRyYW5zZm9ybSkKdHJhaW5sb2FkZXIgPSB0b3JjaC51dGlscy5kYXRhLkRhdGFMb2FkZXIodHJhaW5zZXQsIGJhdGNoX3NpemU9NCwgc2h1ZmZsZT1UcnVlLCBudW1fd29ya2Vycz0yKQoKIyBEb3dubG9hZCBhbmQgbG9hZCB0aGUgdGVzdCBkYXRhCnRlc3RzZXQgPSB0b3JjaHZpc2lvbi5kYXRhc2V0cy5DSUZBUjEwKHJvb3Q9Jy4vZGF0YScsIHRyYWluPUZhbHNlLCBkb3dubG9hZD1UcnVlLCB0cmFuc2Zvcm09dHJhbnNmb3JtKQp0ZXN0bG9hZGVyID0gdG9yY2gudXRpbHMuZGF0YS5EYXRhTG9hZGVyKHRlc3RzZXQsIGJhdGNoX3NpemU9NCwgc2h1ZmZsZT1GYWxzZSwgbnVtX3dvcmtlcnM9Mik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torchvision
import torchvision.transforms as transforms

# Define a transform to normalize the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Download and load the training data
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)

# Download and load the test data
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong>Transforms</strong>: We use <code>transforms.Compose</code> to chain multiple transformations. <code>transforms.ToTensor</code> converts images to PyTorch tensors, and <code>transforms.Normalize</code> normalizes the images.</li>
<li><strong>Datasets</strong>: <code>torchvision.datasets.CIFAR10</code> downloads the CIFAR-10 dataset and applies the specified transformations.</li>
<li><strong>DataLoader</strong>: <code>torch.utils.data.DataLoader</code> creates an iterable over the dataset, allowing for efficient data loading.</li>
</ul>
</div><h1><ol start="3">
<li>Creating Custom Datasets</li>
</ol>
</h1>
<div class='content'><p>Sometimes, you need to work with custom datasets. PyTorch provides the <code>torch.utils.data.Dataset</code> class, which you can subclass to create your own dataset.</p>
</div><h2><p>Example: Custom Dataset for Image Classification</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9zCmZyb20gUElMIGltcG9ydCBJbWFnZQpmcm9tIHRvcmNoLnV0aWxzLmRhdGEgaW1wb3J0IERhdGFzZXQKCmNsYXNzIEN1c3RvbUltYWdlRGF0YXNldChEYXRhc2V0KToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCBpbWdfZGlyLCB0cmFuc2Zvcm09Tm9uZSk6CiAgICAgICAgc2VsZi5pbWdfZGlyID0gaW1nX2RpcgogICAgICAgIHNlbGYudHJhbnNmb3JtID0gdHJhbnNmb3JtCiAgICAgICAgc2VsZi5pbWdfbGFiZWxzID0gWyhmLCAwKSBmb3IgZiBpbiBvcy5saXN0ZGlyKGltZ19kaXIpXSAgIyBEdW1teSBsYWJlbHMgZm9yIGV4YW1wbGUKCiAgICBkZWYgX19sZW5fXyhzZWxmKToKICAgICAgICByZXR1cm4gbGVuKHNlbGYuaW1nX2xhYmVscykKCiAgICBkZWYgX19nZXRpdGVtX18oc2VsZiwgaWR4KToKICAgICAgICBpbWdfcGF0aCA9IG9zLnBhdGguam9pbihzZWxmLmltZ19kaXIsIHNlbGYuaW1nX2xhYmVsc1tpZHhdWzBdKQogICAgICAgIGltYWdlID0gSW1hZ2Uub3BlbihpbWdfcGF0aCkKICAgICAgICBsYWJlbCA9IHNlbGYuaW1nX2xhYmVsc1tpZHhdWzFdCiAgICAgICAgaWYgc2VsZi50cmFuc2Zvcm06CiAgICAgICAgICAgIGltYWdlID0gc2VsZi50cmFuc2Zvcm0oaW1hZ2UpCiAgICAgICAgcmV0dXJuIGltYWdlLCBsYWJlbA=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import os
from PIL import Image
from torch.utils.data import Dataset

class CustomImageDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.img_labels = [(f, 0) for f in os.listdir(img_dir)]  # Dummy labels for example

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels[idx][0])
        image = Image.open(img_path)
        label = self.img_labels[idx][1]
        if self.transform:
            image = self.transform(image)
        return image, label</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong><code>__init__</code></strong>: Initializes the dataset with the directory of images and optional transformations.</li>
<li><strong><code>__len__</code></strong>: Returns the number of samples in the dataset.</li>
<li><strong><code>__getitem__</code></strong>: Loads and returns a sample from the dataset at the given index.</li>
</ul>
</div><h1><ol start="4">
<li>DataLoader for Efficient Data Loading</li>
</ol>
</h1>
<div class='content'><p>The <code>DataLoader</code> class provides an efficient way to load data in batches, shuffle data, and use multiple workers for parallel data loading.</p>
</div><h2><p>Example: Using DataLoader with Custom Dataset</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y3VzdG9tX2RhdGFzZXQgPSBDdXN0b21JbWFnZURhdGFzZXQoaW1nX2Rpcj0nLi9jdXN0b21fZGF0YScsIHRyYW5zZm9ybT10cmFuc2Zvcm0pCmN1c3RvbV9kYXRhbG9hZGVyID0gdG9yY2gudXRpbHMuZGF0YS5EYXRhTG9hZGVyKGN1c3RvbV9kYXRhc2V0LCBiYXRjaF9zaXplPTQsIHNodWZmbGU9VHJ1ZSwgbnVtX3dvcmtlcnM9Mik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>custom_dataset = CustomImageDataset(img_dir='./custom_data', transform=transform)
custom_dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=4, shuffle=True, num_workers=2)</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong>Batch Size</strong>: Number of samples per batch.</li>
<li><strong>Shuffle</strong>: Whether to shuffle the data at every epoch.</li>
<li><strong>Num Workers</strong>: Number of subprocesses to use for data loading.</li>
</ul>
</div><h1><ol start="5">
<li>Practical Example: Loading and Preprocessing CIFAR-10 Dataset</li>
</ol>
</h1>
<div class='content'><p>Let's put everything together and load the CIFAR-10 dataset, apply transformations, and create a DataLoader.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaHZpc2lvbgppbXBvcnQgdG9yY2h2aXNpb24udHJhbnNmb3JtcyBhcyB0cmFuc2Zvcm1zCgojIERlZmluZSB0cmFuc2Zvcm1hdGlvbnMKdHJhbnNmb3JtID0gdHJhbnNmb3Jtcy5Db21wb3NlKFsKICAgIHRyYW5zZm9ybXMuUmFuZG9tSG9yaXpvbnRhbEZsaXAoKSwKICAgIHRyYW5zZm9ybXMuUmFuZG9tQ3JvcCgzMiwgcGFkZGluZz00KSwKICAgIHRyYW5zZm9ybXMuVG9UZW5zb3IoKSwKICAgIHRyYW5zZm9ybXMuTm9ybWFsaXplKCgwLjUsIDAuNSwgMC41KSwgKDAuNSwgMC41LCAwLjUpKQpdKQoKIyBMb2FkIENJRkFSLTEwIGRhdGFzZXQKdHJhaW5zZXQgPSB0b3JjaHZpc2lvbi5kYXRhc2V0cy5DSUZBUjEwKHJvb3Q9Jy4vZGF0YScsIHRyYWluPVRydWUsIGRvd25sb2FkPVRydWUsIHRyYW5zZm9ybT10cmFuc2Zvcm0pCnRyYWlubG9hZGVyID0gdG9yY2gudXRpbHMuZGF0YS5EYXRhTG9hZGVyKHRyYWluc2V0LCBiYXRjaF9zaXplPTMyLCBzaHVmZmxlPVRydWUsIG51bV93b3JrZXJzPTIpCgp0ZXN0c2V0ID0gdG9yY2h2aXNpb24uZGF0YXNldHMuQ0lGQVIxMChyb290PScuL2RhdGEnLCB0cmFpbj1GYWxzZSwgZG93bmxvYWQ9VHJ1ZSwgdHJhbnNmb3JtPXRyYW5zZm9ybSkKdGVzdGxvYWRlciA9IHRvcmNoLnV0aWxzLmRhdGEuRGF0YUxvYWRlcih0ZXN0c2V0LCBiYXRjaF9zaXplPTMyLCBzaHVmZmxlPUZhbHNlLCBudW1fd29ya2Vycz0yKQoKIyBJdGVyYXRlIHRocm91Z2ggdGhlIGRhdGEKZGF0YWl0ZXIgPSBpdGVyKHRyYWlubG9hZGVyKQppbWFnZXMsIGxhYmVscyA9IGRhdGFpdGVyLm5leHQoKQoKcHJpbnQoaW1hZ2VzLnNoYXBlKSAgIyBPdXRwdXQ6IHRvcmNoLlNpemUoWzMyLCAzLCAzMiwgMzJdKQpwcmludChsYWJlbHMuc2hhcGUpICAjIE91dHB1dDogdG9yY2guU2l6ZShbMzJdKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torchvision
import torchvision.transforms as transforms

# Define transformations
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Load CIFAR-10 dataset
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)

# Iterate through the data
dataiter = iter(trainloader)
images, labels = dataiter.next()

print(images.shape)  # Output: torch.Size([32, 3, 32, 32])
print(labels.shape)  # Output: torch.Size([32])</pre></div><div class='content'></div><h2><p>Explanation:</p>
</h2>
<div class='content'><ul>
<li><strong>Transformations</strong>: Added <code>RandomHorizontalFlip</code> and <code>RandomCrop</code> for data augmentation.</li>
<li><strong>Batch Size</strong>: Increased to 32 for more efficient training.</li>
<li><strong>Data Iteration</strong>: Demonstrates how to iterate through the DataLoader and access batches of data.</li>
</ul>
</div><h1><ol start="6">
<li>Exercises</li>
</ol>
</h1>
<div class='content'></div><h2><p>Exercise 1: Load and Preprocess MNIST Dataset</p>
</h2>
<div class='content'><ol>
<li>Load the MNIST dataset using <code>torchvision.datasets.MNIST</code>.</li>
<li>Apply the following transformations:
<ul>
<li>Convert images to tensors.</li>
<li>Normalize images with mean 0.5 and standard deviation 0.5.</li>
</ul>
</li>
<li>Create a DataLoader with a batch size of 64.</li>
</ol>
</div><h2><p>Solution:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNodmlzaW9uLnRyYW5zZm9ybXMgYXMgdHJhbnNmb3JtcwppbXBvcnQgdG9yY2h2aXNpb24uZGF0YXNldHMgYXMgZGF0YXNldHMKZnJvbSB0b3JjaC51dGlscy5kYXRhIGltcG9ydCBEYXRhTG9hZGVyCgojIERlZmluZSB0cmFuc2Zvcm1hdGlvbnMKdHJhbnNmb3JtID0gdHJhbnNmb3Jtcy5Db21wb3NlKFsKICAgIHRyYW5zZm9ybXMuVG9UZW5zb3IoKSwKICAgIHRyYW5zZm9ybXMuTm9ybWFsaXplKCgwLjUsKSwgKDAuNSwpKQpdKQoKIyBMb2FkIE1OSVNUIGRhdGFzZXQKdHJhaW5zZXQgPSBkYXRhc2V0cy5NTklTVChyb290PScuL2RhdGEnLCB0cmFpbj1UcnVlLCBkb3dubG9hZD1UcnVlLCB0cmFuc2Zvcm09dHJhbnNmb3JtKQp0cmFpbmxvYWRlciA9IERhdGFMb2FkZXIodHJhaW5zZXQsIGJhdGNoX3NpemU9NjQsIHNodWZmbGU9VHJ1ZSwgbnVtX3dvcmtlcnM9MikKCnRlc3RzZXQgPSBkYXRhc2V0cy5NTklTVChyb290PScuL2RhdGEnLCB0cmFpbj1GYWxzZSwgZG93bmxvYWQ9VHJ1ZSwgdHJhbnNmb3JtPXRyYW5zZm9ybSkKdGVzdGxvYWRlciA9IERhdGFMb2FkZXIodGVzdHNldCwgYmF0Y2hfc2l6ZT02NCwgc2h1ZmZsZT1GYWxzZSwgbnVtX3dvcmtlcnM9Mik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader

# Define transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load MNIST dataset
trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)

testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)</pre></div><div class='content'></div><h2><p>Exercise 2: Create a Custom Dataset for Text Data</p>
</h2>
<div class='content'><ol>
<li>Create a custom dataset class for text data.</li>
<li>Implement the <code>__init__</code>, <code>__len__</code>, and <code>__getitem__</code> methods.</li>
<li>Use the dataset with a DataLoader.</li>
</ol>
</div><h2><p>Solution:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0b3JjaC51dGlscy5kYXRhIGltcG9ydCBEYXRhc2V0LCBEYXRhTG9hZGVyCgpjbGFzcyBDdXN0b21UZXh0RGF0YXNldChEYXRhc2V0KToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCB0ZXh0X2xpc3QsIHRyYW5zZm9ybT1Ob25lKToKICAgICAgICBzZWxmLnRleHRfbGlzdCA9IHRleHRfbGlzdAogICAgICAgIHNlbGYudHJhbnNmb3JtID0gdHJhbnNmb3JtCgogICAgZGVmIF9fbGVuX18oc2VsZik6CiAgICAgICAgcmV0dXJuIGxlbihzZWxmLnRleHRfbGlzdCkKCiAgICBkZWYgX19nZXRpdGVtX18oc2VsZiwgaWR4KToKICAgICAgICB0ZXh0ID0gc2VsZi50ZXh0X2xpc3RbaWR4XQogICAgICAgIGlmIHNlbGYudHJhbnNmb3JtOgogICAgICAgICAgICB0ZXh0ID0gc2VsZi50cmFuc2Zvcm0odGV4dCkKICAgICAgICByZXR1cm4gdGV4dAoKIyBFeGFtcGxlIHRleHQgZGF0YQp0ZXh0X2RhdGEgPSBbIkhlbGxvIHdvcmxkIiwgIlB5VG9yY2ggaXMgZ3JlYXQiLCAiRGF0YSBsb2FkaW5nIGFuZCBwcmVwcm9jZXNzaW5nIl0KCiMgQ3JlYXRlIGRhdGFzZXQgYW5kIGRhdGFsb2FkZXIKdGV4dF9kYXRhc2V0ID0gQ3VzdG9tVGV4dERhdGFzZXQodGV4dF9kYXRhKQp0ZXh0X2RhdGFsb2FkZXIgPSBEYXRhTG9hZGVyKHRleHRfZGF0YXNldCwgYmF0Y2hfc2l6ZT0yLCBzaHVmZmxlPVRydWUpCgojIEl0ZXJhdGUgdGhyb3VnaCB0aGUgZGF0YQpmb3IgYmF0Y2ggaW4gdGV4dF9kYXRhbG9hZGVyOgogICAgcHJpbnQoYmF0Y2gp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from torch.utils.data import Dataset, DataLoader

class CustomTextDataset(Dataset):
    def __init__(self, text_list, transform=None):
        self.text_list = text_list
        self.transform = transform

    def __len__(self):
        return len(self.text_list)

    def __getitem__(self, idx):
        text = self.text_list[idx]
        if self.transform:
            text = self.transform(text)
        return text

# Example text data
text_data = [&quot;Hello world&quot;, &quot;PyTorch is great&quot;, &quot;Data loading and preprocessing&quot;]

# Create dataset and dataloader
text_dataset = CustomTextDataset(text_data)
text_dataloader = DataLoader(text_dataset, batch_size=2, shuffle=True)

# Iterate through the data
for batch in text_dataloader:
    print(batch)</pre></div><div class='content'></div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we covered the basics of data loading and preprocessing in PyTorch. We explored how to use <code>torchvision</code> for common datasets and transformations, create custom datasets, and efficiently load data using <code>DataLoader</code>. These skills are essential for preparing data for training neural networks. In the next section, we will dive into the training loop, where we will use the data loaders to train our models.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-04-loss-functions-optimization' title="Loss Functions and Optimization">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-02-training-loop' title="Training Loop">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
