<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Natural Language Processing Project</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/07-02-nlp-project" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/07-02-nlp-project" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/07-02-nlp-project" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/pytorch/07-02-nlp-project" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/pytorch/07-02-nlp-project" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

			</div>
		</div>
	</div>
</div>

<!--  
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>
 -->				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-01-image-classification-project' title="Image Classification Project">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Natural Language Processing Project</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-03-time-series-forecasting-project' title="Time Series Forecasting Project">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>In this project, we will apply the concepts learned in previous modules to build a Natural Language Processing (NLP) model using PyTorch. The project will involve the following steps:</p>
<ol>
<li>Data Collection and Preprocessing</li>
<li>Building the NLP Model</li>
<li>Training the Model</li>
<li>Evaluating the Model</li>
<li>Making Predictions</li>
</ol>
</div><h1>Step 1: Data Collection and Preprocessing</h1>
<div class='content'></div><h2>1.1 Data Collection</h2>
<div class='content'><p>For this project, we will use the IMDb movie reviews dataset, which is a common dataset for sentiment analysis tasks. The dataset contains 50,000 movie reviews, split evenly into 25,000 training and 25,000 testing samples.</p>
</div><h2>1.2 Data Preprocessing</h2>
<div class='content'><p>Preprocessing steps include tokenization, padding, and converting text to numerical format.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmZyb20gdG9yY2h0ZXh0LmxlZ2FjeSBpbXBvcnQgZGF0YSwgZGF0YXNldHMKCiMgRGVmaW5lIHRoZSBmaWVsZHMgYXNzb2NpYXRlZCB3aXRoIHRoZSBzZXF1ZW5jZXMuClRFWFQgPSBkYXRhLkZpZWxkKHRva2VuaXplPSdzcGFjeScsIHRva2VuaXplcl9sYW5ndWFnZT0nZW5fY29yZV93ZWJfc20nLCBpbmNsdWRlX2xlbmd0aHM9VHJ1ZSkKTEFCRUwgPSBkYXRhLkxhYmVsRmllbGQoZHR5cGU9dG9yY2guZmxvYXQpCgojIExvYWQgdGhlIElNRGIgZGF0YXNldC4KdHJhaW5fZGF0YSwgdGVzdF9kYXRhID0gZGF0YXNldHMuSU1EQi5zcGxpdHMoVEVYVCwgTEFCRUwpCgojIEJ1aWxkIHRoZSB2b2NhYnVsYXJ5IHVzaW5nIHRoZSB0cmFpbmluZyBkYXRhLgpURVhULmJ1aWxkX3ZvY2FiKHRyYWluX2RhdGEsIG1heF9zaXplPTI1MDAwLCB2ZWN0b3JzPSJnbG92ZS42Qi4xMDBkIiwgdW5rX2luaXQ9dG9yY2guVGVuc29yLm5vcm1hbF8pCkxBQkVMLmJ1aWxkX3ZvY2FiKHRyYWluX2RhdGEpCgojIENyZWF0ZSBpdGVyYXRvcnMgZm9yIHRoZSBkYXRhLgpCQVRDSF9TSVpFID0gNjQKZGV2aWNlID0gdG9yY2guZGV2aWNlKCdjdWRhJyBpZiB0b3JjaC5jdWRhLmlzX2F2YWlsYWJsZSgpIGVsc2UgJ2NwdScpCgp0cmFpbl9pdGVyYXRvciwgdGVzdF9pdGVyYXRvciA9IGRhdGEuQnVja2V0SXRlcmF0b3Iuc3BsaXRzKAogICAgKHRyYWluX2RhdGEsIHRlc3RfZGF0YSksCiAgICBiYXRjaF9zaXplPUJBVENIX1NJWkUsCiAgICBzb3J0X3dpdGhpbl9iYXRjaD1UcnVlLAogICAgZGV2aWNlPWRldmljZQop"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
from torchtext.legacy import data, datasets

# Define the fields associated with the sequences.
TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True)
LABEL = data.LabelField(dtype=torch.float)

# Load the IMDb dataset.
train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)

# Build the vocabulary using the training data.
TEXT.build_vocab(train_data, max_size=25000, vectors=&quot;glove.6B.100d&quot;, unk_init=torch.Tensor.normal_)
LABEL.build_vocab(train_data)

# Create iterators for the data.
BATCH_SIZE = 64
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

train_iterator, test_iterator = data.BucketIterator.splits(
    (train_data, test_data),
    batch_size=BATCH_SIZE,
    sort_within_batch=True,
    device=device
)</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>Field</strong>: Defines how the data should be processed.</li>
<li><strong>datasets.IMDB</strong>: Loads the IMDb dataset.</li>
<li><strong>build_vocab</strong>: Builds the vocabulary and loads pre-trained word embeddings.</li>
<li><strong>BucketIterator</strong>: Creates iterators that return batches of data.</li>
</ul>
</div><h1>Step 2: Building the NLP Model</h1>
<div class='content'><p>We will build a simple LSTM-based model for sentiment analysis.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uIGFzIG5uCgpjbGFzcyBMU1RNTW9kZWwobm4uTW9kdWxlKToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCB2b2NhYl9zaXplLCBlbWJlZGRpbmdfZGltLCBoaWRkZW5fZGltLCBvdXRwdXRfZGltLCBuX2xheWVycywgYmlkaXJlY3Rpb25hbCwgZHJvcG91dCk6CiAgICAgICAgc3VwZXIoKS5fX2luaXRfXygpCiAgICAgICAgCiAgICAgICAgc2VsZi5lbWJlZGRpbmcgPSBubi5FbWJlZGRpbmcodm9jYWJfc2l6ZSwgZW1iZWRkaW5nX2RpbSkKICAgICAgICBzZWxmLmxzdG0gPSBubi5MU1RNKGVtYmVkZGluZ19kaW0sIGhpZGRlbl9kaW0sIG51bV9sYXllcnM9bl9sYXllcnMsIGJpZGlyZWN0aW9uYWw9YmlkaXJlY3Rpb25hbCwgZHJvcG91dD1kcm9wb3V0KQogICAgICAgIHNlbGYuZmMgPSBubi5MaW5lYXIoaGlkZGVuX2RpbSAqIDIgaWYgYmlkaXJlY3Rpb25hbCBlbHNlIGhpZGRlbl9kaW0sIG91dHB1dF9kaW0pCiAgICAgICAgc2VsZi5kcm9wb3V0ID0gbm4uRHJvcG91dChkcm9wb3V0KQogICAgICAgIAogICAgZGVmIGZvcndhcmQoc2VsZiwgdGV4dCwgdGV4dF9sZW5ndGhzKToKICAgICAgICBlbWJlZGRlZCA9IHNlbGYuZHJvcG91dChzZWxmLmVtYmVkZGluZyh0ZXh0KSkKICAgICAgICBwYWNrZWRfZW1iZWRkZWQgPSBubi51dGlscy5ybm4ucGFja19wYWRkZWRfc2VxdWVuY2UoZW1iZWRkZWQsIHRleHRfbGVuZ3RocykKICAgICAgICBwYWNrZWRfb3V0cHV0LCAoaGlkZGVuLCBjZWxsKSA9IHNlbGYubHN0bShwYWNrZWRfZW1iZWRkZWQpCiAgICAgICAgb3V0cHV0LCBvdXRwdXRfbGVuZ3RocyA9IG5uLnV0aWxzLnJubi5wYWRfcGFja2VkX3NlcXVlbmNlKHBhY2tlZF9vdXRwdXQpCiAgICAgICAgaGlkZGVuID0gc2VsZi5kcm9wb3V0KHRvcmNoLmNhdCgoaGlkZGVuWy0yLDosOl0sIGhpZGRlblstMSw6LDpdKSwgZGltPTEpKQogICAgICAgIHJldHVybiBzZWxmLmZjKGhpZGRlbik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn as nn

class LSTMModel(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):
        super().__init__()
        
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)
        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, text, text_lengths):
        embedded = self.dropout(self.embedding(text))
        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)
        packed_output, (hidden, cell) = self.lstm(packed_embedded)
        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)
        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))
        return self.fc(hidden)</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>Embedding</strong>: Converts words to dense vectors.</li>
<li><strong>LSTM</strong>: Processes the sequence of word vectors.</li>
<li><strong>Linear Layer</strong>: Maps the LSTM output to the desired output dimension.</li>
<li><strong>Dropout</strong>: Regularization to prevent overfitting.</li>
</ul>
</div><h1>Step 3: Training the Model</h1>
<div class='content'></div><h2>3.1 Define Training Parameters</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("SU5QVVRfRElNID0gbGVuKFRFWFQudm9jYWIpCkVNQkVERElOR19ESU0gPSAxMDAKSElEREVOX0RJTSA9IDI1NgpPVVRQVVRfRElNID0gMQpOX0xBWUVSUyA9IDIKQklESVJFQ1RJT05BTCA9IFRydWUKRFJPUE9VVCA9IDAuNQoKbW9kZWwgPSBMU1RNTW9kZWwoSU5QVVRfRElNLCBFTUJFRERJTkdfRElNLCBISURERU5fRElNLCBPVVRQVVRfRElNLCBOX0xBWUVSUywgQklESVJFQ1RJT05BTCwgRFJPUE9VVCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>INPUT_DIM = len(TEXT.vocab)
EMBEDDING_DIM = 100
HIDDEN_DIM = 256
OUTPUT_DIM = 1
N_LAYERS = 2
BIDIRECTIONAL = True
DROPOUT = 0.5

model = LSTMModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)</pre></div><div class='content'></div><h2>3.2 Define Optimizer and Loss Function</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgpvcHRpbWl6ZXIgPSBvcHRpbS5BZGFtKG1vZGVsLnBhcmFtZXRlcnMoKSkKY3JpdGVyaW9uID0gbm4uQkNFV2l0aExvZ2l0c0xvc3MoKQoKbW9kZWwgPSBtb2RlbC50byhkZXZpY2UpCmNyaXRlcmlvbiA9IGNyaXRlcmlvbi50byhkZXZpY2Up"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

optimizer = optim.Adam(model.parameters())
criterion = nn.BCEWithLogitsLoss()

model = model.to(device)
criterion = criterion.to(device)</pre></div><div class='content'></div><h2>3.3 Training Loop</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGJpbmFyeV9hY2N1cmFjeShwcmVkcywgeSk6CiAgICByb3VuZGVkX3ByZWRzID0gdG9yY2gucm91bmQodG9yY2guc2lnbW9pZChwcmVkcykpCiAgICBjb3JyZWN0ID0gKHJvdW5kZWRfcHJlZHMgPT0geSkuZmxvYXQoKQogICAgcmV0dXJuIGNvcnJlY3Quc3VtKCkgLyBsZW4oY29ycmVjdCkKCmRlZiB0cmFpbihtb2RlbCwgaXRlcmF0b3IsIG9wdGltaXplciwgY3JpdGVyaW9uKToKICAgIGVwb2NoX2xvc3MgPSAwCiAgICBlcG9jaF9hY2MgPSAwCiAgICBtb2RlbC50cmFpbigpCiAgICAKICAgIGZvciBiYXRjaCBpbiBpdGVyYXRvcjoKICAgICAgICBvcHRpbWl6ZXIuemVyb19ncmFkKCkKICAgICAgICB0ZXh0LCB0ZXh0X2xlbmd0aHMgPSBiYXRjaC50ZXh0CiAgICAgICAgcHJlZGljdGlvbnMgPSBtb2RlbCh0ZXh0LCB0ZXh0X2xlbmd0aHMpLnNxdWVlemUoMSkKICAgICAgICBsb3NzID0gY3JpdGVyaW9uKHByZWRpY3Rpb25zLCBiYXRjaC5sYWJlbCkKICAgICAgICBhY2MgPSBiaW5hcnlfYWNjdXJhY3kocHJlZGljdGlvbnMsIGJhdGNoLmxhYmVsKQogICAgICAgIGxvc3MuYmFja3dhcmQoKQogICAgICAgIG9wdGltaXplci5zdGVwKCkKICAgICAgICBlcG9jaF9sb3NzICs9IGxvc3MuaXRlbSgpCiAgICAgICAgZXBvY2hfYWNjICs9IGFjYy5pdGVtKCkKICAgICAgICAKICAgIHJldHVybiBlcG9jaF9sb3NzIC8gbGVuKGl0ZXJhdG9yKSwgZXBvY2hfYWNjIC8gbGVuKGl0ZXJhdG9yKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def binary_accuracy(preds, y):
    rounded_preds = torch.round(torch.sigmoid(preds))
    correct = (rounded_preds == y).float()
    return correct.sum() / len(correct)

def train(model, iterator, optimizer, criterion):
    epoch_loss = 0
    epoch_acc = 0
    model.train()
    
    for batch in iterator:
        optimizer.zero_grad()
        text, text_lengths = batch.text
        predictions = model(text, text_lengths).squeeze(1)
        loss = criterion(predictions, batch.label)
        acc = binary_accuracy(predictions, batch.label)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
        epoch_acc += acc.item()
        
    return epoch_loss / len(iterator), epoch_acc / len(iterator)</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>binary_accuracy</strong>: Computes the accuracy of the model.</li>
<li><strong>train</strong>: Trains the model for one epoch.</li>
</ul>
</div><h1>Step 4: Evaluating the Model</h1>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGV2YWx1YXRlKG1vZGVsLCBpdGVyYXRvciwgY3JpdGVyaW9uKToKICAgIGVwb2NoX2xvc3MgPSAwCiAgICBlcG9jaF9hY2MgPSAwCiAgICBtb2RlbC5ldmFsKCkKICAgIAogICAgd2l0aCB0b3JjaC5ub19ncmFkKCk6CiAgICAgICAgZm9yIGJhdGNoIGluIGl0ZXJhdG9yOgogICAgICAgICAgICB0ZXh0LCB0ZXh0X2xlbmd0aHMgPSBiYXRjaC50ZXh0CiAgICAgICAgICAgIHByZWRpY3Rpb25zID0gbW9kZWwodGV4dCwgdGV4dF9sZW5ndGhzKS5zcXVlZXplKDEpCiAgICAgICAgICAgIGxvc3MgPSBjcml0ZXJpb24ocHJlZGljdGlvbnMsIGJhdGNoLmxhYmVsKQogICAgICAgICAgICBhY2MgPSBiaW5hcnlfYWNjdXJhY3kocHJlZGljdGlvbnMsIGJhdGNoLmxhYmVsKQogICAgICAgICAgICBlcG9jaF9sb3NzICs9IGxvc3MuaXRlbSgpCiAgICAgICAgICAgIGVwb2NoX2FjYyArPSBhY2MuaXRlbSgpCiAgICAgICAgICAgIAogICAgcmV0dXJuIGVwb2NoX2xvc3MgLyBsZW4oaXRlcmF0b3IpLCBlcG9jaF9hY2MgLyBsZW4oaXRlcmF0b3Ip"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def evaluate(model, iterator, criterion):
    epoch_loss = 0
    epoch_acc = 0
    model.eval()
    
    with torch.no_grad():
        for batch in iterator:
            text, text_lengths = batch.text
            predictions = model(text, text_lengths).squeeze(1)
            loss = criterion(predictions, batch.label)
            acc = binary_accuracy(predictions, batch.label)
            epoch_loss += loss.item()
            epoch_acc += acc.item()
            
    return epoch_loss / len(iterator), epoch_acc / len(iterator)</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>evaluate</strong>: Evaluates the model on the validation/test set.</li>
</ul>
</div><h1>Step 5: Making Predictions</h1>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIHByZWRpY3Rfc2VudGltZW50KG1vZGVsLCBzZW50ZW5jZSwgbWluX2xlbj01KToKICAgIG1vZGVsLmV2YWwoKQogICAgdG9rZW5pemVkID0gW3Rvay50ZXh0IGZvciB0b2sgaW4gbmxwLnRva2VuaXplcihzZW50ZW5jZSldCiAgICBpZiBsZW4odG9rZW5pemVkKSA8IG1pbl9sZW46CiAgICAgICAgdG9rZW5pemVkICs9IFsnPHBhZD4nXSAqIChtaW5fbGVuIC0gbGVuKHRva2VuaXplZCkpCiAgICBpbmRleGVkID0gW1RFWFQudm9jYWIuc3RvaVt0XSBmb3IgdCBpbiB0b2tlbml6ZWRdCiAgICB0ZW5zb3IgPSB0b3JjaC5Mb25nVGVuc29yKGluZGV4ZWQpLnRvKGRldmljZSkKICAgIHRlbnNvciA9IHRlbnNvci51bnNxdWVlemUoMSkKICAgIGxlbmd0aF90ZW5zb3IgPSB0b3JjaC5Mb25nVGVuc29yKFtsZW4oaW5kZXhlZCldKQogICAgcHJlZGljdGlvbiA9IHRvcmNoLnNpZ21vaWQobW9kZWwodGVuc29yLCBsZW5ndGhfdGVuc29yKSkKICAgIHJldHVybiBwcmVkaWN0aW9uLml0ZW0oKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def predict_sentiment(model, sentence, min_len=5):
    model.eval()
    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]
    if len(tokenized) &lt; min_len:
        tokenized += ['&lt;pad&gt;'] * (min_len - len(tokenized))
    indexed = [TEXT.vocab.stoi[t] for t in tokenized]
    tensor = torch.LongTensor(indexed).to(device)
    tensor = tensor.unsqueeze(1)
    length_tensor = torch.LongTensor([len(indexed)])
    prediction = torch.sigmoid(model(tensor, length_tensor))
    return prediction.item()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ul>
<li><strong>predict_sentiment</strong>: Predicts the sentiment of a given sentence.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this project, we built an LSTM-based sentiment analysis model using PyTorch. We covered data collection and preprocessing, model building, training, evaluation, and making predictions. This project serves as a practical application of the concepts learned in the course and provides a foundation for more advanced NLP tasks.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-01-image-classification-project' title="Image Classification Project">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-03-time-series-forecasting-project' title="Time Series Forecasting Project">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>PyTorch: From Beginner to Advanced</h1>
<h2>Module 1: Introduction to PyTorch</h2>
<ul>
<li><a href="01-01-what-is-pytorch">What is PyTorch?</a></li>
<li><a href="01-02-setting-up-environment">Setting Up the Environment</a></li>
<li><a href="01-03-basic-tensor-operations">Basic Tensor Operations</a></li>
<li><a href="01-04-autograd">Autograd: Automatic Differentiation</a></li>
</ul>
<h2>Module 2: Building Neural Networks</h2>
<ul>
<li><a href="02-01-introduction-to-neural-networks">Introduction to Neural Networks</a></li>
<li><a href="02-02-creating-simple-neural-network">Creating a Simple Neural Network</a></li>
<li><a href="02-03-activation-functions">Activation Functions</a></li>
<li><a href="02-04-loss-functions-optimization">Loss Functions and Optimization</a></li>
</ul>
<h2>Module 3: Training Neural Networks</h2>
<ul>
<li><a href="03-01-data-loading-preprocessing">Data Loading and Preprocessing</a></li>
<li><a href="03-02-training-loop">Training Loop</a></li>
<li><a href="03-03-validation-testing">Validation and Testing</a></li>
<li><a href="03-04-saving-loading-models">Saving and Loading Models</a></li>
</ul>
<h2>Module 4: Convolutional Neural Networks (CNNs)</h2>
<ul>
<li><a href="04-01-introduction-to-cnns">Introduction to CNNs</a></li>
<li><a href="04-02-building-cnn-from-scratch">Building a CNN from Scratch</a></li>
<li><a href="04-03-transfer-learning">Transfer Learning with Pre-trained Models</a></li>
<li><a href="04-04-fine-tuning-cnns">Fine-Tuning CNNs</a></li>
</ul>
<h2>Module 5: Recurrent Neural Networks (RNNs)</h2>
<ul>
<li><a href="05-01-introduction-to-rnns">Introduction to RNNs</a></li>
<li><a href="05-02-building-rnn-from-scratch">Building an RNN from Scratch</a></li>
<li><a href="05-03-lstm-networks">Long Short-Term Memory (LSTM) Networks</a></li>
<li><a href="05-04-gru-networks">Gated Recurrent Units (GRUs)</a></li>
</ul>
<h2>Module 6: Advanced Topics</h2>
<ul>
<li><a href="06-01-gans">Generative Adversarial Networks (GANs)</a></li>
<li><a href="06-02-reinforcement-learning">Reinforcement Learning with PyTorch</a></li>
<li><a href="06-03-deploying-models">Deploying PyTorch Models</a></li>
<li><a href="06-04-optimizing-performance">Optimizing Performance</a></li>
</ul>
<h2>Module 7: Case Studies and Projects</h2>
<ul>
<li><a href="07-01-image-classification-project">Image Classification Project</a></li>
<li><a href="07-02-nlp-project">Natural Language Processing Project</a></li>
<li><a href="07-03-time-series-forecasting-project">Time Series Forecasting Project</a></li>
<li><a href="07-04-custom-project">Custom Project</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
