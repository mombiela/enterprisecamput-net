<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Spark and In-Memory Computing</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_distribuidas/05-02-spark-computacion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_distribuidas/05-02-spark-computacio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_distribuidas/05-02-spark-computing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/arquitecturas_distribuidas/05-02-spark-computacion" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/arquitecturas_distribuidas/05-02-spark-computacio" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Spark and In-Memory Computing</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-stream-processing' title="Data Stream Processing">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Apache Spark is an open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. Spark is known for its ability to process data in-memory, which significantly speeds up data processing tasks compared to traditional disk-based processing frameworks like Hadoop.</p>
</div><h1>Key Concepts of Spark and In-Memory Computing</h1>
<div class='content'></div><h2><ol>
<li>Introduction to Apache Spark</li>
</ol></h2>
<div class='content'><ul>
<li>
<p><strong>What is Apache Spark?</strong></p>
<ul>
<li>A unified analytics engine for large-scale data processing.</li>
<li>Provides high-level APIs in Java, Scala, Python, and R.</li>
<li>Supports general execution graphs and in-memory computing.</li>
</ul>
</li>
<li>
<p><strong>Core Components of Spark:</strong></p>
<ul>
<li><strong>Spark Core:</strong> The foundation of the Spark platform, responsible for basic I/O functions, task scheduling, and memory management.</li>
<li><strong>Spark SQL:</strong> Module for working with structured data using SQL queries.</li>
<li><strong>Spark Streaming:</strong> Enables scalable and fault-tolerant stream processing of live data streams.</li>
<li><strong>MLlib:</strong> Machine learning library that provides various algorithms and utilities.</li>
<li><strong>GraphX:</strong> API for graph processing and analysis.</li>
</ul>
</li>
</ul>
</div><h2><ol start="2">
<li>In-Memory Computing</li>
</ol></h2>
<div class='content'><ul>
<li>
<p><strong>Definition:</strong></p>
<ul>
<li>In-memory computing refers to the storage of data in the main memory (RAM) of the computing infrastructure rather than on traditional disk storage.</li>
</ul>
</li>
<li>
<p><strong>Advantages:</strong></p>
<ul>
<li><strong>Speed:</strong> Faster data processing as data is accessed from RAM.</li>
<li><strong>Efficiency:</strong> Reduces the need for I/O operations, leading to lower latency.</li>
<li><strong>Scalability:</strong> Can handle large datasets by distributing data across multiple nodes in a cluster.</li>
</ul>
</li>
</ul>
</div><h2><ol start="3">
<li>Resilient Distributed Datasets (RDDs)</li>
</ol></h2>
<div class='content'><ul>
<li>
<p><strong>What are RDDs?</strong></p>
<ul>
<li>Immutable distributed collections of objects.</li>
<li>Can be created by loading an external dataset or by transforming an existing RDD.</li>
</ul>
</li>
<li>
<p><strong>Key Properties:</strong></p>
<ul>
<li><strong>Immutability:</strong> Once created, RDDs cannot be altered.</li>
<li><strong>Fault Tolerance:</strong> RDDs can recover from node failures using lineage information.</li>
<li><strong>Lazy Evaluation:</strong> Transformations on RDDs are not executed until an action is called.</li>
</ul>
</li>
</ul>
</div><h2><ol start="4">
<li>DataFrames and Datasets</li>
</ol></h2>
<div class='content'><ul>
<li>
<p><strong>DataFrames:</strong></p>
<ul>
<li>Distributed collections of data organized into named columns.</li>
<li>Similar to a table in a relational database or a data frame in R/Python.</li>
</ul>
</li>
<li>
<p><strong>Datasets:</strong></p>
<ul>
<li>Strongly-typed, distributed collections of data.</li>
<li>Provides the benefits of RDDs (type-safety, object-oriented programming) with the optimization benefits of DataFrames.</li>
</ul>
</li>
</ul>
</div><h1>Practical Examples</h1>
<div class='content'></div><h2>Example 1: Creating an RDD</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgSW5pdGlhbGl6ZSBTcGFya0NvbnRleHQKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsIiwgIlJERCBFeGFtcGxlIikKCiMgQ3JlYXRlIGFuIFJERCBmcm9tIGEgbGlzdApkYXRhID0gWzEsIDIsIDMsIDQsIDVdCnJkZCA9IHNjLnBhcmFsbGVsaXplKGRhdGEpCgojIFBlcmZvcm0gYSB0cmFuc2Zvcm1hdGlvbiAobWFwKSBhbmQgYW4gYWN0aW9uIChjb2xsZWN0KQpzcXVhcmVkX3JkZCA9IHJkZC5tYXAobGFtYmRhIHg6IHggKiB4KQpyZXN1bHQgPSBzcXVhcmVkX3JkZC5jb2xsZWN0KCkKCnByaW50KHJlc3VsdCkgICMgT3V0cHV0OiBbMSwgNCwgOSwgMTYsIDI1XQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Initialize SparkContext
sc = SparkContext(&quot;local&quot;, &quot;RDD Example&quot;)

# Create an RDD from a list
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Perform a transformation (map) and an action (collect)
squared_rdd = rdd.map(lambda x: x * x)
result = squared_rdd.collect()

print(result)  # Output: [1, 4, 9, 16, 25]</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>SparkContext</code> is initialized to create an RDD.</li>
<li><code>parallelize</code> method is used to create an RDD from a list.</li>
<li><code>map</code> transformation is applied to square each element.</li>
<li><code>collect</code> action is used to retrieve the results.</li>
</ul>
</div><h2>Example 2: Working with DataFrames</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaXRpYWxpemUgU3BhcmtTZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiRGF0YUZyYW1lIEV4YW1wbGUiKS5nZXRPckNyZWF0ZSgpCgojIENyZWF0ZSBhIERhdGFGcmFtZSBmcm9tIGEgbGlzdCBvZiB0dXBsZXMKZGF0YSA9IFsoIkFsaWNlIiwgMzQpLCAoIkJvYiIsIDQ1KSwgKCJDYXRoeSIsIDI5KV0KY29sdW1ucyA9IFsiTmFtZSIsICJBZ2UiXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBjb2x1bW5zKQoKIyBTaG93IHRoZSBEYXRhRnJhbWUKZGYuc2hvdygpCgojIFBlcmZvcm0gYSBTUUwgcXVlcnkKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnJlc3VsdCA9IHNwYXJrLnNxbCgiU0VMRUNUIE5hbWUsIEFnZSBGUk9NIHBlb3BsZSBXSEVSRSBBZ2UgPiAzMCIpCnJlc3VsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Initialize SparkSession
spark = SparkSession.builder.appName(&quot;DataFrame Example&quot;).getOrCreate()

# Create a DataFrame from a list of tuples
data = [(&quot;Alice&quot;, 34), (&quot;Bob&quot;, 45), (&quot;Cathy&quot;, 29)]
columns = [&quot;Name&quot;, &quot;Age&quot;]
df = spark.createDataFrame(data, columns)

# Show the DataFrame
df.show()

# Perform a SQL query
df.createOrReplaceTempView(&quot;people&quot;)
result = spark.sql(&quot;SELECT Name, Age FROM people WHERE Age &gt; 30&quot;)
result.show()</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>SparkSession</code> is initialized to create a DataFrame.</li>
<li>A DataFrame is created from a list of tuples with specified column names.</li>
<li><code>show</code> method displays the DataFrame.</li>
<li>A SQL query is executed on the DataFrame using <code>createOrReplaceTempView</code> and <code>sql</code> methods.</li>
</ul>
</div><h1>Practical Exercises</h1>
<div class='content'></div><h2>Exercise 1: Basic RDD Operations</h2>
<div class='content'><p>Create an RDD from a list of numbers and perform the following operations:</p>
<ol>
<li>Filter out even numbers.</li>
<li>Multiply each remaining number by 10.</li>
<li>Collect and print the results.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJFeGVyY2lzZSAxIikKCmRhdGEgPSBbMSwgMiwgMywgNCwgNSwgNiwgNywgOCwgOSwgMTBdCnJkZCA9IHNjLnBhcmFsbGVsaXplKGRhdGEpCgpmaWx0ZXJlZF9yZGQgPSByZGQuZmlsdGVyKGxhbWJkYSB4OiB4ICUgMiAhPSAwKQptdWx0aXBsaWVkX3JkZCA9IGZpbHRlcmVkX3JkZC5tYXAobGFtYmRhIHg6IHggKiAxMCkKcmVzdWx0ID0gbXVsdGlwbGllZF9yZGQuY29sbGVjdCgpCgpwcmludChyZXN1bHQpICAjIE91dHB1dDogWzEwLCAzMCwgNTAsIDcwLCA5MF0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

sc = SparkContext(&quot;local&quot;, &quot;Exercise 1&quot;)

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
rdd = sc.parallelize(data)

filtered_rdd = rdd.filter(lambda x: x % 2 != 0)
multiplied_rdd = filtered_rdd.map(lambda x: x * 10)
result = multiplied_rdd.collect()

print(result)  # Output: [10, 30, 50, 70, 90]</pre></div><div class='content'></div><h2>Exercise 2: DataFrame Operations</h2>
<div class='content'><p>Create a DataFrame from a list of dictionaries containing employee data (name, age, department). Perform the following operations:</p>
<ol>
<li>Filter employees older than 30.</li>
<li>Select only the name and department columns.</li>
<li>Show the results.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIkV4ZXJjaXNlIDIiKS5nZXRPckNyZWF0ZSgpCgpkYXRhID0gWwogICAgeyJuYW1lIjogIkFsaWNlIiwgImFnZSI6IDM0LCAiZGVwYXJ0bWVudCI6ICJIUiJ9LAogICAgeyJuYW1lIjogIkJvYiIsICJhZ2UiOiA0NSwgImRlcGFydG1lbnQiOiAiRW5naW5lZXJpbmcifSwKICAgIHsibmFtZSI6ICJDYXRoeSIsICJhZ2UiOiAyOSwgImRlcGFydG1lbnQiOiAiTWFya2V0aW5nIn0KXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhKQoKZmlsdGVyZWRfZGYgPSBkZi5maWx0ZXIoZGYuYWdlID4gMzApCnNlbGVjdGVkX2RmID0gZmlsdGVyZWRfZGYuc2VsZWN0KCJuYW1lIiwgImRlcGFydG1lbnQiKQpzZWxlY3RlZF9kZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Exercise 2&quot;).getOrCreate()

data = [
    {&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 34, &quot;department&quot;: &quot;HR&quot;},
    {&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 45, &quot;department&quot;: &quot;Engineering&quot;},
    {&quot;name&quot;: &quot;Cathy&quot;, &quot;age&quot;: 29, &quot;department&quot;: &quot;Marketing&quot;}
]
df = spark.createDataFrame(data)

filtered_df = df.filter(df.age &gt; 30)
selected_df = filtered_df.select(&quot;name&quot;, &quot;department&quot;)
selected_df.show()</pre></div><div class='content'></div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Lazy Evaluation:</strong> Remember that transformations in Spark are lazily evaluated. Actions trigger the execution of transformations.</li>
<li><strong>Memory Management:</strong> Be mindful of the memory usage when working with large datasets. Use appropriate partitioning and caching strategies.</li>
<li><strong>DataFrame vs. RDD:</strong> Use DataFrames and Datasets for most applications due to their optimization benefits. Use RDDs when you need low-level transformations and actions.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we explored the basics of Apache Spark and in-memory computing. We covered key concepts such as RDDs, DataFrames, and Datasets, and provided practical examples and exercises to reinforce the learning. Understanding these concepts is crucial for efficiently processing large-scale data in a distributed environment. In the next section, we will delve into data stream processing, which is another critical aspect of distributed computing.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-stream-processing' title="Data Stream Processing">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Distributed Architectures Course</h1>
<h2>Module 1: Introduction to Distributed Systems</h2>
<ul>
<li><a href="01-01-basic-concepts">Basic Concepts of Distributed Systems</a></li>
<li><a href="01-02-system-models">Models of Distributed Systems</a></li>
<li><a href="01-03-advantages-challenges">Advantages and Challenges of Distributed Systems</a></li>
</ul>
<h2>Module 2: Communication in Distributed Systems</h2>
<ul>
<li><a href="02-01-communication-protocols">Communication Protocols</a></li>
<li><a href="02-02-rpc-rmi">RPC and RMI</a></li>
<li><a href="02-03-messaging-queues">Messaging and Message Queues</a></li>
</ul>
<h2>Module 3: Consistency and Replication</h2>
<ul>
<li><a href="03-01-consistency-models">Consistency Models</a></li>
<li><a href="03-02-consensus-algorithms">Consensus Algorithms</a></li>
<li><a href="03-03-data-replication">Data Replication</a></li>
</ul>
<h2>Module 4: Distributed Storage</h2>
<ul>
<li><a href="04-01-file-systems">Distributed File Systems</a></li>
<li><a href="04-02-databases">Distributed Databases</a></li>
<li><a href="04-03-caches">Distributed Caches</a></li>
</ul>
<h2>Module 5: Distributed Computing</h2>
<ul>
<li><a href="05-01-mapreduce-hadoop">MapReduce and Hadoop</a></li>
<li><a href="05-02-spark-computing">Spark and In-Memory Computing</a></li>
<li><a href="05-03-stream-processing">Data Stream Processing</a></li>
</ul>
<h2>Module 6: Security in Distributed Systems</h2>
<ul>
<li><a href="06-01-authentication-authorization">Authentication and Authorization</a></li>
<li><a href="06-02-encryption-protection">Encryption and Data Protection</a></li>
<li><a href="06-03-identity-management">Identity Management</a></li>
</ul>
<h2>Module 7: Monitoring and Maintenance</h2>
<ul>
<li><a href="07-01-system-monitoring">Monitoring Distributed Systems</a></li>
<li><a href="07-02-fault-management">Fault Management and Recovery</a></li>
<li><a href="07-03-automation-orchestration">Automation and Orchestration</a></li>
</ul>
<h2>Module 8: Case Studies and Applications</h2>
<ul>
<li><a href="08-01-microservices-architectures">Microservices Architectures</a></li>
<li><a href="08-02-messaging-systems">Real-Time Messaging Systems</a></li>
<li><a href="08-03-cloud-applications">Cloud Applications</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
