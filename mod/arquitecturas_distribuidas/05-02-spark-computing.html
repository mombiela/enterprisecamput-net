<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark and In-Memory Computing</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_distribuidas/05-02-spark-computacion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_distribuidas/05-02-spark-computacio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_distribuidas/05-02-spark-computing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/arquitecturas_distribuidas/05-02-spark-computacion" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/arquitecturas_distribuidas/05-02-spark-computacio" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Spark and In-Memory Computing</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-03-stream-processing' title="Data Stream Processing">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Apache Spark is an open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. Spark is known for its ability to process data in-memory, which significantly speeds up data processing tasks compared to traditional disk-based processing frameworks like Hadoop.</p>
</div><h1>Key Concepts of Spark and In-Memory Computing</h1>
<div class='content'></div><h2>1. Introduction to Apache Spark</h2>
<div class='content'><ul>
<li>
<p><strong>What is Apache Spark?</strong></p>
<ul>
<li>A unified analytics engine for large-scale data processing.</li>
<li>Provides high-level APIs in Java, Scala, Python, and R.</li>
<li>Supports general execution graphs and in-memory computing.</li>
</ul>
</li>
<li>
<p><strong>Core Components of Spark:</strong></p>
<ul>
<li><strong>Spark Core:</strong> The foundation of the Spark platform, responsible for basic I/O functions, task scheduling, and memory management.</li>
<li><strong>Spark SQL:</strong> Module for working with structured data using SQL queries.</li>
<li><strong>Spark Streaming:</strong> Enables scalable and fault-tolerant stream processing of live data streams.</li>
<li><strong>MLlib:</strong> Machine learning library that provides various algorithms and utilities.</li>
<li><strong>GraphX:</strong> API for graph processing and analysis.</li>
</ul>
</li>
</ul>
</div><h2>2. In-Memory Computing</h2>
<div class='content'><ul>
<li>
<p><strong>Definition:</strong></p>
<ul>
<li>In-memory computing refers to the storage of data in the main memory (RAM) of the computing infrastructure rather than on traditional disk storage.</li>
</ul>
</li>
<li>
<p><strong>Advantages:</strong></p>
<ul>
<li><strong>Speed:</strong> Faster data processing as data is accessed from RAM.</li>
<li><strong>Efficiency:</strong> Reduces the need for I/O operations, leading to lower latency.</li>
<li><strong>Scalability:</strong> Can handle large datasets by distributing data across multiple nodes in a cluster.</li>
</ul>
</li>
</ul>
</div><h2>3. Resilient Distributed Datasets (RDDs)</h2>
<div class='content'><ul>
<li>
<p><strong>What are RDDs?</strong></p>
<ul>
<li>Immutable distributed collections of objects.</li>
<li>Can be created by loading an external dataset or by transforming an existing RDD.</li>
</ul>
</li>
<li>
<p><strong>Key Properties:</strong></p>
<ul>
<li><strong>Immutability:</strong> Once created, RDDs cannot be altered.</li>
<li><strong>Fault Tolerance:</strong> RDDs can recover from node failures using lineage information.</li>
<li><strong>Lazy Evaluation:</strong> Transformations on RDDs are not executed until an action is called.</li>
</ul>
</li>
</ul>
</div><h2>4. DataFrames and Datasets</h2>
<div class='content'><ul>
<li>
<p><strong>DataFrames:</strong></p>
<ul>
<li>Distributed collections of data organized into named columns.</li>
<li>Similar to a table in a relational database or a data frame in R/Python.</li>
</ul>
</li>
<li>
<p><strong>Datasets:</strong></p>
<ul>
<li>Strongly-typed, distributed collections of data.</li>
<li>Provides the benefits of RDDs (type-safety, object-oriented programming) with the optimization benefits of DataFrames.</li>
</ul>
</li>
</ul>
</div><h1>Practical Examples</h1>
<div class='content'></div><h2>Example 1: Creating an RDD</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgSW5pdGlhbGl6ZSBTcGFya0NvbnRleHQKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsIiwgIlJERCBFeGFtcGxlIikKCiMgQ3JlYXRlIGFuIFJERCBmcm9tIGEgbGlzdApkYXRhID0gWzEsIDIsIDMsIDQsIDVdCnJkZCA9IHNjLnBhcmFsbGVsaXplKGRhdGEpCgojIFBlcmZvcm0gYSB0cmFuc2Zvcm1hdGlvbiAobWFwKSBhbmQgYW4gYWN0aW9uIChjb2xsZWN0KQpzcXVhcmVkX3JkZCA9IHJkZC5tYXAobGFtYmRhIHg6IHggKiB4KQpyZXN1bHQgPSBzcXVhcmVkX3JkZC5jb2xsZWN0KCkKCnByaW50KHJlc3VsdCkgICMgT3V0cHV0OiBbMSwgNCwgOSwgMTYsIDI1XQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Initialize SparkContext
sc = SparkContext(&quot;local&quot;, &quot;RDD Example&quot;)

# Create an RDD from a list
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Perform a transformation (map) and an action (collect)
squared_rdd = rdd.map(lambda x: x * x)
result = squared_rdd.collect()

print(result)  # Output: [1, 4, 9, 16, 25]</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>SparkContext</code> is initialized to create an RDD.</li>
<li><code>parallelize</code> method is used to create an RDD from a list.</li>
<li><code>map</code> transformation is applied to square each element.</li>
<li><code>collect</code> action is used to retrieve the results.</li>
</ul>
</div><h2>Example 2: Working with DataFrames</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaXRpYWxpemUgU3BhcmtTZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiRGF0YUZyYW1lIEV4YW1wbGUiKS5nZXRPckNyZWF0ZSgpCgojIENyZWF0ZSBhIERhdGFGcmFtZSBmcm9tIGEgbGlzdCBvZiB0dXBsZXMKZGF0YSA9IFsoIkFsaWNlIiwgMzQpLCAoIkJvYiIsIDQ1KSwgKCJDYXRoeSIsIDI5KV0KY29sdW1ucyA9IFsiTmFtZSIsICJBZ2UiXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBjb2x1bW5zKQoKIyBTaG93IHRoZSBEYXRhRnJhbWUKZGYuc2hvdygpCgojIFBlcmZvcm0gYSBTUUwgcXVlcnkKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnJlc3VsdCA9IHNwYXJrLnNxbCgiU0VMRUNUIE5hbWUsIEFnZSBGUk9NIHBlb3BsZSBXSEVSRSBBZ2UgPiAzMCIpCnJlc3VsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Initialize SparkSession
spark = SparkSession.builder.appName(&quot;DataFrame Example&quot;).getOrCreate()

# Create a DataFrame from a list of tuples
data = [(&quot;Alice&quot;, 34), (&quot;Bob&quot;, 45), (&quot;Cathy&quot;, 29)]
columns = [&quot;Name&quot;, &quot;Age&quot;]
df = spark.createDataFrame(data, columns)

# Show the DataFrame
df.show()

# Perform a SQL query
df.createOrReplaceTempView(&quot;people&quot;)
result = spark.sql(&quot;SELECT Name, Age FROM people WHERE Age &gt; 30&quot;)
result.show()</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>SparkSession</code> is initialized to create a DataFrame.</li>
<li>A DataFrame is created from a list of tuples with specified column names.</li>
<li><code>show</code> method displays the DataFrame.</li>
<li>A SQL query is executed on the DataFrame using <code>createOrReplaceTempView</code> and <code>sql</code> methods.</li>
</ul>
</div><h1>Practical Exercises</h1>
<div class='content'></div><h2>Exercise 1: Basic RDD Operations</h2>
<div class='content'><p>Create an RDD from a list of numbers and perform the following operations:</p>
<ol>
<li>Filter out even numbers.</li>
<li>Multiply each remaining number by 10.</li>
<li>Collect and print the results.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJFeGVyY2lzZSAxIikKCmRhdGEgPSBbMSwgMiwgMywgNCwgNSwgNiwgNywgOCwgOSwgMTBdCnJkZCA9IHNjLnBhcmFsbGVsaXplKGRhdGEpCgpmaWx0ZXJlZF9yZGQgPSByZGQuZmlsdGVyKGxhbWJkYSB4OiB4ICUgMiAhPSAwKQptdWx0aXBsaWVkX3JkZCA9IGZpbHRlcmVkX3JkZC5tYXAobGFtYmRhIHg6IHggKiAxMCkKcmVzdWx0ID0gbXVsdGlwbGllZF9yZGQuY29sbGVjdCgpCgpwcmludChyZXN1bHQpICAjIE91dHB1dDogWzEwLCAzMCwgNTAsIDcwLCA5MF0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

sc = SparkContext(&quot;local&quot;, &quot;Exercise 1&quot;)

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
rdd = sc.parallelize(data)

filtered_rdd = rdd.filter(lambda x: x % 2 != 0)
multiplied_rdd = filtered_rdd.map(lambda x: x * 10)
result = multiplied_rdd.collect()

print(result)  # Output: [10, 30, 50, 70, 90]</pre></div><div class='content'></div><h2>Exercise 2: DataFrame Operations</h2>
<div class='content'><p>Create a DataFrame from a list of dictionaries containing employee data (name, age, department). Perform the following operations:</p>
<ol>
<li>Filter employees older than 30.</li>
<li>Select only the name and department columns.</li>
<li>Show the results.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIkV4ZXJjaXNlIDIiKS5nZXRPckNyZWF0ZSgpCgpkYXRhID0gWwogICAgeyJuYW1lIjogIkFsaWNlIiwgImFnZSI6IDM0LCAiZGVwYXJ0bWVudCI6ICJIUiJ9LAogICAgeyJuYW1lIjogIkJvYiIsICJhZ2UiOiA0NSwgImRlcGFydG1lbnQiOiAiRW5naW5lZXJpbmcifSwKICAgIHsibmFtZSI6ICJDYXRoeSIsICJhZ2UiOiAyOSwgImRlcGFydG1lbnQiOiAiTWFya2V0aW5nIn0KXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhKQoKZmlsdGVyZWRfZGYgPSBkZi5maWx0ZXIoZGYuYWdlID4gMzApCnNlbGVjdGVkX2RmID0gZmlsdGVyZWRfZGYuc2VsZWN0KCJuYW1lIiwgImRlcGFydG1lbnQiKQpzZWxlY3RlZF9kZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Exercise 2&quot;).getOrCreate()

data = [
    {&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 34, &quot;department&quot;: &quot;HR&quot;},
    {&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 45, &quot;department&quot;: &quot;Engineering&quot;},
    {&quot;name&quot;: &quot;Cathy&quot;, &quot;age&quot;: 29, &quot;department&quot;: &quot;Marketing&quot;}
]
df = spark.createDataFrame(data)

filtered_df = df.filter(df.age &gt; 30)
selected_df = filtered_df.select(&quot;name&quot;, &quot;department&quot;)
selected_df.show()</pre></div><div class='content'></div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Lazy Evaluation:</strong> Remember that transformations in Spark are lazily evaluated. Actions trigger the execution of transformations.</li>
<li><strong>Memory Management:</strong> Be mindful of the memory usage when working with large datasets. Use appropriate partitioning and caching strategies.</li>
<li><strong>DataFrame vs. RDD:</strong> Use DataFrames and Datasets for most applications due to their optimization benefits. Use RDDs when you need low-level transformations and actions.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we explored the basics of Apache Spark and in-memory computing. We covered key concepts such as RDDs, DataFrames, and Datasets, and provided practical examples and exercises to reinforce the learning. Understanding these concepts is crucial for efficiently processing large-scale data in a distributed environment. In the next section, we will delve into data stream processing, which is another critical aspect of distributed computing.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-03-stream-processing' title="Data Stream Processing">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
