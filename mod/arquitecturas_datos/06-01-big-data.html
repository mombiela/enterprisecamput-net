<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Big Data</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_datos/06-01-big-data" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_datos/06-01-big-data" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_datos/06-01-big-data" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/arquitecturas_datos/06-01-big-data" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/arquitecturas_datos/06-01-big-data" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-use-cases' title="Data Analysis Use Cases">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Big Data</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-02-data-lakes' title="Data Lakes">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1><p>Introduction</p>
</h1>
<div class='content'><p>Big Data refers to the vast volumes of data that are generated at high velocity and with great variety. This data can come from various sources such as social media, sensors, transactions, and more. The primary challenge with Big Data is not just its size but also the complexity involved in storing, processing, and analyzing it to extract meaningful insights.</p>
</div><h1><p>Key Concepts of Big Data</p>
</h1>
<div class='content'></div><h2><p>The 3 Vs of Big Data</p>
</h2>
<div class='content'><ol>
<li><strong>Volume</strong>: The sheer amount of data generated every second. This can range from terabytes to petabytes of information.</li>
<li><strong>Velocity</strong>: The speed at which new data is generated and the pace at which it needs to be processed.</li>
<li><strong>Variety</strong>: The different types of data (structured, semi-structured, and unstructured) from various sources.</li>
</ol>
</div><h2><p>Additional Vs</p>
</h2>
<div class='content'><ul>
<li><strong>Veracity</strong>: The quality and accuracy of the data.</li>
<li><strong>Value</strong>: The potential insights and benefits that can be derived from the data.</li>
</ul>
</div><h1><p>Importance of Big Data</p>
</h1>
<div class='content'><p>Big Data is crucial for organizations because it enables them to:</p>
<ul>
<li><strong>Gain Insights</strong>: Analyze large datasets to uncover hidden patterns, correlations, and trends.</li>
<li><strong>Improve Decision Making</strong>: Make data-driven decisions that can lead to better outcomes.</li>
<li><strong>Enhance Customer Experience</strong>: Personalize services and products based on customer behavior and preferences.</li>
<li><strong>Optimize Operations</strong>: Streamline processes and improve efficiency by analyzing operational data.</li>
</ul>
</div><h1><p>Key Components of Big Data Architecture</p>
</h1>
<div class='content'></div><h2><p>Data Sources</p>
</h2>
<div class='content'><ul>
<li><strong>Social Media</strong>: Platforms like Twitter, Facebook, and Instagram.</li>
<li><strong>Sensors/IoT Devices</strong>: Devices that collect data from the physical world.</li>
<li><strong>Transactional Systems</strong>: Systems that record business transactions.</li>
<li><strong>Log Files</strong>: Files that record events and activities within systems.</li>
</ul>
</div><h2><p>Data Storage</p>
</h2>
<div class='content'><ul>
<li><strong>Distributed File Systems</strong>: Systems like Hadoop Distributed File System (HDFS) that store large volumes of data across multiple machines.</li>
<li><strong>NoSQL Databases</strong>: Databases like MongoDB, Cassandra, and HBase that are designed to handle large volumes of unstructured data.</li>
</ul>
</div><h2><p>Data Processing</p>
</h2>
<div class='content'><ul>
<li><strong>Batch Processing</strong>: Processing large volumes of data at once using tools like Apache Hadoop.</li>
<li><strong>Stream Processing</strong>: Processing data in real-time as it arrives using tools like Apache Kafka and Apache Flink.</li>
</ul>
</div><h2><p>Data Analysis</p>
</h2>
<div class='content'><ul>
<li><strong>Data Mining</strong>: Extracting patterns from large datasets.</li>
<li><strong>Machine Learning</strong>: Building models that can predict outcomes based on data.</li>
<li><strong>Visualization</strong>: Representing data in graphical formats to make it easier to understand.</li>
</ul>
</div><h1><p>Practical Example: Setting Up a Big Data Environment</p>
</h1>
<div class='content'></div><h2><p>Step 1: Install Hadoop</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEb3dubG9hZCBIYWRvb3AKd2dldCBodHRwczovL2Rvd25sb2Fkcy5hcGFjaGUub3JnL2hhZG9vcC9jb21tb24vaGFkb29wLTMuMy4xL2hhZG9vcC0zLjMuMS50YXIuZ3oKCiMgRXh0cmFjdCB0aGUgdGFyIGZpbGUKdGFyIC14enZmIGhhZG9vcC0zLjMuMS50YXIuZ3oKCiMgTW92ZSB0byAvdXNyL2xvY2FsCnN1ZG8gbXYgaGFkb29wLTMuMy4xIC91c3IvbG9jYWwvaGFkb29wCgojIFNldCBlbnZpcm9ubWVudCB2YXJpYWJsZXMKZXhwb3J0IEhBRE9PUF9IT01FPS91c3IvbG9jYWwvaGFkb29wCmV4cG9ydCBQQVRIPSRQQVRIOiRIQURPT1BfSE9NRS9iaW4="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Download Hadoop
wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz

# Extract the tar file
tar -xzvf hadoop-3.3.1.tar.gz

# Move to /usr/local
sudo mv hadoop-3.3.1 /usr/local/hadoop

# Set environment variables
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin</pre></div><div class='content'></div><h2><p>Step 2: Configure Hadoop</p>
</h2>
<div class='content'><p>Edit the <code>core-site.xml</code> file:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PGNvbmZpZ3VyYXRpb24+CiAgICA8cHJvcGVydHk+CiAgICAgICAgPG5hbWU+ZnMuZGVmYXVsdEZTPC9uYW1lPgogICAgICAgIDx2YWx1ZT5oZGZzOi8vbG9jYWxob3N0OjkwMDA8L3ZhbHVlPgogICAgPC9wcm9wZXJ0eT4KPC9jb25maWd1cmF0aW9uPg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</pre></div><div class='content'><p>Edit the <code>hdfs-site.xml</code> file:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PGNvbmZpZ3VyYXRpb24+CiAgICA8cHJvcGVydHk+CiAgICAgICAgPG5hbWU+ZGZzLnJlcGxpY2F0aW9uPC9uYW1lPgogICAgICAgIDx2YWx1ZT4xPC92YWx1ZT4KICAgIDwvcHJvcGVydHk+CjwvY29uZmlndXJhdGlvbj4="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</pre></div><div class='content'></div><h2><p>Step 3: Start Hadoop</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGb3JtYXQgdGhlIG5hbWVub2RlCmhkZnMgbmFtZW5vZGUgLWZvcm1hdAoKIyBTdGFydCB0aGUgSGFkb29wIGRhZW1vbnMKc3RhcnQtZGZzLnNoCnN0YXJ0LXlhcm4uc2g="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Format the namenode
hdfs namenode -format

# Start the Hadoop daemons
start-dfs.sh
start-yarn.sh</pre></div><div class='content'></div><h2><p>Step 4: Verify Installation</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYSBkaXJlY3RvcnkgaW4gSERGUwpoZGZzIGRmcyAtbWtkaXIgL3VzZXIKCiMgTGlzdCB0aGUgY29udGVudHMgb2YgdGhlIHJvb3QgZGlyZWN0b3J5IGluIEhERlMKaGRmcyBkZnMgLWxzIC8="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create a directory in HDFS
hdfs dfs -mkdir /user

# List the contents of the root directory in HDFS
hdfs dfs -ls /</pre></div><div class='content'></div><h1><p>Practical Exercise</p>
</h1>
<div class='content'></div><h2><p>Exercise: Analyzing Twitter Data with Hadoop</p>
</h2>
<div class='content'><ol>
<li><strong>Data Collection</strong>: Use the Twitter API to collect tweets containing a specific hashtag.</li>
<li><strong>Data Storage</strong>: Store the collected tweets in HDFS.</li>
<li><strong>Data Processing</strong>: Use Hadoop MapReduce to count the number of occurrences of each word in the tweets.</li>
<li><strong>Data Analysis</strong>: Identify the most frequently used words.</li>
</ol>
</div><h2><p>Solution</p>
</h2>
<div class='content'><h4>Step 1: Data Collection</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHR3ZWVweQoKIyBUd2l0dGVyIEFQSSBjcmVkZW50aWFscwpjb25zdW1lcl9rZXkgPSAneW91cl9jb25zdW1lcl9rZXknCmNvbnN1bWVyX3NlY3JldCA9ICd5b3VyX2NvbnN1bWVyX3NlY3JldCcKYWNjZXNzX3Rva2VuID0gJ3lvdXJfYWNjZXNzX3Rva2VuJwphY2Nlc3NfdG9rZW5fc2VjcmV0ID0gJ3lvdXJfYWNjZXNzX3Rva2VuX3NlY3JldCcKCiMgQXV0aGVudGljYXRlIHdpdGggdGhlIFR3aXR0ZXIgQVBJCmF1dGggPSB0d2VlcHkuT0F1dGhIYW5kbGVyKGNvbnN1bWVyX2tleSwgY29uc3VtZXJfc2VjcmV0KQphdXRoLnNldF9hY2Nlc3NfdG9rZW4oYWNjZXNzX3Rva2VuLCBhY2Nlc3NfdG9rZW5fc2VjcmV0KQphcGkgPSB0d2VlcHkuQVBJKGF1dGgpCgojIENvbGxlY3QgdHdlZXRzCnR3ZWV0cyA9IGFwaS5zZWFyY2gocT0nI0JpZ0RhdGEnLCBjb3VudD0xMDApCgojIFNhdmUgdHdlZXRzIHRvIGEgZmlsZQp3aXRoIG9wZW4oJ3R3ZWV0cy50eHQnLCAndycpIGFzIGY6CiAgICBmb3IgdHdlZXQgaW4gdHdlZXRzOgogICAgICAgIGYud3JpdGUodHdlZXQudGV4dCArICdcbicp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tweepy

# Twitter API credentials
consumer_key = 'your_consumer_key'
consumer_secret = 'your_consumer_secret'
access_token = 'your_access_token'
access_token_secret = 'your_access_token_secret'

# Authenticate with the Twitter API
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

# Collect tweets
tweets = api.search(q='#BigData', count=100)

# Save tweets to a file
with open('tweets.txt', 'w') as f:
    for tweet in tweets:
        f.write(tweet.text + '\n')</pre></div><div class='content'><h4>Step 2: Data Storage</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYSBkaXJlY3RvcnkgaW4gSERGUwpoZGZzIGRmcyAtbWtkaXIgL3VzZXIvdHdlZXRzCgojIFVwbG9hZCB0aGUgdHdlZXRzIGZpbGUgdG8gSERGUwpoZGZzIGRmcyAtcHV0IHR3ZWV0cy50eHQgL3VzZXIvdHdlZXRz"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create a directory in HDFS
hdfs dfs -mkdir /user/tweets

# Upload the tweets file to HDFS
hdfs dfs -put tweets.txt /user/tweets</pre></div><div class='content'><h4>Step 3: Data Processing</h4>
<p>Create a MapReduce job to count word occurrences.</p>
<p><strong>Mapper.py</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHN5cwoKIyBSZWFkIGlucHV0IGZyb20gc3RhbmRhcmQgaW5wdXQKZm9yIGxpbmUgaW4gc3lzLnN0ZGluOgogICAgd29yZHMgPSBsaW5lLnN0cmlwKCkuc3BsaXQoKQogICAgZm9yIHdvcmQgaW4gd29yZHM6CiAgICAgICAgcHJpbnQoZid7d29yZH1cdDEnKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import sys

# Read input from standard input
for line in sys.stdin:
    words = line.strip().split()
    for word in words:
        print(f'{word}\t1')</pre></div><div class='content'><p><strong>Reducer.py</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHN5cwpmcm9tIGNvbGxlY3Rpb25zIGltcG9ydCBkZWZhdWx0ZGljdAoKd29yZF9jb3VudCA9IGRlZmF1bHRkaWN0KGludCkKCiMgUmVhZCBpbnB1dCBmcm9tIHN0YW5kYXJkIGlucHV0CmZvciBsaW5lIGluIHN5cy5zdGRpbjoKICAgIHdvcmQsIGNvdW50ID0gbGluZS5zdHJpcCgpLnNwbGl0KCdcdCcpCiAgICB3b3JkX2NvdW50W3dvcmRdICs9IGludChjb3VudCkKCiMgT3V0cHV0IHdvcmQgY291bnRzCmZvciB3b3JkLCBjb3VudCBpbiB3b3JkX2NvdW50Lml0ZW1zKCk6CiAgICBwcmludChmJ3t3b3JkfVx0e2NvdW50fScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import sys
from collections import defaultdict

word_count = defaultdict(int)

# Read input from standard input
for line in sys.stdin:
    word, count = line.strip().split('\t')
    word_count[word] += int(count)

# Output word counts
for word, count in word_count.items():
    print(f'{word}\t{count}')</pre></div><div class='content'><p>Run the MapReduce job:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aGFkb29wIGphciAvdXNyL2xvY2FsL2hhZG9vcC9zaGFyZS9oYWRvb3AvdG9vbHMvbGliL2hhZG9vcC1zdHJlYW1pbmctMy4zLjEuamFyIFwKICAgIC1pbnB1dCAvdXNlci90d2VldHMvdHdlZXRzLnR4dCBcCiAgICAtb3V0cHV0IC91c2VyL3R3ZWV0cy9vdXRwdXQgXAogICAgLW1hcHBlciBNYXBwZXIucHkgXAogICAgLXJlZHVjZXIgUmVkdWNlci5weQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar \
    -input /user/tweets/tweets.txt \
    -output /user/tweets/output \
    -mapper Mapper.py \
    -reducer Reducer.py</pre></div><div class='content'><h4>Step 4: Data Analysis</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBWaWV3IHRoZSBvdXRwdXQKaGRmcyBkZnMgLWNhdCAvdXNlci90d2VldHMvb3V0cHV0L3BhcnQtMDAwMDA="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># View the output
hdfs dfs -cat /user/tweets/output/part-00000</pre></div><div class='content'></div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we covered the fundamental concepts of Big Data, its importance, and the key components of a Big Data architecture. We also provided a practical example of setting up a Hadoop environment and a hands-on exercise to analyze Twitter data using Hadoop. Understanding Big Data is crucial for designing scalable and efficient data architectures that can handle the growing volume, velocity, and variety of data in modern organizations.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-use-cases' title="Data Analysis Use Cases">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-02-data-lakes' title="Data Lakes">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
