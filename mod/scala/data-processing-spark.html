<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Processing with Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/scala/data-processing-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/scala/data-processing-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/scala/data-processing-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/scala/data-processing-spark" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/scala/data-processing-spark" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='web-development-play-framework'>&#x25C4;Web Development with Play Framework</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Data Processing with Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='building-rest-apis'>Building REST APIs &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to Apache Spark</h1>
<div class='content'><p>Apache Spark is a powerful open-source unified analytics engine for large-scale data processing. It provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Resilient Distributed Datasets (RDDs):</strong> Immutable distributed collections of objects that can be processed in parallel.</li>
<li><strong>DataFrames:</strong> Distributed collections of data organized into named columns, similar to a table in a relational database.</li>
<li><strong>Spark SQL:</strong> Module for working with structured data using SQL queries.</li>
<li><strong>Spark Streaming:</strong> Enables scalable and fault-tolerant stream processing of live data streams.</li>
<li><strong>MLlib:</strong> Machine learning library for Spark.</li>
<li><strong>GraphX:</strong> API for graphs and graph-parallel computation.</li>
</ul>
</div><h1>Setting Up Spark with Scala</h1>
<div class='content'><p>To start using Spark with Scala, you need to set up your development environment.</p>
</div><h2>Installation Steps</h2>
<div class='content'><ol>
<li><strong>Install Java Development Kit (JDK):</strong> Spark requires Java to run.</li>
<li><strong>Download and Install Apache Spark:</strong> Get the latest version from the official website.</li>
<li><strong>Set Up Scala:</strong> Install Scala on your machine.</li>
<li><strong>Install an IDE:</strong> IntelliJ IDEA is recommended for Scala development.</li>
</ol>
</div><h2>Example: Setting Up a Simple Spark Application</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgoKb2JqZWN0IFNpbXBsZUFwcCB7CiAgZGVmIG1haW4oYXJnczogQXJyYXlbU3RyaW5nXSk6IFVuaXQgPSB7CiAgICB2YWwgc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlcgogICAgICAuYXBwTmFtZSgiU2ltcGxlIEFwcGxpY2F0aW9uIikKICAgICAgLmNvbmZpZygic3BhcmsubWFzdGVyIiwgImxvY2FsIikKICAgICAgLmdldE9yQ3JlYXRlKCkKCiAgICB2YWwgZGF0YSA9IHNwYXJrLnJlYWQudGV4dEZpbGUoImRhdGEudHh0IikucmRkCiAgICB2YWwgbnVtQXMgPSBkYXRhLmZpbHRlcihsaW5lID0+IGxpbmUuY29udGFpbnMoImEiKSkuY291bnQoKQogICAgdmFsIG51bUJzID0gZGF0YS5maWx0ZXIobGluZSA9PiBsaW5lLmNvbnRhaW5zKCJiIikpLmNvdW50KCkKCiAgICBwcmludGxuKHMiTGluZXMgd2l0aCBhOiAkbnVtQXMsIExpbmVzIHdpdGggYjogJG51bUJzIikKCiAgICBzcGFyay5zdG9wKCkKICB9Cn0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession

object SimpleApp {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder
      .appName(&quot;Simple Application&quot;)
      .config(&quot;spark.master&quot;, &quot;local&quot;)
      .getOrCreate()

    val data = spark.read.textFile(&quot;data.txt&quot;).rdd
    val numAs = data.filter(line =&gt; line.contains(&quot;a&quot;)).count()
    val numBs = data.filter(line =&gt; line.contains(&quot;b&quot;)).count()

    println(s&quot;Lines with a: $numAs, Lines with b: $numBs&quot;)

    spark.stop()
  }
}</pre></div><div class='content'><p>Explanation:</p>
<ul>
<li><strong>SparkSession:</strong> Entry point to programming Spark with the Dataset and DataFrame API.</li>
<li><strong>read.textFile:</strong> Reads a text file and returns an RDD.</li>
<li><strong>filter:</strong> Filters the RDD based on a condition.</li>
<li><strong>count:</strong> Counts the number of elements in the RDD.</li>
</ul>
</div><h1>Working with RDDs</h1>
<div class='content'><p>RDDs are the fundamental data structure of Spark. They are immutable and distributed collections of objects.</p>
</div><h2>Creating RDDs</h2>
<div class='content'><p>You can create RDDs from existing data in your program or from external datasets.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRhdGEgPSBBcnJheSgxLCAyLCAzLCA0LCA1KQp2YWwgZGlzdERhdGEgPSBzcGFyay5zcGFya0NvbnRleHQucGFyYWxsZWxpemUoZGF0YSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val data = Array(1, 2, 3, 4, 5)
val distData = spark.sparkContext.parallelize(data)</pre></div><div class='content'></div><h2>Transformations and Actions</h2>
<div class='content'><ul>
<li><strong>Transformations:</strong> Operations on RDDs that return a new RDD (e.g., <code>map</code>, <code>filter</code>).</li>
<li><strong>Actions:</strong> Operations that return a value to the driver program or write data to an external storage system (e.g., <code>count</code>, <code>collect</code>).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNwYXJrLnNwYXJrQ29udGV4dC5wYXJhbGxlbGl6ZShTZXEoMSwgMiwgMywgNCwgNSkpCnZhbCBtYXBwZWRSREQgPSByZGQubWFwKHggPT4geCAqIHgpCnZhbCBmaWx0ZXJlZFJERCA9IG1hcHBlZFJERC5maWx0ZXIoeCA9PiB4ID4gMTApCnZhbCByZXN1bHQgPSBmaWx0ZXJlZFJERC5jb2xsZWN0KCkKcmVzdWx0LmZvcmVhY2gocHJpbnRsbik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = spark.sparkContext.parallelize(Seq(1, 2, 3, 4, 5))
val mappedRDD = rdd.map(x =&gt; x * x)
val filteredRDD = mappedRDD.filter(x =&gt; x &gt; 10)
val result = filteredRDD.collect()
result.foreach(println)</pre></div><div class='content'></div><h1>Working with DataFrames</h1>
<div class='content'><p>DataFrames are similar to RDDs but with additional optimizations and the ability to use SQL queries.</p>
</div><h2>Creating DataFrames</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRmID0gc3BhcmsucmVhZC5qc29uKCJwZW9wbGUuanNvbiIpCmRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val df = spark.read.json(&quot;people.json&quot;)
df.show()</pre></div><div class='content'></div><h2>DataFrame Operations</h2>
<div class='content'><ul>
<li><strong>Select:</strong> Select specific columns.</li>
<li><strong>Filter:</strong> Filter rows based on a condition.</li>
<li><strong>GroupBy:</strong> Group rows by a specific column.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuc2VsZWN0KCJuYW1lIiwgImFnZSIpLnNob3coKQpkZi5maWx0ZXIoJCJhZ2UiID4gMjEpLnNob3coKQpkZi5ncm91cEJ5KCJhZ2UiKS5jb3VudCgpLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.select(&quot;name&quot;, &quot;age&quot;).show()
df.filter($&quot;age&quot; &gt; 21).show()
df.groupBy(&quot;age&quot;).count().show()</pre></div><div class='content'></div><h1>Spark SQL</h1>
<div class='content'><p>Spark SQL allows you to run SQL queries on DataFrames.</p>
</div><h2>Example: Running SQL Queries</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnZhbCBzcWxERiA9IHNwYXJrLnNxbCgiU0VMRUNUICogRlJPTSBwZW9wbGUgV0hFUkUgYWdlID4gMjEiKQpzcWxERi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.createOrReplaceTempView(&quot;people&quot;)
val sqlDF = spark.sql(&quot;SELECT * FROM people WHERE age &gt; 21&quot;)
sqlDF.show()</pre></div><div class='content'></div><h1>Advanced Topics</h1>
<h2>Spark Streaming</h2>
<div class='content'><p>Spark Streaming enables real-time data processing.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RyZWFtaW5nLl8KdmFsIHNzYyA9IG5ldyBTdHJlYW1pbmdDb250ZXh0KHNwYXJrLnNwYXJrQ29udGV4dCwgU2Vjb25kcygxKSkKdmFsIGxpbmVzID0gc3NjLnNvY2tldFRleHRTdHJlYW0oImxvY2FsaG9zdCIsIDk5OTkpCnZhbCB3b3JkcyA9IGxpbmVzLmZsYXRNYXAoXy5zcGxpdCgiICIpKQp2YWwgd29yZENvdW50cyA9IHdvcmRzLm1hcCh4ID0+ICh4LCAxKSkucmVkdWNlQnlLZXkoXyArIF8pCndvcmRDb3VudHMucHJpbnQoKQpzc2Muc3RhcnQoKQpzc2MuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.streaming._
val ssc = new StreamingContext(spark.sparkContext, Seconds(1))
val lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
val words = lines.flatMap(_.split(&quot; &quot;))
val wordCounts = words.map(x =&gt; (x, 1)).reduceByKey(_ + _)
wordCounts.print()
ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h2>Machine Learning with MLlib</h2>
<div class='content'><p>MLlib provides various machine learning algorithms.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3BhcmsubWwuY2xhc3NpZmljYXRpb24uTG9naXN0aWNSZWdyZXNzaW9uCnZhbCB0cmFpbmluZyA9IHNwYXJrLnJlYWQuZm9ybWF0KCJsaWJzdm0iKS5sb2FkKCJkYXRhL21sbGliL3NhbXBsZV9saWJzdm1fZGF0YS50eHQiKQp2YWwgbHIgPSBuZXcgTG9naXN0aWNSZWdyZXNzaW9uKCkKdmFsIG1vZGVsID0gbHIuZml0KHRyYWluaW5nKQp2YWwgcmVzdWx0ID0gbW9kZWwudHJhbnNmb3JtKHRyYWluaW5nKQpyZXN1bHQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.ml.classification.LogisticRegression
val training = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)
val lr = new LogisticRegression()
val model = lr.fit(training)
val result = model.transform(training)
result.show()</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this topic, we covered the basics of data processing with Spark using Scala, including setting up Spark, working with RDDs and DataFrames, running SQL queries, and exploring advanced topics like Spark Streaming and MLlib. Spark's powerful APIs and optimizations make it an excellent choice for large-scale data processing tasks.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='web-development-play-framework'>&#x25C4;Web Development with Play Framework</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Data Processing with Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='building-rest-apis'>Building REST APIs &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
