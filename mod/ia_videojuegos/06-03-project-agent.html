<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 3: Development of an Agent with Machine Learning</title>

    <link rel="alternate" href="https://campusempresa.com/mod/ia_videojuegos/06-03-proyecto-agente" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/ia_videojuegos/06-03-projecte-agent" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/ia_videojuegos/06-03-project-agent" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=2" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/ia_videojuegos/06-03-proyecto-agente" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/ia_videojuegos/06-03-projecte-agent" class="px-2">CA</a>
<br>
			<cite>Building today's and tomorrow's society</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Programming Languages</a>
				 					<a href="/categ/frameworks">Frameworks and Libraries</a>
				 					<a href="/categ/tech-tools">Technical Tools</a>
				 					<a href="/categ/foundations">Theoretical Foundations</a>
				 					<a href="/categ/soft-skills">Social Skills</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='06-02-project-npc' title="Project 2: Creation of an NPC with Decision Making">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Project 3: Development of an Agent with Machine Learning</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-01-books-articles' title="Recommended Books and Articles">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this project, you will develop an intelligent agent using machine learning techniques. This agent will learn from its environment and improve its performance over time. We will focus on reinforcement learning, a popular method in game AI for training agents to make decisions.</p>
</div><h1><p>Objectives</p>
</h1>
<div class='content'><ul>
<li>Understand the basics of reinforcement learning.</li>
<li>Implement a simple reinforcement learning algorithm.</li>
<li>Train an agent to perform a specific task.</li>
<li>Evaluate and optimize the agent's performance.</li>
</ul>
</div><h1><p>Prerequisites</p>
</h1>
<div class='content'><p>Before starting this project, ensure you have a good understanding of the following concepts:</p>
<ul>
<li>Basic programming skills in Python.</li>
<li>Understanding of machine learning concepts.</li>
<li>Familiarity with reinforcement learning principles.</li>
</ul>
</div><h1><p>Step-by-Step Guide</p>
</h1>
<div class='content'></div><h2><p>Step 1: Setting Up the Environment</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Install Required Libraries:</strong>
Ensure you have Python installed. You will also need libraries like <code>numpy</code>, <code>gym</code>, and <code>tensorflow</code> or <code>pytorch</code>. Install them using pip:</p>
<pre><code class="language-bash">pip install numpy gym tensorflow
</code></pre>
</li>
<li>
<p><strong>Create a New Project Directory:</strong>
Organize your files by creating a new directory for this project.</p>
<pre><code class="language-bash">mkdir RL_Agent_Project
cd RL_Agent_Project
</code></pre>
</li>
</ol>
</div><h2><p>Step 2: Understanding the Problem</p>
</h2>
<div class='content'><p>For this project, we will use the OpenAI Gym environment, specifically the CartPole-v1 environment. The objective is to balance a pole on a cart by applying forces to the cart.</p>
</div><h2><p>Step 3: Implementing the Agent</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Import Libraries:</strong></p>
<pre><code class="language-python">import gym
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
</code></pre>
</li>
<li>
<p><strong>Create the Environment:</strong></p>
<pre><code class="language-python">env = gym.make('CartPole-v1')
state_size = env.observation_space.shape[0]
action_size = env.action_space.n
</code></pre>
</li>
<li>
<p><strong>Build the Neural Network:</strong></p>
<pre><code class="language-python">def build_model(state_size, action_size):
    model = Sequential()
    model.add(Dense(24, input_dim=state_size, activation='relu'))
    model.add(Dense(24, activation='relu'))
    model.add(Dense(action_size, activation='linear'))
    model.compile(loss='mse', optimizer=Adam(lr=0.001))
    return model

model = build_model(state_size, action_size)
</code></pre>
</li>
<li>
<p><strong>Define the Agent:</strong></p>
<pre><code class="language-python">class DQNAgent:
    def __init__(self, state_size, action_size):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = []
        self.gamma = 0.95    # discount rate
        self.epsilon = 1.0   # exploration rate
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.model = build_model(state_size, action_size)

    def remember(self, state, action, reward, next_state, done):
        self.memory.append((state, action, reward, next_state, done))

    def act(self, state):
        if np.random.rand() &lt;= self.epsilon:
            return np.random.choice(self.action_size)
        act_values = self.model.predict(state)
        return np.argmax(act_values[0])

    def replay(self, batch_size):
        minibatch = np.random.choice(self.memory, batch_size)
        for state, action, reward, next_state, done in minibatch:
            target = reward
            if not done:
                target = (reward + self.gamma *
                          np.amax(self.model.predict(next_state)[0]))
            target_f = self.model.predict(state)
            target_f[0][action] = target
            self.model.fit(state, target_f, epochs=1, verbose=0)
        if self.epsilon &gt; self.epsilon_min:
            self.epsilon *= self.epsilon_decay
</code></pre>
</li>
</ol>
</div><h2><p>Step 4: Training the Agent</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Initialize the Agent:</strong></p>
<pre><code class="language-python">agent = DQNAgent(state_size, action_size)
</code></pre>
</li>
<li>
<p><strong>Train the Agent:</strong></p>
<pre><code class="language-python">episodes = 1000
batch_size = 32

for e in range(episodes):
    state = env.reset()
    state = np.reshape(state, [1, state_size])
    for time in range(500):
        action = agent.act(state)
        next_state, reward, done, _ = env.step(action)
        reward = reward if not done else -10
        next_state = np.reshape(next_state, [1, state_size])
        agent.remember(state, action, reward, next_state, done)
        state = next_state
        if done:
            print(f&quot;episode: {e}/{episodes}, score: {time}, e: {agent.epsilon:.2}&quot;)
            break
        if len(agent.memory) &gt; batch_size:
            agent.replay(batch_size)
</code></pre>
</li>
</ol>
</div><h2><p>Step 5: Evaluating the Agent</p>
</h2>
<div class='content'><ol>
<li><strong>Test the Agent:</strong>
<pre><code class="language-python">for e in range(10):
    state = env.reset()
    state = np.reshape(state, [1, state_size])
    for time in range(500):
        env.render()
        action = agent.act(state)
        next_state, reward, done, _ = env.step(action)
        next_state = np.reshape(next_state, [1, state_size])
        state = next_state
        if done:
            print(f&quot;episode: {e}/10, score: {time}&quot;)
            break
env.close()
</code></pre>
</li>
</ol>
</div><h2><p>Step 6: Optimization and Fine-Tuning</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Hyperparameter Tuning:</strong>
Experiment with different values for learning rate, discount factor, and exploration rate to improve the agent's performance.</p>
</li>
<li>
<p><strong>Memory Management:</strong>
Implement techniques to manage the memory efficiently, such as using a deque with a fixed size.</p>
</li>
<li>
<p><strong>Advanced Techniques:</strong>
Explore advanced reinforcement learning algorithms like Double DQN, Dueling DQN, or Prioritized Experience Replay for better performance.</p>
</li>
</ol>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this project, you have successfully developed an intelligent agent using reinforcement learning. You have learned how to set up the environment, implement a neural network, train the agent, and evaluate its performance. By experimenting with different parameters and techniques, you can further improve the agent's capabilities.</p>
<p>This project serves as a foundation for more complex AI implementations in video games. Continue exploring and experimenting with different environments and algorithms to enhance your skills in game AI development.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='06-02-project-npc' title="Project 2: Creation of an NPC with Decision Making">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-01-books-articles' title="Recommended Books and Articles">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Advertising</h1>
<p>This space is reserved for advertising.</p>
<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Thank you for collaborating!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
