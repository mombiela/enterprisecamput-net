<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cloud Data Fusion</title>

    <link rel="alternate" href="https://campusempresa.com/mod/gcp/04-05-cloud-data-fusion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/gcp/04-05-cloud-data-fusion" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/gcp/04-05-cloud-data-fusion" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/gcp/04-05-cloud-data-fusion" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/gcp/04-05-cloud-data-fusion" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-04-cloud-pubsub' title="Cloud Pub/Sub">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Cloud Data Fusion</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-01-ai-platform' title="AI Platform">Next &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Cloud Data Fusion is a fully managed, cloud-native data integration service that allows you to efficiently build and manage ETL/ELT data pipelines. It provides a graphical interface to design data pipelines, making it easier for both technical and non-technical users to create complex data workflows.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ol>
<li><strong>ETL/ELT</strong>: Extract, Transform, Load (ETL) and Extract, Load, Transform (ELT) are processes used to move data from source systems to a data warehouse or data lake.</li>
<li><strong>Pipelines</strong>: A sequence of data processing steps, including data extraction, transformation, and loading.</li>
<li><strong>Plugins</strong>: Reusable components that perform specific tasks within a pipeline, such as reading from a database or writing to a storage system.</li>
<li><strong>Wrangling</strong>: The process of cleaning and transforming raw data into a more usable format.</li>
</ol>
</div><h1>Features</h1>
<div class='content'><ul>
<li><strong>Visual Interface</strong>: Drag-and-drop interface for designing data pipelines.</li>
<li><strong>Pre-built Connectors</strong>: Connect to various data sources and sinks, including databases, cloud storage, and on-premises systems.</li>
<li><strong>Data Transformation</strong>: Built-in transformations and the ability to write custom transformations.</li>
<li><strong>Monitoring and Logging</strong>: Real-time monitoring and logging of pipeline executions.</li>
<li><strong>Scalability</strong>: Automatically scales to handle large volumes of data.</li>
</ul>
</div><h1>Setting Up Cloud Data Fusion</h1>
<div class='content'></div><h2>Step 1: Enable the Cloud Data Fusion API</h2>
<div class='content'><ol>
<li>Go to the <a href="https://console.cloud.google.com/">Google Cloud Console</a>.</li>
<li>Navigate to the <strong>API &amp; Services</strong> section.</li>
<li>Click on <strong>Enable APIs and Services</strong>.</li>
<li>Search for &quot;Cloud Data Fusion&quot; and enable the API.</li>
</ol>
</div><h2>Step 2: Create a Cloud Data Fusion Instance</h2>
<div class='content'><ol>
<li>In the Google Cloud Console, navigate to <strong>Cloud Data Fusion</strong>.</li>
<li>Click on <strong>Create Instance</strong>.</li>
<li>Fill in the required details:
<ul>
<li><strong>Instance Name</strong>: A unique name for your instance.</li>
<li><strong>Region</strong>: Select the region where you want to deploy the instance.</li>
<li><strong>Zone</strong>: Optionally, select a specific zone.</li>
</ul>
</li>
<li>Click <strong>Create</strong> to provision the instance.</li>
</ol>
</div><h2>Step 3: Access the Cloud Data Fusion UI</h2>
<div class='content'><ol>
<li>Once the instance is created, click on the instance name to open the instance details page.</li>
<li>Click on <strong>Instance URL</strong> to open the Cloud Data Fusion UI.</li>
</ol>
</div><h1>Creating a Simple Pipeline</h1>
<div class='content'></div><h2>Example: Loading Data from Cloud Storage to BigQuery</h2>
<div class='content'><ol>
<li>
<p><strong>Create a New Pipeline</strong>:</p>
<ul>
<li>In the Cloud Data Fusion UI, click on <strong>Studio</strong>.</li>
<li>Click on <strong>Create Pipeline</strong> and select <strong>Data Pipeline</strong>.</li>
</ul>
</li>
<li>
<p><strong>Add a Source</strong>:</p>
<ul>
<li>Drag the <strong>GCS</strong> (Google Cloud Storage) source plugin onto the canvas.</li>
<li>Configure the plugin by specifying the bucket and file path.</li>
</ul>
</li>
<li>
<p><strong>Add a Transformation</strong>:</p>
<ul>
<li>Drag the <strong>Wrangler</strong> plugin onto the canvas.</li>
<li>Connect the GCS source to the Wrangler.</li>
<li>Configure the Wrangler to clean and transform the data as needed.</li>
</ul>
</li>
<li>
<p><strong>Add a Sink</strong>:</p>
<ul>
<li>Drag the <strong>BigQuery</strong> sink plugin onto the canvas.</li>
<li>Connect the Wrangler to the BigQuery sink.</li>
<li>Configure the plugin by specifying the dataset and table.</li>
</ul>
</li>
<li>
<p><strong>Deploy and Run the Pipeline</strong>:</p>
<ul>
<li>Click on <strong>Deploy</strong> to deploy the pipeline.</li>
<li>Once deployed, click on <strong>Run</strong> to execute the pipeline.</li>
</ul>
</li>
</ol>
</div><h2>Code Example</h2>
<div class='content'><p>Below is a JSON representation of a simple pipeline that reads data from a GCS bucket, transforms it using Wrangler, and writes it to a BigQuery table.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ewogICJuYW1lIjogIkdDUyB0byBCaWdRdWVyeSBQaXBlbGluZSIsCiAgImRlc2NyaXB0aW9uIjogIkEgc2ltcGxlIHBpcGVsaW5lIHRvIGxvYWQgZGF0YSBmcm9tIEdDUyB0byBCaWdRdWVyeSIsCiAgIm5vZGVzIjogWwogICAgewogICAgICAiaWQiOiAiR0NTIiwKICAgICAgInR5cGUiOiAic291cmNlIiwKICAgICAgInBsdWdpbiI6IHsKICAgICAgICAibmFtZSI6ICJHQ1MiLAogICAgICAgICJwcm9wZXJ0aWVzIjogewogICAgICAgICAgInBhdGgiOiAiZ3M6Ly95b3VyLWJ1Y2tldC95b3VyLWZpbGUuY3N2IiwKICAgICAgICAgICJmb3JtYXQiOiAiY3N2IgogICAgICAgIH0KICAgICAgfQogICAgfSwKICAgIHsKICAgICAgImlkIjogIldyYW5nbGVyIiwKICAgICAgInR5cGUiOiAidHJhbnNmb3JtIiwKICAgICAgInBsdWdpbiI6IHsKICAgICAgICAibmFtZSI6ICJXcmFuZ2xlciIsCiAgICAgICAgInByb3BlcnRpZXMiOiB7CiAgICAgICAgICAiZGlyZWN0aXZlcyI6ICJwYXJzZS1hcy1jc3YgYm9keSAsXG5zZXQtaGVhZGVycyBoZWFkZXIxLGhlYWRlcjIsaGVhZGVyMyIKICAgICAgICB9CiAgICAgIH0KICAgIH0sCiAgICB7CiAgICAgICJpZCI6ICJCaWdRdWVyeSIsCiAgICAgICJ0eXBlIjogInNpbmsiLAogICAgICAicGx1Z2luIjogewogICAgICAgICJuYW1lIjogIkJpZ1F1ZXJ5IiwKICAgICAgICAicHJvcGVydGllcyI6IHsKICAgICAgICAgICJkYXRhc2V0IjogInlvdXJfZGF0YXNldCIsCiAgICAgICAgICAidGFibGUiOiAieW91cl90YWJsZSIKICAgICAgICB9CiAgICAgIH0KICAgIH0KICBdLAogICJjb25uZWN0aW9ucyI6IFsKICAgIHsKICAgICAgImZyb20iOiAiR0NTIiwKICAgICAgInRvIjogIldyYW5nbGVyIgogICAgfSwKICAgIHsKICAgICAgImZyb20iOiAiV3JhbmdsZXIiLAogICAgICAidG8iOiAiQmlnUXVlcnkiCiAgICB9CiAgXQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>{
  &quot;name&quot;: &quot;GCS to BigQuery Pipeline&quot;,
  &quot;description&quot;: &quot;A simple pipeline to load data from GCS to BigQuery&quot;,
  &quot;nodes&quot;: [
    {
      &quot;id&quot;: &quot;GCS&quot;,
      &quot;type&quot;: &quot;source&quot;,
      &quot;plugin&quot;: {
        &quot;name&quot;: &quot;GCS&quot;,
        &quot;properties&quot;: {
          &quot;path&quot;: &quot;gs://your-bucket/your-file.csv&quot;,
          &quot;format&quot;: &quot;csv&quot;
        }
      }
    },
    {
      &quot;id&quot;: &quot;Wrangler&quot;,
      &quot;type&quot;: &quot;transform&quot;,
      &quot;plugin&quot;: {
        &quot;name&quot;: &quot;Wrangler&quot;,
        &quot;properties&quot;: {
          &quot;directives&quot;: &quot;parse-as-csv body ,\nset-headers header1,header2,header3&quot;
        }
      }
    },
    {
      &quot;id&quot;: &quot;BigQuery&quot;,
      &quot;type&quot;: &quot;sink&quot;,
      &quot;plugin&quot;: {
        &quot;name&quot;: &quot;BigQuery&quot;,
        &quot;properties&quot;: {
          &quot;dataset&quot;: &quot;your_dataset&quot;,
          &quot;table&quot;: &quot;your_table&quot;
        }
      }
    }
  ],
  &quot;connections&quot;: [
    {
      &quot;from&quot;: &quot;GCS&quot;,
      &quot;to&quot;: &quot;Wrangler&quot;
    },
    {
      &quot;from&quot;: &quot;Wrangler&quot;,
      &quot;to&quot;: &quot;BigQuery&quot;
    }
  ]
}</pre></div><div class='content'></div><h1>Practical Exercise</h1>
<div class='content'></div><h2>Exercise: Create a Pipeline to Load Data from Cloud Storage to BigQuery</h2>
<div class='content'><ol>
<li><strong>Objective</strong>: Create a pipeline that reads a CSV file from a GCS bucket, transforms the data, and loads it into a BigQuery table.</li>
<li><strong>Steps</strong>:
<ul>
<li>Create a new pipeline in Cloud Data Fusion.</li>
<li>Add a GCS source and configure it to read a CSV file.</li>
<li>Add a Wrangler transformation to clean and transform the data.</li>
<li>Add a BigQuery sink and configure it to write to a specific table.</li>
<li>Deploy and run the pipeline.</li>
</ul>
</li>
</ol>
</div><h2>Solution</h2>
<div class='content'><p>Follow the steps outlined in the &quot;Creating a Simple Pipeline&quot; section to complete the exercise.</p>
</div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Incorrect File Path</strong>: Ensure the file path in the GCS source plugin is correct.</li>
<li><strong>Schema Mismatch</strong>: Ensure the schema in the Wrangler transformation matches the schema in the BigQuery table.</li>
<li><strong>Permissions</strong>: Ensure the Cloud Data Fusion service account has the necessary permissions to read from GCS and write to BigQuery.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, you learned about Cloud Data Fusion, its key features, and how to set it up. You also created a simple pipeline to load data from Cloud Storage to BigQuery. This knowledge will help you build and manage complex data integration workflows on Google Cloud Platform. In the next module, we will explore more advanced data and analytics services on GCP.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-04-cloud-pubsub' title="Cloud Pub/Sub">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-01-ai-platform' title="AI Platform">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
