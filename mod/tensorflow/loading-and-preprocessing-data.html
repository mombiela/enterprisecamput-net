<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Loading and Preprocessing Data</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/loading-and-preprocessing-data" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/loading-and-preprocessing-data" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/loading-and-preprocessing-data" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/tensorflow/loading-and-preprocessing-data" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/tensorflow/loading-and-preprocessing-data" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='eager-execution'>&#x25C4;Eager Execution</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Loading and Preprocessing Data</a>
	</div>
	<div class='col-4 text-end'>
					<a href='datasets-and-iterators'>Datasets and Iterators &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we will cover how to load and preprocess data using TensorFlow. This is a crucial step in any machine learning pipeline, as the quality and format of your data can significantly affect the performance of your models.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Data Loading</strong>: Importing data from various sources such as CSV files, images, or databases.</li>
<li><strong>Data Preprocessing</strong>: Transforming raw data into a format suitable for training machine learning models. This includes normalization, augmentation, and splitting data into training, validation, and test sets.</li>
</ul>
</div><h1>Data Loading</h1>
<div class='content'></div><h2>Loading Data from CSV Files</h2>
<div class='content'><p>TensorFlow provides several utilities to load data from CSV files. The <code>tf.data</code> API is particularly useful for this purpose.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRGVmaW5lIHRoZSBmaWxlIHBhdGgKZmlsZV9wYXRoID0gJ3BhdGgvdG8veW91ci9kYXRhLmNzdicKCiMgQ3JlYXRlIGEgZGF0YXNldCBmcm9tIHRoZSBDU1YgZmlsZQpkYXRhc2V0ID0gdGYuZGF0YS5leHBlcmltZW50YWwubWFrZV9jc3ZfZGF0YXNldCgKICAgIGZpbGVfcGF0aCwKICAgIGJhdGNoX3NpemU9MzIsICAjIE51bWJlciBvZiBzYW1wbGVzIHBlciBiYXRjaAogICAgbGFiZWxfbmFtZT0ndGFyZ2V0X2NvbHVtbicsICAjIFRoZSBjb2x1bW4gdG8gYmUgdXNlZCBhcyBsYWJlbHMKICAgIG5hX3ZhbHVlPSI/IiwgICMgVmFsdWUgdG8gYmUgY29uc2lkZXJlZCBhcyBtaXNzaW5nCiAgICBudW1fZXBvY2hzPTEsICAjIE51bWJlciBvZiB0aW1lcyB0byBpdGVyYXRlIG92ZXIgdGhlIGRhdGFzZXQKICAgIGlnbm9yZV9lcnJvcnM9VHJ1ZSAgIyBJZ25vcmUgZXJyb3JzIGR1cmluZyBsb2FkaW5nCikKCiMgSW5zcGVjdCB0aGUgZGF0YXNldApmb3IgZmVhdHVyZXMsIGxhYmVsIGluIGRhdGFzZXQudGFrZSgxKToKICAgIHByaW50KCJGZWF0dXJlczogIiwgZmVhdHVyZXMpCiAgICBwcmludCgiTGFiZWw6ICIsIGxhYmVsKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Define the file path
file_path = 'path/to/your/data.csv'

# Create a dataset from the CSV file
dataset = tf.data.experimental.make_csv_dataset(
    file_path,
    batch_size=32,  # Number of samples per batch
    label_name='target_column',  # The column to be used as labels
    na_value=&quot;?&quot;,  # Value to be considered as missing
    num_epochs=1,  # Number of times to iterate over the dataset
    ignore_errors=True  # Ignore errors during loading
)

# Inspect the dataset
for features, label in dataset.take(1):
    print(&quot;Features: &quot;, features)
    print(&quot;Label: &quot;, label)</pre></div><div class='content'></div><h2>Loading Image Data</h2>
<div class='content'><p>TensorFlow also provides utilities to load and preprocess image data. The <code>tf.keras.preprocessing.image_dataset_from_directory</code> function is very handy for this.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRGVmaW5lIHRoZSBkaXJlY3RvcnkgcGF0aApkaXJlY3RvcnlfcGF0aCA9ICdwYXRoL3RvL3lvdXIvaW1hZ2VzJwoKIyBDcmVhdGUgYSBkYXRhc2V0IGZyb20gdGhlIGRpcmVjdG9yeQpkYXRhc2V0ID0gdGYua2VyYXMucHJlcHJvY2Vzc2luZy5pbWFnZV9kYXRhc2V0X2Zyb21fZGlyZWN0b3J5KAogICAgZGlyZWN0b3J5X3BhdGgsCiAgICBpbWFnZV9zaXplPSgyNTYsIDI1NiksICAjIFJlc2l6ZSBpbWFnZXMgdG8gMjU2eDI1NgogICAgYmF0Y2hfc2l6ZT0zMiwgICMgTnVtYmVyIG9mIHNhbXBsZXMgcGVyIGJhdGNoCiAgICBsYWJlbF9tb2RlPSdpbnQnICAjIExhYmVscyBhcmUgcmV0dXJuZWQgYXMgaW50ZWdlcnMKKQoKIyBJbnNwZWN0IHRoZSBkYXRhc2V0CmZvciBpbWFnZXMsIGxhYmVscyBpbiBkYXRhc2V0LnRha2UoMSk6CiAgICBwcmludCgiSW1hZ2VzOiAiLCBpbWFnZXMuc2hhcGUpCiAgICBwcmludCgiTGFiZWxzOiAiLCBsYWJlbHMp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Define the directory path
directory_path = 'path/to/your/images'

# Create a dataset from the directory
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    directory_path,
    image_size=(256, 256),  # Resize images to 256x256
    batch_size=32,  # Number of samples per batch
    label_mode='int'  # Labels are returned as integers
)

# Inspect the dataset
for images, labels in dataset.take(1):
    print(&quot;Images: &quot;, images.shape)
    print(&quot;Labels: &quot;, labels)</pre></div><div class='content'></div><h1>Data Preprocessing</h1>
<div class='content'></div><h2>Normalization</h2>
<div class='content'><p>Normalization is a common preprocessing step that scales the features to a standard range, usually [0, 1] or [-1, 1].</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIG5vcm1hbGl6ZShpbWFnZSwgbGFiZWwpOgogICAgaW1hZ2UgPSB0Zi5jYXN0KGltYWdlLCB0Zi5mbG9hdDMyKSAvIDI1NS4wCiAgICByZXR1cm4gaW1hZ2UsIGxhYmVsCgojIEFwcGx5IG5vcm1hbGl6YXRpb24gdG8gdGhlIGRhdGFzZXQKbm9ybWFsaXplZF9kYXRhc2V0ID0gZGF0YXNldC5tYXAobm9ybWFsaXplKQoKIyBJbnNwZWN0IHRoZSBub3JtYWxpemVkIGRhdGFzZXQKZm9yIGltYWdlcywgbGFiZWxzIGluIG5vcm1hbGl6ZWRfZGF0YXNldC50YWtlKDEpOgogICAgcHJpbnQoIk5vcm1hbGl6ZWQgSW1hZ2VzOiAiLCBpbWFnZXNbMF0pCiAgICBwcmludCgiTGFiZWxzOiAiLCBsYWJlbHMp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def normalize(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Apply normalization to the dataset
normalized_dataset = dataset.map(normalize)

# Inspect the normalized dataset
for images, labels in normalized_dataset.take(1):
    print(&quot;Normalized Images: &quot;, images[0])
    print(&quot;Labels: &quot;, labels)</pre></div><div class='content'></div><h2>Data Augmentation</h2>
<div class='content'><p>Data augmentation is a technique to artificially increase the size of the training dataset by creating modified versions of images in the dataset.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGF0YV9hdWdtZW50YXRpb24gPSB0Zi5rZXJhcy5TZXF1ZW50aWFsKFsKICAgIHRmLmtlcmFzLmxheWVycy5SYW5kb21GbGlwKCJob3Jpem9udGFsX2FuZF92ZXJ0aWNhbCIpLAogICAgdGYua2VyYXMubGF5ZXJzLlJhbmRvbVJvdGF0aW9uKDAuMiksCl0pCgojIEFwcGx5IGRhdGEgYXVnbWVudGF0aW9uIHRvIHRoZSBkYXRhc2V0CmF1Z21lbnRlZF9kYXRhc2V0ID0gbm9ybWFsaXplZF9kYXRhc2V0Lm1hcChsYW1iZGEgeCwgeTogKGRhdGFfYXVnbWVudGF0aW9uKHgsIHRyYWluaW5nPVRydWUpLCB5KSkKCiMgSW5zcGVjdCB0aGUgYXVnbWVudGVkIGRhdGFzZXQKZm9yIGltYWdlcywgbGFiZWxzIGluIGF1Z21lbnRlZF9kYXRhc2V0LnRha2UoMSk6CiAgICBwcmludCgiQXVnbWVudGVkIEltYWdlczogIiwgaW1hZ2VzWzBdKQogICAgcHJpbnQoIkxhYmVsczogIiwgbGFiZWxzKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip(&quot;horizontal_and_vertical&quot;),
    tf.keras.layers.RandomRotation(0.2),
])

# Apply data augmentation to the dataset
augmented_dataset = normalized_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))

# Inspect the augmented dataset
for images, labels in augmented_dataset.take(1):
    print(&quot;Augmented Images: &quot;, images[0])
    print(&quot;Labels: &quot;, labels)</pre></div><div class='content'></div><h2>Splitting Data</h2>
<div class='content'><p>Splitting the dataset into training, validation, and test sets is essential for evaluating the performance of your model.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZWZpbmUgdGhlIHNwbGl0IHNpemVzCnRyYWluX3NpemUgPSAwLjcKdmFsX3NpemUgPSAwLjE1CnRlc3Rfc2l6ZSA9IDAuMTUKCiMgQ2FsY3VsYXRlIHRoZSBudW1iZXIgb2Ygc2FtcGxlcwp0b3RhbF9zYW1wbGVzID0gbGVuKGxpc3QoZGF0YXNldCkpCnRyYWluX3NhbXBsZXMgPSBpbnQodHJhaW5fc2l6ZSAqIHRvdGFsX3NhbXBsZXMpCnZhbF9zYW1wbGVzID0gaW50KHZhbF9zaXplICogdG90YWxfc2FtcGxlcykKCiMgU3BsaXQgdGhlIGRhdGFzZXQKdHJhaW5fZGF0YXNldCA9IGRhdGFzZXQudGFrZSh0cmFpbl9zYW1wbGVzKQp2YWxfZGF0YXNldCA9IGRhdGFzZXQuc2tpcCh0cmFpbl9zYW1wbGVzKS50YWtlKHZhbF9zYW1wbGVzKQp0ZXN0X2RhdGFzZXQgPSBkYXRhc2V0LnNraXAodHJhaW5fc2FtcGxlcyArIHZhbF9zYW1wbGVzKQoKIyBJbnNwZWN0IHRoZSBzcGxpdHMKcHJpbnQoZiJUcmFpbmluZyBzYW1wbGVzOiB7bGVuKGxpc3QodHJhaW5fZGF0YXNldCkpfSIpCnByaW50KGYiVmFsaWRhdGlvbiBzYW1wbGVzOiB7bGVuKGxpc3QodmFsX2RhdGFzZXQpKX0iKQpwcmludChmIlRlc3Qgc2FtcGxlczoge2xlbihsaXN0KHRlc3RfZGF0YXNldCkpfSIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Define the split sizes
train_size = 0.7
val_size = 0.15
test_size = 0.15

# Calculate the number of samples
total_samples = len(list(dataset))
train_samples = int(train_size * total_samples)
val_samples = int(val_size * total_samples)

# Split the dataset
train_dataset = dataset.take(train_samples)
val_dataset = dataset.skip(train_samples).take(val_samples)
test_dataset = dataset.skip(train_samples + val_samples)

# Inspect the splits
print(f&quot;Training samples: {len(list(train_dataset))}&quot;)
print(f&quot;Validation samples: {len(list(val_dataset))}&quot;)
print(f&quot;Test samples: {len(list(test_dataset))}&quot;)</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this section, we covered the essential steps for loading and preprocessing data in TensorFlow. We learned how to:</p>
<ul>
<li>Load data from CSV files and image directories.</li>
<li>Normalize and augment data.</li>
<li>Split data into training, validation, and test sets.</li>
</ul>
<p>These steps are fundamental for preparing your data for machine learning tasks. Proper data loading and preprocessing can significantly improve the performance and reliability of your models.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='eager-execution'>&#x25C4;Eager Execution</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Loading and Preprocessing Data</a>
	</div>
	<div class='col-4 text-end'>
					<a href='datasets-and-iterators'>Datasets and Iterators &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
