<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Loss Functions and Optimizers</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/04-04-loss-functions-and-optimizers" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/04-04-loss-functions-and-optimizers" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/04-04-loss-functions-and-optimizers" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/tensorflow/04-04-loss-functions-and-optimizers" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/tensorflow/04-04-loss-functions-and-optimizers" class="px-2">CA</a>
<br>
			<cite>Building today's and tomorrow's society</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
									<a href="./">Course Content</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Technical Skills</a>
				<a href="/all/conocimientos">Knowledge</a>
				<a href="/all/soft_skills">Social Skills</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-activation-functions' title="Activation Functions">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Loss Functions and Optimizers</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-01-introduction-to-cnns' title="Introduction to CNNs">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will delve into the core concepts of loss functions and optimizers, which are crucial for training neural networks. Understanding these concepts will help you build more effective and efficient models.</p>
</div><h1><ol>
<li>Introduction to Loss Functions</li>
</ol>
</h1>
<div class='content'><p>Loss functions, also known as cost functions or objective functions, measure how well a neural network's predictions match the actual data. The goal of training a neural network is to minimize the loss function.</p>
</div><h2><p>Key Concepts:</p>
</h2>
<div class='content'><ul>
<li><strong>Prediction Error</strong>: The difference between the predicted value and the actual value.</li>
<li><strong>Minimization</strong>: The process of adjusting the model parameters to reduce the loss.</li>
</ul>
</div><h2><p>Common Loss Functions:</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Mean Squared Error (MSE)</strong>:</p>
<ul>
<li>Used for regression tasks.</li>
<li>Formula: \( \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \)</li>
<li>Where \( y_i \) is the actual value and \( \hat{y}_i \) is the predicted value.</li>
</ul>
</li>
<li>
<p><strong>Binary Cross-Entropy</strong>:</p>
<ul>
<li>Used for binary classification tasks.</li>
<li>Formula: \( \text{Binary Cross-Entropy} = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)] \)</li>
</ul>
</li>
<li>
<p><strong>Categorical Cross-Entropy</strong>:</p>
<ul>
<li>Used for multi-class classification tasks.</li>
<li>Formula: \( \text{Categorical Cross-Entropy} = -\sum_{i=1}^{n} y_i \log(\hat{y}_i) \)</li>
</ul>
</li>
</ol>
</div><h2><p>Example Code:</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRXhhbXBsZSBvZiBNZWFuIFNxdWFyZWQgRXJyb3IKbXNlID0gdGYua2VyYXMubG9zc2VzLk1lYW5TcXVhcmVkRXJyb3IoKQp5X3RydWUgPSBbMC4wLCAxLjAsIDAuMCwgMC4wXQp5X3ByZWQgPSBbMC4xLCAwLjksIDAuMiwgMC4wXQpsb3NzID0gbXNlKHlfdHJ1ZSwgeV9wcmVkKQpwcmludCgnTWVhbiBTcXVhcmVkIEVycm9yOicsIGxvc3MubnVtcHkoKSkKCiMgRXhhbXBsZSBvZiBCaW5hcnkgQ3Jvc3MtRW50cm9weQpiY2UgPSB0Zi5rZXJhcy5sb3NzZXMuQmluYXJ5Q3Jvc3NlbnRyb3B5KCkKeV90cnVlID0gWzAsIDEsIDAsIDBdCnlfcHJlZCA9IFswLjEsIDAuOSwgMC4yLCAwLjBdCmxvc3MgPSBiY2UoeV90cnVlLCB5X3ByZWQpCnByaW50KCdCaW5hcnkgQ3Jvc3MtRW50cm9weTonLCBsb3NzLm51bXB5KCkp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Example of Mean Squared Error
mse = tf.keras.losses.MeanSquaredError()
y_true = [0.0, 1.0, 0.0, 0.0]
y_pred = [0.1, 0.9, 0.2, 0.0]
loss = mse(y_true, y_pred)
print('Mean Squared Error:', loss.numpy())

# Example of Binary Cross-Entropy
bce = tf.keras.losses.BinaryCrossentropy()
y_true = [0, 1, 0, 0]
y_pred = [0.1, 0.9, 0.2, 0.0]
loss = bce(y_true, y_pred)
print('Binary Cross-Entropy:', loss.numpy())</pre></div><div class='content'></div><h1><ol start="2">
<li>Introduction to Optimizers</li>
</ol>
</h1>
<div class='content'><p>Optimizers are algorithms or methods used to change the attributes of the neural network, such as weights and learning rate, to reduce the losses.</p>
</div><h2><p>Key Concepts:</p>
</h2>
<div class='content'><ul>
<li><strong>Gradient Descent</strong>: The most common optimization algorithm used to minimize the loss function.</li>
<li><strong>Learning Rate</strong>: A hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.</li>
</ul>
</div><h2><p>Common Optimizers:</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Stochastic Gradient Descent (SGD)</strong>:</p>
<ul>
<li>Updates the model parameters using the gradient of the loss function.</li>
<li>Formula: \( \theta = \theta - \eta \nabla_\theta J(\theta) \)</li>
<li>Where \( \theta \) is the parameter, \( \eta \) is the learning rate, and \( \nabla_\theta J(\theta) \) is the gradient of the loss function.</li>
</ul>
</li>
<li>
<p><strong>Adam (Adaptive Moment Estimation)</strong>:</p>
<ul>
<li>Combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp.</li>
<li>Formula: \( m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t \)
\( v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \)
\( \hat{m}_t = \frac{m_t}{1 - \beta_1^t} \)
\( \hat{v}<em>t = \frac{v_t}{1 - \beta_2^t} \)
\( \theta_t = \theta</em>{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \)</li>
</ul>
</li>
</ol>
</div><h2><p>Example Code:</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRXhhbXBsZSBvZiBTdG9jaGFzdGljIEdyYWRpZW50IERlc2NlbnQKbW9kZWwgPSB0Zi5rZXJhcy5TZXF1ZW50aWFsKFt0Zi5rZXJhcy5sYXllcnMuRGVuc2UoMSwgaW5wdXRfc2hhcGU9KDEsKSldKQptb2RlbC5jb21waWxlKG9wdGltaXplcj10Zi5rZXJhcy5vcHRpbWl6ZXJzLlNHRChsZWFybmluZ19yYXRlPTAuMDEpLCBsb3NzPSdtc2UnKQoKIyBFeGFtcGxlIG9mIEFkYW0gT3B0aW1pemVyCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPXRmLmtlcmFzLm9wdGltaXplcnMuQWRhbShsZWFybmluZ19yYXRlPTAuMDAxKSwgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Example of Stochastic Gradient Descent
model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mse')

# Example of Adam Optimizer
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy')</pre></div><div class='content'></div><h1><ol start="3">
<li>Practical Exercise</li>
</ol>
</h1>
<div class='content'></div><h2><p>Task:</p>
</h2>
<div class='content'><p>Create a simple neural network to classify the Iris dataset using TensorFlow. Use the Adam optimizer and categorical cross-entropy loss function.</p>
</div><h2><p>Steps:</p>
</h2>
<div class='content'><ol>
<li>Load the Iris dataset.</li>
<li>Preprocess the data.</li>
<li>Build the neural network model.</li>
<li>Compile the model with the Adam optimizer and categorical cross-entropy loss function.</li>
<li>Train the model.</li>
<li>Evaluate the model.</li>
</ol>
</div><h2><p>Solution:</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ucHJlcHJvY2Vzc2luZyBpbXBvcnQgT25lSG90RW5jb2RlcgoKIyBMb2FkIGFuZCBwcmVwcm9jZXNzIHRoZSBkYXRhCmlyaXMgPSBsb2FkX2lyaXMoKQpYID0gaXJpcy5kYXRhCnkgPSBpcmlzLnRhcmdldC5yZXNoYXBlKC0xLCAxKQoKZW5jb2RlciA9IE9uZUhvdEVuY29kZXIoc3BhcnNlPUZhbHNlKQp5ID0gZW5jb2Rlci5maXRfdHJhbnNmb3JtKHkpCgpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBCdWlsZCB0aGUgbW9kZWwKbW9kZWwgPSB0Zi5rZXJhcy5TZXF1ZW50aWFsKFsKICAgIHRmLmtlcmFzLmxheWVycy5EZW5zZSgxMCwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSg0LCkpLAogICAgdGYua2VyYXMubGF5ZXJzLkRlbnNlKDEwLCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICB0Zi5rZXJhcy5sYXllcnMuRGVuc2UoMywgYWN0aXZhdGlvbj0nc29mdG1heCcpCl0pCgojIENvbXBpbGUgdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPXRmLmtlcmFzLm9wdGltaXplcnMuQWRhbShsZWFybmluZ19yYXRlPTAuMDAxKSwgbG9zcz0nY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5JywgbWV0cmljcz1bJ2FjY3VyYWN5J10pCgojIFRyYWluIHRoZSBtb2RlbAptb2RlbC5maXQoWF90cmFpbiwgeV90cmFpbiwgZXBvY2hzPTUwLCBiYXRjaF9zaXplPTUsIHZlcmJvc2U9MSkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmxvc3MsIGFjY3VyYWN5ID0gbW9kZWwuZXZhbHVhdGUoWF90ZXN0LCB5X3Rlc3QsIHZlcmJvc2U9MCkKcHJpbnQoZidUZXN0IExvc3M6IHtsb3NzOi40Zn0sIFRlc3QgQWNjdXJhY3k6IHthY2N1cmFjeTouNGZ9Jyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Load and preprocess the data
iris = load_iris()
X = iris.data
y = iris.target.reshape(-1, 1)

encoder = OneHotEncoder(sparse=False)
y = encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')</pre></div><div class='content'></div><h1><ol start="4">
<li>Summary</li>
</ol>
</h1>
<div class='content'><p>In this section, we covered:</p>
<ul>
<li>The importance of loss functions in measuring the performance of a neural network.</li>
<li>Different types of loss functions such as Mean Squared Error, Binary Cross-Entropy, and Categorical Cross-Entropy.</li>
<li>The role of optimizers in adjusting the model parameters to minimize the loss.</li>
<li>Common optimizers like Stochastic Gradient Descent and Adam.</li>
<li>A practical exercise to apply these concepts in a real-world scenario.</li>
</ul>
<p>Understanding loss functions and optimizers is crucial for training effective neural networks. In the next module, we will explore Convolutional Neural Networks (CNNs) and their applications.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-activation-functions' title="Activation Functions">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-01-introduction-to-cnns' title="Introduction to CNNs">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
