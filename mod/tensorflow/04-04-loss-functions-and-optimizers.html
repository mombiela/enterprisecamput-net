<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Loss Functions and Optimizers</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/04-04-loss-functions-and-optimizers" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/04-04-loss-functions-and-optimizers" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/04-04-loss-functions-and-optimizers" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/tensorflow/04-04-loss-functions-and-optimizers" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/tensorflow/04-04-loss-functions-and-optimizers" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Course Content
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-activation-functions' title="Activation Functions">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Loss Functions and Optimizers</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-01-introduction-to-cnns' title="Introduction to CNNs">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will delve into the core concepts of loss functions and optimizers, which are crucial for training neural networks. Understanding these concepts will help you build more effective and efficient models.</p>
</div><h1><ol>
<li>Introduction to Loss Functions</li>
</ol></h1>
<div class='content'><p>Loss functions, also known as cost functions or objective functions, measure how well a neural network's predictions match the actual data. The goal of training a neural network is to minimize the loss function.</p>
</div><h2>Key Concepts:</h2>
<div class='content'><ul>
<li><strong>Prediction Error</strong>: The difference between the predicted value and the actual value.</li>
<li><strong>Minimization</strong>: The process of adjusting the model parameters to reduce the loss.</li>
</ul>
</div><h2>Common Loss Functions:</h2>
<div class='content'><ol>
<li>
<p><strong>Mean Squared Error (MSE)</strong>:</p>
<ul>
<li>Used for regression tasks.</li>
<li>Formula: \( \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \)</li>
<li>Where \( y_i \) is the actual value and \( \hat{y}_i \) is the predicted value.</li>
</ul>
</li>
<li>
<p><strong>Binary Cross-Entropy</strong>:</p>
<ul>
<li>Used for binary classification tasks.</li>
<li>Formula: \( \text{Binary Cross-Entropy} = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)] \)</li>
</ul>
</li>
<li>
<p><strong>Categorical Cross-Entropy</strong>:</p>
<ul>
<li>Used for multi-class classification tasks.</li>
<li>Formula: \( \text{Categorical Cross-Entropy} = -\sum_{i=1}^{n} y_i \log(\hat{y}_i) \)</li>
</ul>
</li>
</ol>
</div><h2>Example Code:</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRXhhbXBsZSBvZiBNZWFuIFNxdWFyZWQgRXJyb3IKbXNlID0gdGYua2VyYXMubG9zc2VzLk1lYW5TcXVhcmVkRXJyb3IoKQp5X3RydWUgPSBbMC4wLCAxLjAsIDAuMCwgMC4wXQp5X3ByZWQgPSBbMC4xLCAwLjksIDAuMiwgMC4wXQpsb3NzID0gbXNlKHlfdHJ1ZSwgeV9wcmVkKQpwcmludCgnTWVhbiBTcXVhcmVkIEVycm9yOicsIGxvc3MubnVtcHkoKSkKCiMgRXhhbXBsZSBvZiBCaW5hcnkgQ3Jvc3MtRW50cm9weQpiY2UgPSB0Zi5rZXJhcy5sb3NzZXMuQmluYXJ5Q3Jvc3NlbnRyb3B5KCkKeV90cnVlID0gWzAsIDEsIDAsIDBdCnlfcHJlZCA9IFswLjEsIDAuOSwgMC4yLCAwLjBdCmxvc3MgPSBiY2UoeV90cnVlLCB5X3ByZWQpCnByaW50KCdCaW5hcnkgQ3Jvc3MtRW50cm9weTonLCBsb3NzLm51bXB5KCkp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Example of Mean Squared Error
mse = tf.keras.losses.MeanSquaredError()
y_true = [0.0, 1.0, 0.0, 0.0]
y_pred = [0.1, 0.9, 0.2, 0.0]
loss = mse(y_true, y_pred)
print('Mean Squared Error:', loss.numpy())

# Example of Binary Cross-Entropy
bce = tf.keras.losses.BinaryCrossentropy()
y_true = [0, 1, 0, 0]
y_pred = [0.1, 0.9, 0.2, 0.0]
loss = bce(y_true, y_pred)
print('Binary Cross-Entropy:', loss.numpy())</pre></div><div class='content'></div><h1><ol start="2">
<li>Introduction to Optimizers</li>
</ol></h1>
<div class='content'><p>Optimizers are algorithms or methods used to change the attributes of the neural network, such as weights and learning rate, to reduce the losses.</p>
</div><h2>Key Concepts:</h2>
<div class='content'><ul>
<li><strong>Gradient Descent</strong>: The most common optimization algorithm used to minimize the loss function.</li>
<li><strong>Learning Rate</strong>: A hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.</li>
</ul>
</div><h2>Common Optimizers:</h2>
<div class='content'><ol>
<li>
<p><strong>Stochastic Gradient Descent (SGD)</strong>:</p>
<ul>
<li>Updates the model parameters using the gradient of the loss function.</li>
<li>Formula: \( \theta = \theta - \eta \nabla_\theta J(\theta) \)</li>
<li>Where \( \theta \) is the parameter, \( \eta \) is the learning rate, and \( \nabla_\theta J(\theta) \) is the gradient of the loss function.</li>
</ul>
</li>
<li>
<p><strong>Adam (Adaptive Moment Estimation)</strong>:</p>
<ul>
<li>Combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp.</li>
<li>Formula: \( m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t \)
\( v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \)
\( \hat{m}_t = \frac{m_t}{1 - \beta_1^t} \)
\( \hat{v}<em>t = \frac{v_t}{1 - \beta_2^t} \)
\( \theta_t = \theta</em>{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} \)</li>
</ul>
</li>
</ol>
</div><h2>Example Code:</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRXhhbXBsZSBvZiBTdG9jaGFzdGljIEdyYWRpZW50IERlc2NlbnQKbW9kZWwgPSB0Zi5rZXJhcy5TZXF1ZW50aWFsKFt0Zi5rZXJhcy5sYXllcnMuRGVuc2UoMSwgaW5wdXRfc2hhcGU9KDEsKSldKQptb2RlbC5jb21waWxlKG9wdGltaXplcj10Zi5rZXJhcy5vcHRpbWl6ZXJzLlNHRChsZWFybmluZ19yYXRlPTAuMDEpLCBsb3NzPSdtc2UnKQoKIyBFeGFtcGxlIG9mIEFkYW0gT3B0aW1pemVyCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPXRmLmtlcmFzLm9wdGltaXplcnMuQWRhbShsZWFybmluZ19yYXRlPTAuMDAxKSwgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Example of Stochastic Gradient Descent
model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='mse')

# Example of Adam Optimizer
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy')</pre></div><div class='content'></div><h1><ol start="3">
<li>Practical Exercise</li>
</ol></h1>
<div class='content'></div><h2>Task:</h2>
<div class='content'><p>Create a simple neural network to classify the Iris dataset using TensorFlow. Use the Adam optimizer and categorical cross-entropy loss function.</p>
</div><h2>Steps:</h2>
<div class='content'><ol>
<li>Load the Iris dataset.</li>
<li>Preprocess the data.</li>
<li>Build the neural network model.</li>
<li>Compile the model with the Adam optimizer and categorical cross-entropy loss function.</li>
<li>Train the model.</li>
<li>Evaluate the model.</li>
</ol>
</div><h2>Solution:</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ucHJlcHJvY2Vzc2luZyBpbXBvcnQgT25lSG90RW5jb2RlcgoKIyBMb2FkIGFuZCBwcmVwcm9jZXNzIHRoZSBkYXRhCmlyaXMgPSBsb2FkX2lyaXMoKQpYID0gaXJpcy5kYXRhCnkgPSBpcmlzLnRhcmdldC5yZXNoYXBlKC0xLCAxKQoKZW5jb2RlciA9IE9uZUhvdEVuY29kZXIoc3BhcnNlPUZhbHNlKQp5ID0gZW5jb2Rlci5maXRfdHJhbnNmb3JtKHkpCgpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBCdWlsZCB0aGUgbW9kZWwKbW9kZWwgPSB0Zi5rZXJhcy5TZXF1ZW50aWFsKFsKICAgIHRmLmtlcmFzLmxheWVycy5EZW5zZSgxMCwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSg0LCkpLAogICAgdGYua2VyYXMubGF5ZXJzLkRlbnNlKDEwLCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICB0Zi5rZXJhcy5sYXllcnMuRGVuc2UoMywgYWN0aXZhdGlvbj0nc29mdG1heCcpCl0pCgojIENvbXBpbGUgdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPXRmLmtlcmFzLm9wdGltaXplcnMuQWRhbShsZWFybmluZ19yYXRlPTAuMDAxKSwgbG9zcz0nY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5JywgbWV0cmljcz1bJ2FjY3VyYWN5J10pCgojIFRyYWluIHRoZSBtb2RlbAptb2RlbC5maXQoWF90cmFpbiwgeV90cmFpbiwgZXBvY2hzPTUwLCBiYXRjaF9zaXplPTUsIHZlcmJvc2U9MSkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmxvc3MsIGFjY3VyYWN5ID0gbW9kZWwuZXZhbHVhdGUoWF90ZXN0LCB5X3Rlc3QsIHZlcmJvc2U9MCkKcHJpbnQoZidUZXN0IExvc3M6IHtsb3NzOi40Zn0sIFRlc3QgQWNjdXJhY3k6IHthY2N1cmFjeTouNGZ9Jyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Load and preprocess the data
iris = load_iris()
X = iris.data
y = iris.target.reshape(-1, 1)

encoder = OneHotEncoder(sparse=False)
y = encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')</pre></div><div class='content'></div><h1><ol start="4">
<li>Summary</li>
</ol></h1>
<div class='content'><p>In this section, we covered:</p>
<ul>
<li>The importance of loss functions in measuring the performance of a neural network.</li>
<li>Different types of loss functions such as Mean Squared Error, Binary Cross-Entropy, and Categorical Cross-Entropy.</li>
<li>The role of optimizers in adjusting the model parameters to minimize the loss.</li>
<li>Common optimizers like Stochastic Gradient Descent and Adam.</li>
<li>A practical exercise to apply these concepts in a real-world scenario.</li>
</ul>
<p>Understanding loss functions and optimizers is crucial for training effective neural networks. In the next module, we will explore Convolutional Neural Networks (CNNs) and their applications.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-activation-functions' title="Activation Functions">
				<span class="d-none d-md-inline">&#x25C4; Previous</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-01-introduction-to-cnns' title="Introduction to CNNs">
				<span class="d-none d-md-inline">Next &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>TensorFlow Course</h1>
<h2>Module 1: Introduction to TensorFlow</h2>
<ul>
<li><a href="01-01-what-is-tensorflow">What is TensorFlow?</a></li>
<li><a href="01-02-setting-up-tensorflow">Setting Up TensorFlow</a></li>
<li><a href="01-03-basic-tensorflow-concepts">Basic TensorFlow Concepts</a></li>
<li><a href="01-04-tensorflow-hello-world">TensorFlow Hello World</a></li>
</ul>
<h2>Module 2: TensorFlow Basics</h2>
<ul>
<li><a href="02-01-tensors-and-operations">Tensors and Operations</a></li>
<li><a href="02-02-variables-and-constants">Variables and Constants</a></li>
<li><a href="02-03-tensorflow-graphs">TensorFlow Graphs</a></li>
<li><a href="02-04-eager-execution">Eager Execution</a></li>
</ul>
<h2>Module 3: Data Handling in TensorFlow</h2>
<ul>
<li><a href="03-01-loading-data">Loading Data</a></li>
<li><a href="03-02-data-pipelines-with-tf-data">Data Pipelines with tf.data</a></li>
<li><a href="03-03-data-augmentation">Data Augmentation</a></li>
<li><a href="03-04-working-with-datasets">Working with Datasets</a></li>
</ul>
<h2>Module 4: Building Neural Networks</h2>
<ul>
<li><a href="04-01-introduction-to-neural-networks">Introduction to Neural Networks</a></li>
<li><a href="04-02-creating-a-simple-neural-network">Creating a Simple Neural Network</a></li>
<li><a href="04-03-activation-functions">Activation Functions</a></li>
<li><a href="04-04-loss-functions-and-optimizers">Loss Functions and Optimizers</a></li>
</ul>
<h2>Module 5: Convolutional Neural Networks (CNNs)</h2>
<ul>
<li><a href="05-01-introduction-to-cnns">Introduction to CNNs</a></li>
<li><a href="05-02-building-a-cnn">Building a CNN</a></li>
<li><a href="05-03-pooling-layers">Pooling Layers</a></li>
<li><a href="05-04-advanced-cnn-architectures">Advanced CNN Architectures</a></li>
</ul>
<h2>Module 6: Recurrent Neural Networks (RNNs)</h2>
<ul>
<li><a href="06-01-introduction-to-rnns">Introduction to RNNs</a></li>
<li><a href="06-02-building-an-rnn">Building an RNN</a></li>
<li><a href="06-03-long-short-term-memory">Long Short-Term Memory (LSTM)</a></li>
<li><a href="06-04-gated-recurrent-units">Gated Recurrent Units (GRUs)</a></li>
</ul>
<h2>Module 7: Advanced TensorFlow Techniques</h2>
<ul>
<li><a href="07-01-custom-layers-and-models">Custom Layers and Models</a></li>
<li><a href="07-02-tensorflow-hub">TensorFlow Hub</a></li>
<li><a href="07-03-transfer-learning">Transfer Learning</a></li>
<li><a href="07-04-hyperparameter-tuning">Hyperparameter Tuning</a></li>
</ul>
<h2>Module 8: TensorFlow for Production</h2>
<ul>
<li><a href="08-01-model-saving-and-loading">Model Saving and Loading</a></li>
<li><a href="08-02-tensorflow-serving">TensorFlow Serving</a></li>
<li><a href="08-03-deploying-models">Deploying Models</a></li>
<li><a href="08-04-monitoring-and-maintenance">Monitoring and Maintenance</a></li>
</ul>
<h2>Module 9: TensorFlow Extended (TFX)</h2>
<ul>
<li><a href="09-01-introduction-to-tfx">Introduction to TFX</a></li>
<li><a href="09-02-data-validation">Data Validation</a></li>
<li><a href="09-03-transforming-data">Transforming Data</a></li>
<li><a href="09-04-model-analysis">Model Analysis</a></li>
</ul>
<h2>Module 10: Special Topics</h2>
<ul>
<li><a href="10-01-tensorflow-lite">TensorFlow Lite</a></li>
<li><a href="10-02-tensorflow-js">TensorFlow.js</a></li>
<li><a href="10-03-tensorflow-federated">TensorFlow Federated</a></li>
<li><a href="10-04-tensorflow-quantum">TensorFlow Quantum</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">The Project</a> | 
<a href="/about">About Us</a> | 
<a href="/contribute">Contribute</a> | 
<a href="/donate">Donations</a> | 
<a href="/licence">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
