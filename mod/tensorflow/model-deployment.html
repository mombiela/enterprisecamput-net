<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model Deployment</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/model-deployment" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/model-deployment" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/model-deployment" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/tensorflow/model-deployment" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/tensorflow/model-deployment" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='tensorflow-serving'>&#x25C4;TensorFlow Serving</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Model Deployment</a>
	</div>
	<div class='col-4 text-end'>
					<a href='tensorflow-lite'>TensorFlow Lite &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Model deployment is the process of making your trained machine learning model available for use in a production environment. This involves several steps, from exporting the model to serving it via an API or integrating it into an application. In this section, we will cover the essentials of deploying TensorFlow models, from beginner to advanced levels.</p>
</div><h1>Introduction to Model Deployment</h1>
<div class='content'><ul>
<li><strong>Definition</strong>: Model deployment is the process of integrating a machine learning model into an existing production environment to make predictions based on new data.</li>
<li><strong>Importance</strong>: Deployment allows the model to be used in real-world applications, providing value by making predictions on live data.</li>
</ul>
</div><h1>Exporting a TensorFlow Model</h1>
<div class='content'><p>Before deploying a model, it needs to be exported in a format that can be easily loaded and used in production.</p>
</div><h2>Saving a Model</h2>
<div class='content'><p>TensorFlow provides several ways to save a model. The most common method is using the <code>tf.keras</code> API.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgQXNzdW1lIGBtb2RlbGAgaXMgYSBwcmUtdHJhaW5lZCBUZW5zb3JGbG93IG1vZGVsCm1vZGVsLnNhdmUoJ3BhdGhfdG9fbXlfbW9kZWwnKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Assume `model` is a pre-trained TensorFlow model
model.save('path_to_my_model')</pre></div><div class='content'><ul>
<li><strong>HDF5 Format</strong>: The default format when saving a model with <code>model.save()</code>.</li>
<li><strong>SavedModel Format</strong>: A more comprehensive format that includes the model architecture, weights, and training configuration.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwuc2F2ZSgncGF0aF90b19teV9tb2RlbCcsIHNhdmVfZm9ybWF0PSd0Zicp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model.save('path_to_my_model', save_format='tf')</pre></div><div class='content'></div><h2>Loading a Model</h2>
<div class='content'><p>To load a saved model, use the <code>tf.keras.models.load_model</code> function.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bG9hZGVkX21vZGVsID0gdGYua2VyYXMubW9kZWxzLmxvYWRfbW9kZWwoJ3BhdGhfdG9fbXlfbW9kZWwnKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>loaded_model = tf.keras.models.load_model('path_to_my_model')</pre></div><div class='content'></div><h1>Serving a TensorFlow Model</h1>
<div class='content'><p>Once the model is saved, it can be served using TensorFlow Serving, a flexible, high-performance serving system for machine learning models.</p>
</div><h2>TensorFlow Serving</h2>
<div class='content'><p>TensorFlow Serving is designed for production environments and supports serving multiple models and versions.</p>
<h4>Installing TensorFlow Serving</h4>
<p>TensorFlow Serving can be installed using Docker, which simplifies the setup process.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZG9ja2VyIHB1bGwgdGVuc29yZmxvdy9zZXJ2aW5n"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>docker pull tensorflow/serving</pre></div><div class='content'><h4>Serving a Model with TensorFlow Serving</h4>
<ol>
<li><strong>Start TensorFlow Serving</strong>: Use Docker to start a TensorFlow Serving container.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZG9ja2VyIHJ1biAtcCA4NTAxOjg1MDEgLS1uYW1lPXRmX3NlcnZpbmcgXAogIC0tbW91bnQgdHlwZT1iaW5kLHNvdXJjZT0vcGF0aF90b19teV9tb2RlbCx0YXJnZXQ9L21vZGVscy9teV9tb2RlbCBcCiAgLWUgTU9ERUxfTkFNRT1teV9tb2RlbCAtdCB0ZW5zb3JmbG93L3NlcnZpbmc="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>docker run -p 8501:8501 --name=tf_serving \
  --mount type=bind,source=/path_to_my_model,target=/models/my_model \
  -e MODEL_NAME=my_model -t tensorflow/serving</pre></div><div class='content'><ol start="2">
<li><strong>Send Requests to the Model</strong>: Use <code>curl</code> or any HTTP client to send requests to the served model.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y3VybCAtZCAneyJpbnN0YW5jZXMiOiBbWzEuMCwgMi4wLCA1LjBdXX0nIFwKICAtWCBQT1NUIGh0dHA6Ly9sb2NhbGhvc3Q6ODUwMS92MS9tb2RlbHMvbXlfbW9kZWw6cHJlZGljdA=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>curl -d '{&quot;instances&quot;: [[1.0, 2.0, 5.0]]}' \
  -X POST http://localhost:8501/v1/models/my_model:predict</pre></div><div class='content'></div><h2>Using TensorFlow Lite</h2>
<div class='content'><p>For deploying models on mobile and embedded devices, TensorFlow Lite is the preferred solution.</p>
<h4>Converting a Model to TensorFlow Lite</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y29udmVydGVyID0gdGYubGl0ZS5URkxpdGVDb252ZXJ0ZXIuZnJvbV9zYXZlZF9tb2RlbCgncGF0aF90b19teV9tb2RlbCcpCnRmbGl0ZV9tb2RlbCA9IGNvbnZlcnRlci5jb252ZXJ0KCkKCiMgU2F2ZSB0aGUgY29udmVydGVkIG1vZGVsCndpdGggb3BlbignbW9kZWwudGZsaXRlJywgJ3diJykgYXMgZjoKICAgIGYud3JpdGUodGZsaXRlX21vZGVsKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>converter = tf.lite.TFLiteConverter.from_saved_model('path_to_my_model')
tflite_model = converter.convert()

# Save the converted model
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)</pre></div><div class='content'><h4>Running Inference with TensorFlow Lite</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgTG9hZCB0aGUgVEZMaXRlIG1vZGVsIGFuZCBhbGxvY2F0ZSB0ZW5zb3JzCmludGVycHJldGVyID0gdGYubGl0ZS5JbnRlcnByZXRlcihtb2RlbF9wYXRoPSdtb2RlbC50ZmxpdGUnKQppbnRlcnByZXRlci5hbGxvY2F0ZV90ZW5zb3JzKCkKCiMgR2V0IGlucHV0IGFuZCBvdXRwdXQgdGVuc29ycwppbnB1dF9kZXRhaWxzID0gaW50ZXJwcmV0ZXIuZ2V0X2lucHV0X2RldGFpbHMoKQpvdXRwdXRfZGV0YWlscyA9IGludGVycHJldGVyLmdldF9vdXRwdXRfZGV0YWlscygpCgojIFByZXBhcmUgdGhlIGlucHV0IGRhdGEKaW5wdXRfZGF0YSA9IG5wLmFycmF5KFtbMS4wLCAyLjAsIDUuMF1dLCBkdHlwZT1ucC5mbG9hdDMyKQoKIyBQZXJmb3JtIGluZmVyZW5jZQppbnRlcnByZXRlci5zZXRfdGVuc29yKGlucHV0X2RldGFpbHNbMF1bJ2luZGV4J10sIGlucHV0X2RhdGEpCmludGVycHJldGVyLmludm9rZSgpCm91dHB1dF9kYXRhID0gaW50ZXJwcmV0ZXIuZ2V0X3RlbnNvcihvdXRwdXRfZGV0YWlsc1swXVsnaW5kZXgnXSkKcHJpbnQob3V0cHV0X2RhdGEp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Load the TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_path='model.tflite')
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Prepare the input data
input_data = np.array([[1.0, 2.0, 5.0]], dtype=np.float32)

# Perform inference
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)</pre></div><div class='content'></div><h1>Advanced Deployment Techniques</h1>
<div class='content'></div><h2>Using TensorFlow Extended (TFX)</h2>
<div class='content'><p>TFX is an end-to-end platform for deploying production machine learning pipelines.</p>
<ul>
<li><strong>Components</strong>: TFX includes components like <code>ExampleGen</code>, <code>Transform</code>, <code>Trainer</code>, <code>Evaluator</code>, and <code>Pusher</code>.</li>
<li><strong>Pipeline Orchestration</strong>: TFX pipelines can be orchestrated using Apache Airflow or Kubeflow.</li>
</ul>
</div><h2>Deploying on Cloud Platforms</h2>
<div class='content'><p>TensorFlow models can be deployed on various cloud platforms such as Google Cloud AI Platform, AWS SageMaker, and Azure Machine Learning.</p>
<h4>Google Cloud AI Platform</h4>
<ol>
<li><strong>Upload the Model</strong>: Upload the saved model to Google Cloud Storage.</li>
<li><strong>Create a Model on AI Platform</strong>: Use the Google Cloud Console or <code>gcloud</code> CLI to create a model.</li>
<li><strong>Deploy the Model</strong>: Deploy the model version to AI Platform.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Z2Nsb3VkIGFpLXBsYXRmb3JtIG1vZGVscyBjcmVhdGUgbXlfbW9kZWwKZ2Nsb3VkIGFpLXBsYXRmb3JtIHZlcnNpb25zIGNyZWF0ZSB2MSAtLW1vZGVsPW15X21vZGVsIC0tb3JpZ2luPWdzOi8vcGF0aF90b19teV9tb2RlbCAtLXJ1bnRpbWUtdmVyc2lvbj0yLjEgLS1weXRob24tdmVyc2lvbj0zLjc="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>gcloud ai-platform models create my_model
gcloud ai-platform versions create v1 --model=my_model --origin=gs://path_to_my_model --runtime-version=2.1 --python-version=3.7</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>Deploying a TensorFlow model involves several steps, from exporting the model to serving it in a production environment. Whether you are deploying on a local server, mobile device, or cloud platform, TensorFlow provides the tools and libraries necessary to make the process straightforward. By understanding the basics of model deployment and exploring advanced techniques, you can ensure your machine learning models are effectively integrated into real-world applications.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='tensorflow-serving'>&#x25C4;TensorFlow Serving</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Model Deployment</a>
	</div>
	<div class='col-4 text-end'>
					<a href='tensorflow-lite'>TensorFlow Lite &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
