<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Loss Functions and Optimizers</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/loss-functions-and-optimizers" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/loss-functions-and-optimizers" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/loss-functions-and-optimizers" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/tensorflow/loss-functions-and-optimizers" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/tensorflow/loss-functions-and-optimizers" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='activation-functions'>&#x25C4;Activation Functions</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Loss Functions and Optimizers</a>
	</div>
	<div class='col-4 text-end'>
					<a href='training-a-model'>Training a Model &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>In this section, we will explore the fundamental concepts of loss functions and optimizers in TensorFlow. Understanding these concepts is crucial for training machine learning models effectively. We will start with the basics and gradually move to more advanced topics.</p>
</div><h1>Loss Functions</h1>
<div class='content'></div><h2>What is a Loss Function?</h2>
<div class='content'><ul>
<li>A loss function measures how well a model's predictions match the actual data.</li>
<li>It quantifies the difference between the predicted output and the true output.</li>
<li>The goal of training a model is to minimize this loss.</li>
</ul>
</div><h2>Common Loss Functions</h2>
<div class='content'><ol>
<li>
<p><strong>Mean Squared Error (MSE)</strong></p>
<ul>
<li>Used for regression tasks.</li>
<li>Measures the average squared difference between predicted and actual values.</li>
</ul>
<pre><code class="language-python">import tensorflow as tf

y_true = [1.0, 2.0, 3.0]
y_pred = [1.5, 2.5, 3.5]
mse = tf.keras.losses.MeanSquaredError()
loss = mse(y_true, y_pred)
print('Mean Squared Error:', loss.numpy())
</code></pre>
</li>
<li>
<p><strong>Binary Cross-Entropy</strong></p>
<ul>
<li>Used for binary classification tasks.</li>
<li>Measures the difference between two probability distributions.</li>
</ul>
<pre><code class="language-python">y_true = [0, 1, 0, 1]
y_pred = [0.1, 0.9, 0.2, 0.8]
bce = tf.keras.losses.BinaryCrossentropy()
loss = bce(y_true, y_pred)
print('Binary Cross-Entropy:', loss.numpy())
</code></pre>
</li>
<li>
<p><strong>Categorical Cross-Entropy</strong></p>
<ul>
<li>Used for multi-class classification tasks.</li>
<li>Measures the difference between the true label distribution and the predicted label distribution.</li>
</ul>
<pre><code class="language-python">y_true = [[0, 1, 0], [0, 0, 1]]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
cce = tf.keras.losses.CategoricalCrossentropy()
loss = cce(y_true, y_pred)
print('Categorical Cross-Entropy:', loss.numpy())
</code></pre>
</li>
</ol>
</div><h2>Custom Loss Functions</h2>
<div class='content'><ul>
<li>You can create custom loss functions in TensorFlow.</li>
<li>Custom loss functions can be useful for specific tasks or when predefined loss functions do not meet your needs.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGN1c3RvbV9sb3NzKHlfdHJ1ZSwgeV9wcmVkKToKICAgIHJldHVybiB0Zi5yZWR1Y2VfbWVhbih0Zi5zcXVhcmUoeV90cnVlIC0geV9wcmVkKSkKCnlfdHJ1ZSA9IFsxLjAsIDIuMCwgMy4wXQp5X3ByZWQgPSBbMS41LCAyLjUsIDMuNV0KbG9zcyA9IGN1c3RvbV9sb3NzKHlfdHJ1ZSwgeV9wcmVkKQpwcmludCgnQ3VzdG9tIExvc3M6JywgbG9zcy5udW1weSgpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def custom_loss(y_true, y_pred):
    return tf.reduce_mean(tf.square(y_true - y_pred))

y_true = [1.0, 2.0, 3.0]
y_pred = [1.5, 2.5, 3.5]
loss = custom_loss(y_true, y_pred)
print('Custom Loss:', loss.numpy())</pre></div><div class='content'></div><h1>Optimizers</h1>
<div class='content'></div><h2>What is an Optimizer?</h2>
<div class='content'><ul>
<li>An optimizer adjusts the model's parameters to minimize the loss function.</li>
<li>It updates the weights and biases of the model based on the computed gradients.</li>
</ul>
</div><h2>Common Optimizers</h2>
<div class='content'><ol>
<li>
<p><strong>Stochastic Gradient Descent (SGD)</strong></p>
<ul>
<li>Updates parameters using the gradient of the loss function.</li>
</ul>
<pre><code class="language-python">model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(optimizer='sgd', loss='mean_squared_error')
</code></pre>
</li>
<li>
<p><strong>Adam</strong></p>
<ul>
<li>Combines the advantages of two other extensions of stochastic gradient descent.</li>
<li>Adaptive learning rate and momentum.</li>
</ul>
<pre><code class="language-python">model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(optimizer='adam', loss='mean_squared_error')
</code></pre>
</li>
<li>
<p><strong>RMSprop</strong></p>
<ul>
<li>Optimizer that divides the learning rate by an exponentially decaying average of squared gradients.</li>
</ul>
<pre><code class="language-python">model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(optimizer='rmsprop', loss='mean_squared_error')
</code></pre>
</li>
</ol>
</div><h2>Custom Optimizers</h2>
<div class='content'><ul>
<li>TensorFlow allows the creation of custom optimizers.</li>
<li>Custom optimizers can be useful for specific tasks or when predefined optimizers do not meet your needs.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgQ3VzdG9tT3B0aW1pemVyKHRmLmtlcmFzLm9wdGltaXplcnMuT3B0aW1pemVyKToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCBsZWFybmluZ19yYXRlPTAuMDEsIG5hbWU9IkN1c3RvbU9wdGltaXplciIsICoqa3dhcmdzKToKICAgICAgICBzdXBlcigpLl9faW5pdF9fKG5hbWUsICoqa3dhcmdzKQogICAgICAgIHNlbGYubGVhcm5pbmdfcmF0ZSA9IGxlYXJuaW5nX3JhdGUKCiAgICBkZWYgX3Jlc291cmNlX2FwcGx5X2RlbnNlKHNlbGYsIGdyYWQsIHZhciwgYXBwbHlfc3RhdGU9Tm9uZSk6CiAgICAgICAgdmFyLmFzc2lnbl9zdWIoc2VsZi5sZWFybmluZ19yYXRlICogZ3JhZCkKCm1vZGVsID0gdGYua2VyYXMuU2VxdWVudGlhbChbdGYua2VyYXMubGF5ZXJzLkRlbnNlKDEpXSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9Q3VzdG9tT3B0aW1pemVyKCksIGxvc3M9J21lYW5fc3F1YXJlZF9lcnJvcicp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class CustomOptimizer(tf.keras.optimizers.Optimizer):
    def __init__(self, learning_rate=0.01, name=&quot;CustomOptimizer&quot;, **kwargs):
        super().__init__(name, **kwargs)
        self.learning_rate = learning_rate

    def _resource_apply_dense(self, grad, var, apply_state=None):
        var.assign_sub(self.learning_rate * grad)

model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(optimizer=CustomOptimizer(), loss='mean_squared_error')</pre></div><div class='content'></div><h1>Summary</h1>
<div class='content'><ul>
<li>Loss functions and optimizers are critical components of training machine learning models.</li>
<li>Loss functions measure the difference between predicted and actual values, guiding the optimization process.</li>
<li>Optimizers adjust the model's parameters to minimize the loss function.</li>
<li>TensorFlow provides a variety of built-in loss functions and optimizers, and also allows for custom implementations.</li>
</ul>
<p>By understanding and effectively utilizing loss functions and optimizers, you can significantly improve the performance of your machine learning models.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='activation-functions'>&#x25C4;Activation Functions</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Loss Functions and Optimizers</a>
	</div>
	<div class='col-4 text-end'>
					<a href='training-a-model'>Training a Model &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
