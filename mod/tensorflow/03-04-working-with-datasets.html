<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Working with Datasets</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/03-04-working-with-datasets" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/03-04-working-with-datasets" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/03-04-working-with-datasets" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/tensorflow/03-04-working-with-datasets" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/tensorflow/03-04-working-with-datasets" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='03-03-data-augmentation' title="Data Augmentation">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Working with Datasets</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='04-01-introduction-to-neural-networks' title="Introduction to Neural Networks">Next &#x25BA;</a>
			</div>
</div>
<div class='content'><p>In this section, we will explore how to work with datasets in TensorFlow. Handling data efficiently is crucial for training machine learning models. TensorFlow provides powerful tools to manage and preprocess data, making it easier to feed data into your models.</p>
</div><h1><p>Key Concepts</p>
</h1>
<div class='content'><ol>
<li><strong>Datasets</strong>: Collections of data that can be iterated over.</li>
<li><strong>tf.data API</strong>: A set of utilities to build complex input pipelines from simple, reusable pieces.</li>
<li><strong>Data Preprocessing</strong>: Techniques to prepare raw data for model training.</li>
</ol>
</div><h1><p>Creating a Dataset</p>
</h1>
<div class='content'></div><h2><p>From Tensors</p>
</h2>
<div class='content'><p>You can create a dataset directly from tensors using <code>tf.data.Dataset.from_tensor_slices</code>.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRXhhbXBsZSBkYXRhCmZlYXR1cmVzID0gdGYuY29uc3RhbnQoW1sxLjAsIDIuMF0sIFszLjAsIDQuMF0sIFs1LjAsIDYuMF1dKQpsYWJlbHMgPSB0Zi5jb25zdGFudChbMCwgMSwgMl0pCgojIENyZWF0ZSBhIGRhdGFzZXQKZGF0YXNldCA9IHRmLmRhdGEuRGF0YXNldC5mcm9tX3RlbnNvcl9zbGljZXMoKGZlYXR1cmVzLCBsYWJlbHMpKQoKIyBJdGVyYXRlIHRocm91Z2ggdGhlIGRhdGFzZXQKZm9yIGZlYXR1cmUsIGxhYmVsIGluIGRhdGFzZXQ6CiAgICBwcmludChmIkZlYXR1cmU6IHtmZWF0dXJlLm51bXB5KCl9LCBMYWJlbDoge2xhYmVsLm51bXB5KCl9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Example data
features = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
labels = tf.constant([0, 1, 2])

# Create a dataset
dataset = tf.data.Dataset.from_tensor_slices((features, labels))

# Iterate through the dataset
for feature, label in dataset:
    print(f&quot;Feature: {feature.numpy()}, Label: {label.numpy()}&quot;)</pre></div><div class='content'></div><h2><p>From Files</p>
</h2>
<div class='content'><p>You can also create datasets from files, such as CSV files, using <code>tf.data.experimental.make_csv_dataset</code>.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhdGUgYSBkYXRhc2V0IGZyb20gYSBDU1YgZmlsZQpjc3ZfZGF0YXNldCA9IHRmLmRhdGEuZXhwZXJpbWVudGFsLm1ha2VfY3N2X2RhdGFzZXQoCiAgICAicGF0aC90by95b3VyL2ZpbGUuY3N2IiwKICAgIGJhdGNoX3NpemU9NSwgICMgTnVtYmVyIG9mIHNhbXBsZXMgcGVyIGJhdGNoCiAgICBsYWJlbF9uYW1lPSJ0YXJnZXRfY29sdW1uIiwgICMgTmFtZSBvZiB0aGUgbGFiZWwgY29sdW1uCiAgICBuYV92YWx1ZT0iPyIsICAjIFZhbHVlIHRvIGJlIGNvbnNpZGVyZWQgYXMgbWlzc2luZwogICAgbnVtX2Vwb2Nocz0xICAjIE51bWJlciBvZiB0aW1lcyB0byBpdGVyYXRlIG92ZXIgdGhlIGRhdGFzZXQKKQoKIyBJdGVyYXRlIHRocm91Z2ggdGhlIGRhdGFzZXQKZm9yIGJhdGNoIGluIGNzdl9kYXRhc2V0OgogICAgZmVhdHVyZXMsIGxhYmVscyA9IGJhdGNoCiAgICBwcmludChmIkZlYXR1cmVzOiB7ZmVhdHVyZXN9LCBMYWJlbHM6IHtsYWJlbHN9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Create a dataset from a CSV file
csv_dataset = tf.data.experimental.make_csv_dataset(
    &quot;path/to/your/file.csv&quot;,
    batch_size=5,  # Number of samples per batch
    label_name=&quot;target_column&quot;,  # Name of the label column
    na_value=&quot;?&quot;,  # Value to be considered as missing
    num_epochs=1  # Number of times to iterate over the dataset
)

# Iterate through the dataset
for batch in csv_dataset:
    features, labels = batch
    print(f&quot;Features: {features}, Labels: {labels}&quot;)</pre></div><div class='content'></div><h1><p>Data Preprocessing</p>
</h1>
<div class='content'></div><h2><p>Mapping Functions</p>
</h2>
<div class='content'><p>You can apply transformations to each element in the dataset using the <code>map</code> method.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIG5vcm1hbGl6ZShmZWF0dXJlcywgbGFiZWwpOgogICAgZmVhdHVyZXMgPSB0Zi5jYXN0KGZlYXR1cmVzLCB0Zi5mbG9hdDMyKSAvIDI1NS4wCiAgICByZXR1cm4gZmVhdHVyZXMsIGxhYmVsCgojIEFwcGx5IHRoZSBub3JtYWxpemF0aW9uIGZ1bmN0aW9uIHRvIGVhY2ggZWxlbWVudApub3JtYWxpemVkX2RhdGFzZXQgPSBkYXRhc2V0Lm1hcChub3JtYWxpemUpCgojIEl0ZXJhdGUgdGhyb3VnaCB0aGUgbm9ybWFsaXplZCBkYXRhc2V0CmZvciBmZWF0dXJlLCBsYWJlbCBpbiBub3JtYWxpemVkX2RhdGFzZXQ6CiAgICBwcmludChmIk5vcm1hbGl6ZWQgRmVhdHVyZToge2ZlYXR1cmUubnVtcHkoKX0sIExhYmVsOiB7bGFiZWwubnVtcHkoKX0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def normalize(features, label):
    features = tf.cast(features, tf.float32) / 255.0
    return features, label

# Apply the normalization function to each element
normalized_dataset = dataset.map(normalize)

# Iterate through the normalized dataset
for feature, label in normalized_dataset:
    print(f&quot;Normalized Feature: {feature.numpy()}, Label: {label.numpy()}&quot;)</pre></div><div class='content'></div><h2><p>Batching and Shuffling</p>
</h2>
<div class='content'><p>Batching and shuffling are essential for efficient training.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTaHVmZmxlIHRoZSBkYXRhc2V0CnNodWZmbGVkX2RhdGFzZXQgPSBkYXRhc2V0LnNodWZmbGUoYnVmZmVyX3NpemU9MTApCgojIEJhdGNoIHRoZSBkYXRhc2V0CmJhdGNoZWRfZGF0YXNldCA9IHNodWZmbGVkX2RhdGFzZXQuYmF0Y2goYmF0Y2hfc2l6ZT0yKQoKIyBJdGVyYXRlIHRocm91Z2ggdGhlIGJhdGNoZWQgZGF0YXNldApmb3IgYmF0Y2ggaW4gYmF0Y2hlZF9kYXRhc2V0OgogICAgZmVhdHVyZXMsIGxhYmVscyA9IGJhdGNoCiAgICBwcmludChmIkJhdGNoIEZlYXR1cmVzOiB7ZmVhdHVyZXMubnVtcHkoKX0sIEJhdGNoIExhYmVsczoge2xhYmVscy5udW1weSgpfSIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Shuffle the dataset
shuffled_dataset = dataset.shuffle(buffer_size=10)

# Batch the dataset
batched_dataset = shuffled_dataset.batch(batch_size=2)

# Iterate through the batched dataset
for batch in batched_dataset:
    features, labels = batch
    print(f&quot;Batch Features: {features.numpy()}, Batch Labels: {labels.numpy()}&quot;)</pre></div><div class='content'></div><h1><p>Practical Exercise</p>
</h1>
<div class='content'></div><h2><p>Exercise: Create and Preprocess a Dataset</p>
</h2>
<div class='content'><ol>
<li><strong>Create a dataset</strong> from a list of features and labels.</li>
<li><strong>Normalize</strong> the features.</li>
<li><strong>Shuffle</strong> the dataset.</li>
<li><strong>Batch</strong> the dataset.</li>
</ol>
<h4>Solution</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgU3RlcCAxOiBDcmVhdGUgYSBkYXRhc2V0CmZlYXR1cmVzID0gdGYuY29uc3RhbnQoW1sxLjAsIDIuMF0sIFszLjAsIDQuMF0sIFs1LjAsIDYuMF0sIFs3LjAsIDguMF1dKQpsYWJlbHMgPSB0Zi5jb25zdGFudChbMCwgMSwgMiwgM10pCmRhdGFzZXQgPSB0Zi5kYXRhLkRhdGFzZXQuZnJvbV90ZW5zb3Jfc2xpY2VzKChmZWF0dXJlcywgbGFiZWxzKSkKCiMgU3RlcCAyOiBOb3JtYWxpemUgdGhlIGZlYXR1cmVzCmRlZiBub3JtYWxpemUoZmVhdHVyZXMsIGxhYmVsKToKICAgIGZlYXR1cmVzID0gdGYuY2FzdChmZWF0dXJlcywgdGYuZmxvYXQzMikgLyA4LjAKICAgIHJldHVybiBmZWF0dXJlcywgbGFiZWwKCm5vcm1hbGl6ZWRfZGF0YXNldCA9IGRhdGFzZXQubWFwKG5vcm1hbGl6ZSkKCiMgU3RlcCAzOiBTaHVmZmxlIHRoZSBkYXRhc2V0CnNodWZmbGVkX2RhdGFzZXQgPSBub3JtYWxpemVkX2RhdGFzZXQuc2h1ZmZsZShidWZmZXJfc2l6ZT00KQoKIyBTdGVwIDQ6IEJhdGNoIHRoZSBkYXRhc2V0CmJhdGNoZWRfZGF0YXNldCA9IHNodWZmbGVkX2RhdGFzZXQuYmF0Y2goYmF0Y2hfc2l6ZT0yKQoKIyBJdGVyYXRlIHRocm91Z2ggdGhlIGZpbmFsIGRhdGFzZXQKZm9yIGJhdGNoIGluIGJhdGNoZWRfZGF0YXNldDoKICAgIGZlYXR1cmVzLCBsYWJlbHMgPSBiYXRjaAogICAgcHJpbnQoZiJCYXRjaCBGZWF0dXJlczoge2ZlYXR1cmVzLm51bXB5KCl9LCBCYXRjaCBMYWJlbHM6IHtsYWJlbHMubnVtcHkoKX0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Step 1: Create a dataset
features = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])
labels = tf.constant([0, 1, 2, 3])
dataset = tf.data.Dataset.from_tensor_slices((features, labels))

# Step 2: Normalize the features
def normalize(features, label):
    features = tf.cast(features, tf.float32) / 8.0
    return features, label

normalized_dataset = dataset.map(normalize)

# Step 3: Shuffle the dataset
shuffled_dataset = normalized_dataset.shuffle(buffer_size=4)

# Step 4: Batch the dataset
batched_dataset = shuffled_dataset.batch(batch_size=2)

# Iterate through the final dataset
for batch in batched_dataset:
    features, labels = batch
    print(f&quot;Batch Features: {features.numpy()}, Batch Labels: {labels.numpy()}&quot;)</pre></div><div class='content'></div><h1><p>Common Mistakes and Tips</p>
</h1>
<div class='content'><ul>
<li><strong>Buffer Size in Shuffling</strong>: Ensure the buffer size in <code>shuffle</code> is large enough to ensure good shuffling.</li>
<li><strong>Data Types</strong>: Be mindful of data types when performing operations like normalization.</li>
<li><strong>Batch Size</strong>: Choose an appropriate batch size based on your model and hardware capabilities.</li>
</ul>
</div><h1><p>Conclusion</p>
</h1>
<div class='content'><p>In this section, we covered how to create and preprocess datasets in TensorFlow. We learned how to create datasets from tensors and files, apply transformations, and prepare data for training using batching and shuffling. These skills are fundamental for building efficient and scalable machine learning models. In the next module, we will dive into building neural networks using TensorFlow.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='03-03-data-augmentation' title="Data Augmentation">&#x25C4;Previous</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='04-01-introduction-to-neural-networks' title="Introduction to Neural Networks">Next &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
