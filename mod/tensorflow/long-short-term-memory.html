<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Long Short-Term Memory (LSTM)</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/long-short-term-memory" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/long-short-term-memory" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/long-short-term-memory" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/mod/tensorflow/long-short-term-memory" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/mod/tensorflow/long-short-term-memory" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='building-an-rnn'>&#x25C4;Building an RNN</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Long Short-Term Memory (LSTM)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='gated-recurrent-units'>Gated Recurrent Units (GRUs) &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to LSTM</h1>
<div class='content'><p>Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) capable of learning long-term dependencies. They are particularly useful for tasks where context over long sequences is important, such as time series prediction, natural language processing, and speech recognition.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Recurrent Neural Networks (RNNs):</strong> Networks with loops allowing information to persist.</li>
<li><strong>Long-Term Dependencies:</strong> The ability to remember information for long periods.</li>
<li><strong>LSTM Cells:</strong> Special units in LSTM networks designed to avoid the long-term dependency problem.</li>
</ul>
</div><h1>Understanding LSTM Architecture</h1>
<div class='content'><p>LSTM networks are composed of LSTM cells, each containing three main components: the forget gate, the input gate, and the output gate.</p>
</div><h2>LSTM Cell Components</h2>
<div class='content'><ul>
<li><strong>Forget Gate:</strong> Decides what information to discard from the cell state.</li>
<li><strong>Input Gate:</strong> Decides which values from the input to update the cell state.</li>
<li><strong>Output Gate:</strong> Decides what part of the cell state to output.</li>
</ul>
</div><h2>LSTM Cell Diagram</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("W0lucHV0XSAtLT4gW0ZvcmdldCBHYXRlXSAtLT4gW0NlbGwgU3RhdGVdIC0tPiBbT3V0cHV0IEdhdGVdIC0tPiBbT3V0cHV0XQogICAgICAgICAgIFtJbnB1dCBHYXRlXSAtLT4gW0NlbGwgU3RhdGVd"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>[Input] --&gt; [Forget Gate] --&gt; [Cell State] --&gt; [Output Gate] --&gt; [Output]
           [Input Gate] --&gt; [Cell State]</pre></div><div class='content'></div><h1>Implementing LSTM in TensorFlow</h1>
<div class='content'><p>Let's implement a simple LSTM network using TensorFlow to predict a sequence.</p>
</div><h2>Step-by-Step Implementation</h2>
<div class='content'><h4>Step 1: Import Libraries</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBMU1RNLCBEZW5zZQppbXBvcnQgbnVtcHkgYXMgbnA="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import numpy as np</pre></div><div class='content'><h4>Step 2: Prepare Data</h4>
<p>For simplicity, we'll use a sine wave as our dataset.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHZW5lcmF0ZSBhIHNpbmUgd2F2ZQp0aW1lX3N0ZXBzID0gbnAubGluc3BhY2UoMCwgMTAwLCAxMDAwKQpkYXRhID0gbnAuc2luKHRpbWVfc3RlcHMpCgojIFByZXBhcmUgdGhlIGRhdGFzZXQKZGVmIGNyZWF0ZV9kYXRhc2V0KGRhdGEsIHRpbWVfc3RlcD0xMCk6CiAgICBYLCB5ID0gW10sIFtdCiAgICBmb3IgaSBpbiByYW5nZShsZW4oZGF0YSkgLSB0aW1lX3N0ZXAgLSAxKToKICAgICAgICBYLmFwcGVuZChkYXRhW2k6KGkgKyB0aW1lX3N0ZXApXSkKICAgICAgICB5LmFwcGVuZChkYXRhW2kgKyB0aW1lX3N0ZXBdKQogICAgcmV0dXJuIG5wLmFycmF5KFgpLCBucC5hcnJheSh5KQoKdGltZV9zdGVwID0gMTAKWCwgeSA9IGNyZWF0ZV9kYXRhc2V0KGRhdGEsIHRpbWVfc3RlcCkKWCA9IFgucmVzaGFwZShYLnNoYXBlWzBdLCBYLnNoYXBlWzFdLCAxKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Generate a sine wave
time_steps = np.linspace(0, 100, 1000)
data = np.sin(time_steps)

# Prepare the dataset
def create_dataset(data, time_step=10):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step)])
        y.append(data[i + time_step])
    return np.array(X), np.array(y)

time_step = 10
X, y = create_dataset(data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)</pre></div><div class='content'><h4>Step 3: Build the LSTM Model</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKExTVE0oNTAsIHJldHVybl9zZXF1ZW5jZXM9VHJ1ZSwgaW5wdXRfc2hhcGU9KHRpbWVfc3RlcCwgMSkpKQptb2RlbC5hZGQoTFNUTSg1MCwgcmV0dXJuX3NlcXVlbmNlcz1GYWxzZSkpCm1vZGVsLmFkZChEZW5zZSgxKSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtZWFuX3NxdWFyZWRfZXJyb3InKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')</pre></div><div class='content'><h4>Step 4: Train the Model</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwuZml0KFgsIHksIGVwb2Nocz0yMCwgYmF0Y2hfc2l6ZT0zMiwgdmVyYm9zZT0xKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model.fit(X, y, epochs=20, batch_size=32, verbose=1)</pre></div><div class='content'><h4>Step 5: Make Predictions</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cHJlZGljdGlvbnMgPSBtb2RlbC5wcmVkaWN0KFgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>predictions = model.predict(X)</pre></div><div class='content'></div><h2>Explanation of Code</h2>
<div class='content'><ul>
<li><strong>Sequential Model:</strong> A linear stack of layers.</li>
<li><strong>LSTM Layers:</strong> Two LSTM layers with 50 units each. The first LSTM layer returns sequences to feed into the next LSTM layer.</li>
<li><strong>Dense Layer:</strong> A fully connected layer to produce the final output.</li>
<li><strong>Compile:</strong> Using 'adam' optimizer and 'mean_squared_error' loss function.</li>
<li><strong>Fit:</strong> Training the model for 20 epochs with a batch size of 32.</li>
</ul>
</div><h1>Advanced LSTM Techniques</h1>
<h2>Bidirectional LSTM</h2>
<div class='content'><p>Bidirectional LSTMs train two LSTMs on the input sequence, one on the forward direction and one on the backward direction, improving performance on certain tasks.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgQmlkaXJlY3Rpb25hbAoKbW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKEJpZGlyZWN0aW9uYWwoTFNUTSg1MCwgcmV0dXJuX3NlcXVlbmNlcz1UcnVlKSwgaW5wdXRfc2hhcGU9KHRpbWVfc3RlcCwgMSkpKQptb2RlbC5hZGQoQmlkaXJlY3Rpb25hbChMU1RNKDUwLCByZXR1cm5fc2VxdWVuY2VzPUZhbHNlKSkpCm1vZGVsLmFkZChEZW5zZSgxKSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtZWFuX3NxdWFyZWRfZXJyb3InKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Bidirectional

model = Sequential()
model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(time_step, 1)))
model.add(Bidirectional(LSTM(50, return_sequences=False)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')</pre></div><div class='content'></div><h2>LSTM with Dropout</h2>
<div class='content'><p>Dropout is a regularization technique to prevent overfitting.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRHJvcG91dAoKbW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKExTVE0oNTAsIHJldHVybl9zZXF1ZW5jZXM9VHJ1ZSwgaW5wdXRfc2hhcGU9KHRpbWVfc3RlcCwgMSkpKQptb2RlbC5hZGQoRHJvcG91dCgwLjIpKQptb2RlbC5hZGQoTFNUTSg1MCwgcmV0dXJuX3NlcXVlbmNlcz1GYWxzZSkpCm1vZGVsLmFkZChEcm9wb3V0KDAuMikpCm1vZGVsLmFkZChEZW5zZSgxKSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtZWFuX3NxdWFyZWRfZXJyb3InKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Dropout

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>LSTM networks are powerful tools for sequence prediction tasks. Understanding their architecture and how to implement them in TensorFlow is crucial for leveraging their capabilities. By mastering basic and advanced techniques, you can apply LSTMs to a wide range of problems, from simple time series predictions to complex natural language processing tasks.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='building-an-rnn'>&#x25C4;Building an RNN</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Long Short-Term Memory (LSTM)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='gated-recurrent-units'>Gated Recurrent Units (GRUs) &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
