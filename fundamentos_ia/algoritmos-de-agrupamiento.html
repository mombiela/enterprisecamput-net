<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clustering Algorithms</title>

    <link rel="alternate" href="https://campusempresa.com/fundamentos_ia/algoritmos-de-agrupamiento" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/fundamentos_ia/algoritmos-de-agrupamiento" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/fundamentos_ia/algoritmos-de-agrupamiento" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/fundamentos_ia/algoritmos-de-agrupamiento" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/fundamentos_ia/algoritmos-de-agrupamiento" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Clustering is an unsupervised learning technique used in artificial intelligence and machine learning to group a set of objects in such a way that objects in the same group (or cluster) are more similar to each other than to objects in other groups. This technique is fundamental for exploratory data analysis and has applications in various areas such as customer segmentation, anomaly detection, and data compression.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Clustering:</strong> Process of dividing a dataset into groups or clusters, where the data within each group are more similar to each other than to data in other groups.</li>
<li><strong>Distance or Similarity:</strong> Measure used to determine how similar or different two objects are. Common metrics include Euclidean distance, Manhattan distance, and cosine similarity.</li>
<li><strong>Centroids:</strong> Points that represent the center of a cluster in algorithms like K-means.</li>
<li><strong>Clustering Algorithms:</strong> Specific methods used to perform clustering, such as K-means, DBSCAN, and hierarchical clustering.</li>
</ul>
</div><h1>Common Clustering Algorithms</h1>
<div class='content'></div><h2>K-means</h2>
<div class='content'><p>K-means is one of the most popular and easy-to-understand clustering algorithms. The goal is to divide a dataset into K clusters, where each cluster is represented by the centroid of the points in that cluster.</p>
<p>Steps of the K-means algorithm:</p>
<ol>
<li>Select K initial points as centroids.</li>
<li>Assign each data point to the cluster whose centroid is closest.</li>
<li>Recalculate the centroids as the average of the points assigned to each cluster.</li>
<li>Repeat steps 2 and 3 until the centroids do not change significantly.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IEtNZWFucwppbXBvcnQgbnVtcHkgYXMgbnAKCiMgRXhhbXBsZSBkYXRhClggPSBucC5hcnJheShbWzEsIDJdLCBbMSwgNF0sIFsxLCAwXSwKICAgICAgICAgICAgICBbNCwgMl0sIFs0LCA0XSwgWzQsIDBdXSkKCiMgQ3JlYXRlIHRoZSBLLW1lYW5zIG1vZGVsCmttZWFucyA9IEtNZWFucyhuX2NsdXN0ZXJzPTIsIHJhbmRvbV9zdGF0ZT0wKS5maXQoWCkKCiMgUHJlZGljdCB0aGUgY2x1c3RlcnMKbGFiZWxzID0ga21lYW5zLmxhYmVsc18KCiMgR2V0IHRoZSBjZW50cm9pZHMKY2VudHJvaWRzID0ga21lYW5zLmNsdXN0ZXJfY2VudGVyc18KCnByaW50KCJMYWJlbHM6IiwgbGFiZWxzKQpwcmludCgiQ2VudHJvaWRzOiIsIGNlbnRyb2lkcyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.cluster import KMeans
import numpy as np

# Example data
X = np.array([[1, 2], [1, 4], [1, 0],
              [4, 2], [4, 4], [4, 0]])

# Create the K-means model
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)

# Predict the clusters
labels = kmeans.labels_

# Get the centroids
centroids = kmeans.cluster_centers_

print(&quot;Labels:&quot;, labels)
print(&quot;Centroids:&quot;, centroids)</pre></div><div class='content'></div><h2>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</h2>
<div class='content'><p>DBSCAN is a density-based clustering algorithm that can find arbitrarily shaped clusters and handle noise (points that do not belong to any cluster).</p>
<p>Steps of the DBSCAN algorithm:</p>
<ol>
<li>Select a random unvisited point.</li>
<li>Retrieve all points densely connected to that point.</li>
<li>If the point is a core point, form a cluster.</li>
<li>If the point is a border point, mark it as noise.</li>
<li>Repeat until all points have been visited.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IERCU0NBTgoKIyBFeGFtcGxlIGRhdGEKWCA9IG5wLmFycmF5KFtbMSwgMl0sIFsyLCAyXSwgWzIsIDNdLAogICAgICAgICAgICAgIFs4LCA3XSwgWzgsIDhdLCBbMjUsIDgwXV0pCgojIENyZWF0ZSB0aGUgREJTQ0FOIG1vZGVsCmRic2NhbiA9IERCU0NBTihlcHM9MywgbWluX3NhbXBsZXM9MikuZml0KFgpCgojIFByZWRpY3QgdGhlIGNsdXN0ZXJzCmxhYmVscyA9IGRic2Nhbi5sYWJlbHNfCgpwcmludCgiTGFiZWxzOiIsIGxhYmVscyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.cluster import DBSCAN

# Example data
X = np.array([[1, 2], [2, 2], [2, 3],
              [8, 7], [8, 8], [25, 80]])

# Create the DBSCAN model
dbscan = DBSCAN(eps=3, min_samples=2).fit(X)

# Predict the clusters
labels = dbscan.labels_

print(&quot;Labels:&quot;, labels)</pre></div><div class='content'></div><h2>Hierarchical Clustering</h2>
<div class='content'><p>Hierarchical clustering builds a hierarchy of clusters using an agglomerative (bottom-up) or divisive (top-down) approach.</p>
<p>Steps of the agglomerative algorithm:</p>
<ol>
<li>Start with each point as an individual cluster.</li>
<li>Combine the two closest clusters into a single cluster.</li>
<li>Repeat step 2 until all points are in a single cluster.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBzY2lweS5jbHVzdGVyLmhpZXJhcmNoeSBpbXBvcnQgZGVuZHJvZ3JhbSwgbGlua2FnZQppbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0CgojIEV4YW1wbGUgZGF0YQpYID0gbnAuYXJyYXkoW1sxLCAyXSwgWzIsIDJdLCBbMiwgM10sCiAgICAgICAgICAgICAgWzgsIDddLCBbOCwgOF0sIFsyNSwgODBdXSkKCiMgQ3JlYXRlIHRoZSBoaWVyYXJjaGljYWwgY2x1c3RlcmluZyBtb2RlbApaID0gbGlua2FnZShYLCAnd2FyZCcpCgojIERyYXcgdGhlIGRlbmRyb2dyYW0KcGx0LmZpZ3VyZSgpCmRlbmRyb2dyYW0oWikKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

# Example data
X = np.array([[1, 2], [2, 2], [2, 3],
              [8, 7], [8, 8], [25, 80]])

# Create the hierarchical clustering model
Z = linkage(X, 'ward')

# Draw the dendrogram
plt.figure()
dendrogram(Z)
plt.show()</pre></div><div class='content'></div><h1>Comparison of Algorithms</h1>
<div class='content'><p>| Algorithm       | Advantages                                         | Disadvantages                                      |
|-----------------|--------------------------------------------------|--------------------------------------------------|
| K-means         | Simple, fast, easy to understand                | Sensitive to the selection of K, does not handle noise well |
| DBSCAN          | Handles noise well, finds arbitrary clusters | Sensitive to the parameters eps and min_samples      |
| Hierarchical    | Does not require predefining the number of clusters    | Computationally expensive for large datasets |</p>
</div><h1>Conclusion</h1>
<div class='content'><p>Clustering algorithms are powerful tools for exploratory data analysis in artificial intelligence. Each algorithm has its own advantages and disadvantages, and the choice of the appropriate algorithm depends on the nature of the data and the specific problem to be solved. It is essential to understand the characteristics and limitations of each method to apply them effectively in practice.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
