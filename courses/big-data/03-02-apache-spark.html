<!DOCTYPE html>
<html lang="en">
<head>
    <title> Apache Spark </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/mod/big_data/03-02-apache-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/big_data/03-02-apache-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/big_data/03-02-apache-spark" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "big_data";
  		var TEMA_NAME = "3-2";
  		var TYPE = "mod";
  		var PATH = "mod/big_data/03-02-apache-spark";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/big_data/03-02-apache-spark" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/big_data/03-02-apache-spark" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="big_data">
		<a  href="#" class="text-secondary d-none" data-read-mod="big_data" data-read-unit="3-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="big_data" data-unread-unit="3-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Apache Spark</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='03-03-real-time-processing' title="Real-Time Processing" class="py-2 px-3 btn btn-primary"
				data-read-mod="big_data" data-read-unit="3-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='03-03-real-time-processing' title="Real-Time Processing" class="py-2 px-3 btn btn-primary" 
				data-read-mod="big_data" data-read-unit="3-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>Apache Spark is an open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. It is designed to be fast for both batch and streaming data processing, making it a versatile tool in the Big Data ecosystem.</p>
</div><h1>Key Concepts of Apache Spark</h1>
<div class='content'></div><h2><ol>
<li>Unified Analytics Engine</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Batch Processing</strong>: Spark can handle large-scale data processing jobs in a batch mode.</li>
<li><strong>Streaming Processing</strong>: Spark Streaming allows for real-time data processing.</li>
<li><strong>Interactive Queries</strong>: Spark supports interactive queries using Spark SQL.</li>
<li><strong>Machine Learning</strong>: Spark includes MLlib for scalable machine learning algorithms.</li>
<li><strong>Graph Processing</strong>: GraphX is Sparkâ€™s API for graph and graph-parallel computation.</li>
</ul>
</div><h2><ol start="2">
<li>Resilient Distributed Datasets (RDDs)</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Immutable</strong>: Once created, RDDs cannot be modified.</li>
<li><strong>Distributed</strong>: RDDs are distributed across multiple nodes in a cluster.</li>
<li><strong>Fault-Tolerant</strong>: RDDs can recover from node failures.</li>
</ul>
</div><h2><ol start="3">
<li>DataFrames and Datasets</li>
</ol></h2>
<div class='content'><ul>
<li><strong>DataFrames</strong>: Distributed collections of data organized into named columns, similar to a table in a relational database.</li>
<li><strong>Datasets</strong>: Strongly-typed, distributed collections of data that provide the benefits of RDDs with the optimizations of DataFrames.</li>
</ul>
</div><h2><ol start="4">
<li>Lazy Evaluation</li>
</ol></h2>
<div class='content'><ul>
<li>Spark uses lazy evaluation to optimize the execution plan. Transformations on RDDs, DataFrames, or Datasets are not executed immediately but are recorded in a lineage graph.</li>
</ul>
</div><h2><ol start="5">
<li>In-Memory Processing</li>
</ol></h2>
<div class='content'><ul>
<li>Spark performs computations in memory, which significantly speeds up processing compared to disk-based systems like Hadoop MapReduce.</li>
</ul>
</div><h1>Apache Spark Architecture</h1>
<div class='content'></div><h2><ol>
<li>Driver Program</li>
</ol></h2>
<div class='content'><ul>
<li>The driver program runs the main function of the application and creates the SparkContext, which coordinates the execution of tasks on the cluster.</li>
</ul>
</div><h2><ol start="2">
<li>Cluster Manager</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Standalone</strong>: Spark's built-in cluster manager.</li>
<li><strong>Apache Mesos</strong>: A general cluster manager that can also run Hadoop MapReduce and other applications.</li>
<li><strong>Hadoop YARN</strong>: The resource manager in Hadoop 2.</li>
</ul>
</div><h2><ol start="3">
<li>Executors</li>
</ol></h2>
<div class='content'><ul>
<li>Executors are worker nodes that run individual tasks and store data for the application.</li>
</ul>
</div><h2><ol start="4">
<li>Tasks</li>
</ol></h2>
<div class='content'><ul>
<li>Tasks are units of work that are sent to executors by the driver program.</li>
</ul>
</div><h1>Practical Example: Word Count in Apache Spark</h1>
<div class='content'></div><h2>Code Example</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKIyBDcmVhdGUgYSBTcGFyayBjb25maWd1cmF0aW9uIGFuZCBjb250ZXh0CmNvbmYgPSBTcGFya0NvbmYoKS5zZXRBcHBOYW1lKCJXb3JkQ291bnQiKS5zZXRNYXN0ZXIoImxvY2FsIikKc2MgPSBTcGFya0NvbnRleHQoY29uZj1jb25mKQoKIyBSZWFkIHRoZSBpbnB1dCBmaWxlCmlucHV0X2ZpbGUgPSBzYy50ZXh0RmlsZSgicGF0aC90by9pbnB1dC50eHQiKQoKIyBTcGxpdCBlYWNoIGxpbmUgaW50byB3b3Jkcwp3b3JkcyA9IGlucHV0X2ZpbGUuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKQoKIyBNYXAgZWFjaCB3b3JkIHRvIGEgdHVwbGUgKHdvcmQsIDEpCndvcmRfdHVwbGVzID0gd29yZHMubWFwKGxhbWJkYSB3b3JkOiAod29yZCwgMSkpCgojIFJlZHVjZSBieSBrZXkgdG8gY291bnQgb2NjdXJyZW5jZXMgb2YgZWFjaCB3b3JkCndvcmRfY291bnRzID0gd29yZF90dXBsZXMucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQoKIyBDb2xsZWN0IHRoZSByZXN1bHRzIGFuZCBwcmludCB0aGVtCmZvciB3b3JkLCBjb3VudCBpbiB3b3JkX2NvdW50cy5jb2xsZWN0KCk6CiAgICBwcmludChmInt3b3JkfToge2NvdW50fSIpCgojIFN0b3AgdGhlIFNwYXJrIGNvbnRleHQKc2Muc3RvcCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

# Create a Spark configuration and context
conf = SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

# Read the input file
input_file = sc.textFile(&quot;path/to/input.txt&quot;)

# Split each line into words
words = input_file.flatMap(lambda line: line.split(&quot; &quot;))

# Map each word to a tuple (word, 1)
word_tuples = words.map(lambda word: (word, 1))

# Reduce by key to count occurrences of each word
word_counts = word_tuples.reduceByKey(lambda a, b: a + b)

# Collect the results and print them
for word, count in word_counts.collect():
    print(f&quot;{word}: {count}&quot;)

# Stop the Spark context
sc.stop()</pre></div><div class='content'></div><h2>Explanation</h2>
<div class='content'><ol>
<li>
<p><strong>Spark Configuration and Context</strong>:</p>
<ul>
<li><code>SparkConf</code> is used to configure the application name and master URL.</li>
<li><code>SparkContext</code> initializes the Spark application.</li>
</ul>
</li>
<li>
<p><strong>Reading Input File</strong>:</p>
<ul>
<li><code>textFile</code> reads the input text file and creates an RDD.</li>
</ul>
</li>
<li>
<p><strong>Splitting Lines into Words</strong>:</p>
<ul>
<li><code>flatMap</code> transforms each line into a list of words.</li>
</ul>
</li>
<li>
<p><strong>Mapping Words to Tuples</strong>:</p>
<ul>
<li><code>map</code> transforms each word into a tuple (word, 1).</li>
</ul>
</li>
<li>
<p><strong>Reducing by Key</strong>:</p>
<ul>
<li><code>reduceByKey</code> aggregates the counts for each word.</li>
</ul>
</li>
<li>
<p><strong>Collecting and Printing Results</strong>:</p>
<ul>
<li><code>collect</code> gathers the results from the RDD and prints them.</li>
</ul>
</li>
</ol>
</div><h1>Exercises</h1>
<div class='content'></div><h2>Exercise 1: Basic Transformations and Actions</h2>
<div class='content'><p><strong>Task</strong>: Create an RDD from a list of numbers and perform the following operations:</p>
<ol>
<li>Filter out even numbers.</li>
<li>Multiply each remaining number by 2.</li>
<li>Collect and print the results.</li>
</ol>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKY29uZiA9IFNwYXJrQ29uZigpLnNldEFwcE5hbWUoIkJhc2ljVHJhbnNmb3JtYXRpb25zIikuc2V0TWFzdGVyKCJsb2NhbCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCm51bWJlcnMgPSBzYy5wYXJhbGxlbGl6ZShbMSwgMiwgMywgNCwgNSwgNiwgNywgOCwgOSwgMTBdKQoKIyBGaWx0ZXIgb3V0IGV2ZW4gbnVtYmVycwpvZGRfbnVtYmVycyA9IG51bWJlcnMuZmlsdGVyKGxhbWJkYSB4OiB4ICUgMiAhPSAwKQoKIyBNdWx0aXBseSBlYWNoIHJlbWFpbmluZyBudW1iZXIgYnkgMgpkb3VibGVkX251bWJlcnMgPSBvZGRfbnVtYmVycy5tYXAobGFtYmRhIHg6IHggKiAyKQoKIyBDb2xsZWN0IGFuZCBwcmludCB0aGUgcmVzdWx0cwpyZXN1bHRzID0gZG91YmxlZF9udW1iZXJzLmNvbGxlY3QoKQpwcmludChyZXN1bHRzKQoKc2Muc3RvcCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

conf = SparkConf().setAppName(&quot;BasicTransformations&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# Filter out even numbers
odd_numbers = numbers.filter(lambda x: x % 2 != 0)

# Multiply each remaining number by 2
doubled_numbers = odd_numbers.map(lambda x: x * 2)

# Collect and print the results
results = doubled_numbers.collect()
print(results)

sc.stop()</pre></div><div class='content'></div><h2>Exercise 2: Word Count with DataFrames</h2>
<div class='content'><p><strong>Task</strong>: Rewrite the word count example using DataFrames.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWF0ZSBhIFNwYXJrIHNlc3Npb24Kc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJXb3JkQ291bnRERiIpLmdldE9yQ3JlYXRlKCkKCiMgUmVhZCB0aGUgaW5wdXQgZmlsZSBpbnRvIGEgRGF0YUZyYW1lCmRmID0gc3BhcmsucmVhZC50ZXh0KCJwYXRoL3RvL2lucHV0LnR4dCIpCgojIFNwbGl0IGVhY2ggbGluZSBpbnRvIHdvcmRzCndvcmRzID0gZGYuc2VsZWN0RXhwcigiZXhwbG9kZShzcGxpdCh2YWx1ZSwgJyAnKSkgYXMgd29yZCIpCgojIEdyb3VwIGJ5IHdvcmQgYW5kIGNvdW50IG9jY3VycmVuY2VzCndvcmRfY291bnRzID0gd29yZHMuZ3JvdXBCeSgid29yZCIpLmNvdW50KCkKCiMgU2hvdyB0aGUgcmVzdWx0cwp3b3JkX2NvdW50cy5zaG93KCkKCiMgU3RvcCB0aGUgU3Bhcmsgc2Vzc2lvbgpzcGFyay5zdG9wKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Create a Spark session
spark = SparkSession.builder.appName(&quot;WordCountDF&quot;).getOrCreate()

# Read the input file into a DataFrame
df = spark.read.text(&quot;path/to/input.txt&quot;)

# Split each line into words
words = df.selectExpr(&quot;explode(split(value, ' ')) as word&quot;)

# Group by word and count occurrences
word_counts = words.groupBy(&quot;word&quot;).count()

# Show the results
word_counts.show()

# Stop the Spark session
spark.stop()</pre></div><div class='content'></div><h1>Common Mistakes and Tips</h1>
<div class='content'><ol>
<li><strong>Not Using Lazy Evaluation</strong>: Remember that transformations are lazy and actions trigger the execution. Plan your transformations accordingly.</li>
<li><strong>Ignoring Data Skew</strong>: Be mindful of data skew, where some partitions may have significantly more data than others, leading to performance bottlenecks.</li>
<li><strong>Inadequate Resource Allocation</strong>: Properly allocate resources (memory, CPU) to avoid out-of-memory errors and ensure efficient execution.</li>
</ol>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, we covered the fundamental concepts of Apache Spark, its architecture, and practical examples of using Spark for data processing. We also provided exercises to reinforce the learned concepts. Understanding Spark's capabilities and how to use it effectively is crucial for handling large-scale data processing tasks in the Big Data ecosystem.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='03-03-real-time-processing' title="Real-Time Processing" class="py-2 px-3 btn btn-primary"
				data-read-mod="big_data" data-read-unit="3-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='03-03-real-time-processing' title="Real-Time Processing" class="py-2 px-3 btn btn-primary" 
				data-read-mod="big_data" data-read-unit="3-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Big Data Course</h1>
<h2>Module 1: Introduction to Big Data</h2>
<ul>
<li><a href="01-01-basic-concepts">Basic Concepts of Big Data</a></li>
<li><a href="01-02-importance-applications">Importance and Applications of Big Data</a></li>
<li><a href="01-03-challenges-opportunities">Challenges and Opportunities</a></li>
</ul>
<h2>Module 2: Big Data Storage Technologies</h2>
<ul>
<li><a href="02-01-distributed-file-systems">Distributed File Systems</a></li>
<li><a href="02-02-nosql-databases">NoSQL Databases</a></li>
<li><a href="02-03-data-lakes">Data Lakes</a></li>
</ul>
<h2>Module 3: Big Data Processing</h2>
<ul>
<li><a href="03-01-mapreduce-hadoop">MapReduce and Hadoop</a></li>
<li><a href="03-02-apache-spark">Apache Spark</a></li>
<li><a href="03-03-real-time-processing">Real-Time Processing</a></li>
</ul>
<h2>Module 4: Big Data Analysis</h2>
<ul>
<li><a href="04-01-analysis-tools">Analysis Tools</a></li>
<li><a href="04-02-machine-learning-big-data">Machine Learning and Big Data</a></li>
<li><a href="04-03-data-visualization">Data Visualization</a></li>
</ul>
<h2>Module 5: Practices and Case Studies</h2>
<ul>
<li><a href="05-01-best-practices">Best Practices in Big Data</a></li>
<li><a href="05-02-case-studies">Case Studies in Different Industries</a></li>
<li><a href="05-03-practical-projects">Practical Projects</a></li>
</ul>
<h2>Module 6: Big Data Tools and Platforms</h2>
<ul>
<li><a href="06-01-apache-hadoop-ecosystem">Apache Hadoop Ecosystem</a></li>
<li><a href="06-02-apache-spark-ecosystem">Apache Spark Ecosystem</a></li>
<li><a href="06-03-other-tools-platforms">Other Tools and Platforms</a></li>
</ul>
<h2>Module 7: Security and Ethics in Big Data</h2>
<ul>
<li><a href="07-01-data-security">Data Security</a></li>
<li><a href="07-02-privacy-data-protection">Privacy and Data Protection</a></li>
<li><a href="07-03-ethics-use-big-data">Ethics in the Use of Big Data</a></li>
</ul>
<h2>Module 8: Future of Big Data</h2>
<ul>
<li><a href="08-01-emerging-trends">Emerging Trends</a></li>
<li><a href="08-02-impact-artificial-intelligence">Impact of Artificial Intelligence</a></li>
<li><a href="08-03-future-work-big-data">The Future of Work with Big Data</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
