<!DOCTYPE html>
<html lang="en">
<head>
    <title> Kafka with Spark </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/kafka/06-02-kafka-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/kafka/06-02-kafka-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/kafka/06-02-kafka-spark" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "kafka";
  		var TEMA_NAME = "6-2";
  		var TYPE = "mod";
  		var PATH = "mod/kafka/06-02-kafka-spark";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.8d8afe898f.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/kafka/06-02-kafka-spark" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/kafka/06-02-kafka-spark" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="kafka">
		<a  href="#" class="text-secondary d-none" data-read-mod="kafka" data-read-unit="6-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="kafka" data-unread-unit="6-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-01-kafka-hadoop' title="Kafka with Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-01-kafka-hadoop' title="Kafka with Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Kafka with Spark</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-03-kafka-flink' title="Kafka with Flink" class="py-2 px-3 btn btn-primary"
				data-read-mod="kafka" data-read-unit="6-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-03-kafka-flink' title="Kafka with Flink" class="py-2 px-3 btn btn-primary" 
				data-read-mod="kafka" data-read-unit="6-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>In this module, we will explore how Apache Kafka can be integrated with Apache Spark to build robust, scalable, and real-time data processing pipelines. We will cover the following key concepts:</p>
<ol>
<li><strong>Introduction to Kafka and Spark Integration</strong></li>
<li><strong>Setting Up Kafka and Spark</strong></li>
<li><strong>Reading Data from Kafka in Spark</strong></li>
<li><strong>Processing Data with Spark Streaming</strong></li>
<li><strong>Writing Data to Kafka from Spark</strong></li>
<li><strong>Practical Exercises</strong></li>
</ol>
</div><h2><ol>
<li>Introduction to Kafka and Spark Integration</li>
</ol></h2>
<div class='content'><p>Apache Kafka and Apache Spark are two powerful tools for real-time data processing. Kafka is a distributed streaming platform that can handle high-throughput, low-latency data streams. Spark, on the other hand, is a unified analytics engine for large-scale data processing, known for its speed and ease of use.</p>
</div><h3>Key Benefits of Integrating Kafka with Spark:</h3>
<div class='content'><ul>
<li><strong>Real-time Data Processing</strong>: Spark can process data in real-time as it is ingested by Kafka.</li>
<li><strong>Scalability</strong>: Both Kafka and Spark are designed to scale horizontally, making them suitable for large-scale data processing.</li>
<li><strong>Fault Tolerance</strong>: Both systems provide mechanisms for fault tolerance, ensuring data integrity and reliability.</li>
</ul>
</div><h2><ol start="2">
<li>Setting Up Kafka and Spark</li>
</ol></h2>
<div class='content'><p>Before we dive into the integration, let's set up Kafka and Spark on your local machine.</p>
</div><h3>Prerequisites:</h3>
<div class='content'><ul>
<li>Java 8 or higher</li>
<li>Apache Kafka</li>
<li>Apache Spark</li>
</ul>
</div><h3>Step-by-Step Setup:</h3>
<div class='content'><ol>
<li>
<p><strong>Download and Install Kafka</strong>:</p>
<ul>
<li>Download Kafka from the <a href="https://kafka.apache.org/downloads">official website</a>.</li>
<li>Extract the downloaded file and navigate to the Kafka directory.</li>
<li>Start the ZooKeeper server:
<pre><code class="language-sh">bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>
</li>
<li>Start the Kafka server:
<pre><code class="language-sh">bin/kafka-server-start.sh config/server.properties
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>Download and Install Spark</strong>:</p>
<ul>
<li>Download Spark from the <a href="https://spark.apache.org/downloads.html">official website</a>.</li>
<li>Extract the downloaded file and navigate to the Spark directory.</li>
<li>Start the Spark shell:
<pre><code class="language-sh">bin/spark-shell
</code></pre>
</li>
</ul>
</li>
</ol>
</div><h2><ol start="3">
<li>Reading Data from Kafka in Spark</li>
</ol></h2>
<div class='content'><p>To read data from Kafka in Spark, we will use the <code>spark-sql-kafka</code> package. This package allows Spark to read data from Kafka topics.</p>
</div><h3>Example Code:</h3>
<div class='content'></div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyCiAgLmFwcE5hbWUoIkthZmthU3BhcmtJbnRlZ3JhdGlvbiIpCiAgLm1hc3RlcigibG9jYWxbKl0iKQogIC5nZXRPckNyZWF0ZSgpCgovLyBSZWFkIGRhdGEgZnJvbSBLYWZrYQp2YWwga2Fma2FERiA9IHNwYXJrLnJlYWRTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInN1YnNjcmliZSIsICJ0ZXN0LXRvcGljIikKICAubG9hZCgpCgovLyBDb252ZXJ0IHRoZSBiaW5hcnkgdmFsdWUgdG8gc3RyaW5nCnZhbCBzdHJpbmdERiA9IGthZmthREYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIikKCi8vIFByaW50IHRoZSBzY2hlbWEKc3RyaW5nREYucHJpbnRTY2hlbWEoKQoKLy8gU3RhcnQgdGhlIHN0cmVhbWluZyBxdWVyeQp2YWwgcXVlcnkgPSBzdHJpbmdERi53cml0ZVN0cmVhbQogIC5vdXRwdXRNb2RlKCJhcHBlbmQiKQogIC5mb3JtYXQoImNvbnNvbGUiKQogIC5zdGFydCgpCgpxdWVyeS5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName(&quot;KafkaSparkIntegration&quot;)
  .master(&quot;local[*]&quot;)
  .getOrCreate()

// Read data from Kafka
val kafkaDF = spark.readStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;subscribe&quot;, &quot;test-topic&quot;)
  .load()

// Convert the binary value to string
val stringDF = kafkaDF.selectExpr(&quot;CAST(value AS STRING)&quot;)

// Print the schema
stringDF.printSchema()

// Start the streaming query
val query = stringDF.writeStream
  .outputMode(&quot;append&quot;)
  .format(&quot;console&quot;)
  .start()

query.awaitTermination()</pre></div><div class='content'></div><h3>Explanation:</h3>
<div class='content'><ul>
<li><strong>SparkSession</strong>: Entry point to Spark functionality.</li>
<li><strong>kafka.bootstrap.servers</strong>: Kafka broker address.</li>
<li><strong>subscribe</strong>: Kafka topic to read from.</li>
<li><strong>CAST(value AS STRING)</strong>: Convert the binary value to a string for easier processing.</li>
<li><strong>writeStream</strong>: Write the streaming data to the console.</li>
</ul>
</div><h2><ol start="4">
<li>Processing Data with Spark Streaming</li>
</ol></h2>
<div class='content'><p>Once we have the data from Kafka, we can process it using Spark Streaming.</p>
</div><h3>Example Code:</h3>
<div class='content'></div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLmZ1bmN0aW9ucy5fCgp2YWwgcHJvY2Vzc2VkREYgPSBzdHJpbmdERgogIC53aXRoQ29sdW1uKCJ0aW1lc3RhbXAiLCBjdXJyZW50X3RpbWVzdGFtcCgpKQogIC53aXRoQ29sdW1uKCJ2YWx1ZV9sZW5ndGgiLCBsZW5ndGgoY29sKCJ2YWx1ZSIpKSkKCi8vIFByaW50IHRoZSBzY2hlbWEKcHJvY2Vzc2VkREYucHJpbnRTY2hlbWEoKQoKLy8gU3RhcnQgdGhlIHN0cmVhbWluZyBxdWVyeQp2YWwgcXVlcnkgPSBwcm9jZXNzZWRERi53cml0ZVN0cmVhbQogIC5vdXRwdXRNb2RlKCJhcHBlbmQiKQogIC5mb3JtYXQoImNvbnNvbGUiKQogIC5zdGFydCgpCgpxdWVyeS5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.functions._

val processedDF = stringDF
  .withColumn(&quot;timestamp&quot;, current_timestamp())
  .withColumn(&quot;value_length&quot;, length(col(&quot;value&quot;)))

// Print the schema
processedDF.printSchema()

// Start the streaming query
val query = processedDF.writeStream
  .outputMode(&quot;append&quot;)
  .format(&quot;console&quot;)
  .start()

query.awaitTermination()</pre></div><div class='content'></div><h3>Explanation:</h3>
<div class='content'><ul>
<li><strong>current_timestamp()</strong>: Add a timestamp column to the data.</li>
<li><strong>length(col(&quot;value&quot;))</strong>: Add a column that contains the length of the value.</li>
</ul>
</div><h2><ol start="5">
<li>Writing Data to Kafka from Spark</li>
</ol></h2>
<div class='content'><p>After processing the data, we can write it back to a Kafka topic.</p>
</div><h3>Example Code:</h3>
<div class='content'></div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIG91dHB1dERGID0gcHJvY2Vzc2VkREYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIEFTIGtleSIsICJDQVNUKHZhbHVlIEFTIFNUUklORykgQVMgdmFsdWUiKQoKb3V0cHV0REYud3JpdGVTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInRvcGljIiwgIm91dHB1dC10b3BpYyIpCiAgLm9wdGlvbigiY2hlY2twb2ludExvY2F0aW9uIiwgIi90bXAvY2hlY2twb2ludCIpCiAgLnN0YXJ0KCkKICAuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val outputDF = processedDF.selectExpr(&quot;CAST(value AS STRING) AS key&quot;, &quot;CAST(value AS STRING) AS value&quot;)

outputDF.writeStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;topic&quot;, &quot;output-topic&quot;)
  .option(&quot;checkpointLocation&quot;, &quot;/tmp/checkpoint&quot;)
  .start()
  .awaitTermination()</pre></div><div class='content'></div><h3>Explanation:</h3>
<div class='content'><ul>
<li><strong>selectExpr</strong>: Select and cast the columns to the appropriate types for Kafka.</li>
<li><strong>checkpointLocation</strong>: Directory to store checkpoint data for fault tolerance.</li>
</ul>
</div><h2><ol start="6">
<li>Practical Exercises</li>
</ol></h2>
<div class='content'></div><h3>Exercise 1: Basic Kafka-Spark Integration</h3>
<div class='content'><ol>
<li>Set up a Kafka topic named <code>exercise-topic</code>.</li>
<li>Write a Spark application to read data from <code>exercise-topic</code>, process it by converting the value to uppercase, and write it to a new Kafka topic named <code>exercise-output</code>.</li>
</ol>
</div><h3>Solution:</h3>
<div class='content'></div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyCiAgLmFwcE5hbWUoIkthZmthU3BhcmtFeGVyY2lzZSIpCiAgLm1hc3RlcigibG9jYWxbKl0iKQogIC5nZXRPckNyZWF0ZSgpCgp2YWwga2Fma2FERiA9IHNwYXJrLnJlYWRTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInN1YnNjcmliZSIsICJleGVyY2lzZS10b3BpYyIpCiAgLmxvYWQoKQoKdmFsIHN0cmluZ0RGID0ga2Fma2FERi5zZWxlY3RFeHByKCJDQVNUKHZhbHVlIEFTIFNUUklORykiKQoKdmFsIHByb2Nlc3NlZERGID0gc3RyaW5nREYud2l0aENvbHVtbigidmFsdWUiLCB1cHBlcihjb2woInZhbHVlIikpKQoKdmFsIG91dHB1dERGID0gcHJvY2Vzc2VkREYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIEFTIGtleSIsICJDQVNUKHZhbHVlIEFTIFNUUklORykgQVMgdmFsdWUiKQoKb3V0cHV0REYud3JpdGVTdHJlYW0KICAuZm9ybWF0KCJrYWZrYSIpCiAgLm9wdGlvbigia2Fma2EuYm9vdHN0cmFwLnNlcnZlcnMiLCAibG9jYWxob3N0OjkwOTIiKQogIC5vcHRpb24oInRvcGljIiwgImV4ZXJjaXNlLW91dHB1dCIpCiAgLm9wdGlvbigiY2hlY2twb2ludExvY2F0aW9uIiwgIi90bXAvZXhlcmNpc2UtY2hlY2twb2ludCIpCiAgLnN0YXJ0KCkKICAuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName(&quot;KafkaSparkExercise&quot;)
  .master(&quot;local[*]&quot;)
  .getOrCreate()

val kafkaDF = spark.readStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;subscribe&quot;, &quot;exercise-topic&quot;)
  .load()

val stringDF = kafkaDF.selectExpr(&quot;CAST(value AS STRING)&quot;)

val processedDF = stringDF.withColumn(&quot;value&quot;, upper(col(&quot;value&quot;)))

val outputDF = processedDF.selectExpr(&quot;CAST(value AS STRING) AS key&quot;, &quot;CAST(value AS STRING) AS value&quot;)

outputDF.writeStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;topic&quot;, &quot;exercise-output&quot;)
  .option(&quot;checkpointLocation&quot;, &quot;/tmp/exercise-checkpoint&quot;)
  .start()
  .awaitTermination()</pre></div><div class='content'></div><h3>Exercise 2: Advanced Processing</h3>
<div class='content'><ol>
<li>Set up a Kafka topic named <code>advanced-topic</code>.</li>
<li>Write a Spark application to read data from <code>advanced-topic</code>, filter out messages that contain the word &quot;error&quot;, and write the filtered data to a new Kafka topic named <code>filtered-output</code>.</li>
</ol>
</div><h3>Solution:</h3>
<div class='content'></div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyCiAgLmFwcE5hbWUoIkthZmthU3BhcmtBZHZhbmNlZEV4ZXJjaXNlIikKICAubWFzdGVyKCJsb2NhbFsqXSIpCiAgLmdldE9yQ3JlYXRlKCkKCnZhbCBrYWZrYURGID0gc3BhcmsucmVhZFN0cmVhbQogIC5mb3JtYXQoImthZmthIikKICAub3B0aW9uKCJrYWZrYS5ib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpCiAgLm9wdGlvbigic3Vic2NyaWJlIiwgImFkdmFuY2VkLXRvcGljIikKICAubG9hZCgpCgp2YWwgc3RyaW5nREYgPSBrYWZrYURGLnNlbGVjdEV4cHIoIkNBU1QodmFsdWUgQVMgU1RSSU5HKSIpCgp2YWwgZmlsdGVyZWRERiA9IHN0cmluZ0RGLmZpbHRlcighY29sKCJ2YWx1ZSIpLmNvbnRhaW5zKCJlcnJvciIpKQoKdmFsIG91dHB1dERGID0gZmlsdGVyZWRERi5zZWxlY3RFeHByKCJDQVNUKHZhbHVlIEFTIFNUUklORykgQVMga2V5IiwgIkNBU1QodmFsdWUgQVMgU1RSSU5HKSBBUyB2YWx1ZSIpCgpvdXRwdXRERi53cml0ZVN0cmVhbQogIC5mb3JtYXQoImthZmthIikKICAub3B0aW9uKCJrYWZrYS5ib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpCiAgLm9wdGlvbigidG9waWMiLCAiZmlsdGVyZWQtb3V0cHV0IikKICAub3B0aW9uKCJjaGVja3BvaW50TG9jYXRpb24iLCAiL3RtcC9hZHZhbmNlZC1jaGVja3BvaW50IikKICAuc3RhcnQoKQogIC5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder
  .appName(&quot;KafkaSparkAdvancedExercise&quot;)
  .master(&quot;local[*]&quot;)
  .getOrCreate()

val kafkaDF = spark.readStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;subscribe&quot;, &quot;advanced-topic&quot;)
  .load()

val stringDF = kafkaDF.selectExpr(&quot;CAST(value AS STRING)&quot;)

val filteredDF = stringDF.filter(!col(&quot;value&quot;).contains(&quot;error&quot;))

val outputDF = filteredDF.selectExpr(&quot;CAST(value AS STRING) AS key&quot;, &quot;CAST(value AS STRING) AS value&quot;)

outputDF.writeStream
  .format(&quot;kafka&quot;)
  .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;)
  .option(&quot;topic&quot;, &quot;filtered-output&quot;)
  .option(&quot;checkpointLocation&quot;, &quot;/tmp/advanced-checkpoint&quot;)
  .start()
  .awaitTermination()</pre></div><div class='content'></div><h2>Conclusion</h2>
<div class='content'><p>In this module, we have learned how to integrate Apache Kafka with Apache Spark to build real-time data processing pipelines. We covered the setup of Kafka and Spark, reading data from Kafka in Spark, processing the data using Spark Streaming, and writing the processed data back to Kafka. We also provided practical exercises to reinforce the learned concepts. This integration is powerful for building scalable and fault-tolerant data processing applications.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-01-kafka-hadoop' title="Kafka with Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-01-kafka-hadoop' title="Kafka with Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-03-kafka-flink' title="Kafka with Flink" class="py-2 px-3 btn btn-primary"
				data-read-mod="kafka" data-read-unit="6-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-03-kafka-flink' title="Kafka with Flink" class="py-2 px-3 btn btn-primary" 
				data-read-mod="kafka" data-read-unit="6-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Kafka Course</h1>
<h2>Module 1: Introduction to Kafka</h2>
<ul>
<li><a href="01-01-what-is-kafka">What is Kafka?</a></li>
<li><a href="01-02-kafka-use-cases">Kafka Use Cases</a></li>
<li><a href="01-03-kafka-architecture-overview">Kafka Architecture Overview</a></li>
<li><a href="01-04-setting-up-kafka">Setting Up Kafka</a></li>
</ul>
<h2>Module 2: Kafka Core Concepts</h2>
<ul>
<li><a href="02-01-producers-and-consumers">Producers and Consumers</a></li>
<li><a href="02-02-topics-and-partitions">Topics and Partitions</a></li>
<li><a href="02-03-brokers-and-clusters">Brokers and Clusters</a></li>
<li><a href="02-04-messages-and-offsets">Messages and Offsets</a></li>
</ul>
<h2>Module 3: Kafka Operations</h2>
<ul>
<li><a href="03-01-producing-messages">Producing Messages</a></li>
<li><a href="03-02-consuming-messages">Consuming Messages</a></li>
<li><a href="03-03-kafka-connect">Kafka Connect</a></li>
<li><a href="03-04-kafka-streams">Kafka Streams</a></li>
</ul>
<h2>Module 4: Kafka Configuration and Management</h2>
<ul>
<li><a href="04-01-configuring-kafka">Configuring Kafka</a></li>
<li><a href="04-02-managing-kafka-topics">Managing Kafka Topics</a></li>
<li><a href="04-03-monitoring-kafka">Monitoring Kafka</a></li>
<li><a href="04-04-kafka-security">Kafka Security</a></li>
</ul>
<h2>Module 5: Advanced Kafka Topics</h2>
<ul>
<li><a href="05-01-kafka-performance-tuning">Kafka Performance Tuning</a></li>
<li><a href="05-02-kafka-multi-data-center">Kafka in a Multi-Data Center Setup</a></li>
<li><a href="05-03-kafka-schema-registry">Kafka with Schema Registry</a></li>
<li><a href="05-04-kafka-streams-advanced">Kafka Streams Advanced</a></li>
</ul>
<h2>Module 6: Kafka Ecosystem and Integrations</h2>
<ul>
<li><a href="06-01-kafka-hadoop">Kafka with Hadoop</a></li>
<li><a href="06-02-kafka-spark">Kafka with Spark</a></li>
<li><a href="06-03-kafka-flink">Kafka with Flink</a></li>
<li><a href="06-04-kafka-elasticsearch">Kafka with Elasticsearch</a></li>
</ul>
<h2>Module 7: Kafka Case Studies and Best Practices</h2>
<ul>
<li><a href="07-01-real-world-kafka-use-cases">Real-World Kafka Use Cases</a></li>
<li><a href="07-02-kafka-best-practices">Kafka Best Practices</a></li>
<li><a href="07-03-common-kafka-pitfalls">Common Kafka Pitfalls</a></li>
<li><a href="07-04-future-of-kafka">Future of Kafka</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
