<!DOCTYPE html>
<html lang="en">
<head>
    <title> Neural Networks and Deep Learning </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos_avanzados/05-04-redes-neuronales" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos_avanzados/05-04-xarxes-neuronals" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos_avanzados/05-04-neural-networks" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "algoritmos_avanzados";
  		var TEMA_NAME = "5-4";
  		var TYPE = "mod";
  		var PATH = "mod/algoritmos_avanzados/05-04-neural-networks";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/algoritmos_avanzados/05-04-redes-neuronales" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/algoritmos_avanzados/05-04-xarxes-neuronals" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="algoritmos_avanzados">
		<a  href="#" class="text-secondary d-none" data-read-mod="algoritmos_avanzados" data-read-unit="5-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="algoritmos_avanzados" data-unread-unit="5-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-03-regression-algorithms' title="Regression Algorithms" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-03-regression-algorithms' title="Regression Algorithms" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Neural Networks and Deep Learning</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-05-clustering-algorithms' title="Clustering Algorithms" class="py-2 px-3 btn btn-primary"
				data-read-mod="algoritmos_avanzados" data-read-unit="5-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-05-clustering-algorithms' title="Clustering Algorithms" class="py-2 px-3 btn btn-primary" 
				data-read-mod="algoritmos_avanzados" data-read-unit="5-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Neural Networks and Deep Learning are at the core of modern machine learning techniques. They are used to solve complex problems in various domains such as image recognition, natural language processing, and more. This section will cover the fundamental concepts, architectures, and practical applications of neural networks and deep learning.</p>
</div><h1>Key Concepts</h1>
<div class='content'></div><h2><ol>
<li>Artificial Neurons</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Definition</strong>: The basic unit of a neural network, inspired by biological neurons.</li>
<li><strong>Components</strong>:
<ul>
<li><strong>Inputs (x1, x2, ..., xn)</strong>: Features or data points.</li>
<li><strong>Weights (w1, w2, ..., wn)</strong>: Parameters that adjust the input's importance.</li>
<li><strong>Bias (b)</strong>: An additional parameter to adjust the output.</li>
<li><strong>Activation Function (Ïƒ)</strong>: A function that introduces non-linearity.</li>
</ul>
</li>
</ul>
</div><h2><ol start="2">
<li>Activation Functions</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Purpose</strong>: To introduce non-linearity into the model, allowing it to learn complex patterns.</li>
<li><strong>Common Activation Functions</strong>:
<ul>
<li><strong>Sigmoid</strong>: \( \sigma(x) = \frac{1}{1 + e^{-x}} \)</li>
<li><strong>Tanh</strong>: \( \text{tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \)</li>
<li><strong>ReLU (Rectified Linear Unit)</strong>: \( \text{ReLU}(x) = \max(0, x) \)</li>
</ul>
</li>
</ul>
</div><h2><ol start="3">
<li>Layers of a Neural Network</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Input Layer</strong>: The first layer that receives the input data.</li>
<li><strong>Hidden Layers</strong>: Intermediate layers that perform computations and feature extraction.</li>
<li><strong>Output Layer</strong>: The final layer that produces the output.</li>
</ul>
</div><h2><ol start="4">
<li>Forward Propagation</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Process</strong>: The input data is passed through the network, layer by layer, to produce an output.</li>
<li><strong>Mathematical Representation</strong>:
\[
\text{Output} = \sigma(W \cdot X + b)
\]
where \( W \) is the weight matrix, \( X \) is the input vector, and \( b \) is the bias vector.</li>
</ul>
</div><h2><ol start="5">
<li>Loss Function</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Purpose</strong>: To measure the difference between the predicted output and the actual output.</li>
<li><strong>Common Loss Functions</strong>:
<ul>
<li><strong>Mean Squared Error (MSE)</strong>: \( \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \)</li>
<li><strong>Cross-Entropy Loss</strong>: Used for classification problems.</li>
</ul>
</li>
</ul>
</div><h2><ol start="6">
<li>Backpropagation</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Purpose</strong>: To update the weights and biases to minimize the loss function.</li>
<li><strong>Process</strong>:
<ul>
<li>Calculate the gradient of the loss function with respect to each weight.</li>
<li>Update the weights using gradient descent.</li>
</ul>
</li>
</ul>
</div><h1>Practical Example: Building a Simple Neural Network</h1>
<div class='content'></div><h2>Step-by-Step Implementation</h2>
<div class='content'><h4>1. Import Libraries</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gc2tsZWFybi5kYXRhc2V0cyBpbXBvcnQgbWFrZV9tb29ucwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5wcmVwcm9jZXNzaW5nIGltcG9ydCBTdGFuZGFyZFNjYWxlcgppbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt</pre></div><div class='content'><h4>2. Generate and Preprocess Data</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHZW5lcmF0ZSBhIGRhdGFzZXQKWCwgeSA9IG1ha2VfbW9vbnMobl9zYW1wbGVzPTEwMDAsIG5vaXNlPTAuMiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBTcGxpdCBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0IHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjIsIHJhbmRvbV9zdGF0ZT00MikKCiMgU3RhbmRhcmRpemUgdGhlIGRhdGEKc2NhbGVyID0gU3RhbmRhcmRTY2FsZXIoKQpYX3RyYWluID0gc2NhbGVyLmZpdF90cmFuc2Zvcm0oWF90cmFpbikKWF90ZXN0ID0gc2NhbGVyLnRyYW5zZm9ybShYX3Rlc3Qp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Generate a dataset
X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)</pre></div><div class='content'><h4>3. Define the Neural Network</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class SimpleNeuralNetwork:
    def __init__(self, input_dim, hidden_dim, output_dim):
        self.W1 = np.random.randn(input_dim, hidden_dim)
        self.b1 = np.zeros((1, hidden_dim))
        self.W2 = np.random.randn(hidden_dim, output_dim)
        self.b2 = np.zeros((1, output_dim))
    
    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))
    
    def sigmoid_derivative(self, z):
        return z * (1 - z)
    
    def forward(self, X):
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.sigmoid(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)
        return self.a2
    
    def compute_loss(self, y, y_hat):
        return np.mean((y - y_hat) ** 2)
    
    def backward(self, X, y, y_hat, learning_rate):
        m = X.shape[0]
        d_loss_y_hat = 2 * (y_hat - y) / m
        d_y_hat_z2 = self.sigmoid_derivative(y_hat)
        d_z2_W2 = self.a1.T
        d_loss_W2 = np.dot(d_z2_W2, d_loss_y_hat * d_y_hat_z2)
        d_loss_b2 = np.sum(d_loss_y_hat * d_y_hat_z2, axis=0, keepdims=True)
        
        d_z2_a1 = self.W2
        d_a1_z1 = self.sigmoid_derivative(self.a1)
        d_z1_W1 = X.T
        d_loss_W1 = np.dot(d_z1_W1, np.dot(d_loss_y_hat * d_y_hat_z2, d_z2_a1.T) * d_a1_z1)
        d_loss_b1 = np.sum(np.dot(d_loss_y_hat * d_y_hat_z2, d_z2_a1.T) * d_a1_z1, axis=0, keepdims=True)
        
        self.W1 -= learning_rate * d_loss_W1
        self.b1 -= learning_rate * d_loss_b1
        self.W2 -= learning_rate * d_loss_W2
        self.b2 -= learning_rate * d_loss_b2</pre></div><div class='content'><h4>4. Train the Neural Network</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBJbml0aWFsaXplIHRoZSBuZXVyYWwgbmV0d29yawpubiA9IFNpbXBsZU5ldXJhbE5ldHdvcmsoaW5wdXRfZGltPTIsIGhpZGRlbl9kaW09Mywgb3V0cHV0X2RpbT0xKQoKIyBUcmFpbmluZyBwYXJhbWV0ZXJzCmVwb2NocyA9IDEwMDAKbGVhcm5pbmdfcmF0ZSA9IDAuMDEKbG9zc2VzID0gW10KCiMgVHJhaW5pbmcgbG9vcApmb3IgZXBvY2ggaW4gcmFuZ2UoZXBvY2hzKToKICAgIHlfaGF0ID0gbm4uZm9yd2FyZChYX3RyYWluKQogICAgbG9zcyA9IG5uLmNvbXB1dGVfbG9zcyh5X3RyYWluLnJlc2hhcGUoLTEsIDEpLCB5X2hhdCkKICAgIGxvc3Nlcy5hcHBlbmQobG9zcykKICAgIG5uLmJhY2t3YXJkKFhfdHJhaW4sIHlfdHJhaW4ucmVzaGFwZSgtMSwgMSksIHlfaGF0LCBsZWFybmluZ19yYXRlKQogICAgCiAgICBpZiBlcG9jaCAlIDEwMCA9PSAwOgogICAgICAgIHByaW50KGYnRXBvY2gge2Vwb2NofSwgTG9zczoge2xvc3N9JykKCiMgUGxvdCB0aGUgbG9zcyBjdXJ2ZQpwbHQucGxvdChsb3NzZXMpCnBsdC54bGFiZWwoJ0Vwb2NoJykKcGx0LnlsYWJlbCgnTG9zcycpCnBsdC50aXRsZSgnTG9zcyBDdXJ2ZScpCnBsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Initialize the neural network
nn = SimpleNeuralNetwork(input_dim=2, hidden_dim=3, output_dim=1)

# Training parameters
epochs = 1000
learning_rate = 0.01
losses = []

# Training loop
for epoch in range(epochs):
    y_hat = nn.forward(X_train)
    loss = nn.compute_loss(y_train.reshape(-1, 1), y_hat)
    losses.append(loss)
    nn.backward(X_train, y_train.reshape(-1, 1), y_hat, learning_rate)
    
    if epoch % 100 == 0:
        print(f'Epoch {epoch}, Loss: {loss}')

# Plot the loss curve
plt.plot(losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss Curve')
plt.show()</pre></div><div class='content'><h4>5. Evaluate the Neural Network</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQcmVkaWN0IG9uIHRoZSB0ZXN0IHNldAp5X3ByZWQgPSBubi5mb3J3YXJkKFhfdGVzdCkKeV9wcmVkID0gKHlfcHJlZCA+IDAuNSkuYXN0eXBlKGludCkKCiMgQ2FsY3VsYXRlIGFjY3VyYWN5CmFjY3VyYWN5ID0gbnAubWVhbih5X3ByZWQgPT0geV90ZXN0LnJlc2hhcGUoLTEsIDEpKQpwcmludChmJ1Rlc3QgQWNjdXJhY3k6IHthY2N1cmFjeSAqIDEwMDouMmZ9JScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Predict on the test set
y_pred = nn.forward(X_test)
y_pred = (y_pred &gt; 0.5).astype(int)

# Calculate accuracy
accuracy = np.mean(y_pred == y_test.reshape(-1, 1))
print(f'Test Accuracy: {accuracy * 100:.2f}%')</pre></div><div class='content'></div><h1>Practical Exercises</h1>
<div class='content'></div><h2>Exercise 1: Implement a ReLU Activation Function</h2>
<div class='content'><p><strong>Task</strong>: Modify the <code>SimpleNeuralNetwork</code> class to use the ReLU activation function instead of the sigmoid function.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgU2ltcGxlTmV1cmFsTmV0d29ya1JlTFUoU2ltcGxlTmV1cmFsTmV0d29yayk6CiAgICBkZWYgcmVsdShzZWxmLCB6KToKICAgICAgICByZXR1cm4gbnAubWF4aW11bSgwLCB6KQogICAgCiAgICBkZWYgcmVsdV9kZXJpdmF0aXZlKHNlbGYsIHopOgogICAgICAgIHJldHVybiBucC53aGVyZSh6ID4gMCwgMSwgMCkKICAgIAogICAgZGVmIGZvcndhcmQoc2VsZiwgWCk6CiAgICAgICAgc2VsZi56MSA9IG5wLmRvdChYLCBzZWxmLlcxKSArIHNlbGYuYjEKICAgICAgICBzZWxmLmExID0gc2VsZi5yZWx1KHNlbGYuejEpCiAgICAgICAgc2VsZi56MiA9IG5wLmRvdChzZWxmLmExLCBzZWxmLlcyKSArIHNlbGYuYjIKICAgICAgICBzZWxmLmEyID0gc2VsZi5yZWx1KHNlbGYuejIpCiAgICAgICAgcmV0dXJuIHNlbGYuYTIKICAgIAogICAgZGVmIGJhY2t3YXJkKHNlbGYsIFgsIHksIHlfaGF0LCBsZWFybmluZ19yYXRlKToKICAgICAgICBtID0gWC5zaGFwZVswXQogICAgICAgIGRfbG9zc195X2hhdCA9IDIgKiAoeV9oYXQgLSB5KSAvIG0KICAgICAgICBkX3lfaGF0X3oyID0gc2VsZi5yZWx1X2Rlcml2YXRpdmUoeV9oYXQpCiAgICAgICAgZF96Ml9XMiA9IHNlbGYuYTEuVAogICAgICAgIGRfbG9zc19XMiA9IG5wLmRvdChkX3oyX1cyLCBkX2xvc3NfeV9oYXQgKiBkX3lfaGF0X3oyKQogICAgICAgIGRfbG9zc19iMiA9IG5wLnN1bShkX2xvc3NfeV9oYXQgKiBkX3lfaGF0X3oyLCBheGlzPTAsIGtlZXBkaW1zPVRydWUpCiAgICAgICAgCiAgICAgICAgZF96Ml9hMSA9IHNlbGYuVzIKICAgICAgICBkX2ExX3oxID0gc2VsZi5yZWx1X2Rlcml2YXRpdmUoc2VsZi5hMSkKICAgICAgICBkX3oxX1cxID0gWC5UCiAgICAgICAgZF9sb3NzX1cxID0gbnAuZG90KGRfejFfVzEsIG5wLmRvdChkX2xvc3NfeV9oYXQgKiBkX3lfaGF0X3oyLCBkX3oyX2ExLlQpICogZF9hMV96MSkKICAgICAgICBkX2xvc3NfYjEgPSBucC5zdW0obnAuZG90KGRfbG9zc195X2hhdCAqIGRfeV9oYXRfejIsIGRfejJfYTEuVCkgKiBkX2ExX3oxLCBheGlzPTAsIGtlZXBkaW1zPVRydWUpCiAgICAgICAgCiAgICAgICAgc2VsZi5XMSAtPSBsZWFybmluZ19yYXRlICogZF9sb3NzX1cxCiAgICAgICAgc2VsZi5iMSAtPSBsZWFybmluZ19yYXRlICogZF9sb3NzX2IxCiAgICAgICAgc2VsZi5XMiAtPSBsZWFybmluZ19yYXRlICogZF9sb3NzX1cyCiAgICAgICAgc2VsZi5iMiAtPSBsZWFybmluZ19yYXRlICogZF9sb3NzX2Iy"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class SimpleNeuralNetworkReLU(SimpleNeuralNetwork):
    def relu(self, z):
        return np.maximum(0, z)
    
    def relu_derivative(self, z):
        return np.where(z &gt; 0, 1, 0)
    
    def forward(self, X):
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.relu(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.relu(self.z2)
        return self.a2
    
    def backward(self, X, y, y_hat, learning_rate):
        m = X.shape[0]
        d_loss_y_hat = 2 * (y_hat - y) / m
        d_y_hat_z2 = self.relu_derivative(y_hat)
        d_z2_W2 = self.a1.T
        d_loss_W2 = np.dot(d_z2_W2, d_loss_y_hat * d_y_hat_z2)
        d_loss_b2 = np.sum(d_loss_y_hat * d_y_hat_z2, axis=0, keepdims=True)
        
        d_z2_a1 = self.W2
        d_a1_z1 = self.relu_derivative(self.a1)
        d_z1_W1 = X.T
        d_loss_W1 = np.dot(d_z1_W1, np.dot(d_loss_y_hat * d_y_hat_z2, d_z2_a1.T) * d_a1_z1)
        d_loss_b1 = np.sum(np.dot(d_loss_y_hat * d_y_hat_z2, d_z2_a1.T) * d_a1_z1, axis=0, keepdims=True)
        
        self.W1 -= learning_rate * d_loss_W1
        self.b1 -= learning_rate * d_loss_b1
        self.W2 -= learning_rate * d_loss_W2
        self.b2 -= learning_rate * d_loss_b2</pre></div><div class='content'></div><h2>Exercise 2: Add a Second Hidden Layer</h2>
<div class='content'><p><strong>Task</strong>: Modify the <code>SimpleNeuralNetwork</code> class to include a second hidden layer.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class TwoLayerNeuralNetwork:
    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):
        self.W1 = np.random.randn(input_dim, hidden_dim1)
        self.b1 = np.zeros((1, hidden_dim1))
        self.W2 = np.random.randn(hidden_dim1, hidden_dim2)
        self.b2 = np.zeros((1, hidden_dim2))
        self.W3 = np.random.randn(hidden_dim2, output_dim)
        self.b3 = np.zeros((1, output_dim))
    
    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))
    
    def sigmoid_derivative(self, z):
        return z * (1 - z)
    
    def forward(self, X):
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.sigmoid(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.sigmoid(self.z2)
        self.z3 = np.dot(self.a2, self.W3) + self.b3
        self.a3 = self.sigmoid(self.z3)
        return self.a3
    
    def compute_loss(self, y, y_hat):
        return np.mean((y - y_hat) ** 2)
    
    def backward(self, X, y, y_hat, learning_rate):
        m = X.shape[0]
        d_loss_y_hat = 2 * (y_hat - y) / m
        d_y_hat_z3 = self.sigmoid_derivative(y_hat)
        d_z3_W3 = self.a2.T
        d_loss_W3 = np.dot(d_z3_W3, d_loss_y_hat * d_y_hat_z3)
        d_loss_b3 = np.sum(d_loss_y_hat * d_y_hat_z3, axis=0, keepdims=True)
        
        d_z3_a2 = self.W3
        d_a2_z2 = self.sigmoid_derivative(self.a2)
        d_z2_W2 = self.a1.T
        d_loss_W2 = np.dot(d_z2_W2, np.dot(d_loss_y_hat * d_y_hat_z3, d_z3_a2.T) * d_a2_z2)
        d_loss_b2 = np.sum(np.dot(d_loss_y_hat * d_y_hat_z3, d_z3_a2.T) * d_a2_z2, axis=0, keepdims=True)
        
        d_z2_a1 = self.W2
        d_a1_z1 = self.sigmoid_derivative(self.a1)
        d_z1_W1 = X.T
        d_loss_W1 = np.dot(d_z1_W1, np.dot(np.dot(d_loss_y_hat * d_y_hat_z3, d_z3_a2.T) * d_a2_z2, d_z2_a1.T) * d_a1_z1)
        d_loss_b1 = np.sum(np.dot(np.dot(d_loss_y_hat * d_y_hat_z3, d_z3_a2.T) * d_a2_z2, d_z2_a1.T) * d_a1_z1, axis=0, keepdims=True)
        
        self.W1 -= learning_rate * d_loss_W1
        self.b1 -= learning_rate * d_loss_b1
        self.W2 -= learning_rate * d_loss_W2
        self.b2 -= learning_rate * d_loss_b2
        self.W3 -= learning_rate * d_loss_W3
        self.b3 -= learning_rate * d_loss_b3</pre></div><div class='content'></div><h1>Summary</h1>
<div class='content'><p>In this section, we covered the fundamental concepts of neural networks and deep learning, including artificial neurons, activation functions, layers, forward propagation, loss functions, and backpropagation. We also implemented a simple neural network from scratch and explored practical exercises to reinforce the concepts. Understanding these basics is crucial for delving deeper into more advanced neural network architectures and applications.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-03-regression-algorithms' title="Regression Algorithms" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-03-regression-algorithms' title="Regression Algorithms" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-05-clustering-algorithms' title="Clustering Algorithms" class="py-2 px-3 btn btn-primary"
				data-read-mod="algoritmos_avanzados" data-read-unit="5-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-05-clustering-algorithms' title="Clustering Algorithms" class="py-2 px-3 btn btn-primary" 
				data-read-mod="algoritmos_avanzados" data-read-unit="5-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Advanced Algorithms</h1>
<h2>Module 1: Introduction to Advanced Algorithms</h2>
<ul>
<li><a href="01-01-basic-concepts">Basic Concepts and Notation</a></li>
<li><a href="01-02-complexity-analysis">Complexity Analysis</a></li>
<li><a href="01-03-recursion-dynamic-programming">Recursion and Dynamic Programming</a></li>
</ul>
<h2>Module 2: Optimization Algorithms</h2>
<ul>
<li><a href="02-01-linear-programming">Linear Programming</a></li>
<li><a href="02-02-combinatorial-optimization">Combinatorial Optimization Algorithms</a></li>
<li><a href="02-03-genetic-algorithms">Genetic Algorithms</a></li>
<li><a href="02-04-ant-colony">Ant Colony Optimization</a></li>
</ul>
<h2>Module 3: Graph Algorithms</h2>
<ul>
<li><a href="03-01-graph-representation">Graph Representation</a></li>
<li><a href="03-02-graph-search">Graph Search: BFS and DFS</a></li>
<li><a href="03-03-shortest-paths">Shortest Path Algorithms</a></li>
<li><a href="03-04-maximum-flow">Maximum Flow Algorithms</a></li>
<li><a href="03-05-graph-matching">Graph Matching Algorithms</a></li>
</ul>
<h2>Module 4: Search and Sorting Algorithms</h2>
<ul>
<li><a href="04-01-binary-search">Binary Search and Variants</a></li>
<li><a href="04-02-advanced-sorting">Advanced Sorting Algorithms</a></li>
<li><a href="04-03-state-space-search">State Space Search</a></li>
</ul>
<h2>Module 5: Machine Learning Algorithms</h2>
<ul>
<li><a href="05-01-introduction-machine-learning">Introduction to Machine Learning</a></li>
<li><a href="05-02-classification-algorithms">Classification Algorithms</a></li>
<li><a href="05-03-regression-algorithms">Regression Algorithms</a></li>
<li><a href="05-04-neural-networks">Neural Networks and Deep Learning</a></li>
<li><a href="05-05-clustering-algorithms">Clustering Algorithms</a></li>
</ul>
<h2>Module 6: Case Studies and Applications</h2>
<ul>
<li><a href="06-01-optimization-industry">Optimization in Industry</a></li>
<li><a href="06-02-graph-applications">Graph Applications in Social Networks</a></li>
<li><a href="06-03-search-sorting-data">Search and Sorting in Large Data Volumes</a></li>
<li><a href="06-04-machine-learning-real-life">Machine Learning Applications in Real Life</a></li>
</ul>
<h2>Module 7: Final Project</h2>
<ul>
<li><a href="07-01-project-definition">Project Definition</a></li>
<li><a href="07-02-project-development">Project Development</a></li>
<li><a href="07-03-presentation-evaluation">Presentation and Evaluation</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
