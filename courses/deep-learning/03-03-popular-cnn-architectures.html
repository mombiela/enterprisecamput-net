<!DOCTYPE html>
<html lang="en">
<head>
    <title> Popular CNN Architectures </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/deep-learning/03-03-arquitecturas-populares-cnn" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/deep-learning/03-03-arquitecturas-populares-cnn" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/deep-learning/03-03-popular-cnn-architectures" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "3-3";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/03-03-popular-cnn-architectures";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/deep-learning/03-03-arquitecturas-populares-cnn" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/deep-learning/03-03-arquitecturas-populares-cnn" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="3-3" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="3-3" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-02-convolutional-pooling-layers' title="Convolutional and Pooling Layers" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-02-convolutional-pooling-layers' title="Convolutional and Pooling Layers" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Popular CNN Architectures</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='03-04-cnn-applications-image-recognition' title="CNN Applications in Image Recognition" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="3-3">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='03-04-cnn-applications-image-recognition' title="CNN Applications in Image Recognition" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="3-3">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will explore some of the most influential and widely used Convolutional Neural Network (CNN) architectures. These architectures have set benchmarks in various image recognition tasks and have inspired numerous advancements in the field of deep learning.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ol>
<li><strong>LeNet-5</strong></li>
<li><strong>AlexNet</strong></li>
<li><strong>VGGNet</strong></li>
<li><strong>GoogLeNet (Inception)</strong></li>
<li><strong>ResNet</strong></li>
<li><strong>DenseNet</strong></li>
</ol>
</div><h2><ol>
<li>LeNet-5</li>
</ol></h2>
<div class='content'></div><h3>Overview</h3>
<div class='content'><p>LeNet-5, developed by Yann LeCun and his colleagues in 1998, is one of the earliest CNN architectures. It was designed for handwritten digit recognition (MNIST dataset).</p>
</div><h3>Architecture</h3>
<div class='content'><ul>
<li><strong>Input Layer:</strong> 32x32 grayscale image.</li>
<li><strong>C1:</strong> Convolutional layer with 6 filters of size 5x5, followed by a subsampling layer.</li>
<li><strong>S2:</strong> Subsampling layer (average pooling) with a 2x2 filter.</li>
<li><strong>C3:</strong> Convolutional layer with 16 filters of size 5x5.</li>
<li><strong>S4:</strong> Subsampling layer (average pooling) with a 2x2 filter.</li>
<li><strong>C5:</strong> Fully connected convolutional layer with 120 filters of size 5x5.</li>
<li><strong>F6:</strong> Fully connected layer with 84 units.</li>
<li><strong>Output Layer:</strong> Fully connected layer with 10 units (one for each digit).</li>
</ul>
</div><h3>Code Example</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBsYXllcnMsIG1vZGVscwoKbW9kZWwgPSBtb2RlbHMuU2VxdWVudGlhbCgpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDYsICg1LCA1KSwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSgzMiwgMzIsIDEpKSkKbW9kZWwuYWRkKGxheWVycy5BdmVyYWdlUG9vbGluZzJEKCgyLCAyKSkpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDE2LCAoNSwgNSksIGFjdGl2YXRpb249J3JlbHUnKSkKbW9kZWwuYWRkKGxheWVycy5BdmVyYWdlUG9vbGluZzJEKCgyLCAyKSkpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDEyMCwgKDUsIDUpLCBhY3RpdmF0aW9uPSdyZWx1JykpCm1vZGVsLmFkZChsYXllcnMuRmxhdHRlbigpKQptb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDg0LCBhY3RpdmF0aW9uPSdyZWx1JykpCm1vZGVsLmFkZChsYXllcnMuRGVuc2UoMTAsIGFjdGl2YXRpb249J3NvZnRtYXgnKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers, models

model = models.Sequential()
model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(32, 32, 1)))
model.add(layers.AveragePooling2D((2, 2)))
model.add(layers.Conv2D(16, (5, 5), activation='relu'))
model.add(layers.AveragePooling2D((2, 2)))
model.add(layers.Conv2D(120, (5, 5), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(84, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))</pre></div><div class='content'></div><h2><ol start="2">
<li>AlexNet</li>
</ol></h2>
<div class='content'></div><h3>Overview</h3>
<div class='content'><p>AlexNet, created by Alex Krizhevsky et al. in 2012, won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) and significantly advanced the field of deep learning.</p>
</div><h3>Architecture</h3>
<div class='content'><ul>
<li><strong>Input Layer:</strong> 227x227 RGB image.</li>
<li><strong>Conv1:</strong> Convolutional layer with 96 filters of size 11x11, stride 4, followed by max pooling.</li>
<li><strong>Conv2:</strong> Convolutional layer with 256 filters of size 5x5, followed by max pooling.</li>
<li><strong>Conv3:</strong> Convolutional layer with 384 filters of size 3x3.</li>
<li><strong>Conv4:</strong> Convolutional layer with 384 filters of size 3x3.</li>
<li><strong>Conv5:</strong> Convolutional layer with 256 filters of size 3x3, followed by max pooling.</li>
<li><strong>FC6:</strong> Fully connected layer with 4096 units.</li>
<li><strong>FC7:</strong> Fully connected layer with 4096 units.</li>
<li><strong>Output Layer:</strong> Fully connected layer with 1000 units (one for each class in ImageNet).</li>
</ul>
</div><h3>Code Example</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwgPSBtb2RlbHMuU2VxdWVudGlhbCgpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDk2LCAoMTEsIDExKSwgc3RyaWRlcz0oNCwgNCksIGFjdGl2YXRpb249J3JlbHUnLCBpbnB1dF9zaGFwZT0oMjI3LCAyMjcsIDMpKSkKbW9kZWwuYWRkKGxheWVycy5NYXhQb29saW5nMkQoKDMsIDMpLCBzdHJpZGVzPSgyLCAyKSkpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDI1NiwgKDUsIDUpLCBhY3RpdmF0aW9uPSdyZWx1JykpCm1vZGVsLmFkZChsYXllcnMuTWF4UG9vbGluZzJEKCgzLCAzKSwgc3RyaWRlcz0oMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgzODQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgzODQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMywgMyksIHN0cmlkZXM9KDIsIDIpKSkKbW9kZWwuYWRkKGxheWVycy5GbGF0dGVuKCkpCm1vZGVsLmFkZChsYXllcnMuRGVuc2UoNDA5NiwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDQwOTYsIGFjdGl2YXRpb249J3JlbHUnKSkKbW9kZWwuYWRkKGxheWVycy5EZW5zZSgxMDAwLCBhY3RpdmF0aW9uPSdzb2Z0bWF4Jykp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model = models.Sequential()
model.add(layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(227, 227, 3)))
model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))
model.add(layers.Conv2D(256, (5, 5), activation='relu'))
model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))
model.add(layers.Conv2D(384, (3, 3), activation='relu'))
model.add(layers.Conv2D(384, (3, 3), activation='relu'))
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(4096, activation='relu'))
model.add(layers.Dense(4096, activation='relu'))
model.add(layers.Dense(1000, activation='softmax'))</pre></div><div class='content'></div><h2><ol start="3">
<li>VGGNet</li>
</ol></h2>
<div class='content'></div><h3>Overview</h3>
<div class='content'><p>VGGNet, developed by the Visual Geometry Group at Oxford, is known for its simplicity and depth. It uses very small (3x3) convolution filters and has a uniform architecture.</p>
</div><h3>Architecture</h3>
<div class='content'><ul>
<li><strong>Input Layer:</strong> 224x224 RGB image.</li>
<li><strong>Conv Layers:</strong> Multiple convolutional layers with 3x3 filters, followed by max pooling.</li>
<li><strong>FC Layers:</strong> Three fully connected layers, the first two with 4096 units and the third with 1000 units.</li>
</ul>
</div><h3>Code Example</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwgPSBtb2RlbHMuU2VxdWVudGlhbCgpCm1vZGVsLmFkZChsYXllcnMuQ29udjJEKDY0LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBpbnB1dF9zaGFwZT0oMjI0LCAyMjQsIDMpKSkKbW9kZWwuYWRkKGxheWVycy5Db252MkQoNjQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgxMjgsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgxMjgsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkZsYXR0ZW4oKSkKbW9kZWwuYWRkKGxheWVycy5EZW5zZSg0MDk2LCBhY3RpdmF0aW9uPSdyZWx1JykpCm1vZGVsLmFkZChsYXllcnMuRGVuc2UoNDA5NiwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDEwMDAsIGFjdGl2YXRpb249J3NvZnRtYXgnKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model = models.Sequential()
model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.Conv2D(256, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(512, (3, 3), activation='relu'))
model.add(layers.Conv2D(512, (3, 3), activation='relu'))
model.add(layers.Conv2D(512, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(512, (3, 3), activation='relu'))
model.add(layers.Conv2D(512, (3, 3), activation='relu'))
model.add(layers.Conv2D(512, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(4096, activation='relu'))
model.add(layers.Dense(4096, activation='relu'))
model.add(layers.Dense(1000, activation='softmax'))</pre></div><div class='content'></div><h2><ol start="4">
<li>GoogLeNet (Inception)</li>
</ol></h2>
<div class='content'></div><h3>Overview</h3>
<div class='content'><p>GoogLeNet, also known as Inception, was developed by Google and won the ILSVRC 2014. It introduced the Inception module, which allows for more efficient computation.</p>
</div><h3>Architecture</h3>
<div class='content'><ul>
<li><strong>Input Layer:</strong> 224x224 RGB image.</li>
<li><strong>Inception Modules:</strong> Multiple inception modules that apply convolutional filters of different sizes in parallel.</li>
<li><strong>Auxiliary Classifiers:</strong> Intermediate classifiers to combat the vanishing gradient problem.</li>
<li><strong>Output Layer:</strong> Fully connected layer with 1000 units.</li>
</ul>
</div><h3>Code Example</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgSW5wdXQsIENvbnYyRCwgTWF4UG9vbGluZzJELCBjb25jYXRlbmF0ZSwgRGVuc2UsIEZsYXR0ZW4KZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgTW9kZWwKCmlucHV0X2ltZyA9IElucHV0KHNoYXBlPSgyMjQsIDIyNCwgMykpCgpkZWYgaW5jZXB0aW9uX21vZHVsZSh4LCBmaWx0ZXJzKToKICAgIGYxLCBmM19yLCBmMywgZjVfciwgZjUsIHBvb2xfcHJvaiA9IGZpbHRlcnMKICAgIGNvbnYxID0gQ29udjJEKGYxLCAoMSwgMSksIHBhZGRpbmc9J3NhbWUnLCBhY3RpdmF0aW9uPSdyZWx1JykoeCkKICAgIGNvbnYzID0gQ29udjJEKGYzX3IsICgxLCAxKSwgcGFkZGluZz0nc2FtZScsIGFjdGl2YXRpb249J3JlbHUnKSh4KQogICAgY29udjMgPSBDb252MkQoZjMsICgzLCAzKSwgcGFkZGluZz0nc2FtZScsIGFjdGl2YXRpb249J3JlbHUnKShjb252MykKICAgIGNvbnY1ID0gQ29udjJEKGY1X3IsICgxLCAxKSwgcGFkZGluZz0nc2FtZScsIGFjdGl2YXRpb249J3JlbHUnKSh4KQogICAgY29udjUgPSBDb252MkQoZjUsICg1LCA1KSwgcGFkZGluZz0nc2FtZScsIGFjdGl2YXRpb249J3JlbHUnKShjb252NSkKICAgIHBvb2wgPSBNYXhQb29saW5nMkQoKDMsIDMpLCBzdHJpZGVzPSgxLCAxKSwgcGFkZGluZz0nc2FtZScpKHgpCiAgICBwb29sID0gQ29udjJEKHBvb2xfcHJvaiwgKDEsIDEpLCBwYWRkaW5nPSdzYW1lJywgYWN0aXZhdGlvbj0ncmVsdScpKHBvb2wpCiAgICByZXR1cm4gY29uY2F0ZW5hdGUoW2NvbnYxLCBjb252MywgY29udjUsIHBvb2xdLCBheGlzPS0xKQoKeCA9IGluY2VwdGlvbl9tb2R1bGUoaW5wdXRfaW1nLCBbNjQsIDk2LCAxMjgsIDE2LCAzMiwgMzJdKQp4ID0gTWF4UG9vbGluZzJEKCgzLCAzKSwgc3RyaWRlcz0oMiwgMikpKHgpCnggPSBpbmNlcHRpb25fbW9kdWxlKHgsIFsxMjgsIDEyOCwgMTkyLCAzMiwgOTYsIDY0XSkKeCA9IE1heFBvb2xpbmcyRCgoMywgMyksIHN0cmlkZXM9KDIsIDIpKSh4KQp4ID0gRmxhdHRlbigpKHgpCnggPSBEZW5zZSgxMDAwLCBhY3RpdmF0aW9uPSdzb2Z0bWF4JykoeCkKCm1vZGVsID0gTW9kZWwoaW5wdXRfaW1nLCB4KQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Dense, Flatten
from tensorflow.keras.models import Model

input_img = Input(shape=(224, 224, 3))

def inception_module(x, filters):
    f1, f3_r, f3, f5_r, f5, pool_proj = filters
    conv1 = Conv2D(f1, (1, 1), padding='same', activation='relu')(x)
    conv3 = Conv2D(f3_r, (1, 1), padding='same', activation='relu')(x)
    conv3 = Conv2D(f3, (3, 3), padding='same', activation='relu')(conv3)
    conv5 = Conv2D(f5_r, (1, 1), padding='same', activation='relu')(x)
    conv5 = Conv2D(f5, (5, 5), padding='same', activation='relu')(conv5)
    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
    pool = Conv2D(pool_proj, (1, 1), padding='same', activation='relu')(pool)
    return concatenate([conv1, conv3, conv5, pool], axis=-1)

x = inception_module(input_img, [64, 96, 128, 16, 32, 32])
x = MaxPooling2D((3, 3), strides=(2, 2))(x)
x = inception_module(x, [128, 128, 192, 32, 96, 64])
x = MaxPooling2D((3, 3), strides=(2, 2))(x)
x = Flatten()(x)
x = Dense(1000, activation='softmax')(x)

model = Model(input_img, x)</pre></div><div class='content'></div><h2><ol start="5">
<li>ResNet</li>
</ol></h2>
<div class='content'></div><h3>Overview</h3>
<div class='content'><p>ResNet, or Residual Network, introduced by Microsoft in 2015, won the ILSVRC 2015. It uses residual connections (skip connections) to allow for training much deeper networks.</p>
</div><h3>Architecture</h3>
<div class='content'><ul>
<li><strong>Input Layer:</strong> 224x224 RGB image.</li>
<li><strong>Residual Blocks:</strong> Multiple residual blocks with identity shortcuts.</li>
<li><strong>Output Layer:</strong> Fully connected layer with 1000 units.</li>
</ul>
</div><h3>Code Example</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgSW5wdXQsIENvbnYyRCwgQmF0Y2hOb3JtYWxpemF0aW9uLCBBY3RpdmF0aW9uLCBhZGQsIERlbnNlLCBGbGF0dGVuCmZyb20gdGVuc29yZmxvdy5rZXJhcy5tb2RlbHMgaW1wb3J0IE1vZGVsCgpkZWYgcmVzaWR1YWxfYmxvY2soeCwgZmlsdGVycyk6CiAgICBzaG9ydGN1dCA9IHgKICAgIHggPSBDb252MkQoZmlsdGVycywgKDMsIDMpLCBwYWRkaW5nPSdzYW1lJykoeCkKICAgIHggPSBCYXRjaE5vcm1hbGl6YXRpb24oKSh4KQogICAgeCA9IEFjdGl2YXRpb24oJ3JlbHUnKSh4KQogICAgeCA9IENvbnYyRChmaWx0ZXJzLCAoMywgMyksIHBhZGRpbmc9J3NhbWUnKSh4KQogICAgeCA9IEJhdGNoTm9ybWFsaXphdGlvbigpKHgpCiAgICB4ID0gYWRkKFt4LCBzaG9ydGN1dF0pCiAgICB4ID0gQWN0aXZhdGlvbigncmVsdScpKHgpCiAgICByZXR1cm4geAoKaW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KDIyNCwgMjI0LCAzKSkKeCA9IENvbnYyRCg2NCwgKDcsIDcpLCBzdHJpZGVzPSgyLCAyKSwgcGFkZGluZz0nc2FtZScpKGlucHV0X2ltZykKeCA9IEJhdGNoTm9ybWFsaXphdGlvbigpKHgpCnggPSBBY3RpdmF0aW9uKCdyZWx1JykoeCkKeCA9IE1heFBvb2xpbmcyRCgoMywgMyksIHN0cmlkZXM9KDIsIDIpKSh4KQp4ID0gcmVzaWR1YWxfYmxvY2soeCwgNjQpCnggPSByZXNpZHVhbF9ibG9jayh4LCA2NCkKeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDY0KQp4ID0gRmxhdHRlbigpKHgpCnggPSBEZW5zZSgxMDAwLCBhY3RpdmF0aW9uPSdzb2Z0bWF4JykoeCkKCm1vZGVsID0gTW9kZWwoaW5wdXRfaW1nLCB4KQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, add, Dense, Flatten
from tensorflow.keras.models import Model

def residual_block(x, filters):
    shortcut = x
    x = Conv2D(filters, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = Conv2D(filters, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = add([x, shortcut])
    x = Activation('relu')(x)
    return x

input_img = Input(shape=(224, 224, 3))
x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_img)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling2D((3, 3), strides=(2, 2))(x)
x = residual_block(x, 64)
x = residual_block(x, 64)
x = residual_block(x, 64)
x = Flatten()(x)
x = Dense(1000, activation='softmax')(x)

model = Model(input_img, x)</pre></div><div class='content'></div><h2><ol start="6">
<li>DenseNet</li>
</ol></h2>
<div class='content'></div><h3>Overview</h3>
<div class='content'><p>DenseNet, or Densely Connected Convolutional Networks, introduced by Gao Huang et al. in 2016, connects each layer to every other layer in a feed-forward fashion.</p>
</div><h3>Architecture</h3>
<div class='content'><ul>
<li><strong>Input Layer:</strong> 224x224 RGB image.</li>
<li><strong>Dense Blocks:</strong> Multiple dense blocks where each layer receives input from all previous layers.</li>
<li><strong>Output Layer:</strong> Fully connected layer with 1000 units.</li>
</ul>
</div><h3>Code Example</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgSW5wdXQsIENvbnYyRCwgQmF0Y2hOb3JtYWxpemF0aW9uLCBBY3RpdmF0aW9uLCBjb25jYXRlbmF0ZSwgRGVuc2UsIEZsYXR0ZW4KZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgTW9kZWwKCmRlZiBkZW5zZV9ibG9jayh4LCBmaWx0ZXJzLCBncm93dGhfcmF0ZSwgbGF5ZXJzKToKICAgIGZvciBfIGluIHJhbmdlKGxheWVycyk6CiAgICAgICAgY29udiA9IEJhdGNoTm9ybWFsaXphdGlvbigpKHgpCiAgICAgICAgY29udiA9IEFjdGl2YXRpb24oJ3JlbHUnKShjb252KQogICAgICAgIGNvbnYgPSBDb252MkQoZ3Jvd3RoX3JhdGUsICgzLCAzKSwgcGFkZGluZz0nc2FtZScpKGNvbnYpCiAgICAgICAgeCA9IGNvbmNhdGVuYXRlKFt4LCBjb252XSkKICAgIHJldHVybiB4CgppbnB1dF9pbWcgPSBJbnB1dChzaGFwZT0oMjI0LCAyMjQsIDMpKQp4ID0gQ29udjJEKDY0LCAoNywgNyksIHN0cmlkZXM9KDIsIDIpLCBwYWRkaW5nPSdzYW1lJykoaW5wdXRfaW1nKQp4ID0gQmF0Y2hOb3JtYWxpemF0aW9uKCkoeCkKeCA9IEFjdGl2YXRpb24oJ3JlbHUnKSh4KQp4ID0gTWF4UG9vbGluZzJEKCgzLCAzKSwgc3RyaWRlcz0oMiwgMikpKHgpCnggPSBkZW5zZV9ibG9jayh4LCA2NCwgMzIsIDYpCnggPSBGbGF0dGVuKCkoeCkKeCA9IERlbnNlKDEwMDAsIGFjdGl2YXRpb249J3NvZnRtYXgnKSh4KQoKbW9kZWwgPSBNb2RlbChpbnB1dF9pbWcsIHgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, concatenate, Dense, Flatten
from tensorflow.keras.models import Model

def dense_block(x, filters, growth_rate, layers):
    for _ in range(layers):
        conv = BatchNormalization()(x)
        conv = Activation('relu')(conv)
        conv = Conv2D(growth_rate, (3, 3), padding='same')(conv)
        x = concatenate([x, conv])
    return x

input_img = Input(shape=(224, 224, 3))
x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(input_img)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling2D((3, 3), strides=(2, 2))(x)
x = dense_block(x, 64, 32, 6)
x = Flatten()(x)
x = Dense(1000, activation='softmax')(x)

model = Model(input_img, x)</pre></div><div class='content'></div><h2>Conclusion</h2>
<div class='content'><p>In this section, we explored some of the most popular CNN architectures that have significantly impacted the field of deep learning. Each architecture has its unique characteristics and has contributed to advancements in image recognition tasks. Understanding these architectures provides a solid foundation for designing and implementing your own CNN models.</p>
<p>Next, we will delve into the applications of CNNs in image recognition, where we will see how these architectures are applied to solve real-world problems.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-02-convolutional-pooling-layers' title="Convolutional and Pooling Layers" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-02-convolutional-pooling-layers' title="Convolutional and Pooling Layers" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='03-04-cnn-applications-image-recognition' title="CNN Applications in Image Recognition" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="3-3">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='03-04-cnn-applications-image-recognition' title="CNN Applications in Image Recognition" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="3-3">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Deep Learning Course</h1>
<h2>Module 1: Introduction to Deep Learning</h2>
<ul>
<li><a href="01-01-what-is-deep-learning">What is Deep Learning?</a></li>
<li><a href="01-02-history-evolution-deep-learning">History and Evolution of Deep Learning</a></li>
<li><a href="01-03-applications-deep-learning">Applications of Deep Learning</a></li>
<li><a href="01-04-basic-concepts-neural-networks">Basic Concepts of Neural Networks</a></li>
</ul>
<h2>Module 2: Fundamentals of Neural Networks</h2>
<ul>
<li><a href="02-01-perceptron-multilayer-perceptron">Perceptron and Multilayer Perceptron</a></li>
<li><a href="02-02-activation-function">Activation Function</a></li>
<li><a href="02-03-forward-backward-propagation">Forward and Backward Propagation</a></li>
<li><a href="02-04-optimization-loss-function">Optimization and Loss Function</a></li>
</ul>
<h2>Module 3: Convolutional Neural Networks (CNN)</h2>
<ul>
<li><a href="03-01-introduction-cnn">Introduction to CNN</a></li>
<li><a href="03-02-convolutional-pooling-layers">Convolutional and Pooling Layers</a></li>
<li><a href="03-03-popular-cnn-architectures">Popular CNN Architectures</a></li>
<li><a href="03-04-cnn-applications-image-recognition">CNN Applications in Image Recognition</a></li>
</ul>
<h2>Module 4: Recurrent Neural Networks (RNN)</h2>
<ul>
<li><a href="04-01-introduction-rnn">Introduction to RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM and GRU</a></li>
<li><a href="04-03-rnn-applications-nlp">RNN Applications in Natural Language Processing</a></li>
<li><a href="04-04-sequences-time-series">Sequences and Time Series</a></li>
</ul>
<h2>Module 5: Advanced Techniques in Deep Learning</h2>
<ul>
<li><a href="05-01-generative-adversarial-networks">Generative Adversarial Networks (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularization-improvement-techniques">Regularization and Improvement Techniques</a></li>
</ul>
<h2>Module 6: Tools and Frameworks</h2>
<ul>
<li><a href="06-01-introduction-tensorflow">Introduction to TensorFlow</a></li>
<li><a href="06-02-introduction-pytorch">Introduction to PyTorch</a></li>
<li><a href="06-03-framework-comparison">Framework Comparison</a></li>
<li><a href="06-04-development-environments-resources">Development Environments and Additional Resources</a></li>
</ul>
<h2>Module 7: Practical Projects</h2>
<ul>
<li><a href="07-01-image-classification-cnn">Image Classification with CNN</a></li>
<li><a href="07-02-text-generation-rnn">Text Generation with RNN</a></li>
<li><a href="07-03-anomaly-detection-autoencoders">Anomaly Detection with Autoencoders</a></li>
<li><a href="07-04-creating-gan-image-generation">Creating a GAN for Image Generation</a></li>
</ul>
<h2>Module 8: Ethical Considerations and the Future of Deep Learning</h2>
<ul>
<li><a href="08-01-ethics-deep-learning">Ethics in Deep Learning</a></li>
<li><a href="08-02-social-economic-impact">Social and Economic Impact</a></li>
<li><a href="08-03-future-trends-deep-learning">Future Trends in Deep Learning</a></li>
<li><a href="08-04-challenges-opportunities">Challenges and Opportunities</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
