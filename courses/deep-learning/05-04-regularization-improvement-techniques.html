<!DOCTYPE html>
<html lang="en">
<head>
    <title> Regularization and Improvement Techniques </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/deep-learning/05-04-regularizacion-tecnicas-mejora" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/deep-learning/05-04-regularizacion-tecnicas-mejora" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/deep-learning/05-04-regularization-improvement-techniques" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "5-4";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/05-04-regularization-improvement-techniques";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/deep-learning/05-04-regularizacion-tecnicas-mejora" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/deep-learning/05-04-regularizacion-tecnicas-mejora" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="5-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="5-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Regularization and Improvement Techniques</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-01-introduction-tensorflow' title="Introduction to TensorFlow" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="5-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-01-introduction-tensorflow' title="Introduction to TensorFlow" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="5-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>In this section, we will explore various techniques to improve the performance of deep learning models by addressing overfitting and enhancing generalization. Regularization techniques are essential for creating robust models that perform well on unseen data.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ol>
<li><strong>Overfitting</strong>: When a model learns the noise in the training data instead of the actual patterns, leading to poor performance on new data.</li>
<li><strong>Underfitting</strong>: When a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and test data.</li>
<li><strong>Regularization</strong>: Techniques used to prevent overfitting by adding constraints or penalties to the model.</li>
</ol>
</div><h2>Common Regularization Techniques</h2>
<div class='content'></div><h3><ol>
<li>L1 and L2 Regularization</li>
</ol></h3>
<div class='content'><p><strong>L1 Regularization (Lasso)</strong>:</p>
<ul>
<li>Adds a penalty equal to the absolute value of the magnitude of coefficients.</li>
<li>Encourages sparsity, meaning it can drive some weights to zero, effectively performing feature selection.</li>
</ul>
<p><strong>L2 Regularization (Ridge)</strong>:</p>
<ul>
<li>Adds a penalty equal to the square of the magnitude of coefficients.</li>
<li>Encourages smaller weights, distributing the impact across all features.</li>
</ul>
<p><strong>Mathematical Formulation</strong>:</p>
<ul>
<li><strong>L1 Regularization</strong>: \( \text{Loss} = \text{Loss}<em>{\text{original}} + \lambda \sum</em>{i} |w_i| \)</li>
<li><strong>L2 Regularization</strong>: \( \text{Loss} = \text{Loss}<em>{\text{original}} + \lambda \sum</em>{i} w_i^2 \)</li>
</ul>
<p><strong>Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZQoKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDY0LCBpbnB1dF9kaW09MTAwLCBhY3RpdmF0aW9uPSdyZWx1Jywga2VybmVsX3JlZ3VsYXJpemVyPXRmLmtlcmFzLnJlZ3VsYXJpemVycy5sMigwLjAxKSksCiAgICBEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykKXSkKCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScsIG1ldHJpY3M9WydhY2N1cmFjeSddKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(64, input_dim=100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h3><ol start="2">
<li>Dropout</li>
</ol></h3>
<div class='content'><ul>
<li>Randomly drops a fraction of neurons during training to prevent co-adaptation.</li>
<li>Helps in making the network more robust and reduces overfitting.</li>
</ul>
<p><strong>Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRHJvcG91dAoKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDY0LCBpbnB1dF9kaW09MTAwLCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBEcm9wb3V0KDAuNSksCiAgICBEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykKXSkKCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScsIG1ldHJpY3M9WydhY2N1cmFjeSddKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Dropout

model = Sequential([
    Dense(64, input_dim=100, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h3><ol start="3">
<li>Data Augmentation</li>
</ol></h3>
<div class='content'><ul>
<li>Generates new training samples by applying random transformations (e.g., rotations, translations) to the existing data.</li>
<li>Particularly useful in image processing to increase the diversity of the training set.</li>
</ul>
<p><strong>Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLnByZXByb2Nlc3NpbmcuaW1hZ2UgaW1wb3J0IEltYWdlRGF0YUdlbmVyYXRvcgoKZGF0YWdlbiA9IEltYWdlRGF0YUdlbmVyYXRvcigKICAgIHJvdGF0aW9uX3JhbmdlPTIwLAogICAgd2lkdGhfc2hpZnRfcmFuZ2U9MC4yLAogICAgaGVpZ2h0X3NoaWZ0X3JhbmdlPTAuMiwKICAgIHNoZWFyX3JhbmdlPTAuMiwKICAgIHpvb21fcmFuZ2U9MC4yLAogICAgaG9yaXpvbnRhbF9mbGlwPVRydWUsCiAgICBmaWxsX21vZGU9J25lYXJlc3QnCikKCiMgQXNzdW1pbmcgWF90cmFpbiBpcyB5b3VyIHRyYWluaW5nIGRhdGEKZGF0YWdlbi5maXQoWF90cmFpbik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Assuming X_train is your training data
datagen.fit(X_train)</pre></div><div class='content'></div><h3><ol start="4">
<li>Early Stopping</li>
</ol></h3>
<div class='content'><ul>
<li>Monitors the model's performance on a validation set and stops training when performance stops improving.</li>
<li>Prevents overfitting by halting training at the optimal point.</li>
</ul>
<p><strong>Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmNhbGxiYWNrcyBpbXBvcnQgRWFybHlTdG9wcGluZwoKZWFybHlfc3RvcHBpbmcgPSBFYXJseVN0b3BwaW5nKG1vbml0b3I9J3ZhbF9sb3NzJywgcGF0aWVuY2U9NSwgcmVzdG9yZV9iZXN0X3dlaWdodHM9VHJ1ZSkKCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluLCB2YWxpZGF0aW9uX3NwbGl0PTAuMiwgZXBvY2hzPTEwMCwgY2FsbGJhY2tzPVtlYXJseV9zdG9wcGluZ10p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping])</pre></div><div class='content'></div><h3><ol start="5">
<li>Batch Normalization</li>
</ol></h3>
<div class='content'><ul>
<li>Normalizes the inputs of each layer to have a mean of zero and a standard deviation of one.</li>
<li>Helps in stabilizing and accelerating the training process.</li>
</ul>
<p><strong>Example</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgQmF0Y2hOb3JtYWxpemF0aW9uCgptb2RlbCA9IFNlcXVlbnRpYWwoWwogICAgRGVuc2UoNjQsIGlucHV0X2RpbT0xMDAsIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIEJhdGNoTm9ybWFsaXphdGlvbigpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import BatchNormalization

model = Sequential([
    Dense(64, input_dim=100, activation='relu'),
    BatchNormalization(),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h2>Practical Exercises</h2>
<div class='content'></div><h3>Exercise 1: Implementing L2 Regularization</h3>
<div class='content'><p><strong>Task</strong>: Modify the given neural network to include L2 regularization.</p>
<p><strong>Code</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZQoKIyBEZWZpbmUgdGhlIG1vZGVsCm1vZGVsID0gU2VxdWVudGlhbChbCiAgICBEZW5zZSg2NCwgaW5wdXRfZGltPTEwMCwgYWN0aXZhdGlvbj0ncmVsdScsIGtlcm5lbF9yZWd1bGFyaXplcj10Zi5rZXJhcy5yZWd1bGFyaXplcnMubDIoMC4wMSkpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgojIENvbXBpbGUgdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScsIG1ldHJpY3M9WydhY2N1cmFjeSddKQoKIyBTdW1tYXJ5IG9mIHRoZSBtb2RlbAptb2RlbC5zdW1tYXJ5KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define the model
model = Sequential([
    Dense(64, input_dim=100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()</pre></div><div class='content'></div><h3>Exercise 2: Applying Dropout</h3>
<div class='content'><p><strong>Task</strong>: Add a Dropout layer to the neural network to prevent overfitting.</p>
<p><strong>Code</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRHJvcG91dAoKIyBEZWZpbmUgdGhlIG1vZGVsCm1vZGVsID0gU2VxdWVudGlhbChbCiAgICBEZW5zZSg2NCwgaW5wdXRfZGltPTEwMCwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgRHJvcG91dCgwLjUpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgojIENvbXBpbGUgdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScsIG1ldHJpY3M9WydhY2N1cmFjeSddKQoKIyBTdW1tYXJ5IG9mIHRoZSBtb2RlbAptb2RlbC5zdW1tYXJ5KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Dropout

# Define the model
model = Sequential([
    Dense(64, input_dim=100, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()</pre></div><div class='content'></div><h3>Exercise 3: Using Early Stopping</h3>
<div class='content'><p><strong>Task</strong>: Implement early stopping in the training process.</p>
<p><strong>Code</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmNhbGxiYWNrcyBpbXBvcnQgRWFybHlTdG9wcGluZwoKIyBEZWZpbmUgdGhlIG1vZGVsCm1vZGVsID0gU2VxdWVudGlhbChbCiAgICBEZW5zZSg2NCwgaW5wdXRfZGltPTEwMCwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgojIENvbXBpbGUgdGhlIG1vZGVsCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScsIG1ldHJpY3M9WydhY2N1cmFjeSddKQoKIyBEZWZpbmUgZWFybHkgc3RvcHBpbmcKZWFybHlfc3RvcHBpbmcgPSBFYXJseVN0b3BwaW5nKG1vbml0b3I9J3ZhbF9sb3NzJywgcGF0aWVuY2U9NSwgcmVzdG9yZV9iZXN0X3dlaWdodHM9VHJ1ZSkKCiMgVHJhaW4gdGhlIG1vZGVsIHdpdGggZWFybHkgc3RvcHBpbmcKbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4sIHZhbGlkYXRpb25fc3BsaXQ9MC4yLCBlcG9jaHM9MTAwLCBjYWxsYmFja3M9W2Vhcmx5X3N0b3BwaW5nXSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.callbacks import EarlyStopping

# Define the model
model = Sequential([
    Dense(64, input_dim=100, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model with early stopping
model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping])</pre></div><div class='content'></div><h2>Summary</h2>
<div class='content'><p>In this section, we covered several regularization and improvement techniques to enhance the performance of deep learning models. These techniques include L1 and L2 regularization, dropout, data augmentation, early stopping, and batch normalization. By applying these methods, you can create more robust models that generalize better to unseen data. In the next module, we will delve into the tools and frameworks commonly used in deep learning.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-01-introduction-tensorflow' title="Introduction to TensorFlow" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="5-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-01-introduction-tensorflow' title="Introduction to TensorFlow" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="5-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Deep Learning Course</h1>
<h2>Module 1: Introduction to Deep Learning</h2>
<ul>
<li><a href="01-01-what-is-deep-learning">What is Deep Learning?</a></li>
<li><a href="01-02-history-evolution-deep-learning">History and Evolution of Deep Learning</a></li>
<li><a href="01-03-applications-deep-learning">Applications of Deep Learning</a></li>
<li><a href="01-04-basic-concepts-neural-networks">Basic Concepts of Neural Networks</a></li>
</ul>
<h2>Module 2: Fundamentals of Neural Networks</h2>
<ul>
<li><a href="02-01-perceptron-multilayer-perceptron">Perceptron and Multilayer Perceptron</a></li>
<li><a href="02-02-activation-function">Activation Function</a></li>
<li><a href="02-03-forward-backward-propagation">Forward and Backward Propagation</a></li>
<li><a href="02-04-optimization-loss-function">Optimization and Loss Function</a></li>
</ul>
<h2>Module 3: Convolutional Neural Networks (CNN)</h2>
<ul>
<li><a href="03-01-introduction-cnn">Introduction to CNN</a></li>
<li><a href="03-02-convolutional-pooling-layers">Convolutional and Pooling Layers</a></li>
<li><a href="03-03-popular-cnn-architectures">Popular CNN Architectures</a></li>
<li><a href="03-04-cnn-applications-image-recognition">CNN Applications in Image Recognition</a></li>
</ul>
<h2>Module 4: Recurrent Neural Networks (RNN)</h2>
<ul>
<li><a href="04-01-introduction-rnn">Introduction to RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM and GRU</a></li>
<li><a href="04-03-rnn-applications-nlp">RNN Applications in Natural Language Processing</a></li>
<li><a href="04-04-sequences-time-series">Sequences and Time Series</a></li>
</ul>
<h2>Module 5: Advanced Techniques in Deep Learning</h2>
<ul>
<li><a href="05-01-generative-adversarial-networks">Generative Adversarial Networks (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularization-improvement-techniques">Regularization and Improvement Techniques</a></li>
</ul>
<h2>Module 6: Tools and Frameworks</h2>
<ul>
<li><a href="06-01-introduction-tensorflow">Introduction to TensorFlow</a></li>
<li><a href="06-02-introduction-pytorch">Introduction to PyTorch</a></li>
<li><a href="06-03-framework-comparison">Framework Comparison</a></li>
<li><a href="06-04-development-environments-resources">Development Environments and Additional Resources</a></li>
</ul>
<h2>Module 7: Practical Projects</h2>
<ul>
<li><a href="07-01-image-classification-cnn">Image Classification with CNN</a></li>
<li><a href="07-02-text-generation-rnn">Text Generation with RNN</a></li>
<li><a href="07-03-anomaly-detection-autoencoders">Anomaly Detection with Autoencoders</a></li>
<li><a href="07-04-creating-gan-image-generation">Creating a GAN for Image Generation</a></li>
</ul>
<h2>Module 8: Ethical Considerations and the Future of Deep Learning</h2>
<ul>
<li><a href="08-01-ethics-deep-learning">Ethics in Deep Learning</a></li>
<li><a href="08-02-social-economic-impact">Social and Economic Impact</a></li>
<li><a href="08-03-future-trends-deep-learning">Future Trends in Deep Learning</a></li>
<li><a href="08-04-challenges-opportunities">Challenges and Opportunities</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
