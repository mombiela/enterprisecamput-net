<!DOCTYPE html>
<html lang="en">
<head>
    <title> Autoencoders </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/05-02-autoencoders" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/05-02-autoencoders" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/05-02-autoencoders" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "5-2";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/05-02-autoencoders";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/05-02-autoencoders" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/mod/deep_learning/05-02-autoencoders" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-generative-adversarial-networks' title="Generative Adversarial Networks (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-generative-adversarial-networks' title="Generative Adversarial Networks (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Autoencoders</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="5-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>Autoencoders are a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). They are primarily used for dimensionality reduction, feature learning, and anomaly detection. In this section, we will cover the following topics:</p>
<ol>
<li><strong>What are Autoencoders?</strong></li>
<li><strong>Architecture of Autoencoders</strong></li>
<li><strong>Types of Autoencoders</strong></li>
<li><strong>Applications of Autoencoders</strong></li>
<li><strong>Practical Example: Implementing an Autoencoder in Python</strong></li>
<li><strong>Exercises</strong></li>
</ol>
</div><h1>What are Autoencoders?</h1>
<div class='content'><p>Autoencoders are neural networks designed to learn a compressed representation (encoding) of input data. They consist of two main parts:</p>
<ul>
<li><strong>Encoder:</strong> Compresses the input into a latent-space representation.</li>
<li><strong>Decoder:</strong> Reconstructs the input from the latent space representation.</li>
</ul>
<p>The goal of an autoencoder is to minimize the difference between the input and the reconstructed output.</p>
</div><h1>Architecture of Autoencoders</h1>
<div class='content'><p>The basic architecture of an autoencoder consists of three main components:</p>
<ol>
<li><strong>Input Layer:</strong> The original data to be compressed.</li>
<li><strong>Hidden Layers (Encoder and Decoder):</strong> The encoder compresses the input data into a lower-dimensional representation, and the decoder reconstructs the data from this representation.</li>
<li><strong>Output Layer:</strong> The reconstructed data, which should be as close as possible to the input data.</li>
</ol>
</div><h2>Diagram of a Basic Autoencoder</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("SW5wdXQgLT4gW0VuY29kZXJdIC0+IExhdGVudCBTcGFjZSAtPiBbRGVjb2Rlcl0gLT4gT3V0cHV0"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Input -&gt; [Encoder] -&gt; Latent Space -&gt; [Decoder] -&gt; Output</pre></div><div class='content'></div><h2>Example Code: Basic Autoencoder in Keras</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmZyb20ga2VyYXMubGF5ZXJzIGltcG9ydCBJbnB1dCwgRGVuc2UKZnJvbSBrZXJhcy5tb2RlbHMgaW1wb3J0IE1vZGVsCgojIERlZmluZSB0aGUgc2l6ZSBvZiB0aGUgaW5wdXQgYW5kIHRoZSBlbmNvZGluZyBkaW1lbnNpb24KaW5wdXRfZGltID0gNzg0ICAjIEV4YW1wbGUgZm9yIE1OSVNUIGRhdGFzZXQgKDI4eDI4IGltYWdlcykKZW5jb2RpbmdfZGltID0gMzIgICMgQ29tcHJlc3Npb24gdG8gMzIgZmVhdHVyZXMKCiMgSW5wdXQgcGxhY2Vob2xkZXIKaW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KGlucHV0X2RpbSwpKQoKIyBFbmNvZGVyIGxheWVycwplbmNvZGVkID0gRGVuc2UoZW5jb2RpbmdfZGltLCBhY3RpdmF0aW9uPSdyZWx1JykoaW5wdXRfaW1nKQoKIyBEZWNvZGVyIGxheWVycwpkZWNvZGVkID0gRGVuc2UoaW5wdXRfZGltLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykoZW5jb2RlZCkKCiMgQXV0b2VuY29kZXIgbW9kZWwKYXV0b2VuY29kZXIgPSBNb2RlbChpbnB1dF9pbWcsIGRlY29kZWQpCgojIENvbXBpbGUgdGhlIG1vZGVsCmF1dG9lbmNvZGVyLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScpCgojIFN1bW1hcnkgb2YgdGhlIG1vZGVsCmF1dG9lbmNvZGVyLnN1bW1hcnkoKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
from keras.layers import Input, Dense
from keras.models import Model

# Define the size of the input and the encoding dimension
input_dim = 784  # Example for MNIST dataset (28x28 images)
encoding_dim = 32  # Compression to 32 features

# Input placeholder
input_img = Input(shape=(input_dim,))

# Encoder layers
encoded = Dense(encoding_dim, activation='relu')(input_img)

# Decoder layers
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Autoencoder model
autoencoder = Model(input_img, decoded)

# Compile the model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Summary of the model
autoencoder.summary()</pre></div><div class='content'></div><h1>Types of Autoencoders</h1>
<div class='content'><p>There are several types of autoencoders, each designed for specific tasks:</p>
<ol>
<li><strong>Vanilla Autoencoder:</strong> The basic form of autoencoder.</li>
<li><strong>Sparse Autoencoder:</strong> Adds a sparsity constraint on the hidden layer to enforce the model to learn useful features.</li>
<li><strong>Denoising Autoencoder:</strong> Trained to remove noise from the input data.</li>
<li><strong>Variational Autoencoder (VAE):</strong> Uses probabilistic methods to learn the latent space representation.</li>
</ol>
</div><h2>Table: Comparison of Autoencoder Types</h2>
<div class='content'><table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla Autoencoder</td>
<td>Basic autoencoder with no constraints</td>
<td>Dimensionality reduction</td>
</tr>
<tr>
<td>Sparse Autoencoder</td>
<td>Adds sparsity constraint to hidden layer</td>
<td>Feature learning</td>
</tr>
<tr>
<td>Denoising Autoencoder</td>
<td>Trained to remove noise from input data</td>
<td>Image denoising</td>
</tr>
<tr>
<td>Variational Autoencoder (VAE)</td>
<td>Uses probabilistic approach for latent space</td>
<td>Generative models</td>
</tr>
</tbody>
</table>
</div><h1>Applications of Autoencoders</h1>
<div class='content'><p>Autoencoders have a wide range of applications, including but not limited to:</p>
<ul>
<li><strong>Dimensionality Reduction:</strong> Reducing the number of features in a dataset while preserving important information.</li>
<li><strong>Anomaly Detection:</strong> Identifying unusual patterns that do not conform to expected behavior.</li>
<li><strong>Image Denoising:</strong> Removing noise from images to improve their quality.</li>
<li><strong>Data Compression:</strong> Compressing data for efficient storage and transmission.</li>
</ul>
</div><h1>Practical Example: Implementing an Autoencoder in Python</h1>
<div class='content'><p>Let's implement a simple autoencoder using the MNIST dataset.</p>
</div><h2>Step-by-Step Implementation</h2>
<div class='content'><ol>
<li><strong>Load the MNIST dataset:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrZXJhcy5kYXRhc2V0cyBpbXBvcnQgbW5pc3QKCiMgTG9hZCB0aGUgZGF0YXNldAooeF90cmFpbiwgXyksICh4X3Rlc3QsIF8pID0gbW5pc3QubG9hZF9kYXRhKCkKCiMgTm9ybWFsaXplIHRoZSBkYXRhCnhfdHJhaW4gPSB4X3RyYWluLmFzdHlwZSgnZmxvYXQzMicpIC8gMjU1Lgp4X3Rlc3QgPSB4X3Rlc3QuYXN0eXBlKCdmbG9hdDMyJykgLyAyNTUuCgojIEZsYXR0ZW4gdGhlIGltYWdlcwp4X3RyYWluID0geF90cmFpbi5yZXNoYXBlKChsZW4oeF90cmFpbiksIG5wLnByb2QoeF90cmFpbi5zaGFwZVsxOl0pKSkKeF90ZXN0ID0geF90ZXN0LnJlc2hhcGUoKGxlbih4X3Rlc3QpLCBucC5wcm9kKHhfdGVzdC5zaGFwZVsxOl0pKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from keras.datasets import mnist

# Load the dataset
(x_train, _), (x_test, _) = mnist.load_data()

# Normalize the data
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# Flatten the images
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))</pre></div><div class='content'><ol start="2">
<li><strong>Define the autoencoder model:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KDc4NCwpKQplbmNvZGVkID0gRGVuc2UoMzIsIGFjdGl2YXRpb249J3JlbHUnKShpbnB1dF9pbWcpCmRlY29kZWQgPSBEZW5zZSg3ODQsIGFjdGl2YXRpb249J3NpZ21vaWQnKShlbmNvZGVkKQoKYXV0b2VuY29kZXIgPSBNb2RlbChpbnB1dF9pbWcsIGRlY29kZWQpCmF1dG9lbmNvZGVyLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>input_img = Input(shape=(784,))
encoded = Dense(32, activation='relu')(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')</pre></div><div class='content'><ol start="3">
<li><strong>Train the autoencoder:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("YXV0b2VuY29kZXIuZml0KHhfdHJhaW4sIHhfdHJhaW4sCiAgICAgICAgICAgICAgICBlcG9jaHM9NTAsCiAgICAgICAgICAgICAgICBiYXRjaF9zaXplPTI1NiwKICAgICAgICAgICAgICAgIHNodWZmbGU9VHJ1ZSwKICAgICAgICAgICAgICAgIHZhbGlkYXRpb25fZGF0YT0oeF90ZXN0LCB4X3Rlc3QpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))</pre></div><div class='content'><ol start="4">
<li><strong>Evaluate the autoencoder:</strong></li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFbmNvZGUgYW5kIGRlY29kZSBzb21lIGRpZ2l0cwplbmNvZGVkX2ltZ3MgPSBhdXRvZW5jb2Rlci5wcmVkaWN0KHhfdGVzdCkKZGVjb2RlZF9pbWdzID0gYXV0b2VuY29kZXIucHJlZGljdChlbmNvZGVkX2ltZ3MpCgojIERpc3BsYXkgb3JpZ2luYWwgYW5kIHJlY29uc3RydWN0ZWQgaW1hZ2VzCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKCm4gPSAxMCAgIyBOdW1iZXIgb2YgZGlnaXRzIHRvIGRpc3BsYXkKcGx0LmZpZ3VyZShmaWdzaXplPSgyMCwgNCkpCmZvciBpIGluIHJhbmdlKG4pOgogICAgIyBEaXNwbGF5IG9yaWdpbmFsCiAgICBheCA9IHBsdC5zdWJwbG90KDIsIG4sIGkgKyAxKQogICAgcGx0Lmltc2hvdyh4X3Rlc3RbaV0ucmVzaGFwZSgyOCwgMjgpKQogICAgcGx0LmdyYXkoKQogICAgYXguZ2V0X3hheGlzKCkuc2V0X3Zpc2libGUoRmFsc2UpCiAgICBheC5nZXRfeWF4aXMoKS5zZXRfdmlzaWJsZShGYWxzZSkKCiAgICAjIERpc3BsYXkgcmVjb25zdHJ1Y3Rpb24KICAgIGF4ID0gcGx0LnN1YnBsb3QoMiwgbiwgaSArIDEgKyBuKQogICAgcGx0Lmltc2hvdyhkZWNvZGVkX2ltZ3NbaV0ucmVzaGFwZSgyOCwgMjgpKQogICAgcGx0LmdyYXkoKQogICAgYXguZ2V0X3hheGlzKCkuc2V0X3Zpc2libGUoRmFsc2UpCiAgICBheC5nZXRfeWF4aXMoKS5zZXRfdmlzaWJsZShGYWxzZSkKcGx0LnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Encode and decode some digits
encoded_imgs = autoencoder.predict(x_test)
decoded_imgs = autoencoder.predict(encoded_imgs)

# Display original and reconstructed images
import matplotlib.pyplot as plt

n = 10  # Number of digits to display
plt.figure(figsize=(20, 4))
for i in range(n):
    # Display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()</pre></div><div class='content'></div><h1>Exercises</h1>
<div class='content'></div><h2>Exercise 1: Implement a Sparse Autoencoder</h2>
<div class='content'><p>Modify the basic autoencoder to include a sparsity constraint on the hidden layer.</p>
<p><strong>Hint:</strong> Use the <code>activity_regularizer</code> parameter in the <code>Dense</code> layer.</p>
</div><h2>Solution:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrZXJhcyBpbXBvcnQgcmVndWxhcml6ZXJzCgojIERlZmluZSB0aGUgc3BhcnNlIGF1dG9lbmNvZGVyCmlucHV0X2ltZyA9IElucHV0KHNoYXBlPSg3ODQsKSkKZW5jb2RlZCA9IERlbnNlKDMyLCBhY3RpdmF0aW9uPSdyZWx1JywgYWN0aXZpdHlfcmVndWxhcml6ZXI9cmVndWxhcml6ZXJzLmwxKDEwZS01KSkoaW5wdXRfaW1nKQpkZWNvZGVkID0gRGVuc2UoNzg0LCBhY3RpdmF0aW9uPSdzaWdtb2lkJykoZW5jb2RlZCkKCnNwYXJzZV9hdXRvZW5jb2RlciA9IE1vZGVsKGlucHV0X2ltZywgZGVjb2RlZCkKc3BhcnNlX2F1dG9lbmNvZGVyLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScpCgojIFRyYWluIHRoZSBzcGFyc2UgYXV0b2VuY29kZXIKc3BhcnNlX2F1dG9lbmNvZGVyLmZpdCh4X3RyYWluLCB4X3RyYWluLAogICAgICAgICAgICAgICAgICAgICAgIGVwb2Nocz01MCwKICAgICAgICAgICAgICAgICAgICAgICBiYXRjaF9zaXplPTI1NiwKICAgICAgICAgICAgICAgICAgICAgICBzaHVmZmxlPVRydWUsCiAgICAgICAgICAgICAgICAgICAgICAgdmFsaWRhdGlvbl9kYXRhPSh4X3Rlc3QsIHhfdGVzdCkp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from keras import regularizers

# Define the sparse autoencoder
input_img = Input(shape=(784,))
encoded = Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

sparse_autoencoder = Model(input_img, decoded)
sparse_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the sparse autoencoder
sparse_autoencoder.fit(x_train, x_train,
                       epochs=50,
                       batch_size=256,
                       shuffle=True,
                       validation_data=(x_test, x_test))</pre></div><div class='content'></div><h2>Exercise 2: Implement a Denoising Autoencoder</h2>
<div class='content'><p>Train an autoencoder to remove noise from the MNIST dataset.</p>
<p><strong>Hint:</strong> Add noise to the input data before training.</p>
</div><h2>Solution:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBBZGQgbm9pc2UgdG8gdGhlIGRhdGEKbm9pc2VfZmFjdG9yID0gMC41CnhfdHJhaW5fbm9pc3kgPSB4X3RyYWluICsgbm9pc2VfZmFjdG9yICogbnAucmFuZG9tLm5vcm1hbChsb2M9MC4wLCBzY2FsZT0xLjAsIHNpemU9eF90cmFpbi5zaGFwZSkKeF90ZXN0X25vaXN5ID0geF90ZXN0ICsgbm9pc2VfZmFjdG9yICogbnAucmFuZG9tLm5vcm1hbChsb2M9MC4wLCBzY2FsZT0xLjAsIHNpemU9eF90ZXN0LnNoYXBlKQoKeF90cmFpbl9ub2lzeSA9IG5wLmNsaXAoeF90cmFpbl9ub2lzeSwgMC4sIDEuKQp4X3Rlc3Rfbm9pc3kgPSBucC5jbGlwKHhfdGVzdF9ub2lzeSwgMC4sIDEuKQoKIyBEZWZpbmUgdGhlIGRlbm9pc2luZyBhdXRvZW5jb2RlcgppbnB1dF9pbWcgPSBJbnB1dChzaGFwZT0oNzg0LCkpCmVuY29kZWQgPSBEZW5zZSgzMiwgYWN0aXZhdGlvbj0ncmVsdScpKGlucHV0X2ltZykKZGVjb2RlZCA9IERlbnNlKDc4NCwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpKGVuY29kZWQpCgpkZW5vaXNpbmdfYXV0b2VuY29kZXIgPSBNb2RlbChpbnB1dF9pbWcsIGRlY29kZWQpCmRlbm9pc2luZ19hdXRvZW5jb2Rlci5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknKQoKIyBUcmFpbiB0aGUgZGVub2lzaW5nIGF1dG9lbmNvZGVyCmRlbm9pc2luZ19hdXRvZW5jb2Rlci5maXQoeF90cmFpbl9ub2lzeSwgeF90cmFpbiwKICAgICAgICAgICAgICAgICAgICAgICAgICBlcG9jaHM9NTAsCiAgICAgICAgICAgICAgICAgICAgICAgICAgYmF0Y2hfc2l6ZT0yNTYsCiAgICAgICAgICAgICAgICAgICAgICAgICAgc2h1ZmZsZT1UcnVlLAogICAgICAgICAgICAgICAgICAgICAgICAgIHZhbGlkYXRpb25fZGF0YT0oeF90ZXN0X25vaXN5LCB4X3Rlc3QpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Add noise to the data
noise_factor = 0.5
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)

x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

# Define the denoising autoencoder
input_img = Input(shape=(784,))
encoded = Dense(32, activation='relu')(input_img)
decoded = Dense(784, activation='sigmoid')(encoded)

denoising_autoencoder = Model(input_img, decoded)
denoising_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the denoising autoencoder
denoising_autoencoder.fit(x_train_noisy, x_train,
                          epochs=50,
                          batch_size=256,
                          shuffle=True,
                          validation_data=(x_test_noisy, x_test))</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this section, we explored the concept of autoencoders, their architecture, types, and applications. We also implemented a basic autoencoder and explored practical examples to reinforce the concepts. Autoencoders are powerful tools in the deep learning toolkit, especially for tasks like dimensionality reduction, anomaly detection, and data denoising. Understanding and implementing autoencoders can significantly enhance your ability to work with complex datasets and extract meaningful features.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-generative-adversarial-networks' title="Generative Adversarial Networks (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-generative-adversarial-networks' title="Generative Adversarial Networks (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="5-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Deep Learning Course</h1>
<h2>Module 1: Introduction to Deep Learning</h2>
<ul>
<li><a href="01-01-what-is-deep-learning">What is Deep Learning?</a></li>
<li><a href="01-02-history-evolution-deep-learning">History and Evolution of Deep Learning</a></li>
<li><a href="01-03-applications-deep-learning">Applications of Deep Learning</a></li>
<li><a href="01-04-basic-concepts-neural-networks">Basic Concepts of Neural Networks</a></li>
</ul>
<h2>Module 2: Fundamentals of Neural Networks</h2>
<ul>
<li><a href="02-01-perceptron-multilayer-perceptron">Perceptron and Multilayer Perceptron</a></li>
<li><a href="02-02-activation-function">Activation Function</a></li>
<li><a href="02-03-forward-backward-propagation">Forward and Backward Propagation</a></li>
<li><a href="02-04-optimization-loss-function">Optimization and Loss Function</a></li>
</ul>
<h2>Module 3: Convolutional Neural Networks (CNN)</h2>
<ul>
<li><a href="03-01-introduction-cnn">Introduction to CNN</a></li>
<li><a href="03-02-convolutional-pooling-layers">Convolutional and Pooling Layers</a></li>
<li><a href="03-03-popular-cnn-architectures">Popular CNN Architectures</a></li>
<li><a href="03-04-cnn-applications-image-recognition">CNN Applications in Image Recognition</a></li>
</ul>
<h2>Module 4: Recurrent Neural Networks (RNN)</h2>
<ul>
<li><a href="04-01-introduction-rnn">Introduction to RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM and GRU</a></li>
<li><a href="04-03-rnn-applications-nlp">RNN Applications in Natural Language Processing</a></li>
<li><a href="04-04-sequences-time-series">Sequences and Time Series</a></li>
</ul>
<h2>Module 5: Advanced Techniques in Deep Learning</h2>
<ul>
<li><a href="05-01-generative-adversarial-networks">Generative Adversarial Networks (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularization-improvement-techniques">Regularization and Improvement Techniques</a></li>
</ul>
<h2>Module 6: Tools and Frameworks</h2>
<ul>
<li><a href="06-01-introduction-tensorflow">Introduction to TensorFlow</a></li>
<li><a href="06-02-introduction-pytorch">Introduction to PyTorch</a></li>
<li><a href="06-03-framework-comparison">Framework Comparison</a></li>
<li><a href="06-04-development-environments-resources">Development Environments and Additional Resources</a></li>
</ul>
<h2>Module 7: Practical Projects</h2>
<ul>
<li><a href="07-01-image-classification-cnn">Image Classification with CNN</a></li>
<li><a href="07-02-text-generation-rnn">Text Generation with RNN</a></li>
<li><a href="07-03-anomaly-detection-autoencoders">Anomaly Detection with Autoencoders</a></li>
<li><a href="07-04-creating-gan-image-generation">Creating a GAN for Image Generation</a></li>
</ul>
<h2>Module 8: Ethical Considerations and the Future of Deep Learning</h2>
<ul>
<li><a href="08-01-ethics-deep-learning">Ethics in Deep Learning</a></li>
<li><a href="08-02-social-economic-impact">Social and Economic Impact</a></li>
<li><a href="08-03-future-trends-deep-learning">Future Trends in Deep Learning</a></li>
<li><a href="08-04-challenges-opportunities">Challenges and Opportunities</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
