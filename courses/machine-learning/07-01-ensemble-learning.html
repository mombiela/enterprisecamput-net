<!DOCTYPE html>
<html lang="en">
<head>
    <title> Ensemble Learning </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/machine-learning/07-01-ensemble-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/machine-learning/07-01-ensemble-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/machine-learning/07-01-ensemble-learning" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "machine_learning";
  		var TEMA_NAME = "7-1";
  		var TYPE = "mod";
  		var PATH = "mod/machine_learning/07-01-ensemble-learning";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.8d8afe898f.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/machine-learning/07-01-ensemble-learning" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/machine-learning/07-01-ensemble-learning" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="machine_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="machine_learning" data-read-unit="7-1" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="machine_learning" data-unread-unit="7-1" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-04-overfitting-underfitting' title="Overfitting and Underfitting" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-04-overfitting-underfitting' title="Overfitting and Underfitting" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Ensemble Learning</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-02-gradient-boosting' title="Gradient Boosting" class="py-2 px-3 btn btn-primary"
				data-read-mod="machine_learning" data-read-unit="7-1">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-02-gradient-boosting' title="Gradient Boosting" class="py-2 px-3 btn btn-primary" 
				data-read-mod="machine_learning" data-read-unit="7-1">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>Ensemble learning is a powerful machine learning technique where multiple models, often referred to as &quot;weak learners,&quot; are combined to produce a stronger model. The idea is that by aggregating the predictions of several models, the ensemble can achieve better performance and generalization than any individual model.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ol>
<li><strong>Weak Learners</strong>: These are models that perform slightly better than random guessing. Examples include decision stumps (single-level decision trees) and simple linear classifiers.</li>
<li><strong>Strong Learner</strong>: An ensemble of weak learners that performs significantly better than any single weak learner.</li>
<li><strong>Diversity</strong>: The individual models should be diverse, meaning they should make different errors. This diversity is crucial for the ensemble to perform well.</li>
<li><strong>Aggregation Methods</strong>: Techniques used to combine the predictions of the weak learners. Common methods include averaging, voting, and weighted voting.</li>
</ol>
</div><h2>Types of Ensemble Methods</h2>
<div class='content'><ol>
<li><strong>Bagging (Bootstrap Aggregating)</strong></li>
<li><strong>Boosting</strong></li>
<li><strong>Stacking</strong></li>
</ol>
</div><h3>Bagging (Bootstrap Aggregating)</h3>
<div class='content'><p>Bagging involves training multiple instances of the same model on different subsets of the training data, generated by bootstrapping (random sampling with replacement). The final prediction is typically made by averaging the predictions (for regression) or majority voting (for classification).</p>
<h4>Example: Random Forest</h4>
<p>Random Forest is a popular bagging method that uses decision trees as the base learners. Each tree is trained on a different bootstrap sample of the data, and the final prediction is made by averaging the predictions of all trees.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBSYW5kb21Gb3Jlc3RDbGFzc2lmaWVyCmZyb20gc2tsZWFybi5kYXRhc2V0cyBpbXBvcnQgbG9hZF9pcmlzCmZyb20gc2tsZWFybi5tb2RlbF9zZWxlY3Rpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXQKZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IGFjY3VyYWN5X3Njb3JlCgojIExvYWQgZGF0YXNldAppcmlzID0gbG9hZF9pcmlzKCkKWCwgeSA9IGlyaXMuZGF0YSwgaXJpcy50YXJnZXQKCiMgU3BsaXQgZGF0YXNldCBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0aW5nIHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjMsIHJhbmRvbV9zdGF0ZT00MikKCiMgSW5pdGlhbGl6ZSBhbmQgdHJhaW4gUmFuZG9tIEZvcmVzdCBjbGFzc2lmaWVyCnJmID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcihuX2VzdGltYXRvcnM9MTAwLCByYW5kb21fc3RhdGU9NDIpCnJmLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IHJmLnByZWRpY3QoWF90ZXN0KQoKIyBFdmFsdWF0ZSB0aGUgbW9kZWwKYWNjdXJhY3kgPSBhY2N1cmFjeV9zY29yZSh5X3Rlc3QsIHlfcHJlZCkKcHJpbnQoZiJBY2N1cmFjeToge2FjY3VyYWN5Oi4yZn0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train Random Forest classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Make predictions
y_pred = rf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy: {accuracy:.2f}&quot;)</pre></div><div class='content'></div><h3>Boosting</h3>
<div class='content'><p>Boosting involves training weak learners sequentially, with each new model focusing on the errors made by the previous models. The final prediction is a weighted sum of the predictions of all models.</p>
<h4>Example: AdaBoost</h4>
<p>AdaBoost (Adaptive Boosting) is a popular boosting method that adjusts the weights of incorrectly classified instances, so subsequent models focus more on these hard-to-classify cases.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBBZGFCb29zdENsYXNzaWZpZXIKZnJvbSBza2xlYXJuLnRyZWUgaW1wb3J0IERlY2lzaW9uVHJlZUNsYXNzaWZpZXIKZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgYWNjdXJhY3lfc2NvcmUKCiMgTG9hZCBkYXRhc2V0CmlyaXMgPSBsb2FkX2lyaXMoKQpYLCB5ID0gaXJpcy5kYXRhLCBpcmlzLnRhcmdldAoKIyBTcGxpdCBkYXRhc2V0IGludG8gdHJhaW5pbmcgYW5kIHRlc3Rpbmcgc2V0cwpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMywgcmFuZG9tX3N0YXRlPTQyKQoKIyBJbml0aWFsaXplIGFuZCB0cmFpbiBBZGFCb29zdCBjbGFzc2lmaWVyCmJhc2VfZXN0aW1hdG9yID0gRGVjaXNpb25UcmVlQ2xhc3NpZmllcihtYXhfZGVwdGg9MSkKYWRhID0gQWRhQm9vc3RDbGFzc2lmaWVyKGJhc2VfZXN0aW1hdG9yPWJhc2VfZXN0aW1hdG9yLCBuX2VzdGltYXRvcnM9NTAsIHJhbmRvbV9zdGF0ZT00MikKYWRhLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IGFkYS5wcmVkaWN0KFhfdGVzdCkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmFjY3VyYWN5ID0gYWNjdXJhY3lfc2NvcmUoeV90ZXN0LCB5X3ByZWQpCnByaW50KGYiQWNjdXJhY3k6IHthY2N1cmFjeTouMmZ9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train AdaBoost classifier
base_estimator = DecisionTreeClassifier(max_depth=1)
ada = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)
ada.fit(X_train, y_train)

# Make predictions
y_pred = ada.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy: {accuracy:.2f}&quot;)</pre></div><div class='content'></div><h3>Stacking</h3>
<div class='content'><p>Stacking involves training multiple models (level-0 models) and then using their predictions as input features for a higher-level model (level-1 model), which makes the final prediction.</p>
<h4>Example: Stacking Classifier</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBTdGFja2luZ0NsYXNzaWZpZXIKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTG9naXN0aWNSZWdyZXNzaW9uCmZyb20gc2tsZWFybi50cmVlIGltcG9ydCBEZWNpc2lvblRyZWVDbGFzc2lmaWVyCmZyb20gc2tsZWFybi5zdm0gaW1wb3J0IFNWQwpmcm9tIHNrbGVhcm4uZGF0YXNldHMgaW1wb3J0IGxvYWRfaXJpcwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBhY2N1cmFjeV9zY29yZQoKIyBMb2FkIGRhdGFzZXQKaXJpcyA9IGxvYWRfaXJpcygpClgsIHkgPSBpcmlzLmRhdGEsIGlyaXMudGFyZ2V0CgojIFNwbGl0IGRhdGFzZXQgaW50byB0cmFpbmluZyBhbmQgdGVzdGluZyBzZXRzClhfdHJhaW4sIFhfdGVzdCwgeV90cmFpbiwgeV90ZXN0ID0gdHJhaW5fdGVzdF9zcGxpdChYLCB5LCB0ZXN0X3NpemU9MC4zLCByYW5kb21fc3RhdGU9NDIpCgojIERlZmluZSBiYXNlIGxlYXJuZXJzCmJhc2VfbGVhcm5lcnMgPSBbCiAgICAoJ2R0JywgRGVjaXNpb25UcmVlQ2xhc3NpZmllcihtYXhfZGVwdGg9MSkpLAogICAgKCdzdm0nLCBTVkMoa2VybmVsPSdsaW5lYXInLCBwcm9iYWJpbGl0eT1UcnVlKSkKXQoKIyBEZWZpbmUgbWV0YS1sZWFybmVyCm1ldGFfbGVhcm5lciA9IExvZ2lzdGljUmVncmVzc2lvbigpCgojIEluaXRpYWxpemUgYW5kIHRyYWluIFN0YWNraW5nIGNsYXNzaWZpZXIKc3RhY2tpbmdfY2xmID0gU3RhY2tpbmdDbGFzc2lmaWVyKGVzdGltYXRvcnM9YmFzZV9sZWFybmVycywgZmluYWxfZXN0aW1hdG9yPW1ldGFfbGVhcm5lcikKc3RhY2tpbmdfY2xmLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IHN0YWNraW5nX2NsZi5wcmVkaWN0KFhfdGVzdCkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmFjY3VyYWN5ID0gYWNjdXJhY3lfc2NvcmUoeV90ZXN0LCB5X3ByZWQpCnByaW50KGYiQWNjdXJhY3k6IHthY2N1cmFjeTouMmZ9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Define base learners
base_learners = [
    ('dt', DecisionTreeClassifier(max_depth=1)),
    ('svm', SVC(kernel='linear', probability=True))
]

# Define meta-learner
meta_learner = LogisticRegression()

# Initialize and train Stacking classifier
stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)
stacking_clf.fit(X_train, y_train)

# Make predictions
y_pred = stacking_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy: {accuracy:.2f}&quot;)</pre></div><div class='content'></div><h2>Practical Exercises</h2>
<div class='content'></div><h3>Exercise 1: Implementing Bagging with Decision Trees</h3>
<div class='content'><p><strong>Task</strong>: Implement a Bagging classifier using decision trees on the Iris dataset and evaluate its performance.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBCYWdnaW5nQ2xhc3NpZmllcgpmcm9tIHNrbGVhcm4udHJlZSBpbXBvcnQgRGVjaXNpb25UcmVlQ2xhc3NpZmllcgpmcm9tIHNrbGVhcm4uZGF0YXNldHMgaW1wb3J0IGxvYWRfaXJpcwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBhY2N1cmFjeV9zY29yZQoKIyBMb2FkIGRhdGFzZXQKaXJpcyA9IGxvYWRfaXJpcygpClgsIHkgPSBpcmlzLmRhdGEsIGlyaXMudGFyZ2V0CgojIFNwbGl0IGRhdGFzZXQgaW50byB0cmFpbmluZyBhbmQgdGVzdGluZyBzZXRzClhfdHJhaW4sIFhfdGVzdCwgeV90cmFpbiwgeV90ZXN0ID0gdHJhaW5fdGVzdF9zcGxpdChYLCB5LCB0ZXN0X3NpemU9MC4zLCByYW5kb21fc3RhdGU9NDIpCgojIEluaXRpYWxpemUgYW5kIHRyYWluIEJhZ2dpbmcgY2xhc3NpZmllcgpiYWdnaW5nX2NsZiA9IEJhZ2dpbmdDbGFzc2lmaWVyKGJhc2VfZXN0aW1hdG9yPURlY2lzaW9uVHJlZUNsYXNzaWZpZXIoKSwgbl9lc3RpbWF0b3JzPTUwLCByYW5kb21fc3RhdGU9NDIpCmJhZ2dpbmdfY2xmLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IGJhZ2dpbmdfY2xmLnByZWRpY3QoWF90ZXN0KQoKIyBFdmFsdWF0ZSB0aGUgbW9kZWwKYWNjdXJhY3kgPSBhY2N1cmFjeV9zY29yZSh5X3Rlc3QsIHlfcHJlZCkKcHJpbnQoZiJBY2N1cmFjeToge2FjY3VyYWN5Oi4yZn0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train Bagging classifier
bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)
bagging_clf.fit(X_train, y_train)

# Make predictions
y_pred = bagging_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy: {accuracy:.2f}&quot;)</pre></div><div class='content'></div><h3>Exercise 2: Implementing Boosting with AdaBoost</h3>
<div class='content'><p><strong>Task</strong>: Implement an AdaBoost classifier using decision trees on the Iris dataset and evaluate its performance.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBBZGFCb29zdENsYXNzaWZpZXIKZnJvbSBza2xlYXJuLnRyZWUgaW1wb3J0IERlY2lzaW9uVHJlZUNsYXNzaWZpZXIKZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgYWNjdXJhY3lfc2NvcmUKCiMgTG9hZCBkYXRhc2V0CmlyaXMgPSBsb2FkX2lyaXMoKQpYLCB5ID0gaXJpcy5kYXRhLCBpcmlzLnRhcmdldAoKIyBTcGxpdCBkYXRhc2V0IGludG8gdHJhaW5pbmcgYW5kIHRlc3Rpbmcgc2V0cwpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMywgcmFuZG9tX3N0YXRlPTQyKQoKIyBJbml0aWFsaXplIGFuZCB0cmFpbiBBZGFCb29zdCBjbGFzc2lmaWVyCmJhc2VfZXN0aW1hdG9yID0gRGVjaXNpb25UcmVlQ2xhc3NpZmllcihtYXhfZGVwdGg9MSkKYWRhID0gQWRhQm9vc3RDbGFzc2lmaWVyKGJhc2VfZXN0aW1hdG9yPWJhc2VfZXN0aW1hdG9yLCBuX2VzdGltYXRvcnM9NTAsIHJhbmRvbV9zdGF0ZT00MikKYWRhLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBNYWtlIHByZWRpY3Rpb25zCnlfcHJlZCA9IGFkYS5wcmVkaWN0KFhfdGVzdCkKCiMgRXZhbHVhdGUgdGhlIG1vZGVsCmFjY3VyYWN5ID0gYWNjdXJhY3lfc2NvcmUoeV90ZXN0LCB5X3ByZWQpCnByaW50KGYiQWNjdXJhY3k6IHthY2N1cmFjeTouMmZ9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train AdaBoost classifier
base_estimator = DecisionTreeClassifier(max_depth=1)
ada = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)
ada.fit(X_train, y_train)

# Make predictions
y_pred = ada.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;Accuracy: {accuracy:.2f}&quot;)</pre></div><div class='content'></div><h2>Common Mistakes and Tips</h2>
<div class='content'><ol>
<li><strong>Overfitting</strong>: While ensembles can reduce overfitting, using too many complex models can still lead to overfitting. Ensure you use cross-validation to tune hyperparameters.</li>
<li><strong>Diversity</strong>: Ensure the base learners are diverse. Using the same model with the same parameters may not yield the best results.</li>
<li><strong>Computational Cost</strong>: Ensembles can be computationally expensive. Consider the trade-off between performance and computational resources.</li>
</ol>
</div><h2>Conclusion</h2>
<div class='content'><p>Ensemble learning is a robust technique that leverages the strengths of multiple models to achieve superior performance. By understanding and implementing methods like bagging, boosting, and stacking, you can significantly enhance the accuracy and robustness of your machine learning models. In the next section, we will delve into Gradient Boosting, a powerful boosting technique that has become a cornerstone in many machine learning competitions and applications.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-04-overfitting-underfitting' title="Overfitting and Underfitting" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-04-overfitting-underfitting' title="Overfitting and Underfitting" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-02-gradient-boosting' title="Gradient Boosting" class="py-2 px-3 btn btn-primary"
				data-read-mod="machine_learning" data-read-unit="7-1">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-02-gradient-boosting' title="Gradient Boosting" class="py-2 px-3 btn btn-primary" 
				data-read-mod="machine_learning" data-read-unit="7-1">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Machine Learning Course</h1>
<h2>Module 1: Introduction to Machine Learning</h2>
<ul>
<li><a href="01-01-what-is-machine-learning">What is Machine Learning?</a></li>
<li><a href="01-02-history-evolution-machine-learning">History and Evolution of Machine Learning</a></li>
<li><a href="01-03-types-machine-learning">Types of Machine Learning</a></li>
<li><a href="01-04-applications-machine-learning">Applications of Machine Learning</a></li>
</ul>
<h2>Module 2: Fundamentals of Statistics and Probability</h2>
<ul>
<li><a href="02-01-basic-concepts-statistics">Basic Concepts of Statistics</a></li>
<li><a href="02-02-probability-distributions">Probability Distributions</a></li>
<li><a href="02-03-statistical-inference">Statistical Inference</a></li>
<li><a href="02-04-bayes-theorem">Bayes' Theorem</a></li>
</ul>
<h2>Module 3: Data Preprocessing</h2>
<ul>
<li><a href="03-01-data-cleaning">Data Cleaning</a></li>
<li><a href="03-02-data-transformation">Data Transformation</a></li>
<li><a href="03-03-normalization-standardization">Normalization and Standardization</a></li>
<li><a href="03-04-handling-missing-data">Handling Missing Data</a></li>
</ul>
<h2>Module 4: Supervised Machine Learning Algorithms</h2>
<ul>
<li><a href="04-01-linear-regression">Linear Regression</a></li>
<li><a href="04-02-logistic-regression">Logistic Regression</a></li>
<li><a href="04-03-decision-trees">Decision Trees</a></li>
<li><a href="04-04-svm">Support Vector Machines (SVM)</a></li>
<li><a href="04-05-knn">K-Nearest Neighbors (K-NN)</a></li>
<li><a href="04-06-neural-networks">Neural Networks</a></li>
</ul>
<h2>Module 5: Unsupervised Machine Learning Algorithms</h2>
<ul>
<li><a href="05-01-clustering-k-means">Clustering: K-means</a></li>
<li><a href="05-02-hierarchical-clustering">Hierarchical Clustering</a></li>
<li><a href="05-03-pca">Principal Component Analysis (PCA)</a></li>
<li><a href="05-04-dbscan">DBSCAN Clustering Analysis</a></li>
</ul>
<h2>Module 6: Model Evaluation and Validation</h2>
<ul>
<li><a href="06-01-evaluation-metrics">Evaluation Metrics</a></li>
<li><a href="06-02-cross-validation">Cross-Validation</a></li>
<li><a href="06-03-roc-curve-auc">ROC Curve and AUC</a></li>
<li><a href="06-04-overfitting-underfitting">Overfitting and Underfitting</a></li>
</ul>
<h2>Module 7: Advanced Techniques and Optimization</h2>
<ul>
<li><a href="07-01-ensemble-learning">Ensemble Learning</a></li>
<li><a href="07-02-gradient-boosting">Gradient Boosting</a></li>
<li><a href="07-03-deep-learning">Deep Learning</a></li>
<li><a href="07-04-hyperparameter-optimization">Hyperparameter Optimization</a></li>
</ul>
<h2>Module 8: Model Implementation and Deployment</h2>
<ul>
<li><a href="08-01-frameworks-libraries">Popular Frameworks and Libraries</a></li>
<li><a href="08-02-implementation-production">Model Implementation in Production</a></li>
<li><a href="08-03-maintenance-monitoring">Model Maintenance and Monitoring</a></li>
<li><a href="08-04-ethics-privacy">Ethical and Privacy Considerations</a></li>
</ul>
<h2>Module 9: Practical Projects</h2>
<ul>
<li><a href="09-01-project-housing-price-prediction">Project 1: Housing Price Prediction</a></li>
<li><a href="09-02-project-image-classification">Project 2: Image Classification</a></li>
<li><a href="09-03-project-sentiment-analysis">Project 3: Sentiment Analysis on Social Media</a></li>
<li><a href="09-04-project-fraud-detection">Project 4: Fraud Detection</a></li>
</ul>
<h2>Module 10: Additional Resources</h2>
<ul>
<li><a href="10-01-recommended-books">Recommended Books</a></li>
<li><a href="10-02-online-courses">Online Courses</a></li>
<li><a href="10-03-communities-forums">Communities and Forums</a></li>
<li><a href="10-04-tools-software">Tools and Software</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
