<!DOCTYPE html>
<html lang="en">
<head>
    <title> Autograd: Automatic Differentiation </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/pytorch/01-04-autograd" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/pytorch/01-04-autograd" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/pytorch/01-04-autograd" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "pytorch";
  		var TEMA_NAME = "1-4";
  		var TYPE = "mod";
  		var PATH = "mod/pytorch/01-04-autograd";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo-header_enterprise.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/pytorch/01-04-autograd" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/pytorch/01-04-autograd" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="pytorch">
		<a  href="#" class="text-secondary d-none" data-read-mod="pytorch" data-read-unit="1-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="pytorch" data-unread-unit="1-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='01-03-basic-tensor-operations' title="Basic Tensor Operations" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='01-03-basic-tensor-operations' title="Basic Tensor Operations" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Autograd: Automatic Differentiation</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-01-introduction-to-neural-networks' title="Introduction to Neural Networks" class="py-2 px-3 btn btn-primary"
				data-read-mod="pytorch" data-read-unit="1-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-01-introduction-to-neural-networks' title="Introduction to Neural Networks" class="py-2 px-3 btn btn-primary" 
				data-read-mod="pytorch" data-read-unit="1-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Autograd is PyTorch's automatic differentiation engine that powers neural network training. It provides automatic computation of gradients, which are essential for optimizing neural networks. This module will cover the basics of autograd, how to use it, and practical examples to solidify your understanding.</p>
</div><h1>Key Concepts</h1>
<div class='content'></div><h2><ol>
<li>Tensors and Gradients</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Tensors</strong>: The fundamental building blocks in PyTorch, similar to NumPy arrays but with additional capabilities for GPU acceleration.</li>
<li><strong>Gradients</strong>: Derivatives of tensors with respect to some scalar value, typically a loss function.</li>
</ul>
</div><h2><ol start="2">
<li>Computational Graph</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Computational Graph</strong>: A directed acyclic graph where nodes represent operations and edges represent tensors. PyTorch dynamically builds this graph as operations are performed.</li>
</ul>
</div><h2><ol start="3">
<li>Backpropagation</li>
</ol></h2>
<div class='content'><ul>
<li><strong>Backpropagation</strong>: The process of computing gradients by traversing the computational graph in reverse order.</li>
</ul>
</div><h1>Practical Examples</h1>
<div class='content'></div><h2>Example 1: Basic Tensor Operations with Autograd</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIENyZWF0ZSB0ZW5zb3JzCnggPSB0b3JjaC50ZW5zb3IoMi4wLCByZXF1aXJlc19ncmFkPVRydWUpCnkgPSB0b3JjaC50ZW5zb3IoMy4wLCByZXF1aXJlc19ncmFkPVRydWUpCgojIFBlcmZvcm0gb3BlcmF0aW9ucwp6ID0geCAqIHkgKyB5KioyCgojIENvbXB1dGUgZ3JhZGllbnRzCnouYmFja3dhcmQoKQoKIyBQcmludCBncmFkaWVudHMKcHJpbnQoZiJHcmFkaWVudCBvZiB4OiB7eC5ncmFkfSIpCnByaW50KGYiR3JhZGllbnQgb2YgeToge3kuZ3JhZH0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Create tensors
x = torch.tensor(2.0, requires_grad=True)
y = torch.tensor(3.0, requires_grad=True)

# Perform operations
z = x * y + y**2

# Compute gradients
z.backward()

# Print gradients
print(f&quot;Gradient of x: {x.grad}&quot;)
print(f&quot;Gradient of y: {y.grad}&quot;)</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ol>
<li><code>requires_grad=True</code> tells PyTorch to track operations on these tensors.</li>
<li><code>z.backward()</code> computes the gradients of <code>z</code> with respect to <code>x</code> and <code>y</code>.</li>
<li><code>x.grad</code> and <code>y.grad</code> hold the computed gradients.</li>
</ol>
</div><h2>Example 2: Using Autograd with a Simple Neural Network</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgoKIyBEZWZpbmUgYSBzaW1wbGUgbGluZWFyIG1vZGVsCm1vZGVsID0gbm4uTGluZWFyKDEsIDEpCgojIElucHV0IHRlbnNvcgppbnB1dF90ZW5zb3IgPSB0b3JjaC50ZW5zb3IoW1sxLjBdXSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQoKIyBGb3J3YXJkIHBhc3MKb3V0cHV0ID0gbW9kZWwoaW5wdXRfdGVuc29yKQoKIyBEZWZpbmUgYSBzaW1wbGUgbG9zcyBmdW5jdGlvbgpsb3NzID0gKG91dHB1dCAtIDIuMCkqKjIKCiMgQmFja3dhcmQgcGFzcwpsb3NzLmJhY2t3YXJkKCkKCiMgUHJpbnQgZ3JhZGllbnRzCnByaW50KGYiR3JhZGllbnQgb2YgaW5wdXRfdGVuc29yOiB7aW5wdXRfdGVuc29yLmdyYWR9IikKcHJpbnQoZiJHcmFkaWVudCBvZiBtb2RlbCB3ZWlnaHQ6IHttb2RlbC53ZWlnaHQuZ3JhZH0iKQpwcmludChmIkdyYWRpZW50IG9mIG1vZGVsIGJpYXM6IHttb2RlbC5iaWFzLmdyYWR9Iik="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn

# Define a simple linear model
model = nn.Linear(1, 1)

# Input tensor
input_tensor = torch.tensor([[1.0]], requires_grad=True)

# Forward pass
output = model(input_tensor)

# Define a simple loss function
loss = (output - 2.0)**2

# Backward pass
loss.backward()

# Print gradients
print(f&quot;Gradient of input_tensor: {input_tensor.grad}&quot;)
print(f&quot;Gradient of model weight: {model.weight.grad}&quot;)
print(f&quot;Gradient of model bias: {model.bias.grad}&quot;)</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ol>
<li>A simple linear model is defined using <code>nn.Linear</code>.</li>
<li>The forward pass computes the output.</li>
<li>A loss function is defined as the squared difference between the output and a target value.</li>
<li><code>loss.backward()</code> computes the gradients of the loss with respect to the input tensor and model parameters.</li>
</ol>
</div><h1>Exercises</h1>
<div class='content'></div><h2>Exercise 1: Compute Gradients for a Polynomial Function</h2>
<div class='content'><p><strong>Task:</strong></p>
<ol>
<li>Create a tensor <code>x</code> with value <code>3.0</code> and set <code>requires_grad=True</code>.</li>
<li>Define a polynomial function <code>y = 3x^3 + 2x^2 + x</code>.</li>
<li>Compute the gradient of <code>y</code> with respect to <code>x</code>.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIENyZWF0ZSB0ZW5zb3IKeCA9IHRvcmNoLnRlbnNvcigzLjAsIHJlcXVpcmVzX2dyYWQ9VHJ1ZSkKCiMgRGVmaW5lIHBvbHlub21pYWwgZnVuY3Rpb24KeSA9IDMgKiB4KiozICsgMiAqIHgqKjIgKyB4CgojIENvbXB1dGUgZ3JhZGllbnQKeS5iYWNrd2FyZCgpCgojIFByaW50IGdyYWRpZW50CnByaW50KGYiR3JhZGllbnQgb2YgeDoge3guZ3JhZH0iKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Create tensor
x = torch.tensor(3.0, requires_grad=True)

# Define polynomial function
y = 3 * x**3 + 2 * x**2 + x

# Compute gradient
y.backward()

# Print gradient
print(f&quot;Gradient of x: {x.grad}&quot;)</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ol>
<li>The tensor <code>x</code> is created with <code>requires_grad=True</code>.</li>
<li>The polynomial function <code>y</code> is defined.</li>
<li><code>y.backward()</code> computes the gradient of <code>y</code> with respect to <code>x</code>.</li>
</ol>
</div><h2>Exercise 2: Gradient Descent Step</h2>
<div class='content'><p><strong>Task:</strong></p>
<ol>
<li>Create a tensor <code>w</code> with value <code>1.0</code> and set <code>requires_grad=True</code>.</li>
<li>Define a simple quadratic function <code>loss = (w - 5)**2</code>.</li>
<li>Perform a gradient descent step to update <code>w</code>.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIENyZWF0ZSB0ZW5zb3IKdyA9IHRvcmNoLnRlbnNvcigxLjAsIHJlcXVpcmVzX2dyYWQ9VHJ1ZSkKCiMgRGVmaW5lIGxvc3MgZnVuY3Rpb24KbG9zcyA9ICh3IC0gNSkqKjIKCiMgQ29tcHV0ZSBncmFkaWVudApsb3NzLmJhY2t3YXJkKCkKCiMgUGVyZm9ybSBncmFkaWVudCBkZXNjZW50IHN0ZXAKbGVhcm5pbmdfcmF0ZSA9IDAuMQp3aXRoIHRvcmNoLm5vX2dyYWQoKToKICAgIHcgLT0gbGVhcm5pbmdfcmF0ZSAqIHcuZ3JhZAoKIyBQcmludCB1cGRhdGVkIHZhbHVlIG9mIHcKcHJpbnQoZiJVcGRhdGVkIHZhbHVlIG9mIHc6IHt3fSIp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Create tensor
w = torch.tensor(1.0, requires_grad=True)

# Define loss function
loss = (w - 5)**2

# Compute gradient
loss.backward()

# Perform gradient descent step
learning_rate = 0.1
with torch.no_grad():
    w -= learning_rate * w.grad

# Print updated value of w
print(f&quot;Updated value of w: {w}&quot;)</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ol>
<li>The tensor <code>w</code> is created with <code>requires_grad=True</code>.</li>
<li>The loss function is defined.</li>
<li><code>loss.backward()</code> computes the gradient of the loss with respect to <code>w</code>.</li>
<li>A gradient descent step is performed to update <code>w</code>.</li>
</ol>
</div><h1>Common Mistakes and Tips</h1>
<div class='content'><ul>
<li><strong>Forgetting <code>requires_grad=True</code></strong>: Ensure that tensors for which you need gradients have <code>requires_grad=True</code>.</li>
<li><strong>Clearing Gradients</strong>: Gradients accumulate by default. Use <code>optimizer.zero_grad()</code> or <code>tensor.grad.zero_()</code> to clear gradients before the next backward pass.</li>
<li><strong>Using <code>torch.no_grad()</code></strong>: Use this context manager to perform operations that should not track gradients, such as during model evaluation or updating parameters manually.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this section, you learned about PyTorch's autograd functionality, which is crucial for training neural networks. You explored basic tensor operations, computational graphs, and backpropagation. Practical examples and exercises helped reinforce these concepts. In the next module, you will dive into building neural networks using PyTorch.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='01-03-basic-tensor-operations' title="Basic Tensor Operations" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='01-03-basic-tensor-operations' title="Basic Tensor Operations" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-01-introduction-to-neural-networks' title="Introduction to Neural Networks" class="py-2 px-3 btn btn-primary"
				data-read-mod="pytorch" data-read-unit="1-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-01-introduction-to-neural-networks' title="Introduction to Neural Networks" class="py-2 px-3 btn btn-primary" 
				data-read-mod="pytorch" data-read-unit="1-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>PyTorch: From Beginner to Advanced</h1>
<h2>Module 1: Introduction to PyTorch</h2>
<ul>
<li><a href="01-01-what-is-pytorch">What is PyTorch?</a></li>
<li><a href="01-02-setting-up-environment">Setting Up the Environment</a></li>
<li><a href="01-03-basic-tensor-operations">Basic Tensor Operations</a></li>
<li><a href="01-04-autograd">Autograd: Automatic Differentiation</a></li>
</ul>
<h2>Module 2: Building Neural Networks</h2>
<ul>
<li><a href="02-01-introduction-to-neural-networks">Introduction to Neural Networks</a></li>
<li><a href="02-02-creating-simple-neural-network">Creating a Simple Neural Network</a></li>
<li><a href="02-03-activation-functions">Activation Functions</a></li>
<li><a href="02-04-loss-functions-optimization">Loss Functions and Optimization</a></li>
</ul>
<h2>Module 3: Training Neural Networks</h2>
<ul>
<li><a href="03-01-data-loading-preprocessing">Data Loading and Preprocessing</a></li>
<li><a href="03-02-training-loop">Training Loop</a></li>
<li><a href="03-03-validation-testing">Validation and Testing</a></li>
<li><a href="03-04-saving-loading-models">Saving and Loading Models</a></li>
</ul>
<h2>Module 4: Convolutional Neural Networks (CNNs)</h2>
<ul>
<li><a href="04-01-introduction-to-cnns">Introduction to CNNs</a></li>
<li><a href="04-02-building-cnn-from-scratch">Building a CNN from Scratch</a></li>
<li><a href="04-03-transfer-learning">Transfer Learning with Pre-trained Models</a></li>
<li><a href="04-04-fine-tuning-cnns">Fine-Tuning CNNs</a></li>
</ul>
<h2>Module 5: Recurrent Neural Networks (RNNs)</h2>
<ul>
<li><a href="05-01-introduction-to-rnns">Introduction to RNNs</a></li>
<li><a href="05-02-building-rnn-from-scratch">Building an RNN from Scratch</a></li>
<li><a href="05-03-lstm-networks">Long Short-Term Memory (LSTM) Networks</a></li>
<li><a href="05-04-gru-networks">Gated Recurrent Units (GRUs)</a></li>
</ul>
<h2>Module 6: Advanced Topics</h2>
<ul>
<li><a href="06-01-gans">Generative Adversarial Networks (GANs)</a></li>
<li><a href="06-02-reinforcement-learning">Reinforcement Learning with PyTorch</a></li>
<li><a href="06-03-deploying-models">Deploying PyTorch Models</a></li>
<li><a href="06-04-optimizing-performance">Optimizing Performance</a></li>
</ul>
<h2>Module 7: Case Studies and Projects</h2>
<ul>
<li><a href="07-01-image-classification-project">Image Classification Project</a></li>
<li><a href="07-02-nlp-project">Natural Language Processing Project</a></li>
<li><a href="07-03-time-series-forecasting-project">Time Series Forecasting Project</a></li>
<li><a href="07-04-custom-project">Custom Project</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
