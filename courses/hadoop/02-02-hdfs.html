<!DOCTYPE html>
<html lang="en">
<head>
    <title> HDFS (Hadoop Distributed File System) </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/hadoop/02-02-hdfs" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/hadoop/02-02-hdfs" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/hadoop/02-02-hdfs" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "hadoop";
  		var TEMA_NAME = "2-2";
  		var TYPE = "mod";
  		var PATH = "mod/hadoop/02-02-hdfs";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.8d8afe898f.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/hadoop/02-02-hdfs" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/hadoop/02-02-hdfs" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="hadoop">
		<a  href="#" class="text-secondary d-none" data-read-mod="hadoop" data-read-unit="2-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="hadoop" data-unread-unit="2-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-01-hadoop-core-components' title="Hadoop Core Components" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-01-hadoop-core-components' title="Hadoop Core Components" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">HDFS (Hadoop Distributed File System)</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-03-mapreduce-framework' title="MapReduce Framework" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="2-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-03-mapreduce-framework' title="MapReduce Framework" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="2-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introduction</h2>
<div class='content'><p>HDFS (Hadoop Distributed File System) is the primary storage system used by Hadoop applications. It is designed to store large datasets reliably and to stream those datasets at high bandwidth to user applications. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware.</p>
</div><h2>Key Concepts</h2>
<div class='content'></div><h3><ol>
<li>Architecture</li>
</ol></h3>
<div class='content'><ul>
<li><strong>NameNode</strong>: The master server that manages the file system namespace and regulates access to files by clients.</li>
<li><strong>DataNode</strong>: The worker nodes that store and retrieve blocks when they are told to (by the NameNode).</li>
<li><strong>Secondary NameNode</strong>: A helper to the primary NameNode, it performs housekeeping functions for the NameNode.</li>
</ul>
</div><h3><ol start="2">
<li>File System Namespace</li>
</ol></h3>
<div class='content'><ul>
<li>HDFS supports a traditional hierarchical file organization. A user or an application can create directories and store files inside these directories.</li>
<li>The file system namespace hierarchy is similar to most other existing file systems: it supports operations such as creating and deleting files, renaming files, and directories.</li>
</ul>
</div><h3><ol start="3">
<li>Data Replication</li>
</ol></h3>
<div class='content'><ul>
<li>HDFS stores each file as a sequence of blocks; all blocks in a file except the last block are the same size.</li>
<li>Blocks are replicated for fault tolerance. The block size and replication factor are configurable per file.</li>
</ul>
</div><h3><ol start="4">
<li>Fault Tolerance</li>
</ol></h3>
<div class='content'><ul>
<li>HDFS is designed to detect faults and recover from them automatically.</li>
<li>Data is replicated across multiple DataNodes to ensure data availability even if some nodes fail.</li>
</ul>
</div><h2>HDFS Architecture</h2>
<div class='content'></div><h3>NameNode and DataNode Interaction</h3>
<div class='content'><ul>
<li>The NameNode maintains the file system namespace and the metadata for all the files and directories.</li>
<li>The DataNodes are responsible for serving read and write requests from the file systemâ€™s clients.</li>
<li>The DataNodes also perform block creation, deletion, and replication upon instruction from the NameNode.</li>
</ul>
</div><h3>Block Management</h3>
<div class='content'><ul>
<li>Files are split into one or more blocks, and these blocks are stored in a set of DataNodes.</li>
<li>The NameNode maintains the mapping of blocks to DataNodes.</li>
</ul>
</div><h3>Heartbeats and Block Reports</h3>
<div class='content'><ul>
<li>DataNodes send periodic heartbeats to the NameNode to confirm their availability.</li>
<li>DataNodes also send block reports to the NameNode to provide information about the blocks they are storing.</li>
</ul>
</div><h2>Practical Example</h2>
<div class='content'></div><h3>Writing a File to HDFS</h3>
<div class='content'><ol>
<li><strong>Client Request</strong>: A client requests to write a file to HDFS.</li>
<li><strong>NameNode Interaction</strong>: The client contacts the NameNode to get the list of DataNodes to store the file blocks.</li>
<li><strong>DataNode Interaction</strong>: The client writes the file blocks to the DataNodes.</li>
<li><strong>Replication</strong>: The DataNodes replicate the blocks to other DataNodes as per the replication factor.</li>
</ol>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Ly8gRXhhbXBsZTogV3JpdGluZyBhIGZpbGUgdG8gSERGUyB1c2luZyBKYXZhIEFQSQppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuY29uZi5Db25maWd1cmF0aW9uOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuZnMuRmlsZVN5c3RlbTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLlBhdGg7CmltcG9ydCBqYXZhLmlvLk91dHB1dFN0cmVhbTsKCnB1YmxpYyBjbGFzcyBIREZTV3JpdGVFeGFtcGxlIHsKICAgIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHsKICAgICAgICB0cnkgewogICAgICAgICAgICBDb25maWd1cmF0aW9uIGNvbmZpZ3VyYXRpb24gPSBuZXcgQ29uZmlndXJhdGlvbigpOwogICAgICAgICAgICBGaWxlU3lzdGVtIGhkZnMgPSBGaWxlU3lzdGVtLmdldChjb25maWd1cmF0aW9uKTsKICAgICAgICAgICAgUGF0aCBmaWxlID0gbmV3IFBhdGgoIi91c2VyL2hhZG9vcC9leGFtcGxlLnR4dCIpOwogICAgICAgICAgICBPdXRwdXRTdHJlYW0gb3MgPSBoZGZzLmNyZWF0ZShmaWxlKTsKICAgICAgICAgICAgb3Mud3JpdGUoIkhlbGxvIEhERlMhIi5nZXRCeXRlcygpKTsKICAgICAgICAgICAgb3MuY2xvc2UoKTsKICAgICAgICB9IGNhdGNoIChFeGNlcHRpb24gZSkgewogICAgICAgICAgICBlLnByaW50U3RhY2tUcmFjZSgpOwogICAgICAgIH0KICAgIH0KfQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>// Example: Writing a file to HDFS using Java API
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.OutputStream;

public class HDFSWriteExample {
    public static void main(String[] args) {
        try {
            Configuration configuration = new Configuration();
            FileSystem hdfs = FileSystem.get(configuration);
            Path file = new Path(&quot;/user/hadoop/example.txt&quot;);
            OutputStream os = hdfs.create(file);
            os.write(&quot;Hello HDFS!&quot;.getBytes());
            os.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}</pre></div><div class='content'></div><h3>Reading a File from HDFS</h3>
<div class='content'><ol>
<li><strong>Client Request</strong>: A client requests to read a file from HDFS.</li>
<li><strong>NameNode Interaction</strong>: The client contacts the NameNode to get the list of DataNodes that store the file blocks.</li>
<li><strong>DataNode Interaction</strong>: The client reads the file blocks from the DataNodes.</li>
</ol>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Ly8gRXhhbXBsZTogUmVhZGluZyBhIGZpbGUgZnJvbSBIREZTIHVzaW5nIEphdmEgQVBJCmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5jb25mLkNvbmZpZ3VyYXRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5mcy5GaWxlU3lzdGVtOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuZnMuUGF0aDsKaW1wb3J0IGphdmEuaW8uSW5wdXRTdHJlYW07CgpwdWJsaWMgY2xhc3MgSERGU1JlYWRFeGFtcGxlIHsKICAgIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHsKICAgICAgICB0cnkgewogICAgICAgICAgICBDb25maWd1cmF0aW9uIGNvbmZpZ3VyYXRpb24gPSBuZXcgQ29uZmlndXJhdGlvbigpOwogICAgICAgICAgICBGaWxlU3lzdGVtIGhkZnMgPSBGaWxlU3lzdGVtLmdldChjb25maWd1cmF0aW9uKTsKICAgICAgICAgICAgUGF0aCBmaWxlID0gbmV3IFBhdGgoIi91c2VyL2hhZG9vcC9leGFtcGxlLnR4dCIpOwogICAgICAgICAgICBJbnB1dFN0cmVhbSBpcyA9IGhkZnMub3BlbihmaWxlKTsKICAgICAgICAgICAgYnl0ZVtdIGJ1ZmZlciA9IG5ldyBieXRlWzI1Nl07CiAgICAgICAgICAgIGludCBieXRlc1JlYWQgPSBpcy5yZWFkKGJ1ZmZlcik7CiAgICAgICAgICAgIHdoaWxlIChieXRlc1JlYWQgPiAwKSB7CiAgICAgICAgICAgICAgICBTeXN0ZW0ub3V0LndyaXRlKGJ1ZmZlciwgMCwgYnl0ZXNSZWFkKTsKICAgICAgICAgICAgICAgIGJ5dGVzUmVhZCA9IGlzLnJlYWQoYnVmZmVyKTsKICAgICAgICAgICAgfQogICAgICAgICAgICBpcy5jbG9zZSgpOwogICAgICAgIH0gY2F0Y2ggKEV4Y2VwdGlvbiBlKSB7CiAgICAgICAgICAgIGUucHJpbnRTdGFja1RyYWNlKCk7CiAgICAgICAgfQogICAgfQp9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>// Example: Reading a file from HDFS using Java API
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.InputStream;

public class HDFSReadExample {
    public static void main(String[] args) {
        try {
            Configuration configuration = new Configuration();
            FileSystem hdfs = FileSystem.get(configuration);
            Path file = new Path(&quot;/user/hadoop/example.txt&quot;);
            InputStream is = hdfs.open(file);
            byte[] buffer = new byte[256];
            int bytesRead = is.read(buffer);
            while (bytesRead &gt; 0) {
                System.out.write(buffer, 0, bytesRead);
                bytesRead = is.read(buffer);
            }
            is.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}</pre></div><div class='content'></div><h2>Exercises</h2>
<div class='content'></div><h3>Exercise 1: Write a File to HDFS</h3>
<div class='content'><p><strong>Task</strong>: Write a Java program to create a new file in HDFS and write the text &quot;Hello, Hadoop!&quot; into it.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmNvbmYuQ29uZmlndXJhdGlvbjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLkZpbGVTeXN0ZW07CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5mcy5QYXRoOwppbXBvcnQgamF2YS5pby5PdXRwdXRTdHJlYW07CgpwdWJsaWMgY2xhc3MgSERGU1dyaXRlRXhlcmNpc2UgewogICAgcHVibGljIHN0YXRpYyB2b2lkIG1haW4oU3RyaW5nW10gYXJncykgewogICAgICAgIHRyeSB7CiAgICAgICAgICAgIENvbmZpZ3VyYXRpb24gY29uZmlndXJhdGlvbiA9IG5ldyBDb25maWd1cmF0aW9uKCk7CiAgICAgICAgICAgIEZpbGVTeXN0ZW0gaGRmcyA9IEZpbGVTeXN0ZW0uZ2V0KGNvbmZpZ3VyYXRpb24pOwogICAgICAgICAgICBQYXRoIGZpbGUgPSBuZXcgUGF0aCgiL3VzZXIvaGFkb29wL2V4ZXJjaXNlLnR4dCIpOwogICAgICAgICAgICBPdXRwdXRTdHJlYW0gb3MgPSBoZGZzLmNyZWF0ZShmaWxlKTsKICAgICAgICAgICAgb3Mud3JpdGUoIkhlbGxvLCBIYWRvb3AhIi5nZXRCeXRlcygpKTsKICAgICAgICAgICAgb3MuY2xvc2UoKTsKICAgICAgICB9IGNhdGNoIChFeGNlcHRpb24gZSkgewogICAgICAgICAgICBlLnByaW50U3RhY2tUcmFjZSgpOwogICAgICAgIH0KICAgIH0KfQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.OutputStream;

public class HDFSWriteExercise {
    public static void main(String[] args) {
        try {
            Configuration configuration = new Configuration();
            FileSystem hdfs = FileSystem.get(configuration);
            Path file = new Path(&quot;/user/hadoop/exercise.txt&quot;);
            OutputStream os = hdfs.create(file);
            os.write(&quot;Hello, Hadoop!&quot;.getBytes());
            os.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}</pre></div><div class='content'></div><h3>Exercise 2: Read a File from HDFS</h3>
<div class='content'><p><strong>Task</strong>: Write a Java program to read the content of the file created in Exercise 1 from HDFS and print it to the console.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmNvbmYuQ29uZmlndXJhdGlvbjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLkZpbGVTeXN0ZW07CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5mcy5QYXRoOwppbXBvcnQgamF2YS5pby5JbnB1dFN0cmVhbTsKCnB1YmxpYyBjbGFzcyBIREZTUmVhZEV4ZXJjaXNlIHsKICAgIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHsKICAgICAgICB0cnkgewogICAgICAgICAgICBDb25maWd1cmF0aW9uIGNvbmZpZ3VyYXRpb24gPSBuZXcgQ29uZmlndXJhdGlvbigpOwogICAgICAgICAgICBGaWxlU3lzdGVtIGhkZnMgPSBGaWxlU3lzdGVtLmdldChjb25maWd1cmF0aW9uKTsKICAgICAgICAgICAgUGF0aCBmaWxlID0gbmV3IFBhdGgoIi91c2VyL2hhZG9vcC9leGVyY2lzZS50eHQiKTsKICAgICAgICAgICAgSW5wdXRTdHJlYW0gaXMgPSBoZGZzLm9wZW4oZmlsZSk7CiAgICAgICAgICAgIGJ5dGVbXSBidWZmZXIgPSBuZXcgYnl0ZVsyNTZdOwogICAgICAgICAgICBpbnQgYnl0ZXNSZWFkID0gaXMucmVhZChidWZmZXIpOwogICAgICAgICAgICB3aGlsZSAoYnl0ZXNSZWFkID4gMCkgewogICAgICAgICAgICAgICAgU3lzdGVtLm91dC53cml0ZShidWZmZXIsIDAsIGJ5dGVzUmVhZCk7CiAgICAgICAgICAgICAgICBieXRlc1JlYWQgPSBpcy5yZWFkKGJ1ZmZlcik7CiAgICAgICAgICAgIH0KICAgICAgICAgICAgaXMuY2xvc2UoKTsKICAgICAgICB9IGNhdGNoIChFeGNlcHRpb24gZSkgewogICAgICAgICAgICBlLnByaW50U3RhY2tUcmFjZSgpOwogICAgICAgIH0KICAgIH0KfQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.InputStream;

public class HDFSReadExercise {
    public static void main(String[] args) {
        try {
            Configuration configuration = new Configuration();
            FileSystem hdfs = FileSystem.get(configuration);
            Path file = new Path(&quot;/user/hadoop/exercise.txt&quot;);
            InputStream is = hdfs.open(file);
            byte[] buffer = new byte[256];
            int bytesRead = is.read(buffer);
            while (bytesRead &gt; 0) {
                System.out.write(buffer, 0, bytesRead);
                bytesRead = is.read(buffer);
            }
            is.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}</pre></div><div class='content'></div><h2>Summary</h2>
<div class='content'><p>In this section, we covered the basics of HDFS, including its architecture, key components, and how it handles data storage and replication. We also provided practical examples of writing and reading files to and from HDFS using Java. Understanding HDFS is crucial for working with Hadoop, as it forms the backbone of data storage in the Hadoop ecosystem. In the next module, we will delve deeper into the MapReduce framework, which is used for processing the data stored in HDFS.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-01-hadoop-core-components' title="Hadoop Core Components" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-01-hadoop-core-components' title="Hadoop Core Components" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-03-mapreduce-framework' title="MapReduce Framework" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="2-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-03-mapreduce-framework' title="MapReduce Framework" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="2-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Hadoop Course</h1>
<h2>Module 1: Introduction to Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">What is Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Hadoop Ecosystem Overview</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Traditional Databases</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Setting Up Hadoop Environment</a></li>
</ul>
<h2>Module 2: Hadoop Architecture</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Hadoop Core Components</a></li>
<li><a href="02-02-hdfs">HDFS (Hadoop Distributed File System)</a></li>
<li><a href="02-03-mapreduce-framework">MapReduce Framework</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Module 3: HDFS (Hadoop Distributed File System)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">HDFS Architecture</a></li>
<li><a href="03-02-hdfs-commands">HDFS Commands</a></li>
<li><a href="03-03-data-replication-in-hdfs">Data Replication in HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">HDFS Fault Tolerance</a></li>
</ul>
<h2>Module 4: MapReduce Programming</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introduction to MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">MapReduce Job Workflow</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Writing a MapReduce Program</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">MapReduce Optimization Techniques</a></li>
</ul>
<h2>Module 5: Hadoop Ecosystem Tools</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Module 6: Advanced Hadoop Concepts</h2>
<ul>
<li><a href="06-01-hadoop-security">Hadoop Security</a></li>
<li><a href="06-02-hadoop-cluster-management">Hadoop Cluster Management</a></li>
<li><a href="06-03-hadoop-performance-tuning">Hadoop Performance Tuning</a></li>
<li><a href="06-04-hadoop-data-serialization">Hadoop Data Serialization</a></li>
</ul>
<h2>Module 7: Real-World Applications and Case Studies</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop in Data Warehousing</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop in Machine Learning</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop in Real-Time Data Processing</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Case Studies of Hadoop Implementations</a></li>
</ul>
<h2>Module 8: Hands-On Projects</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Project 1: Analyzing Big Data with Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Project 2: Building a Data Pipeline with Hadoop Ecosystem</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Project 3: Real-Time Data Processing with Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Project 4: Machine Learning with Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
