<!DOCTYPE html>
<html lang="en">
<head>
    <title> HDFS Fault Tolerance </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/hadoop/03-04-hdfs-fault-tolerance" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/hadoop/03-04-hdfs-fault-tolerance" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/hadoop/03-04-hdfs-fault-tolerance" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "hadoop";
  		var TEMA_NAME = "3-4";
  		var TYPE = "mod";
  		var PATH = "mod/hadoop/03-04-hdfs-fault-tolerance";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/hadoop/03-04-hdfs-fault-tolerance" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/hadoop/03-04-hdfs-fault-tolerance" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="hadoop">
		<a  href="#" class="text-secondary d-none" data-read-mod="hadoop" data-read-unit="3-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="hadoop" data-unread-unit="3-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-03-data-replication-in-hdfs' title="Data Replication in HDFS" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-03-data-replication-in-hdfs' title="Data Replication in HDFS" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">HDFS Fault Tolerance</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='04-01-introduction-to-mapreduce' title="Introduction to MapReduce" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="3-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='04-01-introduction-to-mapreduce' title="Introduction to MapReduce" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="3-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introduction</h2>
<div class='content'><p>HDFS (Hadoop Distributed File System) is designed to store large amounts of data reliably and to stream those data to user applications at high bandwidth. One of the key features of HDFS is its fault tolerance, which ensures data availability and reliability even in the event of hardware failures.</p>
</div><h2>Key Concepts of HDFS Fault Tolerance</h2>
<div class='content'><ol>
<li>
<p><strong>Data Replication</strong>:</p>
<ul>
<li>HDFS stores multiple copies of data blocks across different nodes in the cluster.</li>
<li>The default replication factor is 3, meaning each block of data is stored on three different nodes.</li>
<li>This redundancy ensures that if one node fails, the data can still be accessed from another node.</li>
</ul>
</li>
<li>
<p><strong>Heartbeat and Block Reports</strong>:</p>
<ul>
<li>DataNodes send periodic heartbeats to the NameNode to confirm their availability.</li>
<li>Block reports are sent by DataNodes to the NameNode, listing all the blocks they store.</li>
<li>If a DataNode fails to send a heartbeat, the NameNode marks it as dead and initiates the replication of its blocks to other DataNodes.</li>
</ul>
</li>
<li>
<p><strong>Rack Awareness</strong>:</p>
<ul>
<li>HDFS is rack-aware, meaning it understands the network topology of the cluster.</li>
<li>Data is replicated across different racks to ensure that even if an entire rack fails, the data is still available.</li>
<li>Typically, one replica is stored on a different rack than the other two.</li>
</ul>
</li>
<li>
<p><strong>Data Integrity</strong>:</p>
<ul>
<li>HDFS uses checksums to verify the integrity of data blocks.</li>
<li>When a block is read, its checksum is computed and compared with the stored checksum to detect any corruption.</li>
<li>If corruption is detected, the block is re-replicated from another replica.</li>
</ul>
</li>
<li>
<p><strong>Automatic Recovery</strong>:</p>
<ul>
<li>When a DataNode fails, the NameNode automatically re-replicates the blocks stored on the failed node to other healthy nodes.</li>
<li>This ensures that the replication factor is maintained and data remains available.</li>
</ul>
</li>
</ol>
</div><h2>Practical Example</h2>
<div class='content'></div><h3>Setting Up Replication Factor</h3>
<div class='content'><p>You can set the replication factor for a file in HDFS using the <code>hdfs dfs</code> command. Hereâ€™s an example:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTZXQgdGhlIHJlcGxpY2F0aW9uIGZhY3RvciB0byAyIGZvciBhIHNwZWNpZmljIGZpbGUKaGRmcyBkZnMgLXNldHJlcCAtdyAyIC91c2VyL2hhZG9vcC9teWZpbGUudHh0"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Set the replication factor to 2 for a specific file
hdfs dfs -setrep -w 2 /user/hadoop/myfile.txt</pre></div><div class='content'></div><h3>Checking Data Integrity</h3>
<div class='content'><p>HDFS provides a command to check the integrity of files:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDaGVjayB0aGUgaW50ZWdyaXR5IG9mIGEgZmlsZQpoZGZzIGZzY2sgL3VzZXIvaGFkb29wL215ZmlsZS50eHQ="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Check the integrity of a file
hdfs fsck /user/hadoop/myfile.txt</pre></div><div class='content'></div><h3>Simulating a DataNode Failure</h3>
<div class='content'><p>To understand how HDFS handles DataNode failures, you can manually stop a DataNode and observe the behavior:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTdG9wIGEgRGF0YU5vZGUgKGFzc3VtaW5nIHlvdSBoYXZlIGFjY2VzcyB0byB0aGUgSGFkb29wIGNsdXN0ZXIpCnN0b3AtZGZzLnNo"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Stop a DataNode (assuming you have access to the Hadoop cluster)
stop-dfs.sh</pre></div><div class='content'><p>After stopping the DataNode, you can check the HDFS web UI or use the <code>hdfs dfsadmin</code> command to see how the NameNode handles the failure and re-replicates the blocks.</p>
</div><h2>Practical Exercise</h2>
<div class='content'></div><h3>Exercise: Simulating and Recovering from a DataNode Failure</h3>
<div class='content'><ol>
<li><strong>Objective</strong>: Simulate a DataNode failure and observe how HDFS handles the fault tolerance.</li>
<li><strong>Steps</strong>:
<ul>
<li>Upload a file to HDFS.</li>
<li>Check the replication factor and ensure it is set to 3.</li>
<li>Manually stop a DataNode.</li>
<li>Observe the NameNodeâ€™s response and the re-replication process.</li>
<li>Restart the DataNode and verify the fileâ€™s availability.</li>
</ul>
</li>
</ol>
</div><h3>Solution</h3>
<div class='content'><ol>
<li>
<p><strong>Upload a file to HDFS</strong>:</p>
<pre><code class="language-bash">hdfs dfs -put localfile.txt /user/hadoop/localfile.txt
</code></pre>
</li>
<li>
<p><strong>Check the replication factor</strong>:</p>
<pre><code class="language-bash">hdfs fsck /user/hadoop/localfile.txt -files -blocks -racks
</code></pre>
</li>
<li>
<p><strong>Manually stop a DataNode</strong>:</p>
<pre><code class="language-bash">stop-dfs.sh
</code></pre>
</li>
<li>
<p><strong>Observe the NameNodeâ€™s response</strong>:</p>
<ul>
<li>Check the HDFS web UI or use the following command:
<pre><code class="language-bash">hdfs dfsadmin -report
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>Restart the DataNode</strong>:</p>
<pre><code class="language-bash">start-dfs.sh
</code></pre>
</li>
<li>
<p><strong>Verify the fileâ€™s availability</strong>:</p>
<pre><code class="language-bash">hdfs dfs -cat /user/hadoop/localfile.txt
</code></pre>
</li>
</ol>
</div><h2>Conclusion</h2>
<div class='content'><p>HDFS fault tolerance is a critical feature that ensures data reliability and availability in a Hadoop cluster. By understanding and leveraging data replication, heartbeat mechanisms, rack awareness, data integrity checks, and automatic recovery, HDFS can handle hardware failures gracefully. This module has provided an overview of these concepts, practical examples, and an exercise to reinforce your understanding. In the next module, we will delve deeper into MapReduce programming and its integration with HDFS.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-03-data-replication-in-hdfs' title="Data Replication in HDFS" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-03-data-replication-in-hdfs' title="Data Replication in HDFS" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='04-01-introduction-to-mapreduce' title="Introduction to MapReduce" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="3-4">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='04-01-introduction-to-mapreduce' title="Introduction to MapReduce" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="3-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Hadoop Course</h1>
<h2>Module 1: Introduction to Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">What is Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Hadoop Ecosystem Overview</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Traditional Databases</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Setting Up Hadoop Environment</a></li>
</ul>
<h2>Module 2: Hadoop Architecture</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Hadoop Core Components</a></li>
<li><a href="02-02-hdfs">HDFS (Hadoop Distributed File System)</a></li>
<li><a href="02-03-mapreduce-framework">MapReduce Framework</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Module 3: HDFS (Hadoop Distributed File System)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">HDFS Architecture</a></li>
<li><a href="03-02-hdfs-commands">HDFS Commands</a></li>
<li><a href="03-03-data-replication-in-hdfs">Data Replication in HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">HDFS Fault Tolerance</a></li>
</ul>
<h2>Module 4: MapReduce Programming</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introduction to MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">MapReduce Job Workflow</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Writing a MapReduce Program</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">MapReduce Optimization Techniques</a></li>
</ul>
<h2>Module 5: Hadoop Ecosystem Tools</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Module 6: Advanced Hadoop Concepts</h2>
<ul>
<li><a href="06-01-hadoop-security">Hadoop Security</a></li>
<li><a href="06-02-hadoop-cluster-management">Hadoop Cluster Management</a></li>
<li><a href="06-03-hadoop-performance-tuning">Hadoop Performance Tuning</a></li>
<li><a href="06-04-hadoop-data-serialization">Hadoop Data Serialization</a></li>
</ul>
<h2>Module 7: Real-World Applications and Case Studies</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop in Data Warehousing</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop in Machine Learning</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop in Real-Time Data Processing</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Case Studies of Hadoop Implementations</a></li>
</ul>
<h2>Module 8: Hands-On Projects</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Project 1: Analyzing Big Data with Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Project 2: Building a Data Pipeline with Hadoop Ecosystem</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Project 3: Real-Time Data Processing with Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Project 4: Machine Learning with Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
