<!DOCTYPE html>
<html lang="en">
<head>
    <title> Spark and In-Memory Computing </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/arquitecturas-distribuidas/05-02-spark-computacion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/arquitectures-distribuides/05-02-spark-computacio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/distributed-architectures/05-02-spark-computing" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "arquitecturas_distribuidas";
  		var TEMA_NAME = "5-2";
  		var TYPE = "mod";
  		var PATH = "mod/arquitecturas_distribuidas/05-02-spark-computing";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/arquitecturas-distribuidas/05-02-spark-computacion" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/arquitectures-distribuides/05-02-spark-computacio" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="arquitecturas_distribuidas">
		<a  href="#" class="text-secondary d-none" data-read-mod="arquitecturas_distribuidas" data-read-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="arquitecturas_distribuidas" data-unread-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Spark and In-Memory Computing</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-stream-processing' title="Data Stream Processing" class="py-2 px-3 btn btn-primary"
				data-read-mod="arquitecturas_distribuidas" data-read-unit="5-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-stream-processing' title="Data Stream Processing" class="py-2 px-3 btn btn-primary" 
				data-read-mod="arquitecturas_distribuidas" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>Apache Spark is an open-source, distributed computing system that provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. Spark is known for its ability to process data in-memory, which significantly speeds up data processing tasks compared to traditional disk-based processing frameworks like Hadoop.</p>
</div><h2>Key Concepts of Spark and In-Memory Computing</h2>
<div class='content'></div><h3><ol>
<li>Introduction to Apache Spark</li>
</ol></h3>
<div class='content'><ul>
<li>
<p><strong>What is Apache Spark?</strong></p>
<ul>
<li>A unified analytics engine for large-scale data processing.</li>
<li>Provides high-level APIs in Java, Scala, Python, and R.</li>
<li>Supports general execution graphs and in-memory computing.</li>
</ul>
</li>
<li>
<p><strong>Core Components of Spark:</strong></p>
<ul>
<li><strong>Spark Core:</strong> The foundation of the Spark platform, responsible for basic I/O functions, task scheduling, and memory management.</li>
<li><strong>Spark SQL:</strong> Module for working with structured data using SQL queries.</li>
<li><strong>Spark Streaming:</strong> Enables scalable and fault-tolerant stream processing of live data streams.</li>
<li><strong>MLlib:</strong> Machine learning library that provides various algorithms and utilities.</li>
<li><strong>GraphX:</strong> API for graph processing and analysis.</li>
</ul>
</li>
</ul>
</div><h3><ol start="2">
<li>In-Memory Computing</li>
</ol></h3>
<div class='content'><ul>
<li>
<p><strong>Definition:</strong></p>
<ul>
<li>In-memory computing refers to the storage of data in the main memory (RAM) of the computing infrastructure rather than on traditional disk storage.</li>
</ul>
</li>
<li>
<p><strong>Advantages:</strong></p>
<ul>
<li><strong>Speed:</strong> Faster data processing as data is accessed from RAM.</li>
<li><strong>Efficiency:</strong> Reduces the need for I/O operations, leading to lower latency.</li>
<li><strong>Scalability:</strong> Can handle large datasets by distributing data across multiple nodes in a cluster.</li>
</ul>
</li>
</ul>
</div><h3><ol start="3">
<li>Resilient Distributed Datasets (RDDs)</li>
</ol></h3>
<div class='content'><ul>
<li>
<p><strong>What are RDDs?</strong></p>
<ul>
<li>Immutable distributed collections of objects.</li>
<li>Can be created by loading an external dataset or by transforming an existing RDD.</li>
</ul>
</li>
<li>
<p><strong>Key Properties:</strong></p>
<ul>
<li><strong>Immutability:</strong> Once created, RDDs cannot be altered.</li>
<li><strong>Fault Tolerance:</strong> RDDs can recover from node failures using lineage information.</li>
<li><strong>Lazy Evaluation:</strong> Transformations on RDDs are not executed until an action is called.</li>
</ul>
</li>
</ul>
</div><h3><ol start="4">
<li>DataFrames and Datasets</li>
</ol></h3>
<div class='content'><ul>
<li>
<p><strong>DataFrames:</strong></p>
<ul>
<li>Distributed collections of data organized into named columns.</li>
<li>Similar to a table in a relational database or a data frame in R/Python.</li>
</ul>
</li>
<li>
<p><strong>Datasets:</strong></p>
<ul>
<li>Strongly-typed, distributed collections of data.</li>
<li>Provides the benefits of RDDs (type-safety, object-oriented programming) with the optimization benefits of DataFrames.</li>
</ul>
</li>
</ul>
</div><h2>Practical Examples</h2>
<div class='content'></div><h3>Example 1: Creating an RDD</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgSW5pdGlhbGl6ZSBTcGFya0NvbnRleHQKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsIiwgIlJERCBFeGFtcGxlIikKCiMgQ3JlYXRlIGFuIFJERCBmcm9tIGEgbGlzdApkYXRhID0gWzEsIDIsIDMsIDQsIDVdCnJkZCA9IHNjLnBhcmFsbGVsaXplKGRhdGEpCgojIFBlcmZvcm0gYSB0cmFuc2Zvcm1hdGlvbiAobWFwKSBhbmQgYW4gYWN0aW9uIChjb2xsZWN0KQpzcXVhcmVkX3JkZCA9IHJkZC5tYXAobGFtYmRhIHg6IHggKiB4KQpyZXN1bHQgPSBzcXVhcmVkX3JkZC5jb2xsZWN0KCkKCnByaW50KHJlc3VsdCkgICMgT3V0cHV0OiBbMSwgNCwgOSwgMTYsIDI1XQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Initialize SparkContext
sc = SparkContext(&quot;local&quot;, &quot;RDD Example&quot;)

# Create an RDD from a list
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Perform a transformation (map) and an action (collect)
squared_rdd = rdd.map(lambda x: x * x)
result = squared_rdd.collect()

print(result)  # Output: [1, 4, 9, 16, 25]</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>SparkContext</code> is initialized to create an RDD.</li>
<li><code>parallelize</code> method is used to create an RDD from a list.</li>
<li><code>map</code> transformation is applied to square each element.</li>
<li><code>collect</code> action is used to retrieve the results.</li>
</ul>
</div><h3>Example 2: Working with DataFrames</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaXRpYWxpemUgU3BhcmtTZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiRGF0YUZyYW1lIEV4YW1wbGUiKS5nZXRPckNyZWF0ZSgpCgojIENyZWF0ZSBhIERhdGFGcmFtZSBmcm9tIGEgbGlzdCBvZiB0dXBsZXMKZGF0YSA9IFsoIkFsaWNlIiwgMzQpLCAoIkJvYiIsIDQ1KSwgKCJDYXRoeSIsIDI5KV0KY29sdW1ucyA9IFsiTmFtZSIsICJBZ2UiXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBjb2x1bW5zKQoKIyBTaG93IHRoZSBEYXRhRnJhbWUKZGYuc2hvdygpCgojIFBlcmZvcm0gYSBTUUwgcXVlcnkKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnJlc3VsdCA9IHNwYXJrLnNxbCgiU0VMRUNUIE5hbWUsIEFnZSBGUk9NIHBlb3BsZSBXSEVSRSBBZ2UgPiAzMCIpCnJlc3VsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Initialize SparkSession
spark = SparkSession.builder.appName(&quot;DataFrame Example&quot;).getOrCreate()

# Create a DataFrame from a list of tuples
data = [(&quot;Alice&quot;, 34), (&quot;Bob&quot;, 45), (&quot;Cathy&quot;, 29)]
columns = [&quot;Name&quot;, &quot;Age&quot;]
df = spark.createDataFrame(data, columns)

# Show the DataFrame
df.show()

# Perform a SQL query
df.createOrReplaceTempView(&quot;people&quot;)
result = spark.sql(&quot;SELECT Name, Age FROM people WHERE Age &gt; 30&quot;)
result.show()</pre></div><div class='content'><p><strong>Explanation:</strong></p>
<ul>
<li><code>SparkSession</code> is initialized to create a DataFrame.</li>
<li>A DataFrame is created from a list of tuples with specified column names.</li>
<li><code>show</code> method displays the DataFrame.</li>
<li>A SQL query is executed on the DataFrame using <code>createOrReplaceTempView</code> and <code>sql</code> methods.</li>
</ul>
</div><h2>Practical Exercises</h2>
<div class='content'></div><h3>Exercise 1: Basic RDD Operations</h3>
<div class='content'><p>Create an RDD from a list of numbers and perform the following operations:</p>
<ol>
<li>Filter out even numbers.</li>
<li>Multiply each remaining number by 10.</li>
<li>Collect and print the results.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJFeGVyY2lzZSAxIikKCmRhdGEgPSBbMSwgMiwgMywgNCwgNSwgNiwgNywgOCwgOSwgMTBdCnJkZCA9IHNjLnBhcmFsbGVsaXplKGRhdGEpCgpmaWx0ZXJlZF9yZGQgPSByZGQuZmlsdGVyKGxhbWJkYSB4OiB4ICUgMiAhPSAwKQptdWx0aXBsaWVkX3JkZCA9IGZpbHRlcmVkX3JkZC5tYXAobGFtYmRhIHg6IHggKiAxMCkKcmVzdWx0ID0gbXVsdGlwbGllZF9yZGQuY29sbGVjdCgpCgpwcmludChyZXN1bHQpICAjIE91dHB1dDogWzEwLCAzMCwgNTAsIDcwLCA5MF0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

sc = SparkContext(&quot;local&quot;, &quot;Exercise 1&quot;)

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
rdd = sc.parallelize(data)

filtered_rdd = rdd.filter(lambda x: x % 2 != 0)
multiplied_rdd = filtered_rdd.map(lambda x: x * 10)
result = multiplied_rdd.collect()

print(result)  # Output: [10, 30, 50, 70, 90]</pre></div><div class='content'></div><h3>Exercise 2: DataFrame Operations</h3>
<div class='content'><p>Create a DataFrame from a list of dictionaries containing employee data (name, age, department). Perform the following operations:</p>
<ol>
<li>Filter employees older than 30.</li>
<li>Select only the name and department columns.</li>
<li>Show the results.</li>
</ol>
<p><strong>Solution:</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIkV4ZXJjaXNlIDIiKS5nZXRPckNyZWF0ZSgpCgpkYXRhID0gWwogICAgeyJuYW1lIjogIkFsaWNlIiwgImFnZSI6IDM0LCAiZGVwYXJ0bWVudCI6ICJIUiJ9LAogICAgeyJuYW1lIjogIkJvYiIsICJhZ2UiOiA0NSwgImRlcGFydG1lbnQiOiAiRW5naW5lZXJpbmcifSwKICAgIHsibmFtZSI6ICJDYXRoeSIsICJhZ2UiOiAyOSwgImRlcGFydG1lbnQiOiAiTWFya2V0aW5nIn0KXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhKQoKZmlsdGVyZWRfZGYgPSBkZi5maWx0ZXIoZGYuYWdlID4gMzApCnNlbGVjdGVkX2RmID0gZmlsdGVyZWRfZGYuc2VsZWN0KCJuYW1lIiwgImRlcGFydG1lbnQiKQpzZWxlY3RlZF9kZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Exercise 2&quot;).getOrCreate()

data = [
    {&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 34, &quot;department&quot;: &quot;HR&quot;},
    {&quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 45, &quot;department&quot;: &quot;Engineering&quot;},
    {&quot;name&quot;: &quot;Cathy&quot;, &quot;age&quot;: 29, &quot;department&quot;: &quot;Marketing&quot;}
]
df = spark.createDataFrame(data)

filtered_df = df.filter(df.age &gt; 30)
selected_df = filtered_df.select(&quot;name&quot;, &quot;department&quot;)
selected_df.show()</pre></div><div class='content'></div><h2>Common Mistakes and Tips</h2>
<div class='content'><ul>
<li><strong>Lazy Evaluation:</strong> Remember that transformations in Spark are lazily evaluated. Actions trigger the execution of transformations.</li>
<li><strong>Memory Management:</strong> Be mindful of the memory usage when working with large datasets. Use appropriate partitioning and caching strategies.</li>
<li><strong>DataFrame vs. RDD:</strong> Use DataFrames and Datasets for most applications due to their optimization benefits. Use RDDs when you need low-level transformations and actions.</li>
</ul>
</div><h2>Conclusion</h2>
<div class='content'><p>In this section, we explored the basics of Apache Spark and in-memory computing. We covered key concepts such as RDDs, DataFrames, and Datasets, and provided practical examples and exercises to reinforce the learning. Understanding these concepts is crucial for efficiently processing large-scale data in a distributed environment. In the next section, we will delve into data stream processing, which is another critical aspect of distributed computing.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce and Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-stream-processing' title="Data Stream Processing" class="py-2 px-3 btn btn-primary"
				data-read-mod="arquitecturas_distribuidas" data-read-unit="5-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-stream-processing' title="Data Stream Processing" class="py-2 px-3 btn btn-primary" 
				data-read-mod="arquitecturas_distribuidas" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Distributed Architectures Course</h1>
<h2>Module 1: Introduction to Distributed Systems</h2>
<ul>
<li><a href="01-01-basic-concepts">Basic Concepts of Distributed Systems</a></li>
<li><a href="01-02-system-models">Models of Distributed Systems</a></li>
<li><a href="01-03-advantages-challenges">Advantages and Challenges of Distributed Systems</a></li>
</ul>
<h2>Module 2: Communication in Distributed Systems</h2>
<ul>
<li><a href="02-01-communication-protocols">Communication Protocols</a></li>
<li><a href="02-02-rpc-rmi">RPC and RMI</a></li>
<li><a href="02-03-messaging-queues">Messaging and Message Queues</a></li>
</ul>
<h2>Module 3: Consistency and Replication</h2>
<ul>
<li><a href="03-01-consistency-models">Consistency Models</a></li>
<li><a href="03-02-consensus-algorithms">Consensus Algorithms</a></li>
<li><a href="03-03-data-replication">Data Replication</a></li>
</ul>
<h2>Module 4: Distributed Storage</h2>
<ul>
<li><a href="04-01-file-systems">Distributed File Systems</a></li>
<li><a href="04-02-databases">Distributed Databases</a></li>
<li><a href="04-03-caches">Distributed Caches</a></li>
</ul>
<h2>Module 5: Distributed Computing</h2>
<ul>
<li><a href="05-01-mapreduce-hadoop">MapReduce and Hadoop</a></li>
<li><a href="05-02-spark-computing">Spark and In-Memory Computing</a></li>
<li><a href="05-03-stream-processing">Data Stream Processing</a></li>
</ul>
<h2>Module 6: Security in Distributed Systems</h2>
<ul>
<li><a href="06-01-authentication-authorization">Authentication and Authorization</a></li>
<li><a href="06-02-encryption-protection">Encryption and Data Protection</a></li>
<li><a href="06-03-identity-management">Identity Management</a></li>
</ul>
<h2>Module 7: Monitoring and Maintenance</h2>
<ul>
<li><a href="07-01-system-monitoring">Monitoring Distributed Systems</a></li>
<li><a href="07-02-fault-management">Fault Management and Recovery</a></li>
<li><a href="07-03-automation-orchestration">Automation and Orchestration</a></li>
</ul>
<h2>Module 8: Case Studies and Applications</h2>
<ul>
<li><a href="08-01-microservices-architectures">Microservices Architectures</a></li>
<li><a href="08-02-messaging-systems">Real-Time Messaging Systems</a></li>
<li><a href="08-03-cloud-applications">Cloud Applications</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
