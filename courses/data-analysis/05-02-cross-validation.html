<!DOCTYPE html>
<html lang="en">
<head>
    <title> Cross-Validation and Validation Techniques </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/analisis-datos/05-02-validacion-cruzada" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/analisi-dades/05-02-validacio-creuada" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/data-analysis/05-02-cross-validation" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "en";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "analisis_datos";
  		var TEMA_NAME = "5-2";
  		var TYPE = "mod";
  		var PATH = "mod/analisis_datos/05-02-cross-validation";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo-header_enterprise.png" alt="Logo Enterprise Campus"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<b id="lit_lang_es" class="px-2">EN</b>
	|
	<a href="https://campusempresa.com/cursos/analisis-datos/05-02-validacion-cruzada" class="px-2">ES</a></b>
	|
	<a href="https://campusempresa.cat/cursos/analisi-dades/05-02-validacio-creuada" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>All the knowledge within your reach</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my-courses" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>My courses</b></i>
</a>
<a href="/completed-courses" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Completed             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="analisis_datos">
		<a  href="#" class="text-secondary d-none" data-read-mod="analisis_datos" data-read-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Mark as read
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="analisis_datos" data-unread-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Mark as unread
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Course Content
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-evaluation-metrics' title="Model Evaluation Metrics" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-evaluation-metrics' title="Model Evaluation Metrics" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Cross-Validation and Validation Techniques</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-tuning-optimization' title="Model Tuning and Optimization" class="py-2 px-3 btn btn-primary"
				data-read-mod="analisis_datos" data-read-unit="5-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-tuning-optimization' title="Model Tuning and Optimization" class="py-2 px-3 btn btn-primary" 
				data-read-mod="analisis_datos" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>Cross-validation is a crucial technique in data analysis and machine learning used to assess the performance of a model. It helps in understanding how the results of a statistical analysis will generalize to an independent data set. This section will cover the basics of cross-validation, different cross-validation techniques, and practical examples to solidify your understanding.</p>
</div><h2>Key Concepts of Cross-Validation</h2>
<div class='content'><ol>
<li>
<p><strong>Overfitting and Underfitting</strong>:</p>
<ul>
<li><strong>Overfitting</strong>: When a model learns the training data too well, including noise and outliers, leading to poor performance on unseen data.</li>
<li><strong>Underfitting</strong>: When a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and unseen data.</li>
</ul>
</li>
<li>
<p><strong>Training and Testing Data</strong>:</p>
<ul>
<li><strong>Training Data</strong>: The subset of data used to train the model.</li>
<li><strong>Testing Data</strong>: The subset of data used to evaluate the model's performance.</li>
</ul>
</li>
<li>
<p><strong>Validation Data</strong>:</p>
<ul>
<li>A separate subset of data used to tune the model's hyperparameters and prevent overfitting.</li>
</ul>
</li>
</ol>
</div><h2>Types of Cross-Validation Techniques</h2>
<div class='content'></div><h3><ol>
<li>Holdout Method</li>
</ol></h3>
<div class='content'><ul>
<li><strong>Description</strong>: The dataset is split into two parts: a training set and a testing set.</li>
<li><strong>Advantages</strong>: Simple and quick to implement.</li>
<li><strong>Disadvantages</strong>: Performance can vary significantly depending on how the data is split.</li>
</ul>
</div><h3><ol start="2">
<li>K-Fold Cross-Validation</li>
</ol></h3>
<div class='content'><ul>
<li><strong>Description</strong>: The dataset is divided into <code>k</code> equally sized folds. The model is trained <code>k</code> times, each time using a different fold as the testing set and the remaining <code>k-1</code> folds as the training set.</li>
<li><strong>Advantages</strong>: Provides a more reliable estimate of model performance.</li>
<li><strong>Disadvantages</strong>: Computationally expensive for large datasets.</li>
</ul>
</div><h3><ol start="3">
<li>Stratified K-Fold Cross-Validation</li>
</ol></h3>
<div class='content'><ul>
<li><strong>Description</strong>: Similar to K-Fold Cross-Validation, but ensures that each fold has the same proportion of classes as the original dataset.</li>
<li><strong>Advantages</strong>: Better for imbalanced datasets.</li>
<li><strong>Disadvantages</strong>: Slightly more complex to implement.</li>
</ul>
</div><h3><ol start="4">
<li>Leave-One-Out Cross-Validation (LOOCV)</li>
</ol></h3>
<div class='content'><ul>
<li><strong>Description</strong>: Each data point is used as a single test case, and the model is trained on the remaining data points.</li>
<li><strong>Advantages</strong>: Uses all data points for training and testing.</li>
<li><strong>Disadvantages</strong>: Extremely computationally expensive.</li>
</ul>
</div><h3><ol start="5">
<li>Time Series Cross-Validation</li>
</ol></h3>
<div class='content'><ul>
<li><strong>Description</strong>: Specifically for time series data, where the training set is incrementally increased with each fold.</li>
<li><strong>Advantages</strong>: Maintains the temporal order of data.</li>
<li><strong>Disadvantages</strong>: May not be suitable for non-time series data.</li>
</ul>
</div><h2>Practical Example: K-Fold Cross-Validation</h2>
<div class='content'><p>Let's implement K-Fold Cross-Validation using Python and the <code>scikit-learn</code> library.</p>
</div><h3>Step-by-Step Implementation</h3>
<div class='content'><ol>
<li>
<p><strong>Import Necessary Libraries</strong>:</p>
<pre><code class="language-python">import numpy as np
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
</code></pre>
</li>
<li>
<p><strong>Generate Sample Data</strong>:</p>
<pre><code class="language-python"># Generating synthetic data
X = np.random.rand(100, 1) * 10  # 100 data points, single feature
y = 2.5 * X.squeeze() + np.random.randn(100) * 2  # Linear relationship with noise
</code></pre>
</li>
<li>
<p><strong>Initialize K-Fold Cross-Validation</strong>:</p>
<pre><code class="language-python">kf = KFold(n_splits=5, shuffle=True, random_state=42)
</code></pre>
</li>
<li>
<p><strong>Perform Cross-Validation</strong>:</p>
<pre><code class="language-python">model = LinearRegression()
mse_scores = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    mse_scores.append(mse)

print(f'Mean Squared Error for each fold: {mse_scores}')
print(f'Average Mean Squared Error: {np.mean(mse_scores)}')
</code></pre>
</li>
</ol>
</div><h3>Explanation of the Code</h3>
<div class='content'><ul>
<li><strong>Data Generation</strong>: We create synthetic data with a linear relationship.</li>
<li><strong>K-Fold Initialization</strong>: We initialize K-Fold with 5 splits, shuffling the data and setting a random state for reproducibility.</li>
<li><strong>Model Training and Evaluation</strong>: For each fold, we split the data into training and testing sets, train the model, make predictions, and compute the Mean Squared Error (MSE). Finally, we print the MSE for each fold and the average MSE.</li>
</ul>
</div><h2>Exercises</h2>
<div class='content'></div><h3>Exercise 1: Implement Stratified K-Fold Cross-Validation</h3>
<div class='content'><p><strong>Task</strong>: Implement Stratified K-Fold Cross-Validation on a classification dataset using <code>scikit-learn</code>.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgU3RyYXRpZmllZEtGb2xkCmZyb20gc2tsZWFybi5kYXRhc2V0cyBpbXBvcnQgbG9hZF9pcmlzCmZyb20gc2tsZWFybi5lbnNlbWJsZSBpbXBvcnQgUmFuZG9tRm9yZXN0Q2xhc3NpZmllcgpmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgYWNjdXJhY3lfc2NvcmUKCiMgTG9hZCBkYXRhc2V0CmRhdGEgPSBsb2FkX2lyaXMoKQpYLCB5ID0gZGF0YS5kYXRhLCBkYXRhLnRhcmdldAoKIyBJbml0aWFsaXplIFN0cmF0aWZpZWQgSy1Gb2xkCnNrZiA9IFN0cmF0aWZpZWRLRm9sZChuX3NwbGl0cz01LCBzaHVmZmxlPVRydWUsIHJhbmRvbV9zdGF0ZT00MikKCm1vZGVsID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpCmFjY3VyYWN5X3Njb3JlcyA9IFtdCgpmb3IgdHJhaW5faW5kZXgsIHRlc3RfaW5kZXggaW4gc2tmLnNwbGl0KFgsIHkpOgogICAgWF90cmFpbiwgWF90ZXN0ID0gWFt0cmFpbl9pbmRleF0sIFhbdGVzdF9pbmRleF0KICAgIHlfdHJhaW4sIHlfdGVzdCA9IHlbdHJhaW5faW5kZXhdLCB5W3Rlc3RfaW5kZXhdCgogICAgbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCiAgICB5X3ByZWQgPSBtb2RlbC5wcmVkaWN0KFhfdGVzdCkKICAgIGFjY3VyYWN5ID0gYWNjdXJhY3lfc2NvcmUoeV90ZXN0LCB5X3ByZWQpCiAgICBhY2N1cmFjeV9zY29yZXMuYXBwZW5kKGFjY3VyYWN5KQoKcHJpbnQoZidBY2N1cmFjeSBmb3IgZWFjaCBmb2xkOiB7YWNjdXJhY3lfc2NvcmVzfScpCnByaW50KGYnQXZlcmFnZSBBY2N1cmFjeToge25wLm1lYW4oYWNjdXJhY3lfc2NvcmVzKX0nKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import StratifiedKFold
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Load dataset
data = load_iris()
X, y = data.data, data.target

# Initialize Stratified K-Fold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

model = RandomForestClassifier()
accuracy_scores = []

for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracy_scores.append(accuracy)

print(f'Accuracy for each fold: {accuracy_scores}')
print(f'Average Accuracy: {np.mean(accuracy_scores)}')</pre></div><div class='content'></div><h3>Exercise 2: Implement Leave-One-Out Cross-Validation</h3>
<div class='content'><p><strong>Task</strong>: Implement Leave-One-Out Cross-Validation on a regression dataset using <code>scikit-learn</code>.</p>
<p><strong>Solution</strong>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgTGVhdmVPbmVPdXQKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgpmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgbWVhbl9zcXVhcmVkX2Vycm9yCgojIEdlbmVyYXRlIHN5bnRoZXRpYyBkYXRhClggPSBucC5yYW5kb20ucmFuZCg1MCwgMSkgKiAxMCAgIyA1MCBkYXRhIHBvaW50cywgc2luZ2xlIGZlYXR1cmUKeSA9IDMuNSAqIFguc3F1ZWV6ZSgpICsgbnAucmFuZG9tLnJhbmRuKDUwKSAqIDEuNSAgIyBMaW5lYXIgcmVsYXRpb25zaGlwIHdpdGggbm9pc2UKCiMgSW5pdGlhbGl6ZSBMZWF2ZS1PbmUtT3V0IENyb3NzLVZhbGlkYXRpb24KbG9vID0gTGVhdmVPbmVPdXQoKQoKbW9kZWwgPSBMaW5lYXJSZWdyZXNzaW9uKCkKbXNlX3Njb3JlcyA9IFtdCgpmb3IgdHJhaW5faW5kZXgsIHRlc3RfaW5kZXggaW4gbG9vLnNwbGl0KFgpOgogICAgWF90cmFpbiwgWF90ZXN0ID0gWFt0cmFpbl9pbmRleF0sIFhbdGVzdF9pbmRleF0KICAgIHlfdHJhaW4sIHlfdGVzdCA9IHlbdHJhaW5faW5kZXhdLCB5W3Rlc3RfaW5kZXhdCgogICAgbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCiAgICB5X3ByZWQgPSBtb2RlbC5wcmVkaWN0KFhfdGVzdCkKICAgIG1zZSA9IG1lYW5fc3F1YXJlZF9lcnJvcih5X3Rlc3QsIHlfcHJlZCkKICAgIG1zZV9zY29yZXMuYXBwZW5kKG1zZSkKCnByaW50KGYnTWVhbiBTcXVhcmVkIEVycm9yIGZvciBlYWNoIGZvbGQ6IHttc2Vfc2NvcmVzfScpCnByaW50KGYnQXZlcmFnZSBNZWFuIFNxdWFyZWQgRXJyb3I6IHtucC5tZWFuKG1zZV9zY29yZXMpfScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import LeaveOneOut
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate synthetic data
X = np.random.rand(50, 1) * 10  # 50 data points, single feature
y = 3.5 * X.squeeze() + np.random.randn(50) * 1.5  # Linear relationship with noise

# Initialize Leave-One-Out Cross-Validation
loo = LeaveOneOut()

model = LinearRegression()
mse_scores = []

for train_index, test_index in loo.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    mse_scores.append(mse)

print(f'Mean Squared Error for each fold: {mse_scores}')
print(f'Average Mean Squared Error: {np.mean(mse_scores)}')</pre></div><div class='content'></div><h2>Common Mistakes and Tips</h2>
<div class='content'><ol>
<li><strong>Not Shuffling Data</strong>: Always shuffle your data before splitting to ensure that each fold is representative of the whole dataset.</li>
<li><strong>Ignoring Class Imbalance</strong>: Use Stratified K-Fold for imbalanced datasets to maintain the proportion of classes in each fold.</li>
<li><strong>Computational Cost</strong>: Be mindful of the computational cost, especially with LOOCV, as it can be very expensive for large datasets.</li>
</ol>
</div><h2>Conclusion</h2>
<div class='content'><p>Cross-validation is an essential technique for evaluating the performance of your models and ensuring they generalize well to unseen data. By understanding and implementing different cross-validation techniques, you can improve the robustness and reliability of your data analysis and machine learning models. In the next section, we will delve into model tuning and optimization to further enhance model performance.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-evaluation-metrics' title="Model Evaluation Metrics" class="py-2 px-3 btn btn-primary">
				&#x25C4; Previous 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-evaluation-metrics' title="Model Evaluation Metrics" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-tuning-optimization' title="Model Tuning and Optimization" class="py-2 px-3 btn btn-primary"
				data-read-mod="analisis_datos" data-read-unit="5-2">
				Next &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-tuning-optimization' title="Model Tuning and Optimization" class="py-2 px-3 btn btn-primary" 
				data-read-mod="analisis_datos" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Data Analysis Course</h1>
<h2>Module 1: Introduction to Data Analysis</h2>
<ul>
<li><a href="01-01-basic-concepts">Basic Concepts of Data Analysis</a></li>
<li><a href="01-02-importance">Importance of Data Analysis in Decision Making</a></li>
<li><a href="01-03-tools-software">Commonly Used Tools and Software</a></li>
</ul>
<h2>Module 2: Data Collection and Preparation</h2>
<ul>
<li><a href="02-01-sources-methods">Data Sources and Collection Methods</a></li>
<li><a href="02-02-data-cleaning">Data Cleaning: Identification and Handling of Missing Data</a></li>
<li><a href="02-03-transformation-normalization">Data Transformation and Normalization</a></li>
</ul>
<h2>Module 3: Data Exploration</h2>
<ul>
<li><a href="03-01-eda">Exploratory Data Analysis (EDA)</a></li>
<li><a href="03-02-visualization">Data Visualization: Graphs and Tables</a></li>
<li><a href="03-03-patterns-trends">Pattern and Trend Detection</a></li>
</ul>
<h2>Module 4: Data Modeling</h2>
<ul>
<li><a href="04-01-statistical-models">Introduction to Statistical Models</a></li>
<li><a href="04-02-regression">Linear and Logistic Regression</a></li>
<li><a href="04-03-trees-forests">Decision Trees and Random Forests</a></li>
</ul>
<h2>Module 5: Model Evaluation and Validation</h2>
<ul>
<li><a href="05-01-evaluation-metrics">Model Evaluation Metrics</a></li>
<li><a href="05-02-cross-validation">Cross-Validation and Validation Techniques</a></li>
<li><a href="05-03-tuning-optimization">Model Tuning and Optimization</a></li>
</ul>
<h2>Module 6: Implementation and Communication of Results</h2>
<ul>
<li><a href="06-01-implementation-production">Model Implementation in Production</a></li>
<li><a href="06-02-communication-results">Communication of Results to Stakeholders</a></li>
<li><a href="06-03-documentation-reports">Documentation and Reports</a></li>
</ul>
<h2>Module 7: Practical Cases and Projects</h2>
<ul>
<li><a href="07-01-case-sales">Case Study 1: Sales Data Analysis</a></li>
<li><a href="07-02-case-marketing">Case Study 2: Marketing Data Analysis</a></li>
<li><a href="07-03-final-project">Final Project: Complete Analysis of a Data Set</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective" rel="nofollow">The Project</a> | 
<a href="/about" rel="nofollow">About Us</a> | 
<a href="/contribute" rel="nofollow">Contribute</a> | 
<a href="/donate" rel="nofollow">Donations</a> | 
<a href="/license" rel="nofollow">License</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	We use cookies to improve your user experience and offer content tailored to your interests.
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">User not authenticated</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
