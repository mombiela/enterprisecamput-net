<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dataproc on Google Cloud Platform (GCP)</title>

    <link rel="alternate" href="https://campusempresa.com/gcp/dataproc" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/gcp/dataproc" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/gcp/dataproc" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/gcp/dataproc" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/gcp/dataproc" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='dataflow'>&#x25C4;Dataflow</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Dataproc on Google Cloud Platform (GCP)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='ai-platform'>AI Platform &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to Dataproc</h1>
<div class='content'><p>Google Cloud Dataproc is a fast, easy-to-use, fully managed cloud service for running Apache Spark and Apache Hadoop clusters. It allows you to process large datasets quickly and efficiently.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Cluster</strong>: A collection of virtual machines (VMs) that run Hadoop and Spark jobs.</li>
<li><strong>Job</strong>: A unit of work that you submit to a Dataproc cluster.</li>
<li><strong>Workflow</strong>: A sequence of jobs that can be executed in a specific order.</li>
<li><strong>Autoscaling</strong>: Automatically adjusting the number of worker nodes in a cluster based on the workload.</li>
</ul>
</div><h1>Setting Up Dataproc</h1>
<h2>Creating a Dataproc Cluster</h2>
<div class='content'><p>To create a Dataproc cluster, follow these steps:</p>
<ol>
<li>
<p><strong>Navigate to the Dataproc section in the GCP Console</strong>.</p>
</li>
<li>
<p><strong>Click on &quot;Create Cluster&quot;</strong>.</p>
</li>
<li>
<p><strong>Configure the cluster</strong>:</p>
<ul>
<li><strong>Cluster Name</strong>: Give your cluster a unique name.</li>
<li><strong>Region and Zone</strong>: Select the appropriate region and zone.</li>
<li><strong>Cluster Mode</strong>: Choose between Standard, Single Node, or High Availability.</li>
<li><strong>Node Configuration</strong>: Specify the number and type of master and worker nodes.</li>
<li><strong>Optional Components</strong>: Add optional components like Jupyter, Zeppelin, etc.</li>
</ul>
</li>
<li>
<p><strong>Click &quot;Create&quot;</strong> to launch the cluster.</p>
</li>
</ol>
</div><h2>Example: Creating a Cluster Using gcloud Command</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Z2Nsb3VkIGRhdGFwcm9jIGNsdXN0ZXJzIGNyZWF0ZSBteS1jbHVzdGVyIFwKICAgIC0tcmVnaW9uPXVzLWNlbnRyYWwxIFwKICAgIC0tem9uZT11cy1jZW50cmFsMS1hIFwKICAgIC0tbWFzdGVyLW1hY2hpbmUtdHlwZT1uMS1zdGFuZGFyZC0yIFwKICAgIC0td29ya2VyLW1hY2hpbmUtdHlwZT1uMS1zdGFuZGFyZC0yIFwKICAgIC0tbnVtLXdvcmtlcnM9Mg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>gcloud dataproc clusters create my-cluster \
    --region=us-central1 \
    --zone=us-central1-a \
    --master-machine-type=n1-standard-2 \
    --worker-machine-type=n1-standard-2 \
    --num-workers=2</pre></div><div class='content'><p>This command creates a Dataproc cluster named <code>my-cluster</code> with 1 master node and 2 worker nodes in the <code>us-central1-a</code> zone.</p>
</div><h1>Running Jobs on Dataproc</h1>
<h2>Submitting a Job</h2>
<div class='content'><p>You can submit jobs to a Dataproc cluster using the GCP Console, the <code>gcloud</code> command-line tool, or the Dataproc API.</p>
<h4>Example: Submitting a Spark Job Using gcloud Command</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Z2Nsb3VkIGRhdGFwcm9jIGpvYnMgc3VibWl0IHNwYXJrIFwKICAgIC0tY2x1c3Rlcj1teS1jbHVzdGVyIFwKICAgIC0tcmVnaW9uPXVzLWNlbnRyYWwxIFwKICAgIC0tY2xhc3M9b3JnLmFwYWNoZS5zcGFyay5leGFtcGxlcy5TcGFya1BpIFwKICAgIC0tamFycz1maWxlOi8vL3Vzci9saWIvc3BhcmsvZXhhbXBsZXMvamFycy9zcGFyay1leGFtcGxlcy5qYXIgXAogICAgLS0gMTAwMA=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>gcloud dataproc jobs submit spark \
    --cluster=my-cluster \
    --region=us-central1 \
    --class=org.apache.spark.examples.SparkPi \
    --jars=file:///usr/lib/spark/examples/jars/spark-examples.jar \
    -- 1000</pre></div><div class='content'><p>This command submits a Spark job to calculate Pi using the <code>SparkPi</code> example.</p>
</div><h2>Monitoring Jobs</h2>
<div class='content'><p>You can monitor the status of your jobs in the GCP Console under the Dataproc section. The console provides detailed logs and metrics for each job.</p>
</div><h1>Advanced Dataproc Features</h1>
<h2>Autoscaling Clusters</h2>
<div class='content'><p>Autoscaling allows your cluster to automatically adjust the number of worker nodes based on the workload.</p>
<h4>Example: Enabling Autoscaling</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Z2Nsb3VkIGRhdGFwcm9jIGNsdXN0ZXJzIHVwZGF0ZSBteS1jbHVzdGVyIFwKICAgIC0tcmVnaW9uPXVzLWNlbnRyYWwxIFwKICAgIC0tYXV0b3NjYWxpbmctcG9saWN5PWJhc2ljLWF1dG9zY2FsaW5nLXBvbGljeQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>gcloud dataproc clusters update my-cluster \
    --region=us-central1 \
    --autoscaling-policy=basic-autoscaling-policy</pre></div><div class='content'><p>This command updates the cluster <code>my-cluster</code> to use the <code>basic-autoscaling-policy</code>.</p>
</div><h2>Using Dataproc Workflows</h2>
<div class='content'><p>Dataproc Workflows allow you to define a sequence of jobs that can be executed in a specific order.</p>
<h4>Example: Creating a Workflow Template</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Z2Nsb3VkIGRhdGFwcm9jIHdvcmtmbG93LXRlbXBsYXRlcyBjcmVhdGUgbXktd29ya2Zsb3ctdGVtcGxhdGUgXAogICAgLS1yZWdpb249dXMtY2VudHJhbDEKCmdjbG91ZCBkYXRhcHJvYyB3b3JrZmxvdy10ZW1wbGF0ZXMgc2V0LW1hbmFnZWQtY2x1c3RlciBteS13b3JrZmxvdy10ZW1wbGF0ZSBcCiAgICAtLXJlZ2lvbj11cy1jZW50cmFsMSBcCiAgICAtLWNsdXN0ZXItbmFtZT1teS1jbHVzdGVyIFwKICAgIC0tem9uZT11cy1jZW50cmFsMS1hIFwKICAgIC0tbWFzdGVyLW1hY2hpbmUtdHlwZT1uMS1zdGFuZGFyZC0yIFwKICAgIC0td29ya2VyLW1hY2hpbmUtdHlwZT1uMS1zdGFuZGFyZC0yIFwKICAgIC0tbnVtLXdvcmtlcnM9MgoKZ2Nsb3VkIGRhdGFwcm9jIHdvcmtmbG93LXRlbXBsYXRlcyBhZGQtam9iIHNwYXJrIFwKICAgIC0tc3RlcC1pZD1zcGFyay1qb2IgXAogICAgLS1jbGFzcz1vcmcuYXBhY2hlLnNwYXJrLmV4YW1wbGVzLlNwYXJrUGkgXAogICAgLS1qYXJzPWZpbGU6Ly8vdXNyL2xpYi9zcGFyay9leGFtcGxlcy9qYXJzL3NwYXJrLWV4YW1wbGVzLmphciBcCiAgICAtLXdvcmtmbG93LXRlbXBsYXRlPW15LXdvcmtmbG93LXRlbXBsYXRlIFwKICAgIC0tcmVnaW9uPXVzLWNlbnRyYWwxIFwKICAgIC0tIDEwMDAKCmdjbG91ZCBkYXRhcHJvYyB3b3JrZmxvdy10ZW1wbGF0ZXMgaW5zdGFudGlhdGUgbXktd29ya2Zsb3ctdGVtcGxhdGUgXAogICAgLS1yZWdpb249dXMtY2VudHJhbDE="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>gcloud dataproc workflow-templates create my-workflow-template \
    --region=us-central1

gcloud dataproc workflow-templates set-managed-cluster my-workflow-template \
    --region=us-central1 \
    --cluster-name=my-cluster \
    --zone=us-central1-a \
    --master-machine-type=n1-standard-2 \
    --worker-machine-type=n1-standard-2 \
    --num-workers=2

gcloud dataproc workflow-templates add-job spark \
    --step-id=spark-job \
    --class=org.apache.spark.examples.SparkPi \
    --jars=file:///usr/lib/spark/examples/jars/spark-examples.jar \
    --workflow-template=my-workflow-template \
    --region=us-central1 \
    -- 1000

gcloud dataproc workflow-templates instantiate my-workflow-template \
    --region=us-central1</pre></div><div class='content'><p>This sequence of commands creates a workflow template, adds a Spark job to it, and then instantiates the workflow.</p>
</div><h1>Conclusion</h1>
<div class='content'><p>Google Cloud Dataproc is a powerful tool for managing Hadoop and Spark clusters in the cloud. It simplifies the process of setting up, managing, and scaling clusters, allowing you to focus on processing your data. By understanding the basics of creating clusters, submitting jobs, and utilizing advanced features like autoscaling and workflows, you can effectively leverage Dataproc for your big data needs.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='dataflow'>&#x25C4;Dataflow</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Dataproc on Google Cloud Platform (GCP)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='ai-platform'>AI Platform &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
