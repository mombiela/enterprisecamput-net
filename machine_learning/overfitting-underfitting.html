<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Overfitting and Underfitting</title>

    <link rel="alternate" href="https://campusempresa.com/machine_learning/overfitting-underfitting" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/machine_learning/overfitting-underfitting" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/machine_learning/overfitting-underfitting" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/machine_learning/overfitting-underfitting" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/machine_learning/overfitting-underfitting" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introduction</h1>
<div class='content'><p>In Machine Learning, one of the most common challenges is finding the right balance between fitting the model to the training data and its ability to generalize to unseen data. This balance is affected by two main problems: overfitting and underfitting.</p>
</div><h1>Definitions</h1>
<div class='content'></div><h2>Overfitting</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Occurs when a model fits the training data too well, capturing both general trends and noise and anomalies. This results in excellent performance on the training set but poor performance on the test set or new data.</li>
<li><strong>Symptoms</strong>:
<ul>
<li>High accuracy on the training set.</li>
<li>Low accuracy on the test set.</li>
</ul>
</li>
<li><strong>Common causes</strong>:
<ul>
<li>Model too complex (many parameters).</li>
<li>Too many training iterations.</li>
<li>Training data with noise or anomalies.</li>
</ul>
</li>
</ul>
</div><h2>Underfitting</h2>
<div class='content'><ul>
<li><strong>Definition</strong>: Occurs when a model is too simple to capture the underlying trends in the training data. This results in poor performance on both the training set and the test set.</li>
<li><strong>Symptoms</strong>:
<ul>
<li>Low accuracy on the training set.</li>
<li>Low accuracy on the test set.</li>
</ul>
</li>
<li><strong>Common causes</strong>:
<ul>
<li>Model too simple (few parameters).</li>
<li>Insufficient training time.</li>
<li>Insufficient or unrepresentative training data.</li>
</ul>
</li>
</ul>
</div><h1>Code Examples</h1>
<div class='content'></div><h2>Overfitting</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ucHJlcHJvY2Vzc2luZyBpbXBvcnQgUG9seW5vbWlhbEZlYXR1cmVzCmZyb20gc2tsZWFybi5saW5lYXJfbW9kZWwgaW1wb3J0IExpbmVhclJlZ3Jlc3Npb24KZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IG1lYW5fc3F1YXJlZF9lcnJvcgoKIyBHZW5lcmF0ZSBleGFtcGxlIGRhdGEKbnAucmFuZG9tLnNlZWQoMCkKWCA9IG5wLnNvcnQobnAucmFuZG9tLnJhbmQoMjAsIDEpICogMTAsIGF4aXM9MCkKeSA9IG5wLnNpbihYKS5yYXZlbCgpICsgbnAucmFuZG9tLnJhbmRuKDIwKSAqIDAuNQoKIyBTcGxpdCB0aGUgZGF0YSBpbnRvIHRyYWluaW5nIGFuZCB0ZXN0IHNldHMKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjMsIHJhbmRvbV9zdGF0ZT0wKQoKIyBGaXQgYSBwb2x5bm9taWFsIG1vZGVsIG9mIGRlZ3JlZSAxNSAob3ZlcmZpdHRpbmcpCnBvbHkgPSBQb2x5bm9taWFsRmVhdHVyZXMoZGVncmVlPTE1KQpYX3BvbHlfdHJhaW4gPSBwb2x5LmZpdF90cmFuc2Zvcm0oWF90cmFpbikKWF9wb2x5X3Rlc3QgPSBwb2x5LnRyYW5zZm9ybShYX3Rlc3QpCm1vZGVsID0gTGluZWFyUmVncmVzc2lvbigpCm1vZGVsLmZpdChYX3BvbHlfdHJhaW4sIHlfdHJhaW4pCgojIFByZWRpY3Rpb25zCnlfdHJhaW5fcHJlZCA9IG1vZGVsLnByZWRpY3QoWF9wb2x5X3RyYWluKQp5X3Rlc3RfcHJlZCA9IG1vZGVsLnByZWRpY3QoWF9wb2x5X3Rlc3QpCgojIEV2YWx1YXRpb24KcHJpbnQoIlRyYWluaW5nIHNldCBlcnJvcjoiLCBtZWFuX3NxdWFyZWRfZXJyb3IoeV90cmFpbiwgeV90cmFpbl9wcmVkKSkKcHJpbnQoIlRlc3Qgc2V0IGVycm9yOiIsIG1lYW5fc3F1YXJlZF9lcnJvcih5X3Rlc3QsIHlfdGVzdF9wcmVkKSkKCiMgVmlzdWFsaXphdGlvbgpwbHQuc2NhdHRlcihYLCB5LCBjb2xvcj0nYmxhY2snLCBsYWJlbD0nRGF0YScpCnBsdC5wbG90KFgsIG1vZGVsLnByZWRpY3QocG9seS50cmFuc2Zvcm0oWCkpLCBjb2xvcj0nYmx1ZScsIGxhYmVsPSdQb2x5bm9taWFsIG1vZGVsIChkZWdyZWUgMTUpJykKcGx0LmxlZ2VuZCgpCnBsdC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate example data
np.random.seed(0)
X = np.sort(np.random.rand(20, 1) * 10, axis=0)
y = np.sin(X).ravel() + np.random.randn(20) * 0.5

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Fit a polynomial model of degree 15 (overfitting)
poly = PolynomialFeatures(degree=15)
X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly.transform(X_test)
model = LinearRegression()
model.fit(X_poly_train, y_train)

# Predictions
y_train_pred = model.predict(X_poly_train)
y_test_pred = model.predict(X_poly_test)

# Evaluation
print(&quot;Training set error:&quot;, mean_squared_error(y_train, y_train_pred))
print(&quot;Test set error:&quot;, mean_squared_error(y_test, y_test_pred))

# Visualization
plt.scatter(X, y, color='black', label='Data')
plt.plot(X, model.predict(poly.transform(X)), color='blue', label='Polynomial model (degree 15)')
plt.legend()
plt.show()</pre></div><div class='content'></div><h2>Underfitting</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGaXQgYSBzaW1wbGUgbGluZWFyIG1vZGVsICh1bmRlcmZpdHRpbmcpCm1vZGVsX3NpbXBsZSA9IExpbmVhclJlZ3Jlc3Npb24oKQptb2RlbF9zaW1wbGUuZml0KFhfdHJhaW4sIHlfdHJhaW4pCgojIFByZWRpY3Rpb25zCnlfdHJhaW5fcHJlZF9zaW1wbGUgPSBtb2RlbF9zaW1wbGUucHJlZGljdChYX3RyYWluKQp5X3Rlc3RfcHJlZF9zaW1wbGUgPSBtb2RlbF9zaW1wbGUucHJlZGljdChYX3Rlc3QpCgojIEV2YWx1YXRpb24KcHJpbnQoIlRyYWluaW5nIHNldCBlcnJvciAoc2ltcGxlIG1vZGVsKToiLCBtZWFuX3NxdWFyZWRfZXJyb3IoeV90cmFpbiwgeV90cmFpbl9wcmVkX3NpbXBsZSkpCnByaW50KCJUZXN0IHNldCBlcnJvciAoc2ltcGxlIG1vZGVsKToiLCBtZWFuX3NxdWFyZWRfZXJyb3IoeV90ZXN0LCB5X3Rlc3RfcHJlZF9zaW1wbGUpKQoKIyBWaXN1YWxpemF0aW9uCnBsdC5zY2F0dGVyKFgsIHksIGNvbG9yPSdibGFjaycsIGxhYmVsPSdEYXRhJykKcGx0LnBsb3QoWCwgbW9kZWxfc2ltcGxlLnByZWRpY3QoWCksIGNvbG9yPSdyZWQnLCBsYWJlbD0nU2ltcGxlIGxpbmVhciBtb2RlbCcpCnBsdC5sZWdlbmQoKQpwbHQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Fit a simple linear model (underfitting)
model_simple = LinearRegression()
model_simple.fit(X_train, y_train)

# Predictions
y_train_pred_simple = model_simple.predict(X_train)
y_test_pred_simple = model_simple.predict(X_test)

# Evaluation
print(&quot;Training set error (simple model):&quot;, mean_squared_error(y_train, y_train_pred_simple))
print(&quot;Test set error (simple model):&quot;, mean_squared_error(y_test, y_test_pred_simple))

# Visualization
plt.scatter(X, y, color='black', label='Data')
plt.plot(X, model_simple.predict(X), color='red', label='Simple linear model')
plt.legend()
plt.show()</pre></div><div class='content'></div><h1>Comparison</h1>
<div class='content'><p>| Feature            | Overfitting                          | Underfitting                         |
|--------------------|--------------------------------------|--------------------------------------|
| Model complexity   | High (many parameters)               | Low (few parameters)                 |
| Training performance | High                               | Low                                  |
| Test performance   | Low                                  | Low                                  |
| Main cause         | Capturing noise and anomalies        | Inability to capture underlying trend|</p>
</div><h1>How to Mitigate Overfitting and Underfitting</h1>
<div class='content'></div><h2>Techniques to Mitigate Overfitting</h2>
<div class='content'><ul>
<li><strong>Regularization</strong>: Add a penalty for model complexity (L1, L2).</li>
<li><strong>Cross-validation</strong>: Use cross-validation to evaluate model performance.</li>
<li><strong>Pruning</strong>: In the case of decision trees, prune unnecessary branches.</li>
<li><strong>Early stopping</strong>: Stop training before the model fits the training data too well.</li>
<li><strong>Increase data</strong>: Increase the size of the training dataset.</li>
</ul>
</div><h2>Techniques to Mitigate Underfitting</h2>
<div class='content'><ul>
<li><strong>Increase model complexity</strong>: Use more complex models or add more parameters.</li>
<li><strong>More features</strong>: Include more relevant features in the dataset.</li>
<li><strong>More training time</strong>: Increase the number of training iterations or epochs.</li>
<li><strong>Reduce regularization</strong>: Decrease the penalty for model complexity.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>The balance between overfitting and underfitting is crucial for the success of a Machine Learning model. Understanding the causes and symptoms of each, as well as techniques to mitigate them, is essential for developing models that generalize well to unseen data. Practicing with different models and techniques on various datasets will help improve intuition and skills to handle these challenges.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
