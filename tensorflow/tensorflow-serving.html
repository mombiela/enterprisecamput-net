<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TensorFlow Serving</title>

    <link rel="alternate" href="https://campusempresa.com/tensorflow/tensorflow-serving" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/tensorflow/tensorflow-serving" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/tensorflow/tensorflow-serving" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/tensorflow/tensorflow-serving" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/tensorflow/tensorflow-serving" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='distributed-training'>&#x25C4;Distributed Training</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">TensorFlow Serving</a>
	</div>
	<div class='col-4 text-end'>
					<a href='model-deployment'>Model Deployment &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to TensorFlow Serving</h1>
<div class='content'><p>TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. It allows you to deploy new algorithms and experiments while keeping the same server architecture and APIs.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Model Server</strong>: A server designed to serve machine learning models.</li>
<li><strong>Model Versioning</strong>: Supports multiple versions of models, enabling seamless updates.</li>
<li><strong>Batching</strong>: Combines multiple requests to improve throughput.</li>
<li><strong>Monitoring</strong>: Provides tools to monitor the health and performance of models.</li>
</ul>
</div><h1>Setting Up TensorFlow Serving</h1>
<div class='content'><p>To get started with TensorFlow Serving, you need to install it and set up your environment.</p>
</div><h2>Installation</h2>
<div class='content'><p>You can install TensorFlow Serving using Docker or directly on your system.</p>
<h4>Using Docker</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZG9ja2VyIHB1bGwgdGVuc29yZmxvdy9zZXJ2aW5n"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>docker pull tensorflow/serving</pre></div><div class='content'><h4>Direct Installation</h4>
<p>For Ubuntu:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZWNobyAiZGViIFthcmNoPWFtZDY0XSBodHRwOi8vc3RvcmFnZS5nb29nbGVhcGlzLmNvbS90ZW5zb3JmbG93LXNlcnZpbmctYXB0IHN0YWJsZSB0ZW5zb3JmbG93LW1vZGVsLXNlcnZlciB0ZW5zb3JmbG93LW1vZGVsLXNlcnZlci11bml2ZXJzYWwiIHwgc3VkbyB0ZWUgL2V0Yy9hcHQvc291cmNlcy5saXN0LmQvdGVuc29yZmxvdy1zZXJ2aW5nLmxpc3QgJiYgXApjdXJsIGh0dHBzOi8vc3RvcmFnZS5nb29nbGVhcGlzLmNvbS90ZW5zb3JmbG93LXNlcnZpbmctYXB0L3RlbnNvcmZsb3ctc2VydmluZy5yZWxlYXNlLnB1Yi5ncGcgfCBzdWRvIGFwdC1rZXkgYWRkIC0Kc3VkbyBhcHQtZ2V0IHVwZGF0ZSAmJiBzdWRvIGFwdC1nZXQgaW5zdGFsbCB0ZW5zb3JmbG93LW1vZGVsLXNlcnZlcg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>echo &quot;deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal&quot; | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list &amp;&amp; \
curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -
sudo apt-get update &amp;&amp; sudo apt-get install tensorflow-model-server</pre></div><div class='content'></div><h1>Serving a TensorFlow Model</h1>
<div class='content'><p>Once TensorFlow Serving is installed, you can serve a TensorFlow model.</p>
</div><h2>Exporting a Model</h2>
<div class='content'><p>First, you need to export your trained model in a format that TensorFlow Serving can use.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKCiMgRGVmaW5lIGEgc2ltcGxlIG1vZGVsCm1vZGVsID0gdGYua2VyYXMuU2VxdWVudGlhbChbCiAgICB0Zi5rZXJhcy5sYXllcnMuRGVuc2UoMTAsIGFjdGl2YXRpb249J3JlbHUnLCBpbnB1dF9zaGFwZT0oNzg0LCkpLAogICAgdGYua2VyYXMubGF5ZXJzLkRlbnNlKDEwLCBhY3RpdmF0aW9uPSdzb2Z0bWF4JykKXSkKCiMgU2F2ZSB0aGUgbW9kZWwKbW9kZWwuc2F2ZSgnbXlfbW9kZWwvMScp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf

# Define a simple model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Save the model
model.save('my_model/1')</pre></div><div class='content'></div><h2>Starting the Model Server</h2>
<div class='content'><p>Use the following command to start the TensorFlow Model Server:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZG9ja2VyIHJ1biAtcCA4NTAxOjg1MDEgLS1uYW1lPXRmc2VydmluZ19teV9tb2RlbCAtLW1vdW50IHR5cGU9YmluZCxzb3VyY2U9JChwd2QpL215X21vZGVsLHRhcmdldD0vbW9kZWxzL215X21vZGVsIC1lIE1PREVMX05BTUU9bXlfbW9kZWwgLXQgdGVuc29yZmxvdy9zZXJ2aW5n"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>docker run -p 8501:8501 --name=tfserving_my_model --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving</pre></div><div class='content'></div><h2>Making Predictions</h2>
<div class='content'><p>You can make predictions by sending HTTP POST requests to the TensorFlow Serving API.</p>
<h4>Example Request</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHJlcXVlc3RzCmltcG9ydCBqc29uCgpkYXRhID0ganNvbi5kdW1wcyh7InNpZ25hdHVyZV9uYW1lIjogInNlcnZpbmdfZGVmYXVsdCIsICJpbnN0YW5jZXMiOiBbWzAuMF0qNzg0XX0pCmhlYWRlcnMgPSB7ImNvbnRlbnQtdHlwZSI6ICJhcHBsaWNhdGlvbi9qc29uIn0KanNvbl9yZXNwb25zZSA9IHJlcXVlc3RzLnBvc3QoJ2h0dHA6Ly9sb2NhbGhvc3Q6ODUwMS92MS9tb2RlbHMvbXlfbW9kZWw6cHJlZGljdCcsIGRhdGE9ZGF0YSwgaGVhZGVycz1oZWFkZXJzKQpwcmVkaWN0aW9ucyA9IGpzb24ubG9hZHMoanNvbl9yZXNwb25zZS50ZXh0KVsncHJlZGljdGlvbnMnXQpwcmludChwcmVkaWN0aW9ucyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import requests
import json

data = json.dumps({&quot;signature_name&quot;: &quot;serving_default&quot;, &quot;instances&quot;: [[0.0]*784]})
headers = {&quot;content-type&quot;: &quot;application/json&quot;}
json_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)
predictions = json.loads(json_response.text)['predictions']
print(predictions)</pre></div><div class='content'></div><h1>Advanced Features</h1>
<div class='content'><p>TensorFlow Serving offers several advanced features to optimize and manage your models.</p>
</div><h2>Model Versioning</h2>
<div class='content'><p>TensorFlow Serving supports serving multiple versions of a model simultaneously. This allows you to deploy new versions without downtime.</p>
<h4>Example Directory Structure</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("L21vZGVscwogICAgL215X21vZGVsCiAgICAgICAgLzEKICAgICAgICAvMg=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>/models
    /my_model
        /1
        /2</pre></div><div class='content'></div><h2>Batching</h2>
<div class='content'><p>Batching combines multiple requests into a single batch to improve throughput.</p>
<h4>Enabling Batching</h4>
<p>Create a <code>batching_parameters.txt</code> file:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bWF4X2JhdGNoX3NpemUgeyB2YWx1ZTogMzIgfQpiYXRjaF90aW1lb3V0X21pY3JvcyB7IHZhbHVlOiAxMDAwMCB9"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>max_batch_size { value: 32 }
batch_timeout_micros { value: 10000 }</pre></div><div class='content'><p>Start the server with batching enabled:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZG9ja2VyIHJ1biAtcCA4NTAxOjg1MDEgLS1uYW1lPXRmc2VydmluZ19teV9tb2RlbCAtLW1vdW50IHR5cGU9YmluZCxzb3VyY2U9JChwd2QpL215X21vZGVsLHRhcmdldD0vbW9kZWxzL215X21vZGVsIC1lIE1PREVMX05BTUU9bXlfbW9kZWwgLXQgdGVuc29yZmxvdy9zZXJ2aW5nIC0tZW5hYmxlX2JhdGNoaW5nPXRydWUgLS1iYXRjaGluZ19wYXJhbWV0ZXJzX2ZpbGU9L21vZGVscy9teV9tb2RlbC9iYXRjaGluZ19wYXJhbWV0ZXJzLnR4dA=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>docker run -p 8501:8501 --name=tfserving_my_model --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving --enable_batching=true --batching_parameters_file=/models/my_model/batching_parameters.txt</pre></div><div class='content'></div><h2>Monitoring</h2>
<div class='content'><p>TensorFlow Serving provides monitoring capabilities to track the performance and health of your models.</p>
<h4>Prometheus Integration</h4>
<p>TensorFlow Serving can export metrics in a format that Prometheus can scrape.</p>
<p>Start the server with monitoring enabled:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZG9ja2VyIHJ1biAtcCA4NTAxOjg1MDEgLXAgODUwMjo4NTAyIC0tbmFtZT10ZnNlcnZpbmdfbXlfbW9kZWwgLS1tb3VudCB0eXBlPWJpbmQsc291cmNlPSQocHdkKS9teV9tb2RlbCx0YXJnZXQ9L21vZGVscy9teV9tb2RlbCAtZSBNT0RFTF9OQU1FPW15X21vZGVsIC10IHRlbnNvcmZsb3cvc2VydmluZyAtLW1vbml0b3JpbmdfY29uZmlnX2ZpbGU9L21vZGVscy9teV9tb2RlbC9tb25pdG9yaW5nX2NvbmZpZy50eHQ="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>docker run -p 8501:8501 -p 8502:8502 --name=tfserving_my_model --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving --monitoring_config_file=/models/my_model/monitoring_config.txt</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>TensorFlow Serving is a powerful tool for deploying machine learning models in production. It supports model versioning, batching, and monitoring, making it suitable for high-performance and scalable machine learning applications. By following the steps outlined in this topic, you can set up TensorFlow Serving, deploy your models, and leverage its advanced features to optimize your machine learning workflows.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='distributed-training'>&#x25C4;Distributed Training</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">TensorFlow Serving</a>
	</div>
	<div class='col-4 text-end'>
					<a href='model-deployment'>Model Deployment &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
