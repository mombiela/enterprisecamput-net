<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Collection and Preparation</title>

    <link rel="alternate" href="https://campusempresa.com/apachespark/data-collection-and-preparation" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/apachespark/data-collection-and-preparation" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/apachespark/data-collection-and-preparation" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/apachespark/data-collection-and-preparation" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/apachespark/data-collection-and-preparation" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='project-overview-and-requirements'>&#x25C4;Project Overview and Requirements</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Data Collection and Preparation</a>
	</div>
	<div class='col-4 text-end'>
					<a href='implementation-and-development'>Implementation and Development &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Data collection and preparation are critical steps in any data processing pipeline. In Apache Spark, these steps involve gathering data from various sources, cleaning it, and transforming it into a format suitable for analysis. This section will guide you through the basics of data collection and preparation using Spark, progressing from beginner to advanced levels.</p>
</div><h1>Data Collection</h1>
<div class='content'></div><h2>Reading Data from Various Sources</h2>
<div class='content'><p>Apache Spark supports reading data from multiple sources, including local files, HDFS, S3, and various databases.</p>
<h4>Reading from Local Files</h4>
<p>To read data from a local file, you can use the <code>spark.read</code> method. Here's an example of reading a CSV file:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaXRpYWxpemUgU3Bhcmsgc2Vzc2lvbgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIkRhdGFDb2xsZWN0aW9uIikuZ2V0T3JDcmVhdGUoKQoKIyBSZWFkIENTViBmaWxlCmRmID0gc3BhcmsucmVhZC5jc3YoInBhdGgvdG8vbG9jYWxmaWxlLmNzdiIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQoKIyBTaG93IHRoZSBmaXJzdCBmZXcgcm93cwpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName(&quot;DataCollection&quot;).getOrCreate()

# Read CSV file
df = spark.read.csv(&quot;path/to/localfile.csv&quot;, header=True, inferSchema=True)

# Show the first few rows
df.show()</pre></div><div class='content'><h4>Reading from HDFS</h4>
<p>Reading from HDFS is similar to reading from local files, but you need to specify the HDFS path:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYgPSBzcGFyay5yZWFkLmNzdigiaGRmczovL25hbWVub2RlOjkwMDAvcGF0aC90by9oZGZzZmlsZS5jc3YiLCBoZWFkZXI9VHJ1ZSwgaW5mZXJTY2hlbWE9VHJ1ZSkKZGYuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df = spark.read.csv(&quot;hdfs://namenode:9000/path/to/hdfsfile.csv&quot;, header=True, inferSchema=True)
df.show()</pre></div><div class='content'><h4>Reading from S3</h4>
<p>To read from S3, you need to configure your Spark session with AWS credentials:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("c3BhcmsuX2pzYy5oYWRvb3BDb25maWd1cmF0aW9uKCkuc2V0KCJmcy5zM2EuYWNjZXNzLmtleSIsICJZT1VSX0FDQ0VTU19LRVkiKQpzcGFyay5fanNjLmhhZG9vcENvbmZpZ3VyYXRpb24oKS5zZXQoImZzLnMzYS5zZWNyZXQua2V5IiwgIllPVVJfU0VDUkVUX0tFWSIpCgpkZiA9IHNwYXJrLnJlYWQuY3N2KCJzM2E6Ly9idWNrZXRuYW1lL3BhdGgvdG8vczNmaWxlLmNzdiIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQpkZi5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>spark._jsc.hadoopConfiguration().set(&quot;fs.s3a.access.key&quot;, &quot;YOUR_ACCESS_KEY&quot;)
spark._jsc.hadoopConfiguration().set(&quot;fs.s3a.secret.key&quot;, &quot;YOUR_SECRET_KEY&quot;)

df = spark.read.csv(&quot;s3a://bucketname/path/to/s3file.csv&quot;, header=True, inferSchema=True)
df.show()</pre></div><div class='content'><h4>Reading from Databases</h4>
<p>Spark can also read data from relational databases using JDBC:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("amRiY191cmwgPSAiamRiYzpteXNxbDovL2hvc3RuYW1lOnBvcnQvZGJuYW1lIgpwcm9wZXJ0aWVzID0gewogICAgInVzZXIiOiAidXNlcm5hbWUiLAogICAgInBhc3N3b3JkIjogInBhc3N3b3JkIgp9CgpkZiA9IHNwYXJrLnJlYWQuamRiYyh1cmw9amRiY191cmwsIHRhYmxlPSJ0YWJsZW5hbWUiLCBwcm9wZXJ0aWVzPXByb3BlcnRpZXMpCmRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>jdbc_url = &quot;jdbc:mysql://hostname:port/dbname&quot;
properties = {
    &quot;user&quot;: &quot;username&quot;,
    &quot;password&quot;: &quot;password&quot;
}

df = spark.read.jdbc(url=jdbc_url, table=&quot;tablename&quot;, properties=properties)
df.show()</pre></div><div class='content'></div><h1>Data Cleaning</h1>
<div class='content'></div><h2>Handling Missing Values</h2>
<div class='content'><p>Missing values are common in real-world data. Spark provides several methods to handle them:</p>
<ul>
<li><strong>Dropping missing values:</strong></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfY2xlYW5lZCA9IGRmLm5hLmRyb3AoKQpkZl9jbGVhbmVkLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_cleaned = df.na.drop()
df_cleaned.show()</pre></div><div class='content'><ul>
<li><strong>Filling missing values:</strong></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfZmlsbGVkID0gZGYubmEuZmlsbCh7ImNvbHVtbjEiOiAwLCAiY29sdW1uMiI6ICJ1bmtub3duIn0pCmRmX2ZpbGxlZC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_filled = df.na.fill({&quot;column1&quot;: 0, &quot;column2&quot;: &quot;unknown&quot;})
df_filled.show()</pre></div><div class='content'></div><h2>Removing Duplicates</h2>
<div class='content'><p>Duplicates can skew your analysis. You can remove them using the <code>dropDuplicates</code> method:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfdW5pcXVlID0gZGYuZHJvcER1cGxpY2F0ZXMoKQpkZl91bmlxdWUuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_unique = df.dropDuplicates()
df_unique.show()</pre></div><div class='content'></div><h1>Data Transformation</h1>
<div class='content'></div><h2>Column Operations</h2>
<div class='content'><p>You can perform various operations on DataFrame columns, such as renaming, adding, and dropping columns.</p>
<ul>
<li><strong>Renaming columns:</strong></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfcmVuYW1lZCA9IGRmLndpdGhDb2x1bW5SZW5hbWVkKCJvbGROYW1lIiwgIm5ld05hbWUiKQpkZl9yZW5hbWVkLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_renamed = df.withColumnRenamed(&quot;oldName&quot;, &quot;newName&quot;)
df_renamed.show()</pre></div><div class='content'><ul>
<li><strong>Adding new columns:</strong></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGNvbAoKZGZfbmV3Y29sID0gZGYud2l0aENvbHVtbigibmV3Q29sdW1uIiwgY29sKCJleGlzdGluZ0NvbHVtbiIpICogMikKZGZfbmV3Y29sLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import col

df_newcol = df.withColumn(&quot;newColumn&quot;, col(&quot;existingColumn&quot;) * 2)
df_newcol.show()</pre></div><div class='content'><ul>
<li><strong>Dropping columns:</strong></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfZHJvcHBlZCA9IGRmLmRyb3AoImNvbHVtblRvRHJvcCIpCmRmX2Ryb3BwZWQuc2hvdygp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_dropped = df.drop(&quot;columnToDrop&quot;)
df_dropped.show()</pre></div><div class='content'></div><h2>Filtering Data</h2>
<div class='content'><p>Filtering allows you to select rows based on specific conditions:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfZmlsdGVyZWQgPSBkZi5maWx0ZXIoZGZbImNvbHVtbiJdID4gMTApCmRmX2ZpbHRlcmVkLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_filtered = df.filter(df[&quot;column&quot;] &gt; 10)
df_filtered.show()</pre></div><div class='content'></div><h2>Aggregations</h2>
<div class='content'><p>Aggregations are used to compute summary statistics:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGZfZ3JvdXBlZCA9IGRmLmdyb3VwQnkoImNvbHVtbiIpLmNvdW50KCkKZGZfZ3JvdXBlZC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df_grouped = df.groupBy(&quot;column&quot;).count()
df_grouped.show()</pre></div><div class='content'></div><h1>Advanced Data Preparation</h1>
<div class='content'></div><h2>User-Defined Functions (UDFs)</h2>
<div class='content'><p>UDFs allow you to apply custom transformations to DataFrame columns:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IHVkZgpmcm9tIHB5c3Bhcmsuc3FsLnR5cGVzIGltcG9ydCBJbnRlZ2VyVHlwZQoKZGVmIG11bHRpcGx5X2J5X3R3byh4KToKICAgIHJldHVybiB4ICogMgoKbXVsdGlwbHlfYnlfdHdvX3VkZiA9IHVkZihtdWx0aXBseV9ieV90d28sIEludGVnZXJUeXBlKCkpCgpkZl91ZGYgPSBkZi53aXRoQ29sdW1uKCJuZXdDb2x1bW4iLCBtdWx0aXBseV9ieV90d29fdWRmKGRmWyJleGlzdGluZ0NvbHVtbiJdKSkKZGZfdWRmLnNob3coKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import udf
from pyspark.sql.types import IntegerType

def multiply_by_two(x):
    return x * 2

multiply_by_two_udf = udf(multiply_by_two, IntegerType())

df_udf = df.withColumn(&quot;newColumn&quot;, multiply_by_two_udf(df[&quot;existingColumn&quot;]))
df_udf.show()</pre></div><div class='content'></div><h2>Working with Complex Data Types</h2>
<div class='content'><p>Spark supports complex data types like arrays and structs. You can manipulate these using built-in functions:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGV4cGxvZGUKCiMgRXhwbG9kZSBhbiBhcnJheSBjb2x1bW4KZGZfZXhwbG9kZWQgPSBkZi53aXRoQ29sdW1uKCJleHBsb2RlZENvbHVtbiIsIGV4cGxvZGUoZGZbImFycmF5Q29sdW1uIl0pKQpkZl9leHBsb2RlZC5zaG93KCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import explode

# Explode an array column
df_exploded = df.withColumn(&quot;explodedColumn&quot;, explode(df[&quot;arrayColumn&quot;]))
df_exploded.show()</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>Data collection and preparation are foundational steps in any data processing workflow. Apache Spark provides robust tools for reading data from various sources, cleaning it, and transforming it into a format suitable for analysis. By mastering these techniques, you can ensure that your data is ready for the next stages of your data pipeline, whether that involves machine learning, reporting, or further analysis.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='project-overview-and-requirements'>&#x25C4;Project Overview and Requirements</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Data Collection and Preparation</a>
	</div>
	<div class='col-4 text-end'>
					<a href='implementation-and-development'>Implementation and Development &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
