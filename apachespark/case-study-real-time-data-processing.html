<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case Study: Real-Time Data Processing</title>

    <link rel="alternate" href="https://campusempresa.com/apachespark/case-study-real-time-data-processing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/apachespark/case-study-real-time-data-processing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/apachespark/case-study-real-time-data-processing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/apachespark/case-study-real-time-data-processing" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/apachespark/case-study-real-time-data-processing" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='integrating-spark-with-other-big-data-tools'>&#x25C4;Integrating Spark with Other Big Data Tools</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Case Study: Real-Time Data Processing</a>
	</div>
	<div class='col-4 text-end'>
					<a href='case-study-machine-learning-pipeline'>Case Study: Machine Learning Pipeline &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction</h1>
<div class='content'><p>Real-time data processing is a critical requirement for many modern applications, such as financial trading systems, social media platforms, and IoT devices. Apache Spark, with its powerful streaming capabilities, is an ideal tool for handling real-time data. This case study will guide you through the process of setting up a real-time data processing pipeline using Apache Spark, from beginner to advanced levels.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Real-Time Data Processing</strong>: The continuous input, processing, and output of data in real-time.</li>
<li><strong>Apache Spark</strong>: An open-source unified analytics engine for large-scale data processing.</li>
<li><strong>Spark Streaming</strong>: An extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams.</li>
</ul>
</div><h1>Setting Up the Environment</h1>
<div class='content'><p>Before diving into the case study, ensure you have the following:</p>
<ul>
<li>Apache Spark installed.</li>
<li>A development environment (e.g., IntelliJ IDEA, PyCharm, or Jupyter Notebook).</li>
<li>Basic understanding of Spark and its components.</li>
</ul>
</div><h1>Beginner Level: Basic Streaming with Spark</h1>
<h2>Setting Up a Simple Stream</h2>
<div class='content'><p>We'll start by setting up a simple stream that reads data from a socket.</p>
<h4>Code Example: Simple Socket Stream</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5zdHJlYW1pbmcgaW1wb3J0IFN0cmVhbWluZ0NvbnRleHQKCiMgSW5pdGlhbGl6ZSBTcGFyayBTZXNzaW9uCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiU2ltcGxlU3RyZWFtIikuZ2V0T3JDcmVhdGUoKQoKIyBJbml0aWFsaXplIFN0cmVhbWluZyBDb250ZXh0IHdpdGggYSAxLXNlY29uZCBiYXRjaCBpbnRlcnZhbApzc2MgPSBTdHJlYW1pbmdDb250ZXh0KHNwYXJrLnNwYXJrQ29udGV4dCwgMSkKCiMgQ3JlYXRlIGEgRFN0cmVhbSB0aGF0IGNvbm5lY3RzIHRvIGxvY2FsaG9zdDo5OTk5CmxpbmVzID0gc3NjLnNvY2tldFRleHRTdHJlYW0oImxvY2FsaG9zdCIsIDk5OTkpCgojIFByaW50IGVhY2ggbGluZQpsaW5lcy5wcHJpbnQoKQoKIyBTdGFydCB0aGUgY29tcHV0YXRpb24Kc3NjLnN0YXJ0KCkKCiMgV2FpdCBmb3IgdGhlIGNvbXB1dGF0aW9uIHRvIHRlcm1pbmF0ZQpzc2MuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from pyspark.streaming import StreamingContext

# Initialize Spark Session
spark = SparkSession.builder.appName(&quot;SimpleStream&quot;).getOrCreate()

# Initialize Streaming Context with a 1-second batch interval
ssc = StreamingContext(spark.sparkContext, 1)

# Create a DStream that connects to localhost:9999
lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)

# Print each line
lines.pprint()

# Start the computation
ssc.start()

# Wait for the computation to terminate
ssc.awaitTermination()</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li><strong>SparkSession</strong>: Entry point to Spark functionality.</li>
<li><strong>StreamingContext</strong>: Main entry point for Spark Streaming functionality.</li>
<li><strong>socketTextStream</strong>: Connects to a socket to read data.</li>
</ul>
</div><h2>Running the Stream</h2>
<div class='content'><ol>
<li>Start a socket server on your machine:
<pre><code class="language-bash">nc -lk 9999
</code></pre>
</li>
<li>Run the Spark Streaming application.</li>
<li>Type messages into the terminal running the socket server and observe the output in your Spark application.</li>
</ol>
</div><h1>Intermediate Level: Transformations and Actions</h1>
<h2>Applying Transformations</h2>
<div class='content'><p>Transformations allow you to modify the data stream. Let's filter out lines containing a specific keyword.</p>
<h4>Code Example: Filtering Lines</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGaWx0ZXIgbGluZXMgY29udGFpbmluZyB0aGUgd29yZCAiZXJyb3IiCmVycm9yX2xpbmVzID0gbGluZXMuZmlsdGVyKGxhbWJkYSBsaW5lOiAiZXJyb3IiIGluIGxpbmUpCgojIFByaW50IGZpbHRlcmVkIGxpbmVzCmVycm9yX2xpbmVzLnBwcmludCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Filter lines containing the word &quot;error&quot;
error_lines = lines.filter(lambda line: &quot;error&quot; in line)

# Print filtered lines
error_lines.pprint()</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li><strong>filter</strong>: Transformation that filters the DStream based on a condition.</li>
</ul>
</div><h2>Performing Actions</h2>
<div class='content'><p>Actions trigger the execution of the transformations.</p>
<h4>Code Example: Counting Words</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTcGxpdCBlYWNoIGxpbmUgaW50byB3b3Jkcwp3b3JkcyA9IGxpbmVzLmZsYXRNYXAobGFtYmRhIGxpbmU6IGxpbmUuc3BsaXQoIiAiKSkKCiMgQ291bnQgZWFjaCB3b3JkIGluIGVhY2ggYmF0Y2gKcGFpcnMgPSB3b3Jkcy5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkKd29yZF9jb3VudHMgPSBwYWlycy5yZWR1Y2VCeUtleShsYW1iZGEgeCwgeTogeCArIHkpCgojIFByaW50IHRoZSB3b3JkIGNvdW50cwp3b3JkX2NvdW50cy5wcHJpbnQoKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Split each line into words
words = lines.flatMap(lambda line: line.split(&quot; &quot;))

# Count each word in each batch
pairs = words.map(lambda word: (word, 1))
word_counts = pairs.reduceByKey(lambda x, y: x + y)

# Print the word counts
word_counts.pprint()</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li><strong>flatMap</strong>: Transformation that splits each line into words.</li>
<li><strong>map</strong>: Transformation that maps each word to a (word, 1) pair.</li>
<li><strong>reduceByKey</strong>: Aggregates the counts of each word.</li>
</ul>
</div><h1>Advanced Level: Integrating with Kafka</h1>
<h2>Setting Up Kafka</h2>
<div class='content'><p>Kafka is a distributed streaming platform that can be used to build real-time data pipelines.</p>
<h4>Code Example: Kafka Integration</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnN0cmVhbWluZy5rYWZrYSBpbXBvcnQgS2Fma2FVdGlscwoKIyBDcmVhdGUgYSBEU3RyZWFtIHRoYXQgY29ubmVjdHMgdG8gS2Fma2EKa2Fma2Ffc3RyZWFtID0gS2Fma2FVdGlscy5jcmVhdGVTdHJlYW0oc3NjLCAibG9jYWxob3N0OjIxODEiLCAic3Bhcmstc3RyZWFtaW5nIiwgeyJ0ZXN0LXRvcGljIjogMX0pCgojIEV4dHJhY3QgdGhlIG1lc3NhZ2VzIGZyb20gS2Fma2EKbWVzc2FnZXMgPSBrYWZrYV9zdHJlYW0ubWFwKGxhbWJkYSBtc2c6IG1zZ1sxXSkKCiMgUHJpbnQgdGhlIG1lc3NhZ2VzCm1lc3NhZ2VzLnBwcmludCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.streaming.kafka import KafkaUtils

# Create a DStream that connects to Kafka
kafka_stream = KafkaUtils.createStream(ssc, &quot;localhost:2181&quot;, &quot;spark-streaming&quot;, {&quot;test-topic&quot;: 1})

# Extract the messages from Kafka
messages = kafka_stream.map(lambda msg: msg[1])

# Print the messages
messages.pprint()</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li><strong>KafkaUtils.createStream</strong>: Connects to a Kafka topic.</li>
<li><strong>map</strong>: Extracts the message part of the Kafka record.</li>
</ul>
</div><h2>Advanced Transformations</h2>
<div class='content'><p>Let's perform windowed operations to compute statistics over a sliding window of data.</p>
<h4>Code Example: Windowed Operations</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDb21wdXRlIHdvcmQgY291bnRzIG92ZXIgYSAxMC1zZWNvbmQgd2luZG93IHNsaWRpbmcgZXZlcnkgNSBzZWNvbmRzCndpbmRvd2VkX3dvcmRfY291bnRzID0gd29yZF9jb3VudHMucmVkdWNlQnlLZXlBbmRXaW5kb3cobGFtYmRhIHgsIHk6IHggKyB5LCAxMCwgNSkKCiMgUHJpbnQgdGhlIHdpbmRvd2VkIHdvcmQgY291bnRzCndpbmRvd2VkX3dvcmRfY291bnRzLnBwcmludCgp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Compute word counts over a 10-second window sliding every 5 seconds
windowed_word_counts = word_counts.reduceByKeyAndWindow(lambda x, y: x + y, 10, 5)

# Print the windowed word counts
windowed_word_counts.pprint()</pre></div><div class='content'><p><strong>Explanation</strong>:</p>
<ul>
<li><strong>reduceByKeyAndWindow</strong>: Aggregates data over a sliding window.</li>
</ul>
</div><h1>Conclusion</h1>
<div class='content'><p>In this case study, we explored the basics of real-time data processing using Apache Spark, starting from setting up a simple stream to integrating with Kafka and performing advanced transformations. Real-time data processing with Spark is a powerful tool that can handle large-scale data efficiently and effectively. By understanding these concepts and practicing with the provided examples, you can build robust real-time data processing pipelines for various applications.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='integrating-spark-with-other-big-data-tools'>&#x25C4;Integrating Spark with Other Big Data Tools</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Case Study: Real-Time Data Processing</a>
	</div>
	<div class='col-4 text-end'>
					<a href='case-study-machine-learning-pipeline'>Case Study: Machine Learning Pipeline &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
