<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Neural Networks</title>

    <link rel="alternate" href="https://campusempresa.com/pytorch/introduction-to-neural-networks" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/pytorch/introduction-to-neural-networks" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/pytorch/introduction-to-neural-networks" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/pytorch/introduction-to-neural-networks" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/pytorch/introduction-to-neural-networks" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='autograd-automatic-differentiation'>&#x25C4;Autograd: Automatic Differentiation</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Introduction to Neural Networks</a>
	</div>
	<div class='col-4 text-end'>
					<a href='creating-a-simple-neural-network'>Creating a Simple Neural Network &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Overview</h1>
<div class='content'><p>Neural networks are a fundamental concept in deep learning and are the backbone of many modern machine learning applications. This section will introduce you to the basics of neural networks and how to implement them using PyTorch.</p>
</div><h1>Key Concepts</h1>
<div class='content'><ul>
<li><strong>Neurons and Layers</strong>: The basic building blocks of neural networks.</li>
<li><strong>Activation Functions</strong>: Functions that introduce non-linearity into the network.</li>
<li><strong>Loss Functions</strong>: Metrics to evaluate the performance of the network.</li>
<li><strong>Optimization Algorithms</strong>: Methods to minimize the loss function.</li>
<li><strong>Forward and Backward Propagation</strong>: Mechanisms for training the network.</li>
</ul>
</div><h1>Neurons and Layers</h1>
<div class='content'><p>A neural network consists of layers of neurons. Each neuron receives input, processes it, and passes the output to the next layer.</p>
</div><h2>Example: Single Neuron</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIERlZmluZSBhIHNpbmdsZSBuZXVyb24gd2l0aCBhIHdlaWdodCBhbmQgYmlhcwp3ZWlnaHQgPSB0b3JjaC50ZW5zb3IoMC41LCByZXF1aXJlc19ncmFkPVRydWUpCmJpYXMgPSB0b3JjaC50ZW5zb3IoMC4xLCByZXF1aXJlc19ncmFkPVRydWUpCgojIElucHV0IHZhbHVlCnggPSB0b3JjaC50ZW5zb3IoMS4wKQoKIyBMaW5lYXIgdHJhbnNmb3JtYXRpb24KeSA9IHdlaWdodCAqIHggKyBiaWFzCgpwcmludCh5KSAgIyBPdXRwdXQ6IHRlbnNvcigwLjYwMDAsIGdyYWRfZm49PEFkZEJhY2t3YXJkMD4p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Define a single neuron with a weight and bias
weight = torch.tensor(0.5, requires_grad=True)
bias = torch.tensor(0.1, requires_grad=True)

# Input value
x = torch.tensor(1.0)

# Linear transformation
y = weight * x + bias

print(y)  # Output: tensor(0.6000, grad_fn=&lt;AddBackward0&gt;)</pre></div><div class='content'></div><h2>Example: Simple Neural Network</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uIGFzIG5uCgojIERlZmluZSBhIHNpbXBsZSBuZXVyYWwgbmV0d29yayB3aXRoIG9uZSBoaWRkZW4gbGF5ZXIKY2xhc3MgU2ltcGxlTk4obm4uTW9kdWxlKToKICAgIGRlZiBfX2luaXRfXyhzZWxmKToKICAgICAgICBzdXBlcihTaW1wbGVOTiwgc2VsZikuX19pbml0X18oKQogICAgICAgIHNlbGYuaGlkZGVuID0gbm4uTGluZWFyKDEsIDEwKSAgIyBIaWRkZW4gbGF5ZXIgd2l0aCAxMCBuZXVyb25zCiAgICAgICAgc2VsZi5vdXRwdXQgPSBubi5MaW5lYXIoMTAsIDEpICAjIE91dHB1dCBsYXllcgoKICAgIGRlZiBmb3J3YXJkKHNlbGYsIHgpOgogICAgICAgIHggPSB0b3JjaC5yZWx1KHNlbGYuaGlkZGVuKHgpKSAgIyBBcHBseSBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgICAgICB4ID0gc2VsZi5vdXRwdXQoeCkKICAgICAgICByZXR1cm4geAoKIyBJbnN0YW50aWF0ZSB0aGUgbmV0d29yawpuZXQgPSBTaW1wbGVOTigpCnByaW50KG5ldCk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn as nn

# Define a simple neural network with one hidden layer
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.hidden = nn.Linear(1, 10)  # Hidden layer with 10 neurons
        self.output = nn.Linear(10, 1)  # Output layer

    def forward(self, x):
        x = torch.relu(self.hidden(x))  # Apply ReLU activation function
        x = self.output(x)
        return x

# Instantiate the network
net = SimpleNN()
print(net)</pre></div><div class='content'></div><h1>Activation Functions</h1>
<div class='content'><p>Activation functions introduce non-linearity into the network, allowing it to learn complex patterns.</p>
</div><h2>Common Activation Functions</h2>
<div class='content'><ul>
<li><strong>ReLU (Rectified Linear Unit)</strong>: <code>torch.relu</code></li>
<li><strong>Sigmoid</strong>: <code>torch.sigmoid</code></li>
<li><strong>Tanh</strong>: <code>torch.tanh</code></li>
</ul>
</div><h2>Example: Applying Activation Functions</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIElucHV0IHRlbnNvcgp4ID0gdG9yY2gudGVuc29yKFstMS4wLCAwLjAsIDEuMF0pCgojIEFwcGx5IFJlTFUgYWN0aXZhdGlvbiBmdW5jdGlvbgpyZWx1X291dHB1dCA9IHRvcmNoLnJlbHUoeCkKcHJpbnQocmVsdV9vdXRwdXQpICAjIE91dHB1dDogdGVuc29yKFswLiwgMC4sIDEuXSkKCiMgQXBwbHkgU2lnbW9pZCBhY3RpdmF0aW9uIGZ1bmN0aW9uCnNpZ21vaWRfb3V0cHV0ID0gdG9yY2guc2lnbW9pZCh4KQpwcmludChzaWdtb2lkX291dHB1dCkgICMgT3V0cHV0OiB0ZW5zb3IoWzAuMjY4OSwgMC41MDAwLCAwLjczMTFdKQoKIyBBcHBseSBUYW5oIGFjdGl2YXRpb24gZnVuY3Rpb24KdGFuaF9vdXRwdXQgPSB0b3JjaC50YW5oKHgpCnByaW50KHRhbmhfb3V0cHV0KSAgIyBPdXRwdXQ6IHRlbnNvcihbLTAuNzYxNiwgIDAuMDAwMCwgIDAuNzYxNl0p"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Input tensor
x = torch.tensor([-1.0, 0.0, 1.0])

# Apply ReLU activation function
relu_output = torch.relu(x)
print(relu_output)  # Output: tensor([0., 0., 1.])

# Apply Sigmoid activation function
sigmoid_output = torch.sigmoid(x)
print(sigmoid_output)  # Output: tensor([0.2689, 0.5000, 0.7311])

# Apply Tanh activation function
tanh_output = torch.tanh(x)
print(tanh_output)  # Output: tensor([-0.7616,  0.0000,  0.7616])</pre></div><div class='content'></div><h1>Loss Functions</h1>
<div class='content'><p>Loss functions measure how well the neural network is performing. Common loss functions include Mean Squared Error (MSE) and Cross-Entropy Loss.</p>
</div><h2>Example: Mean Squared Error</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uLmZ1bmN0aW9uYWwgYXMgRgoKIyBQcmVkaWN0ZWQgYW5kIHRhcmdldCB2YWx1ZXMKcHJlZGljdGVkID0gdG9yY2gudGVuc29yKFswLjUsIDAuOCwgMC4zXSkKdGFyZ2V0ID0gdG9yY2gudGVuc29yKFsxLjAsIDAuMCwgMC4wXSkKCiMgQ2FsY3VsYXRlIE1lYW4gU3F1YXJlZCBFcnJvcgpsb3NzID0gRi5tc2VfbG9zcyhwcmVkaWN0ZWQsIHRhcmdldCkKcHJpbnQobG9zcykgICMgT3V0cHV0OiB0ZW5zb3IoMC4zOTMzKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn.functional as F

# Predicted and target values
predicted = torch.tensor([0.5, 0.8, 0.3])
target = torch.tensor([1.0, 0.0, 0.0])

# Calculate Mean Squared Error
loss = F.mse_loss(predicted, target)
print(loss)  # Output: tensor(0.3933)</pre></div><div class='content'></div><h1>Optimization Algorithms</h1>
<div class='content'><p>Optimization algorithms adjust the weights and biases to minimize the loss function. The most common optimization algorithm is Stochastic Gradient Descent (SGD).</p>
</div><h2>Example: Stochastic Gradient Descent</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgojIERlZmluZSBhIHNpbXBsZSBuZXVyYWwgbmV0d29yawpuZXQgPSBTaW1wbGVOTigpCgojIERlZmluZSB0aGUgb3B0aW1pemVyCm9wdGltaXplciA9IG9wdGltLlNHRChuZXQucGFyYW1ldGVycygpLCBscj0wLjAxKQoKIyBEdW1teSBpbnB1dCBhbmQgdGFyZ2V0CmlucHV0ID0gdG9yY2gudGVuc29yKFtbMS4wXV0pCnRhcmdldCA9IHRvcmNoLnRlbnNvcihbWzAuMF1dKQoKIyBGb3J3YXJkIHBhc3MKb3V0cHV0ID0gbmV0KGlucHV0KQpsb3NzID0gRi5tc2VfbG9zcyhvdXRwdXQsIHRhcmdldCkKCiMgQmFja3dhcmQgcGFzcyBhbmQgb3B0aW1pemF0aW9uCm9wdGltaXplci56ZXJvX2dyYWQoKSAgIyBaZXJvIHRoZSBncmFkaWVudHMKbG9zcy5iYWNrd2FyZCgpICAgICAgICAjIEJhY2t3YXJkIHBhc3MKb3B0aW1pemVyLnN0ZXAoKSAgICAgICAjIFVwZGF0ZSB0aGUgd2VpZ2h0cwoKcHJpbnQobG9zcykgICMgT3V0cHV0OiB0ZW5zb3IoMC4yNTAwLCBncmFkX2ZuPTxNc2VMb3NzQmFja3dhcmQ+KQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

# Define a simple neural network
net = SimpleNN()

# Define the optimizer
optimizer = optim.SGD(net.parameters(), lr=0.01)

# Dummy input and target
input = torch.tensor([[1.0]])
target = torch.tensor([[0.0]])

# Forward pass
output = net(input)
loss = F.mse_loss(output, target)

# Backward pass and optimization
optimizer.zero_grad()  # Zero the gradients
loss.backward()        # Backward pass
optimizer.step()       # Update the weights

print(loss)  # Output: tensor(0.2500, grad_fn=&lt;MseLossBackward&gt;)</pre></div><div class='content'></div><h1>Forward and Backward Propagation</h1>
<div class='content'><p>Forward propagation involves passing the input through the network to get the output. Backward propagation involves calculating the gradients and updating the weights.</p>
</div><h2>Example: Full Training Loop</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZWZpbmUgdGhlIG5ldHdvcmssIGxvc3MgZnVuY3Rpb24sIGFuZCBvcHRpbWl6ZXIKbmV0ID0gU2ltcGxlTk4oKQpjcml0ZXJpb24gPSBubi5NU0VMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uU0dEKG5ldC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEpCgojIER1bW15IGRhdGEKaW5wdXRzID0gdG9yY2gudGVuc29yKFtbMS4wXSwgWzIuMF0sIFszLjBdXSkKdGFyZ2V0cyA9IHRvcmNoLnRlbnNvcihbWzAuMF0sIFswLjBdLCBbMS4wXV0pCgojIFRyYWluaW5nIGxvb3AKZm9yIGVwb2NoIGluIHJhbmdlKDEwMCk6CiAgICBmb3IgaSBpbiByYW5nZShsZW4oaW5wdXRzKSk6CiAgICAgICAgaW5wdXQgPSBpbnB1dHNbaV0KICAgICAgICB0YXJnZXQgPSB0YXJnZXRzW2ldCgogICAgICAgICMgRm9yd2FyZCBwYXNzCiAgICAgICAgb3V0cHV0ID0gbmV0KGlucHV0KQogICAgICAgIGxvc3MgPSBjcml0ZXJpb24ob3V0cHV0LCB0YXJnZXQpCgogICAgICAgICMgQmFja3dhcmQgcGFzcyBhbmQgb3B0aW1pemF0aW9uCiAgICAgICAgb3B0aW1pemVyLnplcm9fZ3JhZCgpCiAgICAgICAgbG9zcy5iYWNrd2FyZCgpCiAgICAgICAgb3B0aW1pemVyLnN0ZXAoKQoKICAgIGlmIGVwb2NoICUgMTAgPT0gMDoKICAgICAgICBwcmludChmJ0Vwb2NoIHtlcG9jaH0sIExvc3M6IHtsb3NzLml0ZW0oKX0nKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Define the network, loss function, and optimizer
net = SimpleNN()
criterion = nn.MSELoss()
optimizer = optim.SGD(net.parameters(), lr=0.01)

# Dummy data
inputs = torch.tensor([[1.0], [2.0], [3.0]])
targets = torch.tensor([[0.0], [0.0], [1.0]])

# Training loop
for epoch in range(100):
    for i in range(len(inputs)):
        input = inputs[i]
        target = targets[i]

        # Forward pass
        output = net(input)
        loss = criterion(output, target)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    if epoch % 10 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item()}')</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this section, you learned the basics of neural networks, including neurons, layers, activation functions, loss functions, optimization algorithms, and the concepts of forward and backward propagation. With this foundation, you are now ready to build and train more complex neural networks using PyTorch.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='autograd-automatic-differentiation'>&#x25C4;Autograd: Automatic Differentiation</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Introduction to Neural Networks</a>
	</div>
	<div class='col-4 text-end'>
					<a href='creating-a-simple-neural-network'>Creating a Simple Neural Network &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
