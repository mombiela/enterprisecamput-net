<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Long Short-Term Memory Networks (LSTMs)</title>

    <link rel="alternate" href="https://campusempresa.com/pytorch/long-short-term-memory-networks-lstms" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/pytorch/long-short-term-memory-networks-lstms" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/pytorch/long-short-term-memory-networks-lstms" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/pytorch/long-short-term-memory-networks-lstms" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/pytorch/long-short-term-memory-networks-lstms" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='recurrent-neural-networks-rnns'>&#x25C4;Recurrent Neural Networks (RNNs)</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Long Short-Term Memory Networks (LSTMs)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='transformers'>Transformers &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to LSTMs</h1>
<div class='content'><p>Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) designed to handle the vanishing gradient problem, making them effective for learning long-term dependencies. They are widely used in tasks such as time series prediction, natural language processing, and speech recognition.</p>
</div><h2>Key Concepts</h2>
<div class='content'><ul>
<li><strong>Recurrent Neural Networks (RNNs):</strong> Networks with loops allowing information to persist.</li>
<li><strong>Vanishing Gradient Problem:</strong> Difficulty in training RNNs due to gradients becoming very small.</li>
<li><strong>LSTM Cell:</strong> A special unit in LSTMs designed to maintain long-term dependencies.</li>
</ul>
</div><h1>Understanding LSTM Architecture</h1>
<div class='content'><p>LSTMs have a unique structure that includes several gates to control the flow of information.</p>
</div><h2>Components of an LSTM Cell</h2>
<div class='content'><ul>
<li><strong>Forget Gate:</strong> Decides what information to discard from the cell state.</li>
<li><strong>Input Gate:</strong> Decides which values from the input to update the cell state.</li>
<li><strong>Cell State:</strong> The memory of the network.</li>
<li><strong>Output Gate:</strong> Decides what the next hidden state should be.</li>
</ul>
</div><h2>LSTM Cell Diagram</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("W0lucHV0XSAtLT4gW0ZvcmdldCBHYXRlXSAtLT4gW0NlbGwgU3RhdGVdIC0tPiBbT3V0cHV0IEdhdGVdIC0tPiBbSGlkZGVuIFN0YXRlXQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>[Input] --&gt; [Forget Gate] --&gt; [Cell State] --&gt; [Output Gate] --&gt; [Hidden State]</pre></div><div class='content'></div><h1>Implementing LSTMs in PyTorch</h1>
<div class='content'><p>Let's dive into implementing LSTMs using PyTorch.</p>
</div><h2>Step 1: Importing Libraries</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gub3B0aW0gYXMgb3B0aW0="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn
import torch.optim as optim</pre></div><div class='content'></div><h2>Step 2: Defining the LSTM Model</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgTFNUTU1vZGVsKG5uLk1vZHVsZSk6CiAgICBkZWYgX19pbml0X18oc2VsZiwgaW5wdXRfc2l6ZSwgaGlkZGVuX3NpemUsIG91dHB1dF9zaXplLCBudW1fbGF5ZXJzPTEpOgogICAgICAgIHN1cGVyKExTVE1Nb2RlbCwgc2VsZikuX19pbml0X18oKQogICAgICAgIHNlbGYuaGlkZGVuX3NpemUgPSBoaWRkZW5fc2l6ZQogICAgICAgIHNlbGYubnVtX2xheWVycyA9IG51bV9sYXllcnMKICAgICAgICBzZWxmLmxzdG0gPSBubi5MU1RNKGlucHV0X3NpemUsIGhpZGRlbl9zaXplLCBudW1fbGF5ZXJzLCBiYXRjaF9maXJzdD1UcnVlKQogICAgICAgIHNlbGYuZmMgPSBubi5MaW5lYXIoaGlkZGVuX3NpemUsIG91dHB1dF9zaXplKQogICAgCiAgICBkZWYgZm9yd2FyZChzZWxmLCB4KToKICAgICAgICBoMCA9IHRvcmNoLnplcm9zKHNlbGYubnVtX2xheWVycywgeC5zaXplKDApLCBzZWxmLmhpZGRlbl9zaXplKS50byh4LmRldmljZSkKICAgICAgICBjMCA9IHRvcmNoLnplcm9zKHNlbGYubnVtX2xheWVycywgeC5zaXplKDApLCBzZWxmLmhpZGRlbl9zaXplKS50byh4LmRldmljZSkKICAgICAgICAKICAgICAgICBvdXQsIF8gPSBzZWxmLmxzdG0oeCwgKGgwLCBjMCkpCiAgICAgICAgb3V0ID0gc2VsZi5mYyhvdXRbOiwgLTEsIDpdKQogICAgICAgIHJldHVybiBvdXQ="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out</pre></div><div class='content'></div><h2>Step 3: Training the LSTM Model</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBIeXBlcnBhcmFtZXRlcnMKaW5wdXRfc2l6ZSA9IDEwCmhpZGRlbl9zaXplID0gNTAKb3V0cHV0X3NpemUgPSAxCm51bV9sYXllcnMgPSAyCm51bV9lcG9jaHMgPSAxMDAKbGVhcm5pbmdfcmF0ZSA9IDAuMDAxCgojIE1vZGVsLCBMb3NzLCBPcHRpbWl6ZXIKbW9kZWwgPSBMU1RNTW9kZWwoaW5wdXRfc2l6ZSwgaGlkZGVuX3NpemUsIG91dHB1dF9zaXplLCBudW1fbGF5ZXJzKQpjcml0ZXJpb24gPSBubi5NU0VMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uQWRhbShtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPWxlYXJuaW5nX3JhdGUpCgojIER1bW15IERhdGEKeF90cmFpbiA9IHRvcmNoLnJhbmRuKDEwMCwgMTAsIGlucHV0X3NpemUpCnlfdHJhaW4gPSB0b3JjaC5yYW5kbigxMDAsIG91dHB1dF9zaXplKQoKIyBUcmFpbmluZyBMb29wCmZvciBlcG9jaCBpbiByYW5nZShudW1fZXBvY2hzKToKICAgIG1vZGVsLnRyYWluKCkKICAgIG91dHB1dHMgPSBtb2RlbCh4X3RyYWluKQogICAgb3B0aW1pemVyLnplcm9fZ3JhZCgpCiAgICBsb3NzID0gY3JpdGVyaW9uKG91dHB1dHMsIHlfdHJhaW4pCiAgICBsb3NzLmJhY2t3YXJkKCkKICAgIG9wdGltaXplci5zdGVwKCkKICAgIAogICAgaWYgKGVwb2NoKzEpICUgMTAgPT0gMDoKICAgICAgICBwcmludChmJ0Vwb2NoIFt7ZXBvY2grMX0ve251bV9lcG9jaHN9XSwgTG9zczoge2xvc3MuaXRlbSgpOi40Zn0nKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Hyperparameters
input_size = 10
hidden_size = 50
output_size = 1
num_layers = 2
num_epochs = 100
learning_rate = 0.001

# Model, Loss, Optimizer
model = LSTMModel(input_size, hidden_size, output_size, num_layers)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Dummy Data
x_train = torch.randn(100, 10, input_size)
y_train = torch.randn(100, output_size)

# Training Loop
for epoch in range(num_epochs):
    model.train()
    outputs = model(x_train)
    optimizer.zero_grad()
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h1>Advanced LSTM Techniques</h1>
<h2>Bidirectional LSTMs</h2>
<div class='content'><p>Bidirectional LSTMs process data in both forward and backward directions, providing additional context.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgQmlMU1RNTW9kZWwobm4uTW9kdWxlKToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCBpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgb3V0cHV0X3NpemUsIG51bV9sYXllcnM9MSk6CiAgICAgICAgc3VwZXIoQmlMU1RNTW9kZWwsIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmhpZGRlbl9zaXplID0gaGlkZGVuX3NpemUKICAgICAgICBzZWxmLm51bV9sYXllcnMgPSBudW1fbGF5ZXJzCiAgICAgICAgc2VsZi5sc3RtID0gbm4uTFNUTShpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgbnVtX2xheWVycywgYmF0Y2hfZmlyc3Q9VHJ1ZSwgYmlkaXJlY3Rpb25hbD1UcnVlKQogICAgICAgIHNlbGYuZmMgPSBubi5MaW5lYXIoaGlkZGVuX3NpemUqMiwgb3V0cHV0X3NpemUpCiAgICAKICAgIGRlZiBmb3J3YXJkKHNlbGYsIHgpOgogICAgICAgIGgwID0gdG9yY2guemVyb3Moc2VsZi5udW1fbGF5ZXJzKjIsIHguc2l6ZSgwKSwgc2VsZi5oaWRkZW5fc2l6ZSkudG8oeC5kZXZpY2UpCiAgICAgICAgYzAgPSB0b3JjaC56ZXJvcyhzZWxmLm51bV9sYXllcnMqMiwgeC5zaXplKDApLCBzZWxmLmhpZGRlbl9zaXplKS50byh4LmRldmljZSkKICAgICAgICAKICAgICAgICBvdXQsIF8gPSBzZWxmLmxzdG0oeCwgKGgwLCBjMCkpCiAgICAgICAgb3V0ID0gc2VsZi5mYyhvdXRbOiwgLTEsIDpdKQogICAgICAgIHJldHVybiBvdXQ="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class BiLSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(BiLSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_size*2, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)
        
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out</pre></div><div class='content'></div><h2>LSTM with Dropout</h2>
<div class='content'><p>Adding dropout to LSTM layers helps prevent overfitting.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgTFNUTVdpdGhEcm9wb3V0KG5uLk1vZHVsZSk6CiAgICBkZWYgX19pbml0X18oc2VsZiwgaW5wdXRfc2l6ZSwgaGlkZGVuX3NpemUsIG91dHB1dF9zaXplLCBudW1fbGF5ZXJzPTEsIGRyb3BvdXQ9MC41KToKICAgICAgICBzdXBlcihMU1RNV2l0aERyb3BvdXQsIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmhpZGRlbl9zaXplID0gaGlkZGVuX3NpemUKICAgICAgICBzZWxmLm51bV9sYXllcnMgPSBudW1fbGF5ZXJzCiAgICAgICAgc2VsZi5sc3RtID0gbm4uTFNUTShpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgbnVtX2xheWVycywgYmF0Y2hfZmlyc3Q9VHJ1ZSwgZHJvcG91dD1kcm9wb3V0KQogICAgICAgIHNlbGYuZmMgPSBubi5MaW5lYXIoaGlkZGVuX3NpemUsIG91dHB1dF9zaXplKQogICAgCiAgICBkZWYgZm9yd2FyZChzZWxmLCB4KToKICAgICAgICBoMCA9IHRvcmNoLnplcm9zKHNlbGYubnVtX2xheWVycywgeC5zaXplKDApLCBzZWxmLmhpZGRlbl9zaXplKS50byh4LmRldmljZSkKICAgICAgICBjMCA9IHRvcmNoLnplcm9zKHNlbGYubnVtX2xheWVycywgeC5zaXplKDApLCBzZWxmLmhpZGRlbl9zaXplKS50byh4LmRldmljZSkKICAgICAgICAKICAgICAgICBvdXQsIF8gPSBzZWxmLmxzdG0oeCwgKGgwLCBjMCkpCiAgICAgICAgb3V0ID0gc2VsZi5mYyhvdXRbOiwgLTEsIDpdKQogICAgICAgIHJldHVybiBvdXQ="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class LSTMWithDropout(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.5):
        super(LSTMWithDropout, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>LSTMs are powerful tools for sequence prediction tasks, overcoming the limitations of traditional RNNs. By understanding their architecture and learning to implement them in PyTorch, you can leverage their capabilities for various applications. Advanced techniques like bidirectional LSTMs and dropout can further enhance model performance and robustness.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='recurrent-neural-networks-rnns'>&#x25C4;Recurrent Neural Networks (RNNs)</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Long Short-Term Memory Networks (LSTMs)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='transformers'>Transformers &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Accept</a>
    <a href="/cookies">More Information</a>
</div>	

	</div>    
</body>
</html>
