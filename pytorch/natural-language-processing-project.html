<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Natural Language Processing Project</title>

    <link rel="alternate" href="https://campusempresa.com/pytorch/natural-language-processing-project" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/pytorch/natural-language-processing-project" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/pytorch/natural-language-processing-project" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Building today's and tomorrow's society</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
													<b id="lit_lang_es" class="px-2">EN</b>
				|
				<a href="https://campusempresa.com/pytorch/natural-language-processing-project" class="px-2">ES</a></b>
				|
				<a href="https://campusempresa.cat/pytorch/natural-language-processing-project" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">The Project</a>
				<a href="/about">About Us</a>
				<a href="/contribute">Contribute</a>
				<a href="/donate">Donations</a>
				<a href="/licence">License</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='image-classification-project'>&#x25C4;Image Classification Project</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Natural Language Processing Project</a>
	</div>
	<div class='col-4 text-end'>
					<a href='time-series-forecasting-project'>Time Series Forecasting Project &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introduction to Natural Language Processing (NLP)</h1>
<div class='content'><p>Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The goal is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.</p>
</div><h2>Key Concepts in NLP</h2>
<div class='content'><ul>
<li><strong>Tokenization</strong>: Splitting text into individual words or phrases.</li>
<li><strong>Stop Words</strong>: Common words that are usually filtered out before processing.</li>
<li><strong>Stemming and Lemmatization</strong>: Reducing words to their base or root form.</li>
<li><strong>Bag of Words</strong>: Representing text data as a collection of word frequencies.</li>
<li><strong>TF-IDF</strong>: Term Frequency-Inverse Document Frequency, a statistical measure used to evaluate the importance of a word in a document.</li>
<li><strong>Word Embeddings</strong>: Representing words in a continuous vector space where semantically similar words are closer together.</li>
</ul>
</div><h1>Setting Up the Environment</h1>
<div class='content'><p>Before diving into the project, ensure you have the necessary libraries installed. We'll be using PyTorch for building and training our models.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cGlwIGluc3RhbGwgdG9yY2ggdG9yY2h2aXNpb24gdG9yY2hhdWRpbwpwaXAgaW5zdGFsbCBubHRrCnBpcCBpbnN0YWxsIHNrbGVhcm4="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>pip install torch torchvision torchaudio
pip install nltk
pip install sklearn</pre></div><div class='content'></div><h1>Data Preprocessing</h1>
<h2>Tokenization and Stop Words Removal</h2>
<div class='content'><p>Tokenization is the process of breaking down text into individual words or tokens. Stop words are common words that are usually removed to focus on the more meaningful words.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG5sdGsKZnJvbSBubHRrLnRva2VuaXplIGltcG9ydCB3b3JkX3Rva2VuaXplCmZyb20gbmx0ay5jb3JwdXMgaW1wb3J0IHN0b3B3b3JkcwoKbmx0ay5kb3dubG9hZCgncHVua3QnKQpubHRrLmRvd25sb2FkKCdzdG9wd29yZHMnKQoKdGV4dCA9ICJOYXR1cmFsIExhbmd1YWdlIFByb2Nlc3Npbmcgd2l0aCBQeVRvcmNoIGlzIGZ1biBhbmQgZWR1Y2F0aW9uYWwuIgp0b2tlbnMgPSB3b3JkX3Rva2VuaXplKHRleHQpCnN0b3Bfd29yZHMgPSBzZXQoc3RvcHdvcmRzLndvcmRzKCdlbmdsaXNoJykpCmZpbHRlcmVkX3Rva2VucyA9IFt3b3JkIGZvciB3b3JkIGluIHRva2VucyBpZiB3b3JkLmxvd2VyKCkgbm90IGluIHN0b3Bfd29yZHNdCgpwcmludChmaWx0ZXJlZF90b2tlbnMp"))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

nltk.download('punkt')
nltk.download('stopwords')

text = &quot;Natural Language Processing with PyTorch is fun and educational.&quot;
tokens = word_tokenize(text)
stop_words = set(stopwords.words('english'))
filtered_tokens = [word for word in tokens if word.lower() not in stop_words]

print(filtered_tokens)</pre></div><div class='content'></div><h2>Stemming and Lemmatization</h2>
<div class='content'><p>Stemming and lemmatization are techniques used to reduce words to their base or root form.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBubHRrLnN0ZW0gaW1wb3J0IFBvcnRlclN0ZW1tZXIsIFdvcmROZXRMZW1tYXRpemVyCgpubHRrLmRvd25sb2FkKCd3b3JkbmV0JykKCnN0ZW1tZXIgPSBQb3J0ZXJTdGVtbWVyKCkKbGVtbWF0aXplciA9IFdvcmROZXRMZW1tYXRpemVyKCkKCnN0ZW1tZWRfd29yZHMgPSBbc3RlbW1lci5zdGVtKHdvcmQpIGZvciB3b3JkIGluIGZpbHRlcmVkX3Rva2Vuc10KbGVtbWF0aXplZF93b3JkcyA9IFtsZW1tYXRpemVyLmxlbW1hdGl6ZSh3b3JkKSBmb3Igd29yZCBpbiBmaWx0ZXJlZF90b2tlbnNdCgpwcmludCgiU3RlbW1lZCBXb3JkczoiLCBzdGVtbWVkX3dvcmRzKQpwcmludCgiTGVtbWF0aXplZCBXb3JkczoiLCBsZW1tYXRpemVkX3dvcmRzKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from nltk.stem import PorterStemmer, WordNetLemmatizer

nltk.download('wordnet')

stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

stemmed_words = [stemmer.stem(word) for word in filtered_tokens]
lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]

print(&quot;Stemmed Words:&quot;, stemmed_words)
print(&quot;Lemmatized Words:&quot;, lemmatized_words)</pre></div><div class='content'></div><h1>Feature Extraction</h1>
<h2>Bag of Words</h2>
<div class='content'><p>The Bag of Words model represents text data as a collection of word frequencies.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmZlYXR1cmVfZXh0cmFjdGlvbi50ZXh0IGltcG9ydCBDb3VudFZlY3Rvcml6ZXIKCmNvcnB1cyA9IFsKICAgICdOYXR1cmFsIExhbmd1YWdlIFByb2Nlc3Npbmcgd2l0aCBQeVRvcmNoIGlzIGZ1biBhbmQgZWR1Y2F0aW9uYWwuJywKICAgICdQeVRvcmNoIG1ha2VzIGJ1aWxkaW5nIG5ldXJhbCBuZXR3b3JrcyBlYXN5LicsCiAgICAnTkxQIGlzIGEgZmFzY2luYXRpbmcgZmllbGQgb2Ygc3R1ZHkuJwpdCgp2ZWN0b3JpemVyID0gQ291bnRWZWN0b3JpemVyKCkKWCA9IHZlY3Rvcml6ZXIuZml0X3RyYW5zZm9ybShjb3JwdXMpCgpwcmludCh2ZWN0b3JpemVyLmdldF9mZWF0dXJlX25hbWVzX291dCgpKQpwcmludChYLnRvYXJyYXkoKSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.feature_extraction.text import CountVectorizer

corpus = [
    'Natural Language Processing with PyTorch is fun and educational.',
    'PyTorch makes building neural networks easy.',
    'NLP is a fascinating field of study.'
]

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)

print(vectorizer.get_feature_names_out())
print(X.toarray())</pre></div><div class='content'></div><h2>TF-IDF</h2>
<div class='content'><p>TF-IDF is a statistical measure used to evaluate the importance of a word in a document.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmZlYXR1cmVfZXh0cmFjdGlvbi50ZXh0IGltcG9ydCBUZmlkZlZlY3Rvcml6ZXIKCnRmaWRmX3ZlY3Rvcml6ZXIgPSBUZmlkZlZlY3Rvcml6ZXIoKQpYX3RmaWRmID0gdGZpZGZfdmVjdG9yaXplci5maXRfdHJhbnNmb3JtKGNvcnB1cykKCnByaW50KHRmaWRmX3ZlY3Rvcml6ZXIuZ2V0X2ZlYXR1cmVfbmFtZXNfb3V0KCkpCnByaW50KFhfdGZpZGYudG9hcnJheSgpKQ=="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(corpus)

print(tfidf_vectorizer.get_feature_names_out())
print(X_tfidf.toarray())</pre></div><div class='content'></div><h1>Building an NLP Model with PyTorch</h1>
<h2>Preparing the Dataset</h2>
<div class='content'><p>For this project, we'll use a simple dataset for text classification.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmZyb20gdG9yY2gudXRpbHMuZGF0YSBpbXBvcnQgRGF0YXNldCwgRGF0YUxvYWRlcgoKY2xhc3MgVGV4dERhdGFzZXQoRGF0YXNldCk6CiAgICBkZWYgX19pbml0X18oc2VsZiwgdGV4dHMsIGxhYmVscywgdmVjdG9yaXplcik6CiAgICAgICAgc2VsZi50ZXh0cyA9IHRleHRzCiAgICAgICAgc2VsZi5sYWJlbHMgPSBsYWJlbHMKICAgICAgICBzZWxmLnZlY3Rvcml6ZXIgPSB2ZWN0b3JpemVyCiAgICAgICAgc2VsZi52ZWN0b3JpemVkX3RleHRzID0gc2VsZi52ZWN0b3JpemVyLmZpdF90cmFuc2Zvcm0oc2VsZi50ZXh0cykudG9hcnJheSgpCiAgICAgICAgCiAgICBkZWYgX19sZW5fXyhzZWxmKToKICAgICAgICByZXR1cm4gbGVuKHNlbGYudGV4dHMpCiAgICAKICAgIGRlZiBfX2dldGl0ZW1fXyhzZWxmLCBpZHgpOgogICAgICAgIHRleHRfdmVjdG9yID0gdG9yY2gudGVuc29yKHNlbGYudmVjdG9yaXplZF90ZXh0c1tpZHhdLCBkdHlwZT10b3JjaC5mbG9hdDMyKQogICAgICAgIGxhYmVsID0gdG9yY2gudGVuc29yKHNlbGYubGFiZWxzW2lkeF0sIGR0eXBlPXRvcmNoLmxvbmcpCiAgICAgICAgcmV0dXJuIHRleHRfdmVjdG9yLCBsYWJlbAoKdGV4dHMgPSBbCiAgICAnTmF0dXJhbCBMYW5ndWFnZSBQcm9jZXNzaW5nIHdpdGggUHlUb3JjaCBpcyBmdW4gYW5kIGVkdWNhdGlvbmFsLicsCiAgICAnUHlUb3JjaCBtYWtlcyBidWlsZGluZyBuZXVyYWwgbmV0d29ya3MgZWFzeS4nLAogICAgJ05MUCBpcyBhIGZhc2NpbmF0aW5nIGZpZWxkIG9mIHN0dWR5LicKXQpsYWJlbHMgPSBbMCwgMSwgMF0gICMgRXhhbXBsZSBsYWJlbHMKCmRhdGFzZXQgPSBUZXh0RGF0YXNldCh0ZXh0cywgbGFiZWxzLCB2ZWN0b3JpemVyKQpkYXRhbG9hZGVyID0gRGF0YUxvYWRlcihkYXRhc2V0LCBiYXRjaF9zaXplPTIsIHNodWZmbGU9VHJ1ZSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
from torch.utils.data import Dataset, DataLoader

class TextDataset(Dataset):
    def __init__(self, texts, labels, vectorizer):
        self.texts = texts
        self.labels = labels
        self.vectorizer = vectorizer
        self.vectorized_texts = self.vectorizer.fit_transform(self.texts).toarray()
        
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text_vector = torch.tensor(self.vectorized_texts[idx], dtype=torch.float32)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return text_vector, label

texts = [
    'Natural Language Processing with PyTorch is fun and educational.',
    'PyTorch makes building neural networks easy.',
    'NLP is a fascinating field of study.'
]
labels = [0, 1, 0]  # Example labels

dataset = TextDataset(texts, labels, vectorizer)
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)</pre></div><div class='content'></div><h2>Defining the Model</h2>
<div class='content'><p>We'll define a simple feedforward neural network for text classification.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uIGFzIG5uCgpjbGFzcyBUZXh0Q2xhc3NpZmllcihubi5Nb2R1bGUpOgogICAgZGVmIF9faW5pdF9fKHNlbGYsIGlucHV0X2RpbSwgaGlkZGVuX2RpbSwgb3V0cHV0X2RpbSk6CiAgICAgICAgc3VwZXIoVGV4dENsYXNzaWZpZXIsIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmZjMSA9IG5uLkxpbmVhcihpbnB1dF9kaW0sIGhpZGRlbl9kaW0pCiAgICAgICAgc2VsZi5yZWx1ID0gbm4uUmVMVSgpCiAgICAgICAgc2VsZi5mYzIgPSBubi5MaW5lYXIoaGlkZGVuX2RpbSwgb3V0cHV0X2RpbSkKICAgIAogICAgZGVmIGZvcndhcmQoc2VsZiwgeCk6CiAgICAgICAgb3V0ID0gc2VsZi5mYzEoeCkKICAgICAgICBvdXQgPSBzZWxmLnJlbHUob3V0KQogICAgICAgIG91dCA9IHNlbGYuZmMyKG91dCkKICAgICAgICByZXR1cm4gb3V0CgppbnB1dF9kaW0gPSBsZW4odmVjdG9yaXplci5nZXRfZmVhdHVyZV9uYW1lc19vdXQoKSkKaGlkZGVuX2RpbSA9IDEwCm91dHB1dF9kaW0gPSAyICAjIE51bWJlciBvZiBjbGFzc2VzCgptb2RlbCA9IFRleHRDbGFzc2lmaWVyKGlucHV0X2RpbSwgaGlkZGVuX2RpbSwgb3V0cHV0X2RpbSk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn as nn

class TextClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TextClassifier, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

input_dim = len(vectorizer.get_feature_names_out())
hidden_dim = 10
output_dim = 2  # Number of classes

model = TextClassifier(input_dim, hidden_dim, output_dim)</pre></div><div class='content'></div><h2>Training the Model</h2>
<div class='content'><p>We'll train the model using a simple training loop.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgpjcml0ZXJpb24gPSBubi5Dcm9zc0VudHJvcHlMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uQWRhbShtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDAxKQoKbnVtX2Vwb2NocyA9IDUKCmZvciBlcG9jaCBpbiByYW5nZShudW1fZXBvY2hzKToKICAgIGZvciB0ZXh0cywgbGFiZWxzIGluIGRhdGFsb2FkZXI6CiAgICAgICAgb3V0cHV0cyA9IG1vZGVsKHRleHRzKQogICAgICAgIGxvc3MgPSBjcml0ZXJpb24ob3V0cHV0cywgbGFiZWxzKQogICAgICAgIAogICAgICAgIG9wdGltaXplci56ZXJvX2dyYWQoKQogICAgICAgIGxvc3MuYmFja3dhcmQoKQogICAgICAgIG9wdGltaXplci5zdGVwKCkKICAgIAogICAgcHJpbnQoZidFcG9jaCBbe2Vwb2NoKzF9L3tudW1fZXBvY2hzfV0sIExvc3M6IHtsb3NzLml0ZW0oKTouNGZ9Jyk="))));alert("Copied!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5

for epoch in range(num_epochs):
    for texts, labels in dataloader:
        outputs = model(texts)
        loss = criterion(outputs, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h1>Conclusion</h1>
<div class='content'><p>In this topic, we covered the basics of Natural Language Processing and how to implement an NLP project using PyTorch. We started with data preprocessing techniques such as tokenization, stop words removal, stemming, and lemmatization. We then moved on to feature extraction using Bag of Words and TF-IDF. Finally, we built and trained a simple text classification model using PyTorch.</p>
<p>By following these steps, you should now have a foundational understanding of how to approach NLP projects and implement them using PyTorch. Continue exploring more advanced techniques and models to further enhance your NLP skills.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='image-classification-project'>&#x25C4;Image Classification Project</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Natural Language Processing Project</a>
	</div>
	<div class='col-4 text-end'>
					<a href='time-series-forecasting-project'>Time Series Forecasting Project &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Advertising</h1>
			<p>This space is reserved for advertising.</p>
			<p>If you want to be a sponsor, contact us to include links in this area: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Thank you for collaborating!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. All rights reserved</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
